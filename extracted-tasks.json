[
  {
    "name": "cache",
    "tasks": [
      {
        "package": "cache",
        "slug": "go-cache-set",
        "title": "Set сохраняет значение и время истечения now+ttl.",
        "description": "Level 2 (easy+): Set сохраняет значение и время истечения now+ttl.\nHint: вычислите expires := time.Now().Add(c.ttl).",
        "difficulty": "easy",
        "hint1": "вычислите expires := time.Now().Add(c.ttl).",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\n// Level 1 (easy): реализуйте TTLCache на mutex + map.\n// Hint: храните ttl и защищайте доступ через RWMutex.\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\tif ttl <= 0 {\n\t\tttl = time.Millisecond\n\t}\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\n// Level 2 (easy+): Set сохраняет значение и время истечения now+ttl.\n// Hint: вычислите expires := time.Now().Add(c.ttl).\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.m[key] = entry{v: v, exp: time.Now().Add(c.ttl)}\n}\n\n// Level 3 (medium): Get возвращает значение только если оно ещё не истекло.\n// Hint: протухшие записи нужно удалять и возвращать (nil, false).\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil {\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()\n\te, ok := c.m[key]\n\tc.mu.RUnlock()\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tif time.Now().After(e.exp) {\n\t\tc.mu.Lock()\n\t\tdefer c.mu.Unlock()\n\t\tif entry, ok := c.m[key]; ok && entry.exp.Equal(e.exp) {\n\t\t\tdelete(c.m, key)\n\t\t}\n\t\treturn nil, false\n\t}\n\treturn e.v, true\n}\n\n// Level 4 (medium+): cleanupNow удаляет все записи, чьё exp <= now.\n// Hint: вызывайте под блокировкой, чтобы тесты могли проверять внутреннее состояние.\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tfor k, e := range c.m {\n\t\tif now.After(e.exp) {\n\t\t\tdelete(c.m, k)\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): Delete убирает ключ из кеша и сообщает, был ли он найден.\n// Hint: верните true, если запись существовала, даже если уже истекла.\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil {\n\t\treturn false\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif _, ok := c.m[key]; ok {\n\t\tdelete(c.m, key)\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Level 6 (medium+): Len возвращает количество неистёкших записей на момент вызова.\n// Hint: очистите просроченные элементы перед подсчётом.\nfunc (c *TTLCache) Len() int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.cleanupNow(time.Now())\n\treturn len(c.m)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil { // nil cache acts as a no-op for callers\n\t\treturn\n\t}\n\tc.mu.Lock()           // exclusive lock protects the underlying map\n\tdefer c.mu.Unlock()   // ensure lock release even on panic\n\texpire := time.Time{} // zero expiration means no TTL enforcement\n\tif c.ttl > 0 {        // only compute expiration when ttl is positive\n\t\texpire = time.Now().Add(c.ttl) // schedule the absolute expiration moment\n\t}\n\tc.m[key] = entry{v: v, exp: expire} // store the payload together with expiry timestamp\n}\n\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil { // nil cache never stores values\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()        // take read lock for optimistic lookup\n\tent, ok := c.m[key] // fetch entry if it exists\n\tc.mu.RUnlock()      // release read lock before potential writes\n\tif !ok {            // absent key yields miss immediately\n\t\treturn nil, false\n\t}\n\tif !ent.exp.IsZero() && time.Now().After(ent.exp) { // expire stale entry regardless of ttl setting\n\t\tc.mu.Lock()                                                    // upgrade to write lock to delete entry\n\t\tdefer c.mu.Unlock()                                            // ensure lock release after cleanup\n\t\tif entCur, still := c.m[key]; still && entCur.exp == ent.exp { // confirm the same entry is present\n\t\t\tdelete(c.m, key) // remove expired record from storage\n\t\t}\n\t\treturn nil, false // report miss for expired value\n\t}\n\treturn ent.v, true // return cached value while it is still valid\n}\n\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil { // nothing to clean when cache is nil\n\t\treturn\n\t}\n\tc.mu.Lock()               // ensure exclusive access during cleanup\n\tdefer c.mu.Unlock()       // release lock after iteration\n\tfor k, ent := range c.m { // iterate over all entries to check expiry\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries meet the removal criteria\n\t\t\tdelete(c.m, k) // drop stale entry from map\n\t\t}\n\t}\n}\n\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil { // nil cache never contains keys\n\t\treturn false\n\t}\n\tc.mu.Lock()                // lock to mutate underlying map\n\tdefer c.mu.Unlock()        // ensure unlock happens after deletion attempt\n\tif _, ok := c.m[key]; ok { // detect whether key is present before deletion\n\t\tdelete(c.m, key) // remove entry regardless of expiration state\n\t\treturn true      // signal that entry existed and was removed\n\t}\n\treturn false // report absence when key was not stored\n}\n\nfunc (c *TTLCache) Len() int {\n\tif c == nil { // nil cache behaves like empty cache\n\t\treturn 0\n\t}\n\tnow := time.Now()         // capture current time once to avoid repeat calls\n\tc.mu.Lock()               // lock to safely mutate and count\n\tdefer c.mu.Unlock()       // ensure lock release even if counting fails\n\tfor k, ent := range c.m { // visit every entry to check expiration\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries are removed eagerly\n\t\t\tdelete(c.m, k) // delete stale entry before counting\n\t\t}\n\t}\n\treturn len(c.m) // return number of remaining live entries\n}\n",
        "testCode": "package cache\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestTTLCacheSet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(50 * time.Millisecond)\n\tif len(c.m) != 0 {\n\t\tt.Fatalf(\"expected empty cache, got %d\", len(c.m))\n\t}\n\tc.Set(\"key\", \"value\")\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tent, ok := c.m[\"key\"]\n\tif !ok {\n\t\tt.Fatal(\"expected entry after Set\")\n\t}\n\tif ent.v != \"value\" {\n\t\tt.Fatalf(\"unexpected value: %v\", ent.v)\n\t}\n\tif c.ttl > 0 && time.Until(ent.exp) <= 0 {\n\t\tt.Fatalf(\"expected expiration in future, exp=%v\", ent.exp)\n\t}\n}\n\nfunc TestTTLCacheGet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"alive\", 42)\n\tif v, ok := c.Get(\"alive\"); !ok || v.(int) != 42 {\n\t\tt.Fatalf(\"unexpected get result: %v %v\", v, ok)\n\t}\n\tc.Set(\"expired\", 1)\n\ttime.Sleep(15 * time.Millisecond)\n\tif _, ok := c.Get(\"expired\"); ok {\n\t\tt.Fatal(\"expected expired entry to be removed\")\n\t}\n}\n\nfunc TestTTLCacheCleanupNow(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(0)\n\tc.mu.Lock()\n\tc.m[\"a\"] = entry{v: 1, exp: time.Now().Add(-time.Second)}\n\tc.m[\"b\"] = entry{v: 2, exp: time.Now().Add(time.Second)}\n\tc.mu.Unlock()\n\tc.cleanupNow(time.Now())\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tif _, ok := c.m[\"a\"]; ok {\n\t\tt.Fatal(\"expired entry must be removed\")\n\t}\n\tif _, ok := c.m[\"b\"]; !ok {\n\t\tt.Fatal(\"fresh entry must remain\")\n\t}\n}\n\nfunc TestTTLCacheDelete(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(time.Minute)\n\tc.Set(\"keep\", 1)\n\tif deleted := c.Delete(\"keep\"); !deleted {\n\t\tt.Fatal(\"expected delete to report true\")\n\t}\n\tif deleted := c.Delete(\"missing\"); deleted {\n\t\tt.Fatal(\"expected delete to report false for absent key\")\n\t}\n}\n\nfunc TestTTLCacheLen(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"a\", 1)\n\tc.Set(\"b\", 2)\n\ttime.Sleep(15 * time.Millisecond)\n\tc.Set(\"c\", 3)\n\tif got := c.Len(); got != 1 {\n\t\tt.Fatalf(\"expected len=1, got %d\", got)\n\t}\n\tif _, ok := c.Get(\"a\"); ok {\n\t\tt.Fatal(\"Len should have removed expired entries\")\n\t}\n}\n",
        "tags": [
          "go",
          "cache"
        ],
        "order": 1
      },
      {
        "package": "cache",
        "slug": "go-cache-get",
        "title": "Get возвращает значение только если оно ещё не истекло.",
        "description": "Level 3 (medium): Get возвращает значение только если оно ещё не истекло.\nHint: протухшие записи нужно удалять и возвращать (nil, false).",
        "difficulty": "medium",
        "hint1": "протухшие записи нужно удалять и возвращать (nil, false).",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\n// Level 1 (easy): реализуйте TTLCache на mutex + map.\n// Hint: храните ttl и защищайте доступ через RWMutex.\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\tif ttl <= 0 {\n\t\tttl = time.Millisecond\n\t}\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\n// Level 2 (easy+): Set сохраняет значение и время истечения now+ttl.\n// Hint: вычислите expires := time.Now().Add(c.ttl).\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.m[key] = entry{v: v, exp: time.Now().Add(c.ttl)}\n}\n\n// Level 3 (medium): Get возвращает значение только если оно ещё не истекло.\n// Hint: протухшие записи нужно удалять и возвращать (nil, false).\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil {\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()\n\te, ok := c.m[key]\n\tc.mu.RUnlock()\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tif time.Now().After(e.exp) {\n\t\tc.mu.Lock()\n\t\tdefer c.mu.Unlock()\n\t\tif entry, ok := c.m[key]; ok && entry.exp.Equal(e.exp) {\n\t\t\tdelete(c.m, key)\n\t\t}\n\t\treturn nil, false\n\t}\n\treturn e.v, true\n}\n\n// Level 4 (medium+): cleanupNow удаляет все записи, чьё exp <= now.\n// Hint: вызывайте под блокировкой, чтобы тесты могли проверять внутреннее состояние.\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tfor k, e := range c.m {\n\t\tif now.After(e.exp) {\n\t\t\tdelete(c.m, k)\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): Delete убирает ключ из кеша и сообщает, был ли он найден.\n// Hint: верните true, если запись существовала, даже если уже истекла.\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil {\n\t\treturn false\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif _, ok := c.m[key]; ok {\n\t\tdelete(c.m, key)\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Level 6 (medium+): Len возвращает количество неистёкших записей на момент вызова.\n// Hint: очистите просроченные элементы перед подсчётом.\nfunc (c *TTLCache) Len() int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.cleanupNow(time.Now())\n\treturn len(c.m)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil { // nil cache acts as a no-op for callers\n\t\treturn\n\t}\n\tc.mu.Lock()           // exclusive lock protects the underlying map\n\tdefer c.mu.Unlock()   // ensure lock release even on panic\n\texpire := time.Time{} // zero expiration means no TTL enforcement\n\tif c.ttl > 0 {        // only compute expiration when ttl is positive\n\t\texpire = time.Now().Add(c.ttl) // schedule the absolute expiration moment\n\t}\n\tc.m[key] = entry{v: v, exp: expire} // store the payload together with expiry timestamp\n}\n\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil { // nil cache never stores values\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()        // take read lock for optimistic lookup\n\tent, ok := c.m[key] // fetch entry if it exists\n\tc.mu.RUnlock()      // release read lock before potential writes\n\tif !ok {            // absent key yields miss immediately\n\t\treturn nil, false\n\t}\n\tif !ent.exp.IsZero() && time.Now().After(ent.exp) { // expire stale entry regardless of ttl setting\n\t\tc.mu.Lock()                                                    // upgrade to write lock to delete entry\n\t\tdefer c.mu.Unlock()                                            // ensure lock release after cleanup\n\t\tif entCur, still := c.m[key]; still && entCur.exp == ent.exp { // confirm the same entry is present\n\t\t\tdelete(c.m, key) // remove expired record from storage\n\t\t}\n\t\treturn nil, false // report miss for expired value\n\t}\n\treturn ent.v, true // return cached value while it is still valid\n}\n\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil { // nothing to clean when cache is nil\n\t\treturn\n\t}\n\tc.mu.Lock()               // ensure exclusive access during cleanup\n\tdefer c.mu.Unlock()       // release lock after iteration\n\tfor k, ent := range c.m { // iterate over all entries to check expiry\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries meet the removal criteria\n\t\t\tdelete(c.m, k) // drop stale entry from map\n\t\t}\n\t}\n}\n\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil { // nil cache never contains keys\n\t\treturn false\n\t}\n\tc.mu.Lock()                // lock to mutate underlying map\n\tdefer c.mu.Unlock()        // ensure unlock happens after deletion attempt\n\tif _, ok := c.m[key]; ok { // detect whether key is present before deletion\n\t\tdelete(c.m, key) // remove entry regardless of expiration state\n\t\treturn true      // signal that entry existed and was removed\n\t}\n\treturn false // report absence when key was not stored\n}\n\nfunc (c *TTLCache) Len() int {\n\tif c == nil { // nil cache behaves like empty cache\n\t\treturn 0\n\t}\n\tnow := time.Now()         // capture current time once to avoid repeat calls\n\tc.mu.Lock()               // lock to safely mutate and count\n\tdefer c.mu.Unlock()       // ensure lock release even if counting fails\n\tfor k, ent := range c.m { // visit every entry to check expiration\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries are removed eagerly\n\t\t\tdelete(c.m, k) // delete stale entry before counting\n\t\t}\n\t}\n\treturn len(c.m) // return number of remaining live entries\n}\n",
        "testCode": "package cache\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestTTLCacheSet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(50 * time.Millisecond)\n\tif len(c.m) != 0 {\n\t\tt.Fatalf(\"expected empty cache, got %d\", len(c.m))\n\t}\n\tc.Set(\"key\", \"value\")\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tent, ok := c.m[\"key\"]\n\tif !ok {\n\t\tt.Fatal(\"expected entry after Set\")\n\t}\n\tif ent.v != \"value\" {\n\t\tt.Fatalf(\"unexpected value: %v\", ent.v)\n\t}\n\tif c.ttl > 0 && time.Until(ent.exp) <= 0 {\n\t\tt.Fatalf(\"expected expiration in future, exp=%v\", ent.exp)\n\t}\n}\n\nfunc TestTTLCacheGet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"alive\", 42)\n\tif v, ok := c.Get(\"alive\"); !ok || v.(int) != 42 {\n\t\tt.Fatalf(\"unexpected get result: %v %v\", v, ok)\n\t}\n\tc.Set(\"expired\", 1)\n\ttime.Sleep(15 * time.Millisecond)\n\tif _, ok := c.Get(\"expired\"); ok {\n\t\tt.Fatal(\"expected expired entry to be removed\")\n\t}\n}\n\nfunc TestTTLCacheCleanupNow(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(0)\n\tc.mu.Lock()\n\tc.m[\"a\"] = entry{v: 1, exp: time.Now().Add(-time.Second)}\n\tc.m[\"b\"] = entry{v: 2, exp: time.Now().Add(time.Second)}\n\tc.mu.Unlock()\n\tc.cleanupNow(time.Now())\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tif _, ok := c.m[\"a\"]; ok {\n\t\tt.Fatal(\"expired entry must be removed\")\n\t}\n\tif _, ok := c.m[\"b\"]; !ok {\n\t\tt.Fatal(\"fresh entry must remain\")\n\t}\n}\n\nfunc TestTTLCacheDelete(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(time.Minute)\n\tc.Set(\"keep\", 1)\n\tif deleted := c.Delete(\"keep\"); !deleted {\n\t\tt.Fatal(\"expected delete to report true\")\n\t}\n\tif deleted := c.Delete(\"missing\"); deleted {\n\t\tt.Fatal(\"expected delete to report false for absent key\")\n\t}\n}\n\nfunc TestTTLCacheLen(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"a\", 1)\n\tc.Set(\"b\", 2)\n\ttime.Sleep(15 * time.Millisecond)\n\tc.Set(\"c\", 3)\n\tif got := c.Len(); got != 1 {\n\t\tt.Fatalf(\"expected len=1, got %d\", got)\n\t}\n\tif _, ok := c.Get(\"a\"); ok {\n\t\tt.Fatal(\"Len should have removed expired entries\")\n\t}\n}\n",
        "tags": [
          "go",
          "cache"
        ],
        "order": 2
      },
      {
        "package": "cache",
        "slug": "go-cache-cleanupnow",
        "title": "cleanupNow удаляет все записи, чьё exp <= now.",
        "description": "Level 4 (medium+): cleanupNow удаляет все записи, чьё exp <= now.\nHint: вызывайте под блокировкой, чтобы тесты могли проверять внутреннее состояние.",
        "difficulty": "medium",
        "hint1": "вызывайте под блокировкой, чтобы тесты могли проверять внутреннее состояние.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\n// Level 1 (easy): реализуйте TTLCache на mutex + map.\n// Hint: храните ttl и защищайте доступ через RWMutex.\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\tif ttl <= 0 {\n\t\tttl = time.Millisecond\n\t}\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\n// Level 2 (easy+): Set сохраняет значение и время истечения now+ttl.\n// Hint: вычислите expires := time.Now().Add(c.ttl).\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.m[key] = entry{v: v, exp: time.Now().Add(c.ttl)}\n}\n\n// Level 3 (medium): Get возвращает значение только если оно ещё не истекло.\n// Hint: протухшие записи нужно удалять и возвращать (nil, false).\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil {\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()\n\te, ok := c.m[key]\n\tc.mu.RUnlock()\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tif time.Now().After(e.exp) {\n\t\tc.mu.Lock()\n\t\tdefer c.mu.Unlock()\n\t\tif entry, ok := c.m[key]; ok && entry.exp.Equal(e.exp) {\n\t\t\tdelete(c.m, key)\n\t\t}\n\t\treturn nil, false\n\t}\n\treturn e.v, true\n}\n\n// Level 4 (medium+): cleanupNow удаляет все записи, чьё exp <= now.\n// Hint: вызывайте под блокировкой, чтобы тесты могли проверять внутреннее состояние.\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tfor k, e := range c.m {\n\t\tif now.After(e.exp) {\n\t\t\tdelete(c.m, k)\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): Delete убирает ключ из кеша и сообщает, был ли он найден.\n// Hint: верните true, если запись существовала, даже если уже истекла.\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil {\n\t\treturn false\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif _, ok := c.m[key]; ok {\n\t\tdelete(c.m, key)\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Level 6 (medium+): Len возвращает количество неистёкших записей на момент вызова.\n// Hint: очистите просроченные элементы перед подсчётом.\nfunc (c *TTLCache) Len() int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.cleanupNow(time.Now())\n\treturn len(c.m)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil { // nil cache acts as a no-op for callers\n\t\treturn\n\t}\n\tc.mu.Lock()           // exclusive lock protects the underlying map\n\tdefer c.mu.Unlock()   // ensure lock release even on panic\n\texpire := time.Time{} // zero expiration means no TTL enforcement\n\tif c.ttl > 0 {        // only compute expiration when ttl is positive\n\t\texpire = time.Now().Add(c.ttl) // schedule the absolute expiration moment\n\t}\n\tc.m[key] = entry{v: v, exp: expire} // store the payload together with expiry timestamp\n}\n\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil { // nil cache never stores values\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()        // take read lock for optimistic lookup\n\tent, ok := c.m[key] // fetch entry if it exists\n\tc.mu.RUnlock()      // release read lock before potential writes\n\tif !ok {            // absent key yields miss immediately\n\t\treturn nil, false\n\t}\n\tif !ent.exp.IsZero() && time.Now().After(ent.exp) { // expire stale entry regardless of ttl setting\n\t\tc.mu.Lock()                                                    // upgrade to write lock to delete entry\n\t\tdefer c.mu.Unlock()                                            // ensure lock release after cleanup\n\t\tif entCur, still := c.m[key]; still && entCur.exp == ent.exp { // confirm the same entry is present\n\t\t\tdelete(c.m, key) // remove expired record from storage\n\t\t}\n\t\treturn nil, false // report miss for expired value\n\t}\n\treturn ent.v, true // return cached value while it is still valid\n}\n\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil { // nothing to clean when cache is nil\n\t\treturn\n\t}\n\tc.mu.Lock()               // ensure exclusive access during cleanup\n\tdefer c.mu.Unlock()       // release lock after iteration\n\tfor k, ent := range c.m { // iterate over all entries to check expiry\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries meet the removal criteria\n\t\t\tdelete(c.m, k) // drop stale entry from map\n\t\t}\n\t}\n}\n\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil { // nil cache never contains keys\n\t\treturn false\n\t}\n\tc.mu.Lock()                // lock to mutate underlying map\n\tdefer c.mu.Unlock()        // ensure unlock happens after deletion attempt\n\tif _, ok := c.m[key]; ok { // detect whether key is present before deletion\n\t\tdelete(c.m, key) // remove entry regardless of expiration state\n\t\treturn true      // signal that entry existed and was removed\n\t}\n\treturn false // report absence when key was not stored\n}\n\nfunc (c *TTLCache) Len() int {\n\tif c == nil { // nil cache behaves like empty cache\n\t\treturn 0\n\t}\n\tnow := time.Now()         // capture current time once to avoid repeat calls\n\tc.mu.Lock()               // lock to safely mutate and count\n\tdefer c.mu.Unlock()       // ensure lock release even if counting fails\n\tfor k, ent := range c.m { // visit every entry to check expiration\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries are removed eagerly\n\t\t\tdelete(c.m, k) // delete stale entry before counting\n\t\t}\n\t}\n\treturn len(c.m) // return number of remaining live entries\n}\n",
        "testCode": "package cache\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestTTLCacheSet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(50 * time.Millisecond)\n\tif len(c.m) != 0 {\n\t\tt.Fatalf(\"expected empty cache, got %d\", len(c.m))\n\t}\n\tc.Set(\"key\", \"value\")\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tent, ok := c.m[\"key\"]\n\tif !ok {\n\t\tt.Fatal(\"expected entry after Set\")\n\t}\n\tif ent.v != \"value\" {\n\t\tt.Fatalf(\"unexpected value: %v\", ent.v)\n\t}\n\tif c.ttl > 0 && time.Until(ent.exp) <= 0 {\n\t\tt.Fatalf(\"expected expiration in future, exp=%v\", ent.exp)\n\t}\n}\n\nfunc TestTTLCacheGet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"alive\", 42)\n\tif v, ok := c.Get(\"alive\"); !ok || v.(int) != 42 {\n\t\tt.Fatalf(\"unexpected get result: %v %v\", v, ok)\n\t}\n\tc.Set(\"expired\", 1)\n\ttime.Sleep(15 * time.Millisecond)\n\tif _, ok := c.Get(\"expired\"); ok {\n\t\tt.Fatal(\"expected expired entry to be removed\")\n\t}\n}\n\nfunc TestTTLCacheCleanupNow(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(0)\n\tc.mu.Lock()\n\tc.m[\"a\"] = entry{v: 1, exp: time.Now().Add(-time.Second)}\n\tc.m[\"b\"] = entry{v: 2, exp: time.Now().Add(time.Second)}\n\tc.mu.Unlock()\n\tc.cleanupNow(time.Now())\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tif _, ok := c.m[\"a\"]; ok {\n\t\tt.Fatal(\"expired entry must be removed\")\n\t}\n\tif _, ok := c.m[\"b\"]; !ok {\n\t\tt.Fatal(\"fresh entry must remain\")\n\t}\n}\n\nfunc TestTTLCacheDelete(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(time.Minute)\n\tc.Set(\"keep\", 1)\n\tif deleted := c.Delete(\"keep\"); !deleted {\n\t\tt.Fatal(\"expected delete to report true\")\n\t}\n\tif deleted := c.Delete(\"missing\"); deleted {\n\t\tt.Fatal(\"expected delete to report false for absent key\")\n\t}\n}\n\nfunc TestTTLCacheLen(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"a\", 1)\n\tc.Set(\"b\", 2)\n\ttime.Sleep(15 * time.Millisecond)\n\tc.Set(\"c\", 3)\n\tif got := c.Len(); got != 1 {\n\t\tt.Fatalf(\"expected len=1, got %d\", got)\n\t}\n\tif _, ok := c.Get(\"a\"); ok {\n\t\tt.Fatal(\"Len should have removed expired entries\")\n\t}\n}\n",
        "tags": [
          "go",
          "cache"
        ],
        "order": 3
      },
      {
        "package": "cache",
        "slug": "go-cache-delete",
        "title": "Delete убирает ключ из кеша и сообщает, был ли он найден.",
        "description": "Level 5 (medium+): Delete убирает ключ из кеша и сообщает, был ли он найден.\nHint: верните true, если запись существовала, даже если уже истекла.",
        "difficulty": "medium",
        "hint1": "верните true, если запись существовала, даже если уже истекла.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\n// Level 1 (easy): реализуйте TTLCache на mutex + map.\n// Hint: храните ttl и защищайте доступ через RWMutex.\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\tif ttl <= 0 {\n\t\tttl = time.Millisecond\n\t}\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\n// Level 2 (easy+): Set сохраняет значение и время истечения now+ttl.\n// Hint: вычислите expires := time.Now().Add(c.ttl).\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.m[key] = entry{v: v, exp: time.Now().Add(c.ttl)}\n}\n\n// Level 3 (medium): Get возвращает значение только если оно ещё не истекло.\n// Hint: протухшие записи нужно удалять и возвращать (nil, false).\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil {\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()\n\te, ok := c.m[key]\n\tc.mu.RUnlock()\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tif time.Now().After(e.exp) {\n\t\tc.mu.Lock()\n\t\tdefer c.mu.Unlock()\n\t\tif entry, ok := c.m[key]; ok && entry.exp.Equal(e.exp) {\n\t\t\tdelete(c.m, key)\n\t\t}\n\t\treturn nil, false\n\t}\n\treturn e.v, true\n}\n\n// Level 4 (medium+): cleanupNow удаляет все записи, чьё exp <= now.\n// Hint: вызывайте под блокировкой, чтобы тесты могли проверять внутреннее состояние.\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tfor k, e := range c.m {\n\t\tif now.After(e.exp) {\n\t\t\tdelete(c.m, k)\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): Delete убирает ключ из кеша и сообщает, был ли он найден.\n// Hint: верните true, если запись существовала, даже если уже истекла.\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil {\n\t\treturn false\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif _, ok := c.m[key]; ok {\n\t\tdelete(c.m, key)\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Level 6 (medium+): Len возвращает количество неистёкших записей на момент вызова.\n// Hint: очистите просроченные элементы перед подсчётом.\nfunc (c *TTLCache) Len() int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.cleanupNow(time.Now())\n\treturn len(c.m)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil { // nil cache acts as a no-op for callers\n\t\treturn\n\t}\n\tc.mu.Lock()           // exclusive lock protects the underlying map\n\tdefer c.mu.Unlock()   // ensure lock release even on panic\n\texpire := time.Time{} // zero expiration means no TTL enforcement\n\tif c.ttl > 0 {        // only compute expiration when ttl is positive\n\t\texpire = time.Now().Add(c.ttl) // schedule the absolute expiration moment\n\t}\n\tc.m[key] = entry{v: v, exp: expire} // store the payload together with expiry timestamp\n}\n\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil { // nil cache never stores values\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()        // take read lock for optimistic lookup\n\tent, ok := c.m[key] // fetch entry if it exists\n\tc.mu.RUnlock()      // release read lock before potential writes\n\tif !ok {            // absent key yields miss immediately\n\t\treturn nil, false\n\t}\n\tif !ent.exp.IsZero() && time.Now().After(ent.exp) { // expire stale entry regardless of ttl setting\n\t\tc.mu.Lock()                                                    // upgrade to write lock to delete entry\n\t\tdefer c.mu.Unlock()                                            // ensure lock release after cleanup\n\t\tif entCur, still := c.m[key]; still && entCur.exp == ent.exp { // confirm the same entry is present\n\t\t\tdelete(c.m, key) // remove expired record from storage\n\t\t}\n\t\treturn nil, false // report miss for expired value\n\t}\n\treturn ent.v, true // return cached value while it is still valid\n}\n\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil { // nothing to clean when cache is nil\n\t\treturn\n\t}\n\tc.mu.Lock()               // ensure exclusive access during cleanup\n\tdefer c.mu.Unlock()       // release lock after iteration\n\tfor k, ent := range c.m { // iterate over all entries to check expiry\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries meet the removal criteria\n\t\t\tdelete(c.m, k) // drop stale entry from map\n\t\t}\n\t}\n}\n\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil { // nil cache never contains keys\n\t\treturn false\n\t}\n\tc.mu.Lock()                // lock to mutate underlying map\n\tdefer c.mu.Unlock()        // ensure unlock happens after deletion attempt\n\tif _, ok := c.m[key]; ok { // detect whether key is present before deletion\n\t\tdelete(c.m, key) // remove entry regardless of expiration state\n\t\treturn true      // signal that entry existed and was removed\n\t}\n\treturn false // report absence when key was not stored\n}\n\nfunc (c *TTLCache) Len() int {\n\tif c == nil { // nil cache behaves like empty cache\n\t\treturn 0\n\t}\n\tnow := time.Now()         // capture current time once to avoid repeat calls\n\tc.mu.Lock()               // lock to safely mutate and count\n\tdefer c.mu.Unlock()       // ensure lock release even if counting fails\n\tfor k, ent := range c.m { // visit every entry to check expiration\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries are removed eagerly\n\t\t\tdelete(c.m, k) // delete stale entry before counting\n\t\t}\n\t}\n\treturn len(c.m) // return number of remaining live entries\n}\n",
        "testCode": "package cache\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestTTLCacheSet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(50 * time.Millisecond)\n\tif len(c.m) != 0 {\n\t\tt.Fatalf(\"expected empty cache, got %d\", len(c.m))\n\t}\n\tc.Set(\"key\", \"value\")\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tent, ok := c.m[\"key\"]\n\tif !ok {\n\t\tt.Fatal(\"expected entry after Set\")\n\t}\n\tif ent.v != \"value\" {\n\t\tt.Fatalf(\"unexpected value: %v\", ent.v)\n\t}\n\tif c.ttl > 0 && time.Until(ent.exp) <= 0 {\n\t\tt.Fatalf(\"expected expiration in future, exp=%v\", ent.exp)\n\t}\n}\n\nfunc TestTTLCacheGet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"alive\", 42)\n\tif v, ok := c.Get(\"alive\"); !ok || v.(int) != 42 {\n\t\tt.Fatalf(\"unexpected get result: %v %v\", v, ok)\n\t}\n\tc.Set(\"expired\", 1)\n\ttime.Sleep(15 * time.Millisecond)\n\tif _, ok := c.Get(\"expired\"); ok {\n\t\tt.Fatal(\"expected expired entry to be removed\")\n\t}\n}\n\nfunc TestTTLCacheCleanupNow(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(0)\n\tc.mu.Lock()\n\tc.m[\"a\"] = entry{v: 1, exp: time.Now().Add(-time.Second)}\n\tc.m[\"b\"] = entry{v: 2, exp: time.Now().Add(time.Second)}\n\tc.mu.Unlock()\n\tc.cleanupNow(time.Now())\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tif _, ok := c.m[\"a\"]; ok {\n\t\tt.Fatal(\"expired entry must be removed\")\n\t}\n\tif _, ok := c.m[\"b\"]; !ok {\n\t\tt.Fatal(\"fresh entry must remain\")\n\t}\n}\n\nfunc TestTTLCacheDelete(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(time.Minute)\n\tc.Set(\"keep\", 1)\n\tif deleted := c.Delete(\"keep\"); !deleted {\n\t\tt.Fatal(\"expected delete to report true\")\n\t}\n\tif deleted := c.Delete(\"missing\"); deleted {\n\t\tt.Fatal(\"expected delete to report false for absent key\")\n\t}\n}\n\nfunc TestTTLCacheLen(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"a\", 1)\n\tc.Set(\"b\", 2)\n\ttime.Sleep(15 * time.Millisecond)\n\tc.Set(\"c\", 3)\n\tif got := c.Len(); got != 1 {\n\t\tt.Fatalf(\"expected len=1, got %d\", got)\n\t}\n\tif _, ok := c.Get(\"a\"); ok {\n\t\tt.Fatal(\"Len should have removed expired entries\")\n\t}\n}\n",
        "tags": [
          "go",
          "cache"
        ],
        "order": 4
      },
      {
        "package": "cache",
        "slug": "go-cache-len",
        "title": "Len возвращает количество неистёкших записей на момент вызова.",
        "description": "Level 6 (medium+): Len возвращает количество неистёкших записей на момент вызова.\nHint: очистите просроченные элементы перед подсчётом.",
        "difficulty": "medium",
        "hint1": "очистите просроченные элементы перед подсчётом.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\n// Level 1 (easy): реализуйте TTLCache на mutex + map.\n// Hint: храните ttl и защищайте доступ через RWMutex.\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\tif ttl <= 0 {\n\t\tttl = time.Millisecond\n\t}\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\n// Level 2 (easy+): Set сохраняет значение и время истечения now+ttl.\n// Hint: вычислите expires := time.Now().Add(c.ttl).\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.m[key] = entry{v: v, exp: time.Now().Add(c.ttl)}\n}\n\n// Level 3 (medium): Get возвращает значение только если оно ещё не истекло.\n// Hint: протухшие записи нужно удалять и возвращать (nil, false).\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil {\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()\n\te, ok := c.m[key]\n\tc.mu.RUnlock()\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tif time.Now().After(e.exp) {\n\t\tc.mu.Lock()\n\t\tdefer c.mu.Unlock()\n\t\tif entry, ok := c.m[key]; ok && entry.exp.Equal(e.exp) {\n\t\t\tdelete(c.m, key)\n\t\t}\n\t\treturn nil, false\n\t}\n\treturn e.v, true\n}\n\n// Level 4 (medium+): cleanupNow удаляет все записи, чьё exp <= now.\n// Hint: вызывайте под блокировкой, чтобы тесты могли проверять внутреннее состояние.\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tfor k, e := range c.m {\n\t\tif now.After(e.exp) {\n\t\t\tdelete(c.m, k)\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): Delete убирает ключ из кеша и сообщает, был ли он найден.\n// Hint: верните true, если запись существовала, даже если уже истекла.\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil {\n\t\treturn false\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif _, ok := c.m[key]; ok {\n\t\tdelete(c.m, key)\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Level 6 (medium+): Len возвращает количество неистёкших записей на момент вызова.\n// Hint: очистите просроченные элементы перед подсчётом.\nfunc (c *TTLCache) Len() int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.cleanupNow(time.Now())\n\treturn len(c.m)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage cache\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\ntype entry struct {\n\tv   any\n\texp time.Time\n}\n\ntype TTLCache struct {\n\tmu  sync.RWMutex\n\tm   map[string]entry\n\tttl time.Duration\n}\n\nfunc NewTTLCache(ttl time.Duration) *TTLCache {\n\treturn &TTLCache{m: make(map[string]entry), ttl: ttl}\n}\n\nfunc (c *TTLCache) Set(key string, v any) {\n\tif c == nil { // nil cache acts as a no-op for callers\n\t\treturn\n\t}\n\tc.mu.Lock()           // exclusive lock protects the underlying map\n\tdefer c.mu.Unlock()   // ensure lock release even on panic\n\texpire := time.Time{} // zero expiration means no TTL enforcement\n\tif c.ttl > 0 {        // only compute expiration when ttl is positive\n\t\texpire = time.Now().Add(c.ttl) // schedule the absolute expiration moment\n\t}\n\tc.m[key] = entry{v: v, exp: expire} // store the payload together with expiry timestamp\n}\n\nfunc (c *TTLCache) Get(key string) (any, bool) {\n\tif c == nil { // nil cache never stores values\n\t\treturn nil, false\n\t}\n\tc.mu.RLock()        // take read lock for optimistic lookup\n\tent, ok := c.m[key] // fetch entry if it exists\n\tc.mu.RUnlock()      // release read lock before potential writes\n\tif !ok {            // absent key yields miss immediately\n\t\treturn nil, false\n\t}\n\tif !ent.exp.IsZero() && time.Now().After(ent.exp) { // expire stale entry regardless of ttl setting\n\t\tc.mu.Lock()                                                    // upgrade to write lock to delete entry\n\t\tdefer c.mu.Unlock()                                            // ensure lock release after cleanup\n\t\tif entCur, still := c.m[key]; still && entCur.exp == ent.exp { // confirm the same entry is present\n\t\t\tdelete(c.m, key) // remove expired record from storage\n\t\t}\n\t\treturn nil, false // report miss for expired value\n\t}\n\treturn ent.v, true // return cached value while it is still valid\n}\n\nfunc (c *TTLCache) cleanupNow(now time.Time) {\n\tif c == nil { // nothing to clean when cache is nil\n\t\treturn\n\t}\n\tc.mu.Lock()               // ensure exclusive access during cleanup\n\tdefer c.mu.Unlock()       // release lock after iteration\n\tfor k, ent := range c.m { // iterate over all entries to check expiry\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries meet the removal criteria\n\t\t\tdelete(c.m, k) // drop stale entry from map\n\t\t}\n\t}\n}\n\nfunc (c *TTLCache) Delete(key string) bool {\n\tif c == nil { // nil cache never contains keys\n\t\treturn false\n\t}\n\tc.mu.Lock()                // lock to mutate underlying map\n\tdefer c.mu.Unlock()        // ensure unlock happens after deletion attempt\n\tif _, ok := c.m[key]; ok { // detect whether key is present before deletion\n\t\tdelete(c.m, key) // remove entry regardless of expiration state\n\t\treturn true      // signal that entry existed and was removed\n\t}\n\treturn false // report absence when key was not stored\n}\n\nfunc (c *TTLCache) Len() int {\n\tif c == nil { // nil cache behaves like empty cache\n\t\treturn 0\n\t}\n\tnow := time.Now()         // capture current time once to avoid repeat calls\n\tc.mu.Lock()               // lock to safely mutate and count\n\tdefer c.mu.Unlock()       // ensure lock release even if counting fails\n\tfor k, ent := range c.m { // visit every entry to check expiration\n\t\tif !ent.exp.IsZero() && !now.Before(ent.exp) { // expired entries are removed eagerly\n\t\t\tdelete(c.m, k) // delete stale entry before counting\n\t\t}\n\t}\n\treturn len(c.m) // return number of remaining live entries\n}\n",
        "testCode": "package cache\n\nimport (\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestTTLCacheSet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(50 * time.Millisecond)\n\tif len(c.m) != 0 {\n\t\tt.Fatalf(\"expected empty cache, got %d\", len(c.m))\n\t}\n\tc.Set(\"key\", \"value\")\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tent, ok := c.m[\"key\"]\n\tif !ok {\n\t\tt.Fatal(\"expected entry after Set\")\n\t}\n\tif ent.v != \"value\" {\n\t\tt.Fatalf(\"unexpected value: %v\", ent.v)\n\t}\n\tif c.ttl > 0 && time.Until(ent.exp) <= 0 {\n\t\tt.Fatalf(\"expected expiration in future, exp=%v\", ent.exp)\n\t}\n}\n\nfunc TestTTLCacheGet(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"alive\", 42)\n\tif v, ok := c.Get(\"alive\"); !ok || v.(int) != 42 {\n\t\tt.Fatalf(\"unexpected get result: %v %v\", v, ok)\n\t}\n\tc.Set(\"expired\", 1)\n\ttime.Sleep(15 * time.Millisecond)\n\tif _, ok := c.Get(\"expired\"); ok {\n\t\tt.Fatal(\"expected expired entry to be removed\")\n\t}\n}\n\nfunc TestTTLCacheCleanupNow(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(0)\n\tc.mu.Lock()\n\tc.m[\"a\"] = entry{v: 1, exp: time.Now().Add(-time.Second)}\n\tc.m[\"b\"] = entry{v: 2, exp: time.Now().Add(time.Second)}\n\tc.mu.Unlock()\n\tc.cleanupNow(time.Now())\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tif _, ok := c.m[\"a\"]; ok {\n\t\tt.Fatal(\"expired entry must be removed\")\n\t}\n\tif _, ok := c.m[\"b\"]; !ok {\n\t\tt.Fatal(\"fresh entry must remain\")\n\t}\n}\n\nfunc TestTTLCacheDelete(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(time.Minute)\n\tc.Set(\"keep\", 1)\n\tif deleted := c.Delete(\"keep\"); !deleted {\n\t\tt.Fatal(\"expected delete to report true\")\n\t}\n\tif deleted := c.Delete(\"missing\"); deleted {\n\t\tt.Fatal(\"expected delete to report false for absent key\")\n\t}\n}\n\nfunc TestTTLCacheLen(t *testing.T) {\n\tt.Parallel()\n\tc := NewTTLCache(10 * time.Millisecond)\n\tc.Set(\"a\", 1)\n\tc.Set(\"b\", 2)\n\ttime.Sleep(15 * time.Millisecond)\n\tc.Set(\"c\", 3)\n\tif got := c.Len(); got != 1 {\n\t\tt.Fatalf(\"expected len=1, got %d\", got)\n\t}\n\tif _, ok := c.Get(\"a\"); ok {\n\t\tt.Fatal(\"Len should have removed expired entries\")\n\t}\n}\n",
        "tags": [
          "go",
          "cache"
        ],
        "order": 5
      }
    ],
    "category": "production"
  },
  {
    "name": "channelsx",
    "tasks": [
      {
        "package": "channelsx",
        "slug": "go-channelsx-fanin",
        "title": "FanIn объединяет несколько входных каналов в один поток до отмены контекста.",
        "description": "Level 1 (easy): FanIn объединяет несколько входных каналов в один поток до отмены контекста.\nHint: поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.",
        "difficulty": "easy",
        "hint1": "поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Level 1 (easy): FanIn объединяет несколько входных каналов в один поток до отмены контекста.\n// Hint: поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tout := make(chan T)\n\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): FanOut транслирует значения из одного канала в n независимых каналов.\n// Hint: корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, out := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 3 (medium): OrDone проксирует значения до отмены контекста или закрытия входа.\n// Hint: при ctx.Done() возвращайте сразу, не оставляя горутин.\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 4 (medium): RunWorkerPool запускает pool из workers горутин, которые читают из in и вызывают handler.\n// Hint: завершайте работу при ctx.Done() и возвращайте первую ошибку handler.\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 5 (medium+): RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.\n// Hint: используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tif workers <= 0 || h == nil || ins == nil {\n\t\treturn nil\n\t}\n\n\tmerged := make(chan T)\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase merged <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(merged)\n\t}()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-merged:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 6 (senior-): FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).\n// Hint: переключайтесь между выходами, соблюдая ctx.Done().\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 7 (senior-): MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.\n// Hint: объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif errs == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tprocessErrs := func(err <-chan error) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase e, ok := <-err:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif e != nil {\n\t\t\t\t\thandleErr(e)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, err := range errs {\n\t\tif err == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo processErrs(err)\n\t}\n\n\twg.Wait()\n\treturn firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, ch := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase ch <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tunified := FanIn(ctx, ins...)\n\treturn RunWorkerPool(ctx, unified, workers, h)\n}\n\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := FanIn(ctx, errs...)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase err, ok := <-merged:\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}\n",
        "testCode": "package channelsx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"reflect\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc collect[T any](ch <-chan T) []T {\n\tvar out []T\n\tfor v := range ch {\n\t\tout = append(out, v)\n\t}\n\treturn out\n}\n\nfunc TestFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 2)\n\tb := make(chan int, 2)\n\ta <- 1\n\ta <- 2\n\tb <- 3\n\tclose(a)\n\tclose(b)\n\tout := FanIn(ctx, a, b)\n\tgot := collect(out)\n\tif len(got) != 3 {\n\t\tt.Fatalf(\"unexpected length: %v\", got)\n\t}\n\tfor _, want := range []int{1, 2, 3} {\n\t\tif !contains(got, want) {\n\t\t\tt.Fatalf(\"missing %d in %v\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestFanOut(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor _, v := range []int{1, 2, 3} {\n\t\tin <- v\n\t}\n\tclose(in)\n\touts := FanOut(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\tmu  sync.Mutex\n\t\tall []int\n\t\twg  sync.WaitGroup\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\tvals := collect(ch)\n\t\t\tmu.Lock()\n\t\t\tall = append(all, vals...)\n\t\t\tmu.Unlock()\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif len(all) != 6 {\n\t\tt.Fatalf(\"unexpected total: %v\", all)\n\t}\n}\n\nfunc TestOrDone(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tclose(in)\n\tout := OrDone(ctx, in)\n\tif _, ok := <-out; ok {\n\t\tt.Fatal(\"channel should be closed\")\n\t}\n}\n\nfunc TestRunWorkerPool(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor i := 0; i < 3; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tvar sum atomic.Int64\n\terr := RunWorkerPool(ctx, in, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPoolWithFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 1)\n\tb := make(chan int, 1)\n\ta <- 1\n\tb <- 2\n\tclose(a)\n\tclose(b)\n\tvar sum atomic.Int64\n\terr := RunWorkerPoolWithFanIn(ctx, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t}, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPool_Error(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 1)\n\tin <- 1\n\tclose(in)\n\ttarget := errors.New(\"boom\")\n\terr := RunWorkerPool(ctx, in, 1, func(context.Context, int) error { return target })\n\tif !errors.Is(err, target) {\n\t\tt.Fatalf(\"want %v, got %v\", target, err)\n\t}\n}\n\nfunc TestFanOutWithBalancer(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 4)\n\tfor i := 0; i < 4; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\touts := FanOutWithBalancer(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\twg    sync.WaitGroup\n\t\ttotal atomic.Int64\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\ttotal.Add(int64(len(collect(ch))))\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif total.Load() != 4 {\n\t\tt.Fatalf(\"lost elements, total=%d\", total.Load())\n\t}\n}\n\nfunc TestMergeWorkerResults(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\terrCh1 := make(chan error, 1)\n\terrCh2 := make(chan error, 1)\n\terrCh1 <- nil\n\terrCh2 <- errors.New(\"fail\")\n\tclose(errCh1)\n\tclose(errCh2)\n\terr := MergeWorkerResults(ctx, errCh1, errCh2)\n\tif err == nil || err.Error() != \"fail\" {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc contains[T comparable](in []T, v T) bool {\n\tfor _, el := range in {\n\t\tif reflect.DeepEqual(el, v) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n",
        "tags": [
          "go",
          "channelsx"
        ],
        "order": 0
      },
      {
        "package": "channelsx",
        "slug": "go-channelsx-fanout",
        "title": "FanOut транслирует значения из одного канала в n независимых каналов.",
        "description": "Level 2 (easy+): FanOut транслирует значения из одного канала в n независимых каналов.\nHint: корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().",
        "difficulty": "easy",
        "hint1": "корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Level 1 (easy): FanIn объединяет несколько входных каналов в один поток до отмены контекста.\n// Hint: поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tout := make(chan T)\n\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): FanOut транслирует значения из одного канала в n независимых каналов.\n// Hint: корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, out := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 3 (medium): OrDone проксирует значения до отмены контекста или закрытия входа.\n// Hint: при ctx.Done() возвращайте сразу, не оставляя горутин.\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 4 (medium): RunWorkerPool запускает pool из workers горутин, которые читают из in и вызывают handler.\n// Hint: завершайте работу при ctx.Done() и возвращайте первую ошибку handler.\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 5 (medium+): RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.\n// Hint: используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tif workers <= 0 || h == nil || ins == nil {\n\t\treturn nil\n\t}\n\n\tmerged := make(chan T)\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase merged <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(merged)\n\t}()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-merged:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 6 (senior-): FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).\n// Hint: переключайтесь между выходами, соблюдая ctx.Done().\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 7 (senior-): MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.\n// Hint: объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif errs == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tprocessErrs := func(err <-chan error) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase e, ok := <-err:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif e != nil {\n\t\t\t\t\thandleErr(e)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, err := range errs {\n\t\tif err == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo processErrs(err)\n\t}\n\n\twg.Wait()\n\treturn firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, ch := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase ch <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tunified := FanIn(ctx, ins...)\n\treturn RunWorkerPool(ctx, unified, workers, h)\n}\n\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := FanIn(ctx, errs...)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase err, ok := <-merged:\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}\n",
        "testCode": "package channelsx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"reflect\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc collect[T any](ch <-chan T) []T {\n\tvar out []T\n\tfor v := range ch {\n\t\tout = append(out, v)\n\t}\n\treturn out\n}\n\nfunc TestFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 2)\n\tb := make(chan int, 2)\n\ta <- 1\n\ta <- 2\n\tb <- 3\n\tclose(a)\n\tclose(b)\n\tout := FanIn(ctx, a, b)\n\tgot := collect(out)\n\tif len(got) != 3 {\n\t\tt.Fatalf(\"unexpected length: %v\", got)\n\t}\n\tfor _, want := range []int{1, 2, 3} {\n\t\tif !contains(got, want) {\n\t\t\tt.Fatalf(\"missing %d in %v\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestFanOut(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor _, v := range []int{1, 2, 3} {\n\t\tin <- v\n\t}\n\tclose(in)\n\touts := FanOut(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\tmu  sync.Mutex\n\t\tall []int\n\t\twg  sync.WaitGroup\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\tvals := collect(ch)\n\t\t\tmu.Lock()\n\t\t\tall = append(all, vals...)\n\t\t\tmu.Unlock()\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif len(all) != 6 {\n\t\tt.Fatalf(\"unexpected total: %v\", all)\n\t}\n}\n\nfunc TestOrDone(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tclose(in)\n\tout := OrDone(ctx, in)\n\tif _, ok := <-out; ok {\n\t\tt.Fatal(\"channel should be closed\")\n\t}\n}\n\nfunc TestRunWorkerPool(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor i := 0; i < 3; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tvar sum atomic.Int64\n\terr := RunWorkerPool(ctx, in, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPoolWithFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 1)\n\tb := make(chan int, 1)\n\ta <- 1\n\tb <- 2\n\tclose(a)\n\tclose(b)\n\tvar sum atomic.Int64\n\terr := RunWorkerPoolWithFanIn(ctx, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t}, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPool_Error(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 1)\n\tin <- 1\n\tclose(in)\n\ttarget := errors.New(\"boom\")\n\terr := RunWorkerPool(ctx, in, 1, func(context.Context, int) error { return target })\n\tif !errors.Is(err, target) {\n\t\tt.Fatalf(\"want %v, got %v\", target, err)\n\t}\n}\n\nfunc TestFanOutWithBalancer(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 4)\n\tfor i := 0; i < 4; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\touts := FanOutWithBalancer(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\twg    sync.WaitGroup\n\t\ttotal atomic.Int64\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\ttotal.Add(int64(len(collect(ch))))\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif total.Load() != 4 {\n\t\tt.Fatalf(\"lost elements, total=%d\", total.Load())\n\t}\n}\n\nfunc TestMergeWorkerResults(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\terrCh1 := make(chan error, 1)\n\terrCh2 := make(chan error, 1)\n\terrCh1 <- nil\n\terrCh2 <- errors.New(\"fail\")\n\tclose(errCh1)\n\tclose(errCh2)\n\terr := MergeWorkerResults(ctx, errCh1, errCh2)\n\tif err == nil || err.Error() != \"fail\" {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc contains[T comparable](in []T, v T) bool {\n\tfor _, el := range in {\n\t\tif reflect.DeepEqual(el, v) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n",
        "tags": [
          "go",
          "channelsx"
        ],
        "order": 1
      },
      {
        "package": "channelsx",
        "slug": "go-channelsx-ordone",
        "title": "OrDone проксирует значения до отмены контекста или закрытия входа.",
        "description": "Level 3 (medium): OrDone проксирует значения до отмены контекста или закрытия входа.\nHint: при ctx.Done() возвращайте сразу, не оставляя горутин.",
        "difficulty": "medium",
        "hint1": "при ctx.Done() возвращайте сразу, не оставляя горутин.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Level 1 (easy): FanIn объединяет несколько входных каналов в один поток до отмены контекста.\n// Hint: поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tout := make(chan T)\n\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): FanOut транслирует значения из одного канала в n независимых каналов.\n// Hint: корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, out := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 3 (medium): OrDone проксирует значения до отмены контекста или закрытия входа.\n// Hint: при ctx.Done() возвращайте сразу, не оставляя горутин.\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 4 (medium): RunWorkerPool запускает pool из workers горутин, которые читают из in и вызывают handler.\n// Hint: завершайте работу при ctx.Done() и возвращайте первую ошибку handler.\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 5 (medium+): RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.\n// Hint: используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tif workers <= 0 || h == nil || ins == nil {\n\t\treturn nil\n\t}\n\n\tmerged := make(chan T)\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase merged <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(merged)\n\t}()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-merged:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 6 (senior-): FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).\n// Hint: переключайтесь между выходами, соблюдая ctx.Done().\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 7 (senior-): MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.\n// Hint: объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif errs == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tprocessErrs := func(err <-chan error) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase e, ok := <-err:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif e != nil {\n\t\t\t\t\thandleErr(e)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, err := range errs {\n\t\tif err == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo processErrs(err)\n\t}\n\n\twg.Wait()\n\treturn firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, ch := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase ch <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tunified := FanIn(ctx, ins...)\n\treturn RunWorkerPool(ctx, unified, workers, h)\n}\n\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := FanIn(ctx, errs...)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase err, ok := <-merged:\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}\n",
        "testCode": "package channelsx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"reflect\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc collect[T any](ch <-chan T) []T {\n\tvar out []T\n\tfor v := range ch {\n\t\tout = append(out, v)\n\t}\n\treturn out\n}\n\nfunc TestFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 2)\n\tb := make(chan int, 2)\n\ta <- 1\n\ta <- 2\n\tb <- 3\n\tclose(a)\n\tclose(b)\n\tout := FanIn(ctx, a, b)\n\tgot := collect(out)\n\tif len(got) != 3 {\n\t\tt.Fatalf(\"unexpected length: %v\", got)\n\t}\n\tfor _, want := range []int{1, 2, 3} {\n\t\tif !contains(got, want) {\n\t\t\tt.Fatalf(\"missing %d in %v\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestFanOut(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor _, v := range []int{1, 2, 3} {\n\t\tin <- v\n\t}\n\tclose(in)\n\touts := FanOut(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\tmu  sync.Mutex\n\t\tall []int\n\t\twg  sync.WaitGroup\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\tvals := collect(ch)\n\t\t\tmu.Lock()\n\t\t\tall = append(all, vals...)\n\t\t\tmu.Unlock()\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif len(all) != 6 {\n\t\tt.Fatalf(\"unexpected total: %v\", all)\n\t}\n}\n\nfunc TestOrDone(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tclose(in)\n\tout := OrDone(ctx, in)\n\tif _, ok := <-out; ok {\n\t\tt.Fatal(\"channel should be closed\")\n\t}\n}\n\nfunc TestRunWorkerPool(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor i := 0; i < 3; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tvar sum atomic.Int64\n\terr := RunWorkerPool(ctx, in, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPoolWithFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 1)\n\tb := make(chan int, 1)\n\ta <- 1\n\tb <- 2\n\tclose(a)\n\tclose(b)\n\tvar sum atomic.Int64\n\terr := RunWorkerPoolWithFanIn(ctx, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t}, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPool_Error(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 1)\n\tin <- 1\n\tclose(in)\n\ttarget := errors.New(\"boom\")\n\terr := RunWorkerPool(ctx, in, 1, func(context.Context, int) error { return target })\n\tif !errors.Is(err, target) {\n\t\tt.Fatalf(\"want %v, got %v\", target, err)\n\t}\n}\n\nfunc TestFanOutWithBalancer(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 4)\n\tfor i := 0; i < 4; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\touts := FanOutWithBalancer(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\twg    sync.WaitGroup\n\t\ttotal atomic.Int64\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\ttotal.Add(int64(len(collect(ch))))\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif total.Load() != 4 {\n\t\tt.Fatalf(\"lost elements, total=%d\", total.Load())\n\t}\n}\n\nfunc TestMergeWorkerResults(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\terrCh1 := make(chan error, 1)\n\terrCh2 := make(chan error, 1)\n\terrCh1 <- nil\n\terrCh2 <- errors.New(\"fail\")\n\tclose(errCh1)\n\tclose(errCh2)\n\terr := MergeWorkerResults(ctx, errCh1, errCh2)\n\tif err == nil || err.Error() != \"fail\" {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc contains[T comparable](in []T, v T) bool {\n\tfor _, el := range in {\n\t\tif reflect.DeepEqual(el, v) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n",
        "tags": [
          "go",
          "channelsx"
        ],
        "order": 2
      },
      {
        "package": "channelsx",
        "slug": "go-channelsx-runworkerpoolwithfanin",
        "title": "RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.",
        "description": "Level 5 (medium+): RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.\nHint: используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.",
        "difficulty": "medium",
        "hint1": "используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Level 1 (easy): FanIn объединяет несколько входных каналов в один поток до отмены контекста.\n// Hint: поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tout := make(chan T)\n\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): FanOut транслирует значения из одного канала в n независимых каналов.\n// Hint: корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, out := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 3 (medium): OrDone проксирует значения до отмены контекста или закрытия входа.\n// Hint: при ctx.Done() возвращайте сразу, не оставляя горутин.\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 4 (medium): RunWorkerPool запускает pool из workers горутин, которые читают из in и вызывают handler.\n// Hint: завершайте работу при ctx.Done() и возвращайте первую ошибку handler.\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 5 (medium+): RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.\n// Hint: используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tif workers <= 0 || h == nil || ins == nil {\n\t\treturn nil\n\t}\n\n\tmerged := make(chan T)\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase merged <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(merged)\n\t}()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-merged:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 6 (senior-): FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).\n// Hint: переключайтесь между выходами, соблюдая ctx.Done().\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 7 (senior-): MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.\n// Hint: объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif errs == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tprocessErrs := func(err <-chan error) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase e, ok := <-err:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif e != nil {\n\t\t\t\t\thandleErr(e)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, err := range errs {\n\t\tif err == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo processErrs(err)\n\t}\n\n\twg.Wait()\n\treturn firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, ch := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase ch <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tunified := FanIn(ctx, ins...)\n\treturn RunWorkerPool(ctx, unified, workers, h)\n}\n\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := FanIn(ctx, errs...)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase err, ok := <-merged:\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}\n",
        "testCode": "package channelsx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"reflect\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc collect[T any](ch <-chan T) []T {\n\tvar out []T\n\tfor v := range ch {\n\t\tout = append(out, v)\n\t}\n\treturn out\n}\n\nfunc TestFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 2)\n\tb := make(chan int, 2)\n\ta <- 1\n\ta <- 2\n\tb <- 3\n\tclose(a)\n\tclose(b)\n\tout := FanIn(ctx, a, b)\n\tgot := collect(out)\n\tif len(got) != 3 {\n\t\tt.Fatalf(\"unexpected length: %v\", got)\n\t}\n\tfor _, want := range []int{1, 2, 3} {\n\t\tif !contains(got, want) {\n\t\t\tt.Fatalf(\"missing %d in %v\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestFanOut(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor _, v := range []int{1, 2, 3} {\n\t\tin <- v\n\t}\n\tclose(in)\n\touts := FanOut(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\tmu  sync.Mutex\n\t\tall []int\n\t\twg  sync.WaitGroup\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\tvals := collect(ch)\n\t\t\tmu.Lock()\n\t\t\tall = append(all, vals...)\n\t\t\tmu.Unlock()\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif len(all) != 6 {\n\t\tt.Fatalf(\"unexpected total: %v\", all)\n\t}\n}\n\nfunc TestOrDone(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tclose(in)\n\tout := OrDone(ctx, in)\n\tif _, ok := <-out; ok {\n\t\tt.Fatal(\"channel should be closed\")\n\t}\n}\n\nfunc TestRunWorkerPool(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor i := 0; i < 3; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tvar sum atomic.Int64\n\terr := RunWorkerPool(ctx, in, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPoolWithFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 1)\n\tb := make(chan int, 1)\n\ta <- 1\n\tb <- 2\n\tclose(a)\n\tclose(b)\n\tvar sum atomic.Int64\n\terr := RunWorkerPoolWithFanIn(ctx, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t}, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPool_Error(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 1)\n\tin <- 1\n\tclose(in)\n\ttarget := errors.New(\"boom\")\n\terr := RunWorkerPool(ctx, in, 1, func(context.Context, int) error { return target })\n\tif !errors.Is(err, target) {\n\t\tt.Fatalf(\"want %v, got %v\", target, err)\n\t}\n}\n\nfunc TestFanOutWithBalancer(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 4)\n\tfor i := 0; i < 4; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\touts := FanOutWithBalancer(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\twg    sync.WaitGroup\n\t\ttotal atomic.Int64\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\ttotal.Add(int64(len(collect(ch))))\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif total.Load() != 4 {\n\t\tt.Fatalf(\"lost elements, total=%d\", total.Load())\n\t}\n}\n\nfunc TestMergeWorkerResults(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\terrCh1 := make(chan error, 1)\n\terrCh2 := make(chan error, 1)\n\terrCh1 <- nil\n\terrCh2 <- errors.New(\"fail\")\n\tclose(errCh1)\n\tclose(errCh2)\n\terr := MergeWorkerResults(ctx, errCh1, errCh2)\n\tif err == nil || err.Error() != \"fail\" {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc contains[T comparable](in []T, v T) bool {\n\tfor _, el := range in {\n\t\tif reflect.DeepEqual(el, v) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n",
        "tags": [
          "go",
          "channelsx"
        ],
        "order": 4
      },
      {
        "package": "channelsx",
        "slug": "go-channelsx-fanoutwithbalancer",
        "title": "FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).",
        "description": "Level 6 (senior-): FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).\nHint: переключайтесь между выходами, соблюдая ctx.Done().",
        "difficulty": "hard",
        "hint1": "переключайтесь между выходами, соблюдая ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Level 1 (easy): FanIn объединяет несколько входных каналов в один поток до отмены контекста.\n// Hint: поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tout := make(chan T)\n\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): FanOut транслирует значения из одного канала в n независимых каналов.\n// Hint: корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, out := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 3 (medium): OrDone проксирует значения до отмены контекста или закрытия входа.\n// Hint: при ctx.Done() возвращайте сразу, не оставляя горутин.\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 4 (medium): RunWorkerPool запускает pool из workers горутин, которые читают из in и вызывают handler.\n// Hint: завершайте работу при ctx.Done() и возвращайте первую ошибку handler.\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 5 (medium+): RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.\n// Hint: используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tif workers <= 0 || h == nil || ins == nil {\n\t\treturn nil\n\t}\n\n\tmerged := make(chan T)\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase merged <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(merged)\n\t}()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-merged:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 6 (senior-): FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).\n// Hint: переключайтесь между выходами, соблюдая ctx.Done().\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 7 (senior-): MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.\n// Hint: объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif errs == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tprocessErrs := func(err <-chan error) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase e, ok := <-err:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif e != nil {\n\t\t\t\t\thandleErr(e)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, err := range errs {\n\t\tif err == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo processErrs(err)\n\t}\n\n\twg.Wait()\n\treturn firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, ch := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase ch <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tunified := FanIn(ctx, ins...)\n\treturn RunWorkerPool(ctx, unified, workers, h)\n}\n\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := FanIn(ctx, errs...)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase err, ok := <-merged:\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}\n",
        "testCode": "package channelsx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"reflect\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc collect[T any](ch <-chan T) []T {\n\tvar out []T\n\tfor v := range ch {\n\t\tout = append(out, v)\n\t}\n\treturn out\n}\n\nfunc TestFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 2)\n\tb := make(chan int, 2)\n\ta <- 1\n\ta <- 2\n\tb <- 3\n\tclose(a)\n\tclose(b)\n\tout := FanIn(ctx, a, b)\n\tgot := collect(out)\n\tif len(got) != 3 {\n\t\tt.Fatalf(\"unexpected length: %v\", got)\n\t}\n\tfor _, want := range []int{1, 2, 3} {\n\t\tif !contains(got, want) {\n\t\t\tt.Fatalf(\"missing %d in %v\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestFanOut(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor _, v := range []int{1, 2, 3} {\n\t\tin <- v\n\t}\n\tclose(in)\n\touts := FanOut(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\tmu  sync.Mutex\n\t\tall []int\n\t\twg  sync.WaitGroup\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\tvals := collect(ch)\n\t\t\tmu.Lock()\n\t\t\tall = append(all, vals...)\n\t\t\tmu.Unlock()\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif len(all) != 6 {\n\t\tt.Fatalf(\"unexpected total: %v\", all)\n\t}\n}\n\nfunc TestOrDone(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tclose(in)\n\tout := OrDone(ctx, in)\n\tif _, ok := <-out; ok {\n\t\tt.Fatal(\"channel should be closed\")\n\t}\n}\n\nfunc TestRunWorkerPool(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor i := 0; i < 3; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tvar sum atomic.Int64\n\terr := RunWorkerPool(ctx, in, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPoolWithFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 1)\n\tb := make(chan int, 1)\n\ta <- 1\n\tb <- 2\n\tclose(a)\n\tclose(b)\n\tvar sum atomic.Int64\n\terr := RunWorkerPoolWithFanIn(ctx, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t}, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPool_Error(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 1)\n\tin <- 1\n\tclose(in)\n\ttarget := errors.New(\"boom\")\n\terr := RunWorkerPool(ctx, in, 1, func(context.Context, int) error { return target })\n\tif !errors.Is(err, target) {\n\t\tt.Fatalf(\"want %v, got %v\", target, err)\n\t}\n}\n\nfunc TestFanOutWithBalancer(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 4)\n\tfor i := 0; i < 4; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\touts := FanOutWithBalancer(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\twg    sync.WaitGroup\n\t\ttotal atomic.Int64\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\ttotal.Add(int64(len(collect(ch))))\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif total.Load() != 4 {\n\t\tt.Fatalf(\"lost elements, total=%d\", total.Load())\n\t}\n}\n\nfunc TestMergeWorkerResults(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\terrCh1 := make(chan error, 1)\n\terrCh2 := make(chan error, 1)\n\terrCh1 <- nil\n\terrCh2 <- errors.New(\"fail\")\n\tclose(errCh1)\n\tclose(errCh2)\n\terr := MergeWorkerResults(ctx, errCh1, errCh2)\n\tif err == nil || err.Error() != \"fail\" {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc contains[T comparable](in []T, v T) bool {\n\tfor _, el := range in {\n\t\tif reflect.DeepEqual(el, v) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n",
        "tags": [
          "go",
          "channelsx"
        ],
        "order": 5
      },
      {
        "package": "channelsx",
        "slug": "go-channelsx-mergeworkerresults",
        "title": "MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.",
        "description": "Level 7 (senior-): MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.\nHint: объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().",
        "difficulty": "hard",
        "hint1": "объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Level 1 (easy): FanIn объединяет несколько входных каналов в один поток до отмены контекста.\n// Hint: поднимите горутину на каждый вход и закрывайте выход после завершения всех источников.\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tout := make(chan T)\n\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): FanOut транслирует значения из одного канала в n независимых каналов.\n// Hint: корректно закрывайте каждый выходной канал и реагируйте на ctx.Done().\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, out := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 3 (medium): OrDone проксирует значения до отмены контекста или закрытия входа.\n// Hint: при ctx.Done() возвращайте сразу, не оставляя горутин.\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 4 (medium): RunWorkerPool запускает pool из workers горутин, которые читают из in и вызывают handler.\n// Hint: завершайте работу при ctx.Done() и возвращайте первую ошибку handler.\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 5 (medium+): RunWorkerPoolWithFanIn объединяет несколько каналов и обрабатывает их общим пулом.\n// Hint: используйте FanIn и переиспользуйте RunWorkerPool, аккуратно работая с контекстом.\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tif workers <= 0 || h == nil || ins == nil {\n\t\treturn nil\n\t}\n\n\tmerged := make(chan T)\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase merged <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(merged)\n\t}()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-merged:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\n// Level 6 (senior-): FanOutWithBalancer распределяет значения по n выходам максимально равномерно (round-robin).\n// Hint: переключайтесь между выходами, соблюдая ctx.Done().\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif in == nil || n <= 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, out := range outs {\n\t\t\t\tclose(out)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\n// Level 7 (senior-): MergeWorkerResults принимает несколько каналов ошибок и возвращает первую ненулевую ошибку.\n// Hint: объедините их через FanIn и прекращайте ожидание при первой ошибке или ctx.Done().\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif errs == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tprocessErrs := func(err <-chan error) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase e, ok := <-err:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif e != nil {\n\t\t\t\t\thandleErr(e)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, err := range errs {\n\t\tif err == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo processErrs(err)\n\t}\n\n\twg.Wait()\n\treturn firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage channelsx\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\nfunc FanIn[T any](ctx context.Context, ins ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tvar wg sync.WaitGroup\n\tforward := func(in <-chan T) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo forward(in)\n\t}\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc FanOut[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfor _, ch := range outs {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase ch <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc OrDone[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T)\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\ntype Handler[T any] func(context.Context, T) error\n\nfunc RunWorkerPool[T any](ctx context.Context, in <-chan T, workers int, h Handler[T]) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif h == nil || workers <= 0 || in == nil {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\trecordErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\tworker := func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif err := h(ctx, v); err != nil {\n\t\t\t\t\trecordErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo worker()\n\t}\n\twg.Wait()\n\treturn firstErr\n}\n\nfunc RunWorkerPoolWithFanIn[T any](ctx context.Context, workers int, h Handler[T], ins ...<-chan T) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tunified := FanIn(ctx, ins...)\n\treturn RunWorkerPool(ctx, unified, workers, h)\n}\n\nfunc FanOutWithBalancer[T any](ctx context.Context, in <-chan T, n int) []<-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\touts := make([]chan T, n)\n\tfor i := range outs {\n\t\touts[i] = make(chan T)\n\t}\n\tgo func() {\n\t\tdefer func() {\n\t\t\tfor _, ch := range outs {\n\t\t\t\tclose(ch)\n\t\t\t}\n\t\t}()\n\t\tidx := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttarget := outs[idx]\n\t\t\t\tidx = (idx + 1) % n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase target <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\tres := make([]<-chan T, n)\n\tfor i := range outs {\n\t\tres[i] = outs[i]\n\t}\n\treturn res\n}\n\nfunc MergeWorkerResults(ctx context.Context, errs ...<-chan error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := FanIn(ctx, errs...)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase err, ok := <-merged:\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}\n",
        "testCode": "package channelsx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"reflect\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc collect[T any](ch <-chan T) []T {\n\tvar out []T\n\tfor v := range ch {\n\t\tout = append(out, v)\n\t}\n\treturn out\n}\n\nfunc TestFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 2)\n\tb := make(chan int, 2)\n\ta <- 1\n\ta <- 2\n\tb <- 3\n\tclose(a)\n\tclose(b)\n\tout := FanIn(ctx, a, b)\n\tgot := collect(out)\n\tif len(got) != 3 {\n\t\tt.Fatalf(\"unexpected length: %v\", got)\n\t}\n\tfor _, want := range []int{1, 2, 3} {\n\t\tif !contains(got, want) {\n\t\t\tt.Fatalf(\"missing %d in %v\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestFanOut(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor _, v := range []int{1, 2, 3} {\n\t\tin <- v\n\t}\n\tclose(in)\n\touts := FanOut(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\tmu  sync.Mutex\n\t\tall []int\n\t\twg  sync.WaitGroup\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\tvals := collect(ch)\n\t\t\tmu.Lock()\n\t\t\tall = append(all, vals...)\n\t\t\tmu.Unlock()\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif len(all) != 6 {\n\t\tt.Fatalf(\"unexpected total: %v\", all)\n\t}\n}\n\nfunc TestOrDone(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tclose(in)\n\tout := OrDone(ctx, in)\n\tif _, ok := <-out; ok {\n\t\tt.Fatal(\"channel should be closed\")\n\t}\n}\n\nfunc TestRunWorkerPool(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 3)\n\tfor i := 0; i < 3; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tvar sum atomic.Int64\n\terr := RunWorkerPool(ctx, in, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPoolWithFanIn(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan int, 1)\n\tb := make(chan int, 1)\n\ta <- 1\n\tb <- 2\n\tclose(a)\n\tclose(b)\n\tvar sum atomic.Int64\n\terr := RunWorkerPoolWithFanIn(ctx, 2, func(ctx context.Context, v int) error {\n\t\tsum.Add(int64(v))\n\t\treturn nil\n\t}, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif sum.Load() != 3 {\n\t\tt.Fatalf(\"unexpected sum: %d\", sum.Load())\n\t}\n}\n\nfunc TestRunWorkerPool_Error(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 1)\n\tin <- 1\n\tclose(in)\n\ttarget := errors.New(\"boom\")\n\terr := RunWorkerPool(ctx, in, 1, func(context.Context, int) error { return target })\n\tif !errors.Is(err, target) {\n\t\tt.Fatalf(\"want %v, got %v\", target, err)\n\t}\n}\n\nfunc TestFanOutWithBalancer(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tin := make(chan int, 4)\n\tfor i := 0; i < 4; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\touts := FanOutWithBalancer(ctx, in, 2)\n\tif len(outs) != 2 {\n\t\tt.Fatalf(\"want 2 outs, got %d\", len(outs))\n\t}\n\tvar (\n\t\twg    sync.WaitGroup\n\t\ttotal atomic.Int64\n\t)\n\tfor _, ch := range outs {\n\t\twg.Add(1)\n\t\tgo func(ch <-chan int) {\n\t\t\tdefer wg.Done()\n\t\t\ttotal.Add(int64(len(collect(ch))))\n\t\t}(ch)\n\t}\n\twg.Wait()\n\tif total.Load() != 4 {\n\t\tt.Fatalf(\"lost elements, total=%d\", total.Load())\n\t}\n}\n\nfunc TestMergeWorkerResults(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\terrCh1 := make(chan error, 1)\n\terrCh2 := make(chan error, 1)\n\terrCh1 <- nil\n\terrCh2 <- errors.New(\"fail\")\n\tclose(errCh1)\n\tclose(errCh2)\n\terr := MergeWorkerResults(ctx, errCh1, errCh2)\n\tif err == nil || err.Error() != \"fail\" {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc contains[T comparable](in []T, v T) bool {\n\tfor _, el := range in {\n\t\tif reflect.DeepEqual(el, v) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n",
        "tags": [
          "go",
          "channelsx"
        ],
        "order": 6
      }
    ],
    "category": "concurrency"
  },
  {
    "name": "circuitx",
    "tasks": [
      {
        "package": "circuitx",
        "slug": "go-circuitx-new",
        "title": "конструктор Breaker задаёт исходное состояние Closed и параметры порога/таймаута/halfMax.",
        "description": "Level 1 (easy): конструктор Breaker задаёт исходное состояние Closed и параметры порога/таймаута/halfMax.\nHint: сохраните длительность openDur, чтобы переиспользовать при переходе в Open.",
        "difficulty": "easy",
        "hint1": "сохраните длительность openDur, чтобы переиспользовать при переходе в Open.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.RWMutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\n// Level 1 (easy): конструктор Breaker задаёт исходное состояние Closed и параметры порога/таймаута/halfMax.\n// Hint: сохраните длительность openDur, чтобы переиспользовать при переходе в Open.\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\n// Level 2 (medium): Do выполняет функцию в зависимости от состояния.\n// Hint: в Closed увеличивайте счётчик ошибок и открывайте выключатель при превышении порога.\n// Level 3 (medium+): В Open возвращайте ErrOpen до истечения openUntil, затем переводите в HalfOpen.\n// Level 4 (senior-): В HalfOpen допускайте до halfMax успешных попыток, при ошибке возвращайтесь к Open.\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()\n\tnow := time.Now()\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) {\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen\n\t\t}\n\t}\n\tb.mu.Unlock()\n\terr := f(ctx)\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\tif err == nil {\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++\n\t\t\tif b.halfCount >= b.halfMax {\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++\n\t\tif b.errs >= b.threshold {\n\t\t\tb.tripToOpen()\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen()\n\t}\n\treturn err\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open\n\tb.openUntil = time.Now().Add(b.openDur)\n\tb.errs = 0\n\tb.halfCount = 0\n}\n\n// Level 5 (medium): State возвращает текущее состояние выключателя.\n// Hint: защитите чтение мьютексом.\nfunc (b *Breaker) State() State {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\treturn b.state\n}\n\n// Level 6 (medium): Reset переводит выключатель в Closed и очищает счётчики.\n// Hint: сбросьте errs, halfCount и openUntil.\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\tb.state = Closed\n\tb.errs = 0\n\tb.halfCount = 0\n\tb.openUntil = time.Time{}\n}\n\n// Level 7 (medium+): RemainingHalfOpen возвращает, сколько успешных попыток осталось в HalfOpen.\n// Hint: учитывайте halfMax и halfCount, при Closed/ Open возвращайте 0.\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\tif b.state == HalfOpen {\n\t\treturn b.halfMax - b.halfCount\n\t}\n\treturn 0\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.Mutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{ // initialize breaker in closed state with provided parameters\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()       // inspect and possibly mutate state under lock\n\tnow := time.Now() // snapshot current time for threshold checks\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) { // transition from open to half-open when cooldown finished\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen // deny requests while breaker remains open\n\t\t}\n\t}\n\tb.mu.Unlock() // release lock before invoking user function\n\n\terr := f(ctx) // execute protected operation with provided context\n\n\tb.mu.Lock()         // reacquire lock to update state counters based on outcome\n\tdefer b.mu.Unlock() // ensure lock released before returning\n\n\tif err == nil { // handle successful invocation\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0 // reset consecutive error counter\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++                 // track successes allowed in half-open state\n\t\t\tif b.halfCount >= b.halfMax { // promote breaker to closed after threshold successes\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++                   // increment error counter in closed state\n\t\tif b.errs >= b.threshold { // exceed threshold -> open breaker\n\t\t\tb.tripToOpen() // move to open state and schedule reopen time\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen() // failure in half-open immediately reopens breaker\n\t}\n\treturn err // propagate original error to caller\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open                          // mark breaker as open\n\tb.openUntil = time.Now().Add(b.openDur) // compute moment to attempt half-open transition\n\tb.errs = 0                              // reset error counter for next closed phase\n\tb.halfCount = 0                         // reset half-open success counter\n}\n\nfunc (b *Breaker) State() State {\n\tb.mu.Lock()         // synchronize access to current state\n\tdefer b.mu.Unlock() // release lock after reading\n\treturn b.state      // return snapshot of breaker state\n}\n\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()               // ensure exclusive access while mutating fields\n\tdefer b.mu.Unlock()       // release lock after reset\n\tb.state = Closed          // close breaker immediately\n\tb.errs = 0                // clear accumulated error count\n\tb.halfCount = 0           // reset half-open success counter\n\tb.openUntil = time.Time{} // clear open-until timestamp\n}\n\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.Lock()                                // guard read-modify logic under lock\n\tdefer b.mu.Unlock()                        // release lock afterwards\n\tif b.state != HalfOpen || b.halfMax <= 0 { // only meaningful in half-open state\n\t\treturn 0\n\t}\n\tremaining := b.halfMax - b.halfCount // calculate remaining permitted successes\n\tif remaining < 0 {                   // prevent negative numbers when counters drift\n\t\treturn 0\n\t}\n\treturn remaining\n}\n",
        "testCode": "package circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestNewBreaker(t *testing.T) {\n\tt.Parallel()\n\tb := New(3, time.Second, 2)\n\tif b.state != Closed || b.threshold != 3 || b.halfMax != 2 {\n\t\tt.Fatalf(\"unexpected initial state: %+v\", b)\n\t}\n}\n\nfunc TestBreakerDo(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 20*time.Millisecond, 1)\n\tboom := errors.New(\"boom\")\n\tif err := b.Do(context.Background(), func(context.Context) error { return boom }); err != boom {\n\t\tt.Fatalf(\"expected original error, got %v\", err)\n\t}\n\tif err := b.Do(context.Background(), func(context.Context) error { return nil }); !errors.Is(err, ErrOpen) {\n\t\tt.Fatalf(\"expected circuit open, got %v\", err)\n\t}\n}\n\nfunc TestBreakerState(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 10*time.Millisecond, 1)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\tif state := b.State(); state != Open {\n\t\tt.Fatalf(\"expected state open, got %v\", state)\n\t}\n}\n\nfunc TestBreakerReset(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, time.Second, 1)\n\tb.errs = 5\n\tb.state = Open\n\tb.Reset()\n\tif b.State() != Closed || b.errs != 0 {\n\t\tt.Fatalf(\"expected reset to closed with zero errs: %+v\", b)\n\t}\n}\n\nfunc TestBreakerRemainingHalfOpen(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 5*time.Millisecond, 2)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\ttime.Sleep(10 * time.Millisecond)\n\t_ = b.Do(context.Background(), func(context.Context) error { return nil })\n\tif remaining := b.RemainingHalfOpen(); remaining != 1 {\n\t\tt.Fatalf(\"expected 1 remaining half-open attempt, got %d\", remaining)\n\t}\n}\n",
        "tags": [
          "go",
          "circuitx"
        ],
        "order": 0
      },
      {
        "package": "circuitx",
        "slug": "go-circuitx-do",
        "title": "Do выполняет функцию в зависимости от состояния.",
        "description": "Level 2 (medium): Do выполняет функцию в зависимости от состояния.\nHint: в Closed увеличивайте счётчик ошибок и открывайте выключатель при превышении порога.\nLevel 3 (medium+): В Open возвращайте ErrOpen до истечения openUntil, затем переводите в HalfOpen.\nLevel 4 (senior-): В HalfOpen допускайте до halfMax успешных попыток, при ошибке возвращайтесь к Open.",
        "difficulty": "medium",
        "hint1": "в Closed увеличивайте счётчик ошибок и открывайте выключатель при превышении порога.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.RWMutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\n// Level 1 (easy): конструктор Breaker задаёт исходное состояние Closed и параметры порога/таймаута/halfMax.\n// Hint: сохраните длительность openDur, чтобы переиспользовать при переходе в Open.\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\n// Level 2 (medium): Do выполняет функцию в зависимости от состояния.\n// Hint: в Closed увеличивайте счётчик ошибок и открывайте выключатель при превышении порога.\n// Level 3 (medium+): В Open возвращайте ErrOpen до истечения openUntil, затем переводите в HalfOpen.\n// Level 4 (senior-): В HalfOpen допускайте до halfMax успешных попыток, при ошибке возвращайтесь к Open.\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()\n\tnow := time.Now()\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) {\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen\n\t\t}\n\t}\n\tb.mu.Unlock()\n\terr := f(ctx)\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\tif err == nil {\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++\n\t\t\tif b.halfCount >= b.halfMax {\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++\n\t\tif b.errs >= b.threshold {\n\t\t\tb.tripToOpen()\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen()\n\t}\n\treturn err\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open\n\tb.openUntil = time.Now().Add(b.openDur)\n\tb.errs = 0\n\tb.halfCount = 0\n}\n\n// Level 5 (medium): State возвращает текущее состояние выключателя.\n// Hint: защитите чтение мьютексом.\nfunc (b *Breaker) State() State {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\treturn b.state\n}\n\n// Level 6 (medium): Reset переводит выключатель в Closed и очищает счётчики.\n// Hint: сбросьте errs, halfCount и openUntil.\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\tb.state = Closed\n\tb.errs = 0\n\tb.halfCount = 0\n\tb.openUntil = time.Time{}\n}\n\n// Level 7 (medium+): RemainingHalfOpen возвращает, сколько успешных попыток осталось в HalfOpen.\n// Hint: учитывайте halfMax и halfCount, при Closed/ Open возвращайте 0.\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\tif b.state == HalfOpen {\n\t\treturn b.halfMax - b.halfCount\n\t}\n\treturn 0\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.Mutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{ // initialize breaker in closed state with provided parameters\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()       // inspect and possibly mutate state under lock\n\tnow := time.Now() // snapshot current time for threshold checks\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) { // transition from open to half-open when cooldown finished\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen // deny requests while breaker remains open\n\t\t}\n\t}\n\tb.mu.Unlock() // release lock before invoking user function\n\n\terr := f(ctx) // execute protected operation with provided context\n\n\tb.mu.Lock()         // reacquire lock to update state counters based on outcome\n\tdefer b.mu.Unlock() // ensure lock released before returning\n\n\tif err == nil { // handle successful invocation\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0 // reset consecutive error counter\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++                 // track successes allowed in half-open state\n\t\t\tif b.halfCount >= b.halfMax { // promote breaker to closed after threshold successes\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++                   // increment error counter in closed state\n\t\tif b.errs >= b.threshold { // exceed threshold -> open breaker\n\t\t\tb.tripToOpen() // move to open state and schedule reopen time\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen() // failure in half-open immediately reopens breaker\n\t}\n\treturn err // propagate original error to caller\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open                          // mark breaker as open\n\tb.openUntil = time.Now().Add(b.openDur) // compute moment to attempt half-open transition\n\tb.errs = 0                              // reset error counter for next closed phase\n\tb.halfCount = 0                         // reset half-open success counter\n}\n\nfunc (b *Breaker) State() State {\n\tb.mu.Lock()         // synchronize access to current state\n\tdefer b.mu.Unlock() // release lock after reading\n\treturn b.state      // return snapshot of breaker state\n}\n\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()               // ensure exclusive access while mutating fields\n\tdefer b.mu.Unlock()       // release lock after reset\n\tb.state = Closed          // close breaker immediately\n\tb.errs = 0                // clear accumulated error count\n\tb.halfCount = 0           // reset half-open success counter\n\tb.openUntil = time.Time{} // clear open-until timestamp\n}\n\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.Lock()                                // guard read-modify logic under lock\n\tdefer b.mu.Unlock()                        // release lock afterwards\n\tif b.state != HalfOpen || b.halfMax <= 0 { // only meaningful in half-open state\n\t\treturn 0\n\t}\n\tremaining := b.halfMax - b.halfCount // calculate remaining permitted successes\n\tif remaining < 0 {                   // prevent negative numbers when counters drift\n\t\treturn 0\n\t}\n\treturn remaining\n}\n",
        "testCode": "package circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestNewBreaker(t *testing.T) {\n\tt.Parallel()\n\tb := New(3, time.Second, 2)\n\tif b.state != Closed || b.threshold != 3 || b.halfMax != 2 {\n\t\tt.Fatalf(\"unexpected initial state: %+v\", b)\n\t}\n}\n\nfunc TestBreakerDo(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 20*time.Millisecond, 1)\n\tboom := errors.New(\"boom\")\n\tif err := b.Do(context.Background(), func(context.Context) error { return boom }); err != boom {\n\t\tt.Fatalf(\"expected original error, got %v\", err)\n\t}\n\tif err := b.Do(context.Background(), func(context.Context) error { return nil }); !errors.Is(err, ErrOpen) {\n\t\tt.Fatalf(\"expected circuit open, got %v\", err)\n\t}\n}\n\nfunc TestBreakerState(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 10*time.Millisecond, 1)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\tif state := b.State(); state != Open {\n\t\tt.Fatalf(\"expected state open, got %v\", state)\n\t}\n}\n\nfunc TestBreakerReset(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, time.Second, 1)\n\tb.errs = 5\n\tb.state = Open\n\tb.Reset()\n\tif b.State() != Closed || b.errs != 0 {\n\t\tt.Fatalf(\"expected reset to closed with zero errs: %+v\", b)\n\t}\n}\n\nfunc TestBreakerRemainingHalfOpen(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 5*time.Millisecond, 2)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\ttime.Sleep(10 * time.Millisecond)\n\t_ = b.Do(context.Background(), func(context.Context) error { return nil })\n\tif remaining := b.RemainingHalfOpen(); remaining != 1 {\n\t\tt.Fatalf(\"expected 1 remaining half-open attempt, got %d\", remaining)\n\t}\n}\n",
        "tags": [
          "go",
          "circuitx"
        ],
        "order": 1
      },
      {
        "package": "circuitx",
        "slug": "go-circuitx-state",
        "title": "State возвращает текущее состояние выключателя.",
        "description": "Level 5 (medium): State возвращает текущее состояние выключателя.\nHint: защитите чтение мьютексом.",
        "difficulty": "medium",
        "hint1": "защитите чтение мьютексом.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.RWMutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\n// Level 1 (easy): конструктор Breaker задаёт исходное состояние Closed и параметры порога/таймаута/halfMax.\n// Hint: сохраните длительность openDur, чтобы переиспользовать при переходе в Open.\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\n// Level 2 (medium): Do выполняет функцию в зависимости от состояния.\n// Hint: в Closed увеличивайте счётчик ошибок и открывайте выключатель при превышении порога.\n// Level 3 (medium+): В Open возвращайте ErrOpen до истечения openUntil, затем переводите в HalfOpen.\n// Level 4 (senior-): В HalfOpen допускайте до halfMax успешных попыток, при ошибке возвращайтесь к Open.\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()\n\tnow := time.Now()\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) {\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen\n\t\t}\n\t}\n\tb.mu.Unlock()\n\terr := f(ctx)\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\tif err == nil {\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++\n\t\t\tif b.halfCount >= b.halfMax {\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++\n\t\tif b.errs >= b.threshold {\n\t\t\tb.tripToOpen()\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen()\n\t}\n\treturn err\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open\n\tb.openUntil = time.Now().Add(b.openDur)\n\tb.errs = 0\n\tb.halfCount = 0\n}\n\n// Level 5 (medium): State возвращает текущее состояние выключателя.\n// Hint: защитите чтение мьютексом.\nfunc (b *Breaker) State() State {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\treturn b.state\n}\n\n// Level 6 (medium): Reset переводит выключатель в Closed и очищает счётчики.\n// Hint: сбросьте errs, halfCount и openUntil.\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\tb.state = Closed\n\tb.errs = 0\n\tb.halfCount = 0\n\tb.openUntil = time.Time{}\n}\n\n// Level 7 (medium+): RemainingHalfOpen возвращает, сколько успешных попыток осталось в HalfOpen.\n// Hint: учитывайте halfMax и halfCount, при Closed/ Open возвращайте 0.\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\tif b.state == HalfOpen {\n\t\treturn b.halfMax - b.halfCount\n\t}\n\treturn 0\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.Mutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{ // initialize breaker in closed state with provided parameters\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()       // inspect and possibly mutate state under lock\n\tnow := time.Now() // snapshot current time for threshold checks\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) { // transition from open to half-open when cooldown finished\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen // deny requests while breaker remains open\n\t\t}\n\t}\n\tb.mu.Unlock() // release lock before invoking user function\n\n\terr := f(ctx) // execute protected operation with provided context\n\n\tb.mu.Lock()         // reacquire lock to update state counters based on outcome\n\tdefer b.mu.Unlock() // ensure lock released before returning\n\n\tif err == nil { // handle successful invocation\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0 // reset consecutive error counter\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++                 // track successes allowed in half-open state\n\t\t\tif b.halfCount >= b.halfMax { // promote breaker to closed after threshold successes\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++                   // increment error counter in closed state\n\t\tif b.errs >= b.threshold { // exceed threshold -> open breaker\n\t\t\tb.tripToOpen() // move to open state and schedule reopen time\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen() // failure in half-open immediately reopens breaker\n\t}\n\treturn err // propagate original error to caller\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open                          // mark breaker as open\n\tb.openUntil = time.Now().Add(b.openDur) // compute moment to attempt half-open transition\n\tb.errs = 0                              // reset error counter for next closed phase\n\tb.halfCount = 0                         // reset half-open success counter\n}\n\nfunc (b *Breaker) State() State {\n\tb.mu.Lock()         // synchronize access to current state\n\tdefer b.mu.Unlock() // release lock after reading\n\treturn b.state      // return snapshot of breaker state\n}\n\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()               // ensure exclusive access while mutating fields\n\tdefer b.mu.Unlock()       // release lock after reset\n\tb.state = Closed          // close breaker immediately\n\tb.errs = 0                // clear accumulated error count\n\tb.halfCount = 0           // reset half-open success counter\n\tb.openUntil = time.Time{} // clear open-until timestamp\n}\n\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.Lock()                                // guard read-modify logic under lock\n\tdefer b.mu.Unlock()                        // release lock afterwards\n\tif b.state != HalfOpen || b.halfMax <= 0 { // only meaningful in half-open state\n\t\treturn 0\n\t}\n\tremaining := b.halfMax - b.halfCount // calculate remaining permitted successes\n\tif remaining < 0 {                   // prevent negative numbers when counters drift\n\t\treturn 0\n\t}\n\treturn remaining\n}\n",
        "testCode": "package circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestNewBreaker(t *testing.T) {\n\tt.Parallel()\n\tb := New(3, time.Second, 2)\n\tif b.state != Closed || b.threshold != 3 || b.halfMax != 2 {\n\t\tt.Fatalf(\"unexpected initial state: %+v\", b)\n\t}\n}\n\nfunc TestBreakerDo(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 20*time.Millisecond, 1)\n\tboom := errors.New(\"boom\")\n\tif err := b.Do(context.Background(), func(context.Context) error { return boom }); err != boom {\n\t\tt.Fatalf(\"expected original error, got %v\", err)\n\t}\n\tif err := b.Do(context.Background(), func(context.Context) error { return nil }); !errors.Is(err, ErrOpen) {\n\t\tt.Fatalf(\"expected circuit open, got %v\", err)\n\t}\n}\n\nfunc TestBreakerState(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 10*time.Millisecond, 1)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\tif state := b.State(); state != Open {\n\t\tt.Fatalf(\"expected state open, got %v\", state)\n\t}\n}\n\nfunc TestBreakerReset(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, time.Second, 1)\n\tb.errs = 5\n\tb.state = Open\n\tb.Reset()\n\tif b.State() != Closed || b.errs != 0 {\n\t\tt.Fatalf(\"expected reset to closed with zero errs: %+v\", b)\n\t}\n}\n\nfunc TestBreakerRemainingHalfOpen(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 5*time.Millisecond, 2)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\ttime.Sleep(10 * time.Millisecond)\n\t_ = b.Do(context.Background(), func(context.Context) error { return nil })\n\tif remaining := b.RemainingHalfOpen(); remaining != 1 {\n\t\tt.Fatalf(\"expected 1 remaining half-open attempt, got %d\", remaining)\n\t}\n}\n",
        "tags": [
          "go",
          "circuitx"
        ],
        "order": 4
      },
      {
        "package": "circuitx",
        "slug": "go-circuitx-reset",
        "title": "Reset переводит выключатель в Closed и очищает счётчики.",
        "description": "Level 6 (medium): Reset переводит выключатель в Closed и очищает счётчики.\nHint: сбросьте errs, halfCount и openUntil.",
        "difficulty": "medium",
        "hint1": "сбросьте errs, halfCount и openUntil.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.RWMutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\n// Level 1 (easy): конструктор Breaker задаёт исходное состояние Closed и параметры порога/таймаута/halfMax.\n// Hint: сохраните длительность openDur, чтобы переиспользовать при переходе в Open.\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\n// Level 2 (medium): Do выполняет функцию в зависимости от состояния.\n// Hint: в Closed увеличивайте счётчик ошибок и открывайте выключатель при превышении порога.\n// Level 3 (medium+): В Open возвращайте ErrOpen до истечения openUntil, затем переводите в HalfOpen.\n// Level 4 (senior-): В HalfOpen допускайте до halfMax успешных попыток, при ошибке возвращайтесь к Open.\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()\n\tnow := time.Now()\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) {\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen\n\t\t}\n\t}\n\tb.mu.Unlock()\n\terr := f(ctx)\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\tif err == nil {\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++\n\t\t\tif b.halfCount >= b.halfMax {\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++\n\t\tif b.errs >= b.threshold {\n\t\t\tb.tripToOpen()\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen()\n\t}\n\treturn err\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open\n\tb.openUntil = time.Now().Add(b.openDur)\n\tb.errs = 0\n\tb.halfCount = 0\n}\n\n// Level 5 (medium): State возвращает текущее состояние выключателя.\n// Hint: защитите чтение мьютексом.\nfunc (b *Breaker) State() State {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\treturn b.state\n}\n\n// Level 6 (medium): Reset переводит выключатель в Closed и очищает счётчики.\n// Hint: сбросьте errs, halfCount и openUntil.\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\tb.state = Closed\n\tb.errs = 0\n\tb.halfCount = 0\n\tb.openUntil = time.Time{}\n}\n\n// Level 7 (medium+): RemainingHalfOpen возвращает, сколько успешных попыток осталось в HalfOpen.\n// Hint: учитывайте halfMax и halfCount, при Closed/ Open возвращайте 0.\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\tif b.state == HalfOpen {\n\t\treturn b.halfMax - b.halfCount\n\t}\n\treturn 0\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.Mutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{ // initialize breaker in closed state with provided parameters\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()       // inspect and possibly mutate state under lock\n\tnow := time.Now() // snapshot current time for threshold checks\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) { // transition from open to half-open when cooldown finished\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen // deny requests while breaker remains open\n\t\t}\n\t}\n\tb.mu.Unlock() // release lock before invoking user function\n\n\terr := f(ctx) // execute protected operation with provided context\n\n\tb.mu.Lock()         // reacquire lock to update state counters based on outcome\n\tdefer b.mu.Unlock() // ensure lock released before returning\n\n\tif err == nil { // handle successful invocation\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0 // reset consecutive error counter\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++                 // track successes allowed in half-open state\n\t\t\tif b.halfCount >= b.halfMax { // promote breaker to closed after threshold successes\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++                   // increment error counter in closed state\n\t\tif b.errs >= b.threshold { // exceed threshold -> open breaker\n\t\t\tb.tripToOpen() // move to open state and schedule reopen time\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen() // failure in half-open immediately reopens breaker\n\t}\n\treturn err // propagate original error to caller\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open                          // mark breaker as open\n\tb.openUntil = time.Now().Add(b.openDur) // compute moment to attempt half-open transition\n\tb.errs = 0                              // reset error counter for next closed phase\n\tb.halfCount = 0                         // reset half-open success counter\n}\n\nfunc (b *Breaker) State() State {\n\tb.mu.Lock()         // synchronize access to current state\n\tdefer b.mu.Unlock() // release lock after reading\n\treturn b.state      // return snapshot of breaker state\n}\n\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()               // ensure exclusive access while mutating fields\n\tdefer b.mu.Unlock()       // release lock after reset\n\tb.state = Closed          // close breaker immediately\n\tb.errs = 0                // clear accumulated error count\n\tb.halfCount = 0           // reset half-open success counter\n\tb.openUntil = time.Time{} // clear open-until timestamp\n}\n\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.Lock()                                // guard read-modify logic under lock\n\tdefer b.mu.Unlock()                        // release lock afterwards\n\tif b.state != HalfOpen || b.halfMax <= 0 { // only meaningful in half-open state\n\t\treturn 0\n\t}\n\tremaining := b.halfMax - b.halfCount // calculate remaining permitted successes\n\tif remaining < 0 {                   // prevent negative numbers when counters drift\n\t\treturn 0\n\t}\n\treturn remaining\n}\n",
        "testCode": "package circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestNewBreaker(t *testing.T) {\n\tt.Parallel()\n\tb := New(3, time.Second, 2)\n\tif b.state != Closed || b.threshold != 3 || b.halfMax != 2 {\n\t\tt.Fatalf(\"unexpected initial state: %+v\", b)\n\t}\n}\n\nfunc TestBreakerDo(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 20*time.Millisecond, 1)\n\tboom := errors.New(\"boom\")\n\tif err := b.Do(context.Background(), func(context.Context) error { return boom }); err != boom {\n\t\tt.Fatalf(\"expected original error, got %v\", err)\n\t}\n\tif err := b.Do(context.Background(), func(context.Context) error { return nil }); !errors.Is(err, ErrOpen) {\n\t\tt.Fatalf(\"expected circuit open, got %v\", err)\n\t}\n}\n\nfunc TestBreakerState(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 10*time.Millisecond, 1)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\tif state := b.State(); state != Open {\n\t\tt.Fatalf(\"expected state open, got %v\", state)\n\t}\n}\n\nfunc TestBreakerReset(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, time.Second, 1)\n\tb.errs = 5\n\tb.state = Open\n\tb.Reset()\n\tif b.State() != Closed || b.errs != 0 {\n\t\tt.Fatalf(\"expected reset to closed with zero errs: %+v\", b)\n\t}\n}\n\nfunc TestBreakerRemainingHalfOpen(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 5*time.Millisecond, 2)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\ttime.Sleep(10 * time.Millisecond)\n\t_ = b.Do(context.Background(), func(context.Context) error { return nil })\n\tif remaining := b.RemainingHalfOpen(); remaining != 1 {\n\t\tt.Fatalf(\"expected 1 remaining half-open attempt, got %d\", remaining)\n\t}\n}\n",
        "tags": [
          "go",
          "circuitx"
        ],
        "order": 5
      },
      {
        "package": "circuitx",
        "slug": "go-circuitx-remaininghalfopen",
        "title": "RemainingHalfOpen возвращает, сколько успешных попыток осталось в HalfOpen.",
        "description": "Level 7 (medium+): RemainingHalfOpen возвращает, сколько успешных попыток осталось в HalfOpen.\nHint: учитывайте halfMax и halfCount, при Closed/ Open возвращайте 0.",
        "difficulty": "medium",
        "hint1": "учитывайте halfMax и halfCount, при Closed/ Open возвращайте 0.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.RWMutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\n// Level 1 (easy): конструктор Breaker задаёт исходное состояние Closed и параметры порога/таймаута/halfMax.\n// Hint: сохраните длительность openDur, чтобы переиспользовать при переходе в Open.\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\n// Level 2 (medium): Do выполняет функцию в зависимости от состояния.\n// Hint: в Closed увеличивайте счётчик ошибок и открывайте выключатель при превышении порога.\n// Level 3 (medium+): В Open возвращайте ErrOpen до истечения openUntil, затем переводите в HalfOpen.\n// Level 4 (senior-): В HalfOpen допускайте до halfMax успешных попыток, при ошибке возвращайтесь к Open.\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()\n\tnow := time.Now()\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) {\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen\n\t\t}\n\t}\n\tb.mu.Unlock()\n\terr := f(ctx)\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\tif err == nil {\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++\n\t\t\tif b.halfCount >= b.halfMax {\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++\n\t\tif b.errs >= b.threshold {\n\t\t\tb.tripToOpen()\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen()\n\t}\n\treturn err\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open\n\tb.openUntil = time.Now().Add(b.openDur)\n\tb.errs = 0\n\tb.halfCount = 0\n}\n\n// Level 5 (medium): State возвращает текущее состояние выключателя.\n// Hint: защитите чтение мьютексом.\nfunc (b *Breaker) State() State {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\treturn b.state\n}\n\n// Level 6 (medium): Reset переводит выключатель в Closed и очищает счётчики.\n// Hint: сбросьте errs, halfCount и openUntil.\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\tb.state = Closed\n\tb.errs = 0\n\tb.halfCount = 0\n\tb.openUntil = time.Time{}\n}\n\n// Level 7 (medium+): RemainingHalfOpen возвращает, сколько успешных попыток осталось в HalfOpen.\n// Hint: учитывайте halfMax и halfCount, при Closed/ Open возвращайте 0.\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.RLock()\n\tdefer b.mu.RUnlock()\n\tif b.state == HalfOpen {\n\t\treturn b.halfMax - b.halfCount\n\t}\n\treturn 0\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ErrOpen = errors.New(\"circuit open\")\n\ntype State int\n\nconst (\n\tClosed State = iota\n\tOpen\n\tHalfOpen\n)\n\ntype Breaker struct {\n\tmu        sync.Mutex\n\tstate     State\n\terrs      int\n\tthreshold int\n\topenUntil time.Time\n\topenDur   time.Duration\n\thalfMax   int\n\thalfCount int\n}\n\nfunc New(threshold int, openDur time.Duration, halfMax int) *Breaker {\n\treturn &Breaker{ // initialize breaker in closed state with provided parameters\n\t\tstate:     Closed,\n\t\tthreshold: threshold,\n\t\topenDur:   openDur,\n\t\thalfMax:   halfMax,\n\t}\n}\n\nfunc (b *Breaker) Do(ctx context.Context, f func(context.Context) error) error {\n\tb.mu.Lock()       // inspect and possibly mutate state under lock\n\tnow := time.Now() // snapshot current time for threshold checks\n\tswitch b.state {\n\tcase Open:\n\t\tif now.After(b.openUntil) { // transition from open to half-open when cooldown finished\n\t\t\tb.state = HalfOpen\n\t\t\tb.halfCount = 0\n\t\t} else {\n\t\t\tb.mu.Unlock()\n\t\t\treturn ErrOpen // deny requests while breaker remains open\n\t\t}\n\t}\n\tb.mu.Unlock() // release lock before invoking user function\n\n\terr := f(ctx) // execute protected operation with provided context\n\n\tb.mu.Lock()         // reacquire lock to update state counters based on outcome\n\tdefer b.mu.Unlock() // ensure lock released before returning\n\n\tif err == nil { // handle successful invocation\n\t\tswitch b.state {\n\t\tcase Closed:\n\t\t\tb.errs = 0 // reset consecutive error counter\n\t\tcase HalfOpen:\n\t\t\tb.halfCount++                 // track successes allowed in half-open state\n\t\t\tif b.halfCount >= b.halfMax { // promote breaker to closed after threshold successes\n\t\t\t\tb.state = Closed\n\t\t\t\tb.errs = 0\n\t\t\t\tb.halfCount = 0\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tswitch b.state {\n\tcase Closed:\n\t\tb.errs++                   // increment error counter in closed state\n\t\tif b.errs >= b.threshold { // exceed threshold -> open breaker\n\t\t\tb.tripToOpen() // move to open state and schedule reopen time\n\t\t}\n\tcase HalfOpen:\n\t\tb.tripToOpen() // failure in half-open immediately reopens breaker\n\t}\n\treturn err // propagate original error to caller\n}\n\nfunc (b *Breaker) tripToOpen() {\n\tb.state = Open                          // mark breaker as open\n\tb.openUntil = time.Now().Add(b.openDur) // compute moment to attempt half-open transition\n\tb.errs = 0                              // reset error counter for next closed phase\n\tb.halfCount = 0                         // reset half-open success counter\n}\n\nfunc (b *Breaker) State() State {\n\tb.mu.Lock()         // synchronize access to current state\n\tdefer b.mu.Unlock() // release lock after reading\n\treturn b.state      // return snapshot of breaker state\n}\n\nfunc (b *Breaker) Reset() {\n\tb.mu.Lock()               // ensure exclusive access while mutating fields\n\tdefer b.mu.Unlock()       // release lock after reset\n\tb.state = Closed          // close breaker immediately\n\tb.errs = 0                // clear accumulated error count\n\tb.halfCount = 0           // reset half-open success counter\n\tb.openUntil = time.Time{} // clear open-until timestamp\n}\n\nfunc (b *Breaker) RemainingHalfOpen() int {\n\tb.mu.Lock()                                // guard read-modify logic under lock\n\tdefer b.mu.Unlock()                        // release lock afterwards\n\tif b.state != HalfOpen || b.halfMax <= 0 { // only meaningful in half-open state\n\t\treturn 0\n\t}\n\tremaining := b.halfMax - b.halfCount // calculate remaining permitted successes\n\tif remaining < 0 {                   // prevent negative numbers when counters drift\n\t\treturn 0\n\t}\n\treturn remaining\n}\n",
        "testCode": "package circuitx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestNewBreaker(t *testing.T) {\n\tt.Parallel()\n\tb := New(3, time.Second, 2)\n\tif b.state != Closed || b.threshold != 3 || b.halfMax != 2 {\n\t\tt.Fatalf(\"unexpected initial state: %+v\", b)\n\t}\n}\n\nfunc TestBreakerDo(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 20*time.Millisecond, 1)\n\tboom := errors.New(\"boom\")\n\tif err := b.Do(context.Background(), func(context.Context) error { return boom }); err != boom {\n\t\tt.Fatalf(\"expected original error, got %v\", err)\n\t}\n\tif err := b.Do(context.Background(), func(context.Context) error { return nil }); !errors.Is(err, ErrOpen) {\n\t\tt.Fatalf(\"expected circuit open, got %v\", err)\n\t}\n}\n\nfunc TestBreakerState(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 10*time.Millisecond, 1)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\tif state := b.State(); state != Open {\n\t\tt.Fatalf(\"expected state open, got %v\", state)\n\t}\n}\n\nfunc TestBreakerReset(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, time.Second, 1)\n\tb.errs = 5\n\tb.state = Open\n\tb.Reset()\n\tif b.State() != Closed || b.errs != 0 {\n\t\tt.Fatalf(\"expected reset to closed with zero errs: %+v\", b)\n\t}\n}\n\nfunc TestBreakerRemainingHalfOpen(t *testing.T) {\n\tt.Parallel()\n\tb := New(1, 5*time.Millisecond, 2)\n\t_ = b.Do(context.Background(), func(context.Context) error { return errors.New(\"fail\") })\n\ttime.Sleep(10 * time.Millisecond)\n\t_ = b.Do(context.Background(), func(context.Context) error { return nil })\n\tif remaining := b.RemainingHalfOpen(); remaining != 1 {\n\t\tt.Fatalf(\"expected 1 remaining half-open attempt, got %d\", remaining)\n\t}\n}\n",
        "tags": [
          "go",
          "circuitx"
        ],
        "order": 6
      }
    ],
    "category": "production"
  },
  {
    "name": "concurrency",
    "tasks": [
      {
        "package": "concurrency",
        "slug": "go-concurrency-dowithtimeout",
        "title": "запустить f в горутине и дождаться завершения или таймаута d.",
        "description": "Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\nHint: используйте context.WithTimeout и канал завершения.",
        "difficulty": "easy",
        "hint1": "используйте context.WithTimeout и канал завершения.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 0
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-dowithdeadline",
        "title": "использовать deadline для ожидания выполнения f.",
        "description": "Level 2 (easy+): использовать deadline для ожидания выполнения f.\nHint: context.WithDeadline упростит ожидание таймера.",
        "difficulty": "easy",
        "hint1": "context.WithDeadline упростит ожидание таймера.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 1
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-dowithcancel",
        "title": "создать производный контекст с cancel и передать его в f.",
        "description": "Level 3 (medium): создать производный контекст с cancel и передать его в f.\nHint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.",
        "difficulty": "medium",
        "hint1": "запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 2
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-notifycancel",
        "title": "вернуть канал, закрывающийся при отмене контекста.",
        "description": "Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\nHint: создайте канал и закройте его, когда ctx.Done() сработает.",
        "difficulty": "medium",
        "hint1": "создайте канал и закройте его, когда ctx.Done() сработает.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 3
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-waitforsignal",
        "title": "дождаться закрытия сигнального канала или ctx.Done().",
        "description": "Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\nHint: достаточно одного select с двумя кейсами.",
        "difficulty": "medium",
        "hint1": "достаточно одного select с двумя кейсами.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 4
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-waitall",
        "title": "дождаться закрытия всех сигналов.",
        "description": "Level 6 (medium+): дождаться закрытия всех сигналов.\nHint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.",
        "difficulty": "medium",
        "hint1": "запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 5
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-waitany",
        "title": "дождаться первого закрытого сигнала и вернуть его индекс.",
        "description": "Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\nHint: создайте дочерний контекст и отменяйте его после получения первого индекса.",
        "difficulty": "medium",
        "hint1": "создайте дочерний контекст и отменяйте его после получения первого индекса.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 6
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-rununtil",
        "title": "вызывать f до закрытия done или ctx.Done().",
        "description": "Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\nTask: реализуйте цикл, который повторно вызывает f, пока не закроется done\nили пока родительский контекст не будет отменён.\nHint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.",
        "difficulty": "medium",
        "hint1": "проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 7
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-retrywithcontext",
        "title": "повторять fn до успеха/исчерпания попыток/отмены контекста.",
        "description": "Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\nTask: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\nмежду повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\nHint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.",
        "difficulty": "hard",
        "hint1": "сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 8
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-heartbeat",
        "title": "отправлять heartbeat с периодом interval до отмены контекста.",
        "description": "Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\nTask: вызывайте send сразу и затем периодически, используя заданный интервал,\nпока контекст не будет отменён.\nHint: time.NewTicker + дополнительный первичный вызов send().",
        "difficulty": "hard",
        "hint1": "time.NewTicker + дополнительный первичный вызов send().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): запустить f в горутине и дождаться завершения или таймаута d.\n// Hint: используйте context.WithTimeout и канал завершения.\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\n// Level 2 (easy+): использовать deadline для ожидания выполнения f.\n// Hint: context.WithDeadline упростит ожидание таймера.\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\n// Level 3 (medium): создать производный контекст с cancel и передать его в f.\n// Hint: запустите f в горутине и не забудьте вызвать cancel, чтобы f завершилась.\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\n// Level 4 (medium): вернуть канал, закрывающийся при отмене контекста.\n// Hint: создайте канал и закройте его, когда ctx.Done() сработает.\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn done\n}\n\n// Level 5 (medium): дождаться закрытия сигнального канала или ctx.Done().\n// Hint: достаточно одного select с двумя кейсами.\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\n// Level 6 (medium+): дождаться закрытия всех сигналов.\n// Hint: запустите горутину на каждый сигнал и дождитесь WaitGroup или общего канала.\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, sig := range signals {\n\t\t\tsig := sig\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-sig:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\n// Level 7 (medium+): дождаться первого закрытого сигнала и вернуть его индекс.\n// Hint: создайте дочерний контекст и отменяйте его после получения первого индекса.\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tres := make(chan int, 1)\n\tfor i, sig := range signals {\n\t\ti := i\n\t\tgo func(sig <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxWithCancel.Done():\n\t\t\tcase <-sig:\n\t\t\t\tselect {\n\t\t\t\tcase res <- i:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sig)\n\t}\n\n\tselect {\n\tcase <-ctxWithCancel.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-res:\n\t\treturn idx, nil\n\t}\n}\n\n// Level 8 (medium+): вызывать f до закрытия done или ctx.Done().\n// Task: реализуйте цикл, который повторно вызывает f, пока не закроется done\n// или пока родительский контекст не будет отменён.\n// Hint: проверяйте отмену перед каждой итерацией, чтобы не делать лишних вызовов.\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tf()\n\t\t}\n\t}\n}\n\n// Level 9 (senior-): повторять fn до успеха/исчерпания попыток/отмены контекста.\n// Task: организуйте серию попыток вызова fn, учитывая максимум attempts и задержку\n// между повторами, и завершайте работу при первом успешном выполнении или отмене контекста.\n// Hint: сохраняйте последнюю ошибку и делайте паузу между ретраями через time.NewTimer.\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif attempt >= attempts {\n\t\t\tbreak\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): отправлять heartbeat с периодом interval до отмены контекста.\n// Task: вызывайте send сразу и затем периодически, используя заданный интервал,\n// пока контекст не будет отменён.\n// Hint: time.NewTicker + дополнительный первичный вызов send().\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 9
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-gen",
        "title": "создать источник, передающий nums и закрывающий канал.",
        "description": "Level 1 (easy): создать источник, передающий nums и закрывающий канал.\nHint: верните канал и заполните его значениями в отдельной горутине.",
        "difficulty": "easy",
        "hint1": "верните канал и заполните его значениями в отдельной горутине.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 0
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-genwithcontext",
        "title": "источник с отменой по контексту.",
        "description": "Level 2 (easy+): источник с отменой по контексту.\nHint: отправляйте значения через select, обрабатывая ctx.Done().",
        "difficulty": "easy",
        "hint1": "отправляйте значения через select, обрабатывая ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 1
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-square",
        "title": "возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.",
        "description": "Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\nHint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.",
        "difficulty": "medium",
        "hint1": "поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 2
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-squarestage",
        "title": "вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.",
        "description": "Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\nHint: Stage должен закрыть выход при завершении, уважать ctx.Done().",
        "difficulty": "medium",
        "hint1": "Stage должен закрыть выход при завершении, уважать ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 3
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-multiplystage",
        "title": "Stage, умножающий поток на factor.",
        "description": "Level 5 (medium): Stage, умножающий поток на factor.\nHint: для каждого значения считайте ctx.Done() и отправляйте произведение.",
        "difficulty": "medium",
        "hint1": "для каждого значения считайте ctx.Done() и отправляйте произведение.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 4
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-filterstage",
        "title": "Stage, отфильтровывающий значения по predicate.",
        "description": "Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\nHint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.",
        "difficulty": "medium",
        "hint1": "пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 5
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-takestage",
        "title": "Stage, пропускающий только первые n значений.",
        "description": "Level 7 (medium+): Stage, пропускающий только первые n значений.\nHint: счётчик переданных значений поможет остановиться вовремя.",
        "difficulty": "medium",
        "hint1": "счётчик переданных значений поможет остановиться вовремя.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 6
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-fanin",
        "title": "реализовать Fan-In для нескольких входов с отменой по контексту.",
        "description": "Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\nHint: используйте WaitGroup и закрывайте выход после завершения всех источников.",
        "difficulty": "medium",
        "hint1": "используйте WaitGroup и закрывайте выход после завершения всех источников.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 7
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-sum",
        "title": "собрать сумму значений канала.",
        "description": "Level 9 (medium+): собрать сумму значений канала.\nHint: просто итерируйтесь по каналу до закрытия.",
        "difficulty": "medium",
        "hint1": "просто итерируйтесь по каналу до закрытия.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 8
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-buildpipeline",
        "title": "BuildPipeline должен выстроить цепочку Stage: первый читает из in,",
        "description": "Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\nкаждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\nHint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.",
        "difficulty": "hard",
        "hint1": "при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n)\n\n// Stage описывает обработчик внутри конвейера.\ntype Stage func(context.Context, <-chan int) <-chan int\n\n// Level 1 (easy): создать источник, передающий nums и закрывающий канал.\n// Hint: верните канал и заполните его значениями в отдельной горутине.\nfunc Gen(nums ...int) <-chan int {\n\tout := make(chan int)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tout <- num\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 2 (easy+): источник с отменой по контексту.\n// Hint: отправляйте значения через select, обрабатывая ctx.Done().\nfunc GenWithContext(ctx context.Context, nums ...int) <-chan int {\n\tout := make(chan int)\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(nums) == 0 {\n\t\treturn out\n\t}\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor _, num := range nums {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- num:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): возвратить канал квадратов чисел из in с параллельной обработкой на workers горутин.\n// Hint: поднимите несколько воркеров, каждый читает из общего входа и пишет в общий выход.\nfunc Square(in <-chan int, workers int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor num := range in {\n\t\t\tout <- num * num\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\n// Level 4 (medium): вернуть Stage, который возводит числа в квадрат с заданным числом воркеров.\n// Hint: Stage должен закрыть выход при завершении, уважать ctx.Done().\nfunc SquareStage(workers int) Stage {\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(workers)\n\t\tfor i := 0; i < workers; i++ {\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v * v:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\n\t\tgo func() {\n\t\t\twg.Wait()\n\t\t\tclose(out)\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 5 (medium): Stage, умножающий поток на factor.\n// Hint: для каждого значения считайте ctx.Done() и отправляйте произведение.\nfunc MultiplyStage(factor int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v * factor:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\treturn out\n\t}\n}\n\n// Level 6 (medium+): Stage, отфильтровывающий значения по predicate.\n// Hint: пропускайте только элементы, удовлетворяющие предикату; закрывайте канал при отмене.\nfunc FilterStage(predicate func(int) bool) Stage {\n\tif predicate == nil {\n\t\tpredicate = func(int) bool { return true }\n\t}\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif !predicate(v) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 7 (medium+): Stage, пропускающий только первые n значений.\n// Hint: счётчик переданных значений поможет остановиться вовремя.\nfunc TakeStage(n int) Stage {\n\treturn func(ctx context.Context, in <-chan int) <-chan int {\n\t\tout := make(chan int)\n\t\tgo func() {\n\t\t\tdefer close(out)\n\t\t\tif n <= 0 {\n\t\t\t\tfor range in {\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tcount := 0\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif count < n {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase out <- v:\n\t\t\t\t\t\t\tcount++\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif count >= n {\n\t\t\t\t\t\tfor range in {\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\treturn out\n\t}\n}\n\n// Level 8 (medium+): реализовать Fan-In для нескольких входов с отменой по контексту.\n// Hint: используйте WaitGroup и закрывайте выход после завершения всех источников.\nfunc FanIn(ctx context.Context, ins ...<-chan int) <-chan int {\n\tout := make(chan int)\n\n\tvar wg sync.WaitGroup\n\n\twork := func(in <-chan int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, in := range ins {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 9 (medium+): собрать сумму значений канала.\n// Hint: просто итерируйтесь по каналу до закрытия.\nfunc Sum(in <-chan int) int {\n\tsum := 0\n\tfor e := range in {\n\t\tsum += e\n\t}\n\treturn sum\n}\n\n// Level 10 (senior-): BuildPipeline должен выстроить цепочку Stage: первый читает из in,\n// каждый следующий получает канал предыдущего, а результатом становится канал последнего Stage.\n// Hint: при ctx.Done() весь конвейер обязан корректно остановиться и закрыть каналы.\nfunc BuildPipeline(ctx context.Context, in <-chan int, stages ...Stage) <-chan int {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tout := in\n\tfor _, stage := range stages {\n\t\tif stage == nil {\n\t\t\tcontinue\n\t\t}\n\t\tout = stage(ctx, out)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 9
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runsequential",
        "title": "реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().",
        "description": "Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\nHint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.",
        "difficulty": "easy",
        "hint1": "перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 0
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runsequentiallimited",
        "title": "выполнить не более limit работ последовательно и вернуть количество запусков.",
        "description": "Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\nHint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.",
        "difficulty": "easy",
        "hint1": "следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 1
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runparallel",
        "title": "запустить каждую работу в отдельной горутине и дождаться завершения всех.",
        "description": "Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\nHint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.",
        "difficulty": "medium",
        "hint1": "используйте WaitGroup и собирайте первую ошибку после завершения всех задач.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 2
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runparallelbounded",
        "title": "ограничить уровень параллельности значением limit.",
        "description": "Level 4 (medium): ограничить уровень параллельности значением limit.\nHint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.",
        "difficulty": "medium",
        "hint1": "семафор на базе буферизованного канала поможет ограничить число одновременных запусков.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 3
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runpool",
        "title": "реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.",
        "description": "Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\nHint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.",
        "difficulty": "medium",
        "hint1": "выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 4
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runpoolcancelonerror",
        "title": "worker pool должен прекращать выдачу новых задач после первой ошибки.",
        "description": "Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\nHint: на первую ошибку отмените дочерний контекст и не берите новые задачи.",
        "difficulty": "medium",
        "hint1": "на первую ошибку отмените дочерний контекст и не берите новые задачи.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 5
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-makejobqueue",
        "title": "подготовить канал задач из слайса, учитывая отмену контекста.",
        "description": "Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\nHint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().",
        "difficulty": "medium",
        "hint1": "публикуйте задачи в отдельной горутине, используя select с ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 6
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-throttlejobsubmission",
        "title": "реализовать троттлинг задач — не чаще одного запуска в interval на воркер.",
        "description": "Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\nHint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.",
        "difficulty": "medium",
        "hint1": "храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 7
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runpoolwithpanichandler",
        "title": "обработать паники в задачах и передать их в handler, сохраняя работу пула.",
        "description": "Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\nHint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.",
        "difficulty": "hard",
        "hint1": "оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 8
      },
      {
        "package": "concurrency",
        "slug": "go-concurrency-runpoolwithresults",
        "title": "worker pool, собирающий результаты, должен завершаться по первой ошибке.",
        "description": "Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\nHint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.",
        "difficulty": "hard",
        "hint1": "комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Job описывает работу, которую необходимо выполнить.\ntype Job func(context.Context) error\n\n// ResultJob описывает работу, которая возвращает результат и ошибку.\ntype ResultJob[T any] func(context.Context) (T, error)\n\n// Level 1 (easy): реализовать последовательное выполнение работ с остановкой по первой ошибке или ctx.Done().\n// Hint: перед запуском каждой задачи проверяйте ctx.Err(), возвращайте первую ошибку.\nfunc RunSequential(ctx context.Context, jobs []Job) error {\n\tif len(jobs) == 0 || ctx == nil {\n\t\treturn nil\n\t}\n\n\tfor _, job := range jobs {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn ctx.Err()\n}\n\n// Level 2 (easy+): выполнить не более limit работ последовательно и вернуть количество запусков.\n// Hint: следите за счётчиком выполненных задач, учитывайте граничные случаи с limit <= 0.\nfunc RunSequentialLimited(ctx context.Context, jobs []Job, limit int) (int, error) {\n\tif ctx == nil || jobs == nil || limit <= 0 {\n\t\treturn 0, nil\n\t}\n\n\tcount := 0\n\tfor _, job := range jobs {\n\t\tif count >= limit {\n\t\t\tbreak\n\t\t}\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn count, err\n\t\t}\n\t\tif job == nil {\n\t\t\tcount++\n\t\t\tcontinue\n\t\t}\n\t\tif err := job(ctx); err != nil {\n\t\t\tcount++\n\t\t\treturn count, err\n\t\t}\n\t\tcount++\n\t}\n\n\treturn count, ctx.Err()\n}\n\n// Level 3 (medium): запустить каждую работу в отдельной горутине и дождаться завершения всех.\n// Hint: используйте WaitGroup и собирайте первую ошибку после завершения всех задач.\nfunc RunParallel(ctx context.Context, jobs []Job) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tfirstErr error\n\t\tonce     sync.Once\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(j Job) {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t\thandleErr(j(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\twg.Wait()\n\tif firstErr != nil {\n\t\treturn firstErr\n\t}\n\treturn ctx.Err()\n}\n\n// Level 4 (medium): ограничить уровень параллельности значением limit.\n// Hint: семафор на базе буферизованного канала поможет ограничить число одновременных запусков.\nfunc RunParallelBounded(ctx context.Context, jobs []Job, limit int) error {\n\tif ctx == nil || jobs == nil {\n\t\treturn nil\n\t}\n\n\tif limit <= 0 {\n\t\tlimit = 1\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t\tsem      = make(chan struct{}, limit)\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(job Job) {\n\t\tdefer wg.Done()\n\t\tdefer func() {\n\t\t\t<-sem\n\t\t}()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\thandleErr(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\thandleErr(job(ctx))\n\t}\n\n\tfor _, job := range jobs {\n\t\tif job == nil {\n\t\t\tcontinue\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase sem <- struct{}{}:\n\t\t}\n\t\twg.Add(1)\n\t\tgo work(job)\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 5 (medium): реализовать worker pool, считывающий задачи из канала jobs на workers горутинов.\n// Hint: выделите фиксированное количество воркеров и корректно закрывайте их через WaitGroup.\nfunc RunPool(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 6 (medium+): worker pool должен прекращать выдачу новых задач после первой ошибки.\n// Hint: на первую ошибку отмените дочерний контекст и не берите новые задачи.\nfunc RunPoolCancelOnError(ctx context.Context, jobs <-chan Job, workers int) error {\n\tif ctx == nil || jobs == nil || workers <= 0 {\n\t\treturn nil\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t\thandleErr(job(ctx))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\n\twg.Wait()\n\tif firstErr == nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 7 (medium+): подготовить канал задач из слайса, учитывая отмену контекста.\n// Hint: публикуйте задачи в отдельной горутине, используя select с ctx.Done().\nfunc MakeJobQueue(ctx context.Context, jobs []Job) <-chan Job {\n\tout := make(chan Job)\n\tif ctx != nil && ctx.Err() != nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\n\t\tif ctx == nil {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tfor _, job := range jobs {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase out <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n\n// Level 8 (medium+): реализовать троттлинг задач — не чаще одного запуска в interval на воркер.\n// Hint: храните время последнего отправленного задания и ждите оставшийся интервал через time.NewTimer.\nfunc ThrottleJobSubmission(ctx context.Context, in <-chan Job, interval time.Duration) <-chan Job {\n\tout := make(chan Job)\n\tgo func() {\n\t\tdefer close(out)\n\t\t// Если контекста нет, троттлинг применить нельзя: просто прокидываем все задачи как есть.\n\t\tif ctx == nil {\n\t\t\tfor job := range in {\n\t\t\t\tout <- job\n\t\t\t}\n\t\t}\n\n\t\t// Интервал не задан или неположительный — ведём себя как при «без ограничений», но с учётом ctx.\n\t\tif interval <= 0 {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-in:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- job:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// last хранит момент времени, когда мы отправили последнюю задачу в out.\n\t\tvar last time.Time\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif !last.IsZero() {\n\t\t\t\t\twait := interval - time.Since(last)\n\t\t\t\t\tif wait > 0 {\n\t\t\t\t\t\ttimer := time.NewTimer(wait)\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- job:\n\t\t\t\t\tlast = time.Now()\n\t\t\t\t}\n\n\t\t\t\t// \t// Если в out уже что-то отправляли, ждём оставшийся кусок интервала перед следующим запуском.\n\t\t\t\t// \tif !last.IsZero() { // уже запускали задачи раньше — нужно выдержать паузу\n\t\t\t\t// \t\twait := interval - time.Since(last) // рассчитываем, сколько осталось до полного интервала\n\t\t\t\t// \t\tif wait > 0 {                       // ждём только если интервал ещё не прошёл\n\t\t\t\t// \t\t\ttimer := time.NewTimer(wait) // таймер отсчитывает остаток интервала\n\t\t\t\t// \t\t\tselect {\n\t\t\t\t// \t\t\tcase <-ctx.Done(): // если контекст отменён во время ожидания\n\t\t\t\t// \t\t\t\tif !timer.Stop() { // останавливаем таймер; если уже тикнул, читаем тик\n\t\t\t\t// \t\t\t\t\t<-timer.C // освобождаем значение из канала таймера, чтобы никто не подвис\n\t\t\t\t// \t\t\t\t}\n\t\t\t\t// \t\t\t\treturn // прекращаем выдавать задачи\n\t\t\t\t// \t\t\tcase <-timer.C: // таймер отработал — можно отдавать следующую задачу\n\t\t\t\t// \t\t\t}\n\t\t\t\t// \t\t}\n\t\t\t\t// \t}\n\n\t\t\t\t// \t// Повторно проверяем контекст и записываем задачу в out, фиксируя время отправки.\n\t\t\t\t// \tselect {\n\t\t\t\t// \tcase <-ctx.Done():\n\t\t\t\t// \t\treturn\n\t\t\t\t// \tcase out <- job:\n\t\t\t\t// \t\tlast = time.Now()\n\t\t\t\t// \t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 9 (senior-): обработать паники в задачах и передать их в handler, сохраняя работу пула.\n// Hint: оборачивайте выполнение каждой задачи в recover и передавайте идентификатор воркера.\nfunc RunPoolWithPanicHandler(ctx context.Context, jobs <-chan Job, workers int, handler func(context.Context, int, any)) error {\n\tif ctx == nil {\n\t\treturn nil\n\t}\n\tif workers <= 0 {\n\t\tworkers = 1\n\t}\n\tif handler == nil {\n\t\thandler = func(context.Context, int, any) {}\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tfirstErr error\n\t)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func(id int) {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfunc() {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\t\thandler(ctx, id, r)\n\t\t\t\t\t\t}\n\t\t\t\t\t}()\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\thandleErr(err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work(i)\n\t}\n\twg.Wait()\n\tif firstErr == nil && ctx.Err() != nil {\n\t\treturn ctx.Err()\n\t}\n\treturn firstErr\n}\n\n// Level 10 (senior-): worker pool, собирающий результаты, должен завершаться по первой ошибке.\n// Hint: комбинируйте отменяемый контекст, mutex для среза результатов и остановку при первой ошибке.\nfunc RunPoolWithResults[T any](ctx context.Context, jobs <-chan ResultJob[T], workers int) ([]T, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\n\tvar (\n\t\twg       sync.WaitGroup\n\t\tonce     sync.Once\n\t\tmu       sync.Mutex\n\t\tfirstErr error\n\t\tout      []T\n\t)\n\n\tif jobs == nil || workers <= 0 {\n\t\treturn out, nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\thandleErr := func(err error) {\n\t\tif err != nil {\n\t\t\tonce.Do(func() {\n\t\t\t\tfirstErr = err\n\t\t\t\tcancel()\n\t\t\t})\n\t\t}\n\t}\n\n\twork := func() {\n\t\tdefer wg.Done()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase job, ok := <-jobs:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif job == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tv, err := job(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\thandleErr(err)\n\t\t\t\t}\n\t\t\t\tmu.Lock()\n\t\t\t\tout = append(out, v)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo work()\n\t}\n\twg.Wait()\n\tif firstErr == nil {\n\t\tfirstErr = ctx.Err()\n\t}\n\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcopied := make([]T, len(out))\n\tcopy(copied, out)\n\treturn copied, firstErr\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage concurrency\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc DoWithTimeout(ctx context.Context, f func(), d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithTimeout, cancel := context.WithTimeout(ctx, d)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithTimeout.Done():\n\t\treturn ctxWithTimeout.Err()\n\tcase <-done:\n\t\treturn ctxWithTimeout.Err()\n\t}\n}\n\nfunc DoWithDeadline(ctx context.Context, deadline time.Time, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithDeadline, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf()\n\t}()\n\tselect {\n\tcase <-ctxWithDeadline.Done():\n\t\treturn ctxWithDeadline.Err()\n\tcase <-done:\n\t\treturn ctxWithDeadline.Err()\n\t}\n}\n\nfunc DoWithCancel(ctx context.Context, f func(context.Context)) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tf(ctxWithCancel)\n\t}()\n\tif err := ctx.Err(); err != nil {\n\t\tcancel()\n\t\t<-done\n\t\treturn err\n\t}\n\tcancel()\n\t<-done\n\treturn nil\n}\n\nfunc NotifyCancel(ctx context.Context) <-chan struct{} {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\tif ctx == nil {\n\t\t\treturn\n\t\t}\n\t\t<-ctx.Done()\n\t}()\n\treturn ch\n}\n\nfunc WaitForSignal(ctx context.Context, signal <-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-signal:\n\t\treturn nil\n\t}\n}\n\nfunc WaitAll(ctx context.Context, signals ...<-chan struct{}) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn nil\n\t}\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tvar wg sync.WaitGroup\n\t\twg.Add(len(signals))\n\t\tfor _, ch := range signals {\n\t\t\tch := ch\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\tcase <-ch:\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-done:\n\t\treturn ctx.Err()\n\t}\n}\n\nfunc WaitAny(ctx context.Context, signals ...<-chan struct{}) (int, error) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif len(signals) == 0 {\n\t\treturn -1, nil\n\t}\n\tctxAny, cancel := context.WithCancel(ctx)\n\tresult := make(chan int, 1)\n\tfor idx, ch := range signals {\n\t\tidx := idx\n\t\tgo func(ch <-chan struct{}) {\n\t\t\tselect {\n\t\t\tcase <-ctxAny.Done():\n\t\t\tcase <-ch:\n\t\t\t\tselect {\n\t\t\t\tcase result <- idx:\n\t\t\t\t\tcancel()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(ch)\n\t}\n\tselect {\n\tcase <-ctxAny.Done():\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn -1, err\n\t\t}\n\t\treturn -1, context.Canceled\n\tcase idx := <-result:\n\t\treturn idx, nil\n\t}\n}\n\nfunc RunUntil(ctx context.Context, done <-chan struct{}, f func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-done:\n\t\t\treturn nil\n\t\tdefault:\n\t\t}\n\t\tf()\n\t}\n}\n\nfunc RetryWithContext(ctx context.Context, attempts int, delay time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor attempt := 0; attempt < attempts; attempt++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif attempt == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc Heartbeat(ctx context.Context, interval time.Duration, send func()) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tsend()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-ticker.C:\n\t\t\tsend()\n\t\t}\n\t}\n}\n",
        "testCode": "package concurrency\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestDoWithTimeout_Timeout(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() { time.Sleep(100 * time.Millisecond) }, 10*time.Millisecond)\n\tif err == nil {\n\t\tt.Fatal(\"want timeout error\")\n\t}\n}\n\nfunc TestDoWithTimeout_OK(t *testing.T) {\n\terr := DoWithTimeout(context.Background(), func() {}, 10*time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestDoWithDeadline(t *testing.T) {\n\tdeadline := time.Now().Add(10 * time.Millisecond)\n\terr := DoWithDeadline(context.Background(), deadline, func() { time.Sleep(20 * time.Millisecond) })\n\tif err == nil {\n\t\tt.Fatal(\"expected deadline error\")\n\t}\n}\n\nfunc TestDoWithCancel(t *testing.T) {\n\tvar done atomic.Bool\n\terr := DoWithCancel(context.Background(), func(ctx context.Context) {\n\t\t<-ctx.Done()\n\t\tdone.Store(true)\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif !done.Load() {\n\t\tt.Fatal(\"cancel not propagated\")\n\t}\n}\n\nfunc TestNotifyCancel(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tch := NotifyCancel(ctx)\n\tcancel()\n\tselect {\n\tcase <-ch:\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatal(\"notify channel not closed\")\n\t}\n}\n\nfunc TestWaitForSignal(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tsignal := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(signal)\n\t}()\n\tif err := WaitForSignal(ctx, signal); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAll(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(a)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tif err := WaitAll(ctx, a, b); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestWaitAny(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\ta := make(chan struct{})\n\tb := make(chan struct{})\n\tgo func() {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tclose(b)\n\t}()\n\tindex, err := WaitAny(ctx, a, b)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif index != 1 {\n\t\tt.Fatalf(\"want index=1, got %d\", index)\n\t}\n}\n\nfunc TestRunUntil(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tdone := make(chan struct{})\n\tvar calls atomic.Int64\n\tgo func() {\n\t\ttime.Sleep(30 * time.Millisecond)\n\t\tclose(done)\n\t}()\n\tif err := RunUntil(ctx, done, func() { calls.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls.Load() == 0 {\n\t\tt.Fatal(\"function not executed\")\n\t}\n}\n\nfunc TestRetryWithContext(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tvar attempts atomic.Int64\n\ttargetErr := errors.New(\"fail\")\n\terr := RetryWithContext(ctx, 3, 10*time.Millisecond, func(context.Context) error {\n\t\tif attempts.Add(1) == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn targetErr\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts.Load() != 3 {\n\t\tt.Fatalf(\"want attempts=3, got %d\", attempts.Load())\n\t}\n}\n\nfunc TestHeartbeat(t *testing.T) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Millisecond)\n\tdefer cancel()\n\tvar beats atomic.Int64\n\tif err := Heartbeat(ctx, 10*time.Millisecond, func() { beats.Add(1) }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif beats.Load() < 4 {\n\t\tt.Fatalf(\"too few beats: %d\", beats.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "concurrency"
        ],
        "order": 9
      }
    ],
    "category": "concurrency"
  },
  {
    "name": "configx",
    "tasks": [
      {
        "package": "configx",
        "slug": "go-configx-load",
        "title": "Load читает переменные окружения, задаёт значения по умолчанию и валидирует.",
        "description": "Level 2 (easy+): Load читает переменные окружения, задаёт значения по умолчанию и валидирует.\nHint: Addr обязателен, RPS по умолчанию 100, используйте strconv.Atoi.",
        "difficulty": "easy",
        "hint1": "Addr обязателен, RPS по умолчанию 100, используйте strconv.Atoi.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\n// Level 1 (easy): структура Config хранит Addr и RPS.\n// Hint: значения приходят из переменных окружения APP_ADDR и APP_RPS.\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\n// Level 2 (easy+): Load читает переменные окружения, задаёт значения по умолчанию и валидирует.\n// Hint: Addr обязателен, RPS по умолчанию 100, используйте strconv.Atoi.\nfunc Load() (Config, error) {\n\tenv := map[string]string{\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env)\n}\n\n// Level 3 (medium): ParseEnv принимает map env и возвращает Config, не обращаясь к os.Getenv.\n// Hint: переиспользуйте ApplyDefaults и ValidateConfig.\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" {\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)\n\tif err := ValidateConfig(cfg); err != nil {\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil\n}\n\n// Level 4 (medium): ApplyDefaults заполняет отсутствующие значения (Addr обязательный, RPS=100 по умолчанию).\n// Hint: меняйте структуру по месту.\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif cfg.RPS == 0 {\n\t\tcfg.RPS = 100\n\t}\n}\n\n// Level 5 (medium+): ValidateConfig проверяет корректность значений и возвращает ErrBadConfig.\n// Hint: Addr не должен быть пустым, RPS > 0.\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" {\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 {\n\t\treturn ErrBadConfig\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): FormatConfig возвращает строку вида \"addr=...,rps=...\" для логирования.\n// Hint: используйте fmt.Sprintf.\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS)\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\nfunc Load() (Config, error) {\n\tenv := map[string]string{ // capture environment variables for deterministic parsing\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env) // delegate parsing and validation to shared helper\n}\n\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{ // start with zero-valued config\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" { // parse RPS only when provided\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err // return parsing error to caller\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)                         // fill missing values with defaults\n\tif err := ValidateConfig(cfg); err != nil { // ensure config meets constraints\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil // return validated config\n}\n\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil { // nothing to apply when pointer is nil\n\t\treturn\n\t}\n\tif cfg.RPS == 0 { // default request-per-second limit when unspecified\n\t\tcfg.RPS = 100\n\t}\n}\n\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" { // address must always be provided\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 { // RPS must be strictly positive\n\t\treturn ErrBadConfig\n\t}\n\treturn nil // configuration is valid\n}\n\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS) // render compact log-friendly string\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "testCode": "package configx\n\nimport (\n\t\"testing\"\n)\n\nfunc TestLoad(t *testing.T) {\n    t.Setenv(\"APP_ADDR\", \"127.0.0.1:8080\")\n    t.Setenv(\"APP_RPS\", \"200\")\n    c, err := Load()\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.Addr != \"127.0.0.1:8080\" || c.RPS != 200 {\n\t\tt.Fatalf(\"unexpected config: %+v\", c)\n\t}\n}\n\nfunc TestParseEnv(t *testing.T) {\n\tt.Parallel()\n\tc, err := ParseEnv(map[string]string{\"APP_ADDR\": \"localhost:80\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS=100, got %d\", c.RPS)\n\t}\n}\n\nfunc TestApplyDefaults(t *testing.T) {\n\tt.Parallel()\n\tc := Config{Addr: \"a\"}\n\tApplyDefaults(&c)\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS, got %d\", c.RPS)\n\t}\n}\n\nfunc TestValidateConfig(t *testing.T) {\n\tt.Parallel()\n\tif err := ValidateConfig(Config{Addr: \"a\", RPS: 1}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := ValidateConfig(Config{}); err == nil {\n\t\tt.Fatal(\"expected validation error for empty config\")\n\t}\n}\n\nfunc TestFormatConfig(t *testing.T) {\n\tt.Parallel()\n\tcfg := Config{Addr: \"a\", RPS: 10}\n\tif out := FormatConfig(cfg); out != \"addr=a,rps=10\" {\n\t\tt.Fatalf(\"unexpected format: %q\", out)\n\t}\n}\n",
        "tags": [
          "go",
          "configx"
        ],
        "order": 1
      },
      {
        "package": "configx",
        "slug": "go-configx-parseenv",
        "title": "ParseEnv принимает map env и возвращает Config, не обращаясь к os.Getenv.",
        "description": "Level 3 (medium): ParseEnv принимает map env и возвращает Config, не обращаясь к os.Getenv.\nHint: переиспользуйте ApplyDefaults и ValidateConfig.",
        "difficulty": "medium",
        "hint1": "переиспользуйте ApplyDefaults и ValidateConfig.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\n// Level 1 (easy): структура Config хранит Addr и RPS.\n// Hint: значения приходят из переменных окружения APP_ADDR и APP_RPS.\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\n// Level 2 (easy+): Load читает переменные окружения, задаёт значения по умолчанию и валидирует.\n// Hint: Addr обязателен, RPS по умолчанию 100, используйте strconv.Atoi.\nfunc Load() (Config, error) {\n\tenv := map[string]string{\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env)\n}\n\n// Level 3 (medium): ParseEnv принимает map env и возвращает Config, не обращаясь к os.Getenv.\n// Hint: переиспользуйте ApplyDefaults и ValidateConfig.\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" {\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)\n\tif err := ValidateConfig(cfg); err != nil {\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil\n}\n\n// Level 4 (medium): ApplyDefaults заполняет отсутствующие значения (Addr обязательный, RPS=100 по умолчанию).\n// Hint: меняйте структуру по месту.\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif cfg.RPS == 0 {\n\t\tcfg.RPS = 100\n\t}\n}\n\n// Level 5 (medium+): ValidateConfig проверяет корректность значений и возвращает ErrBadConfig.\n// Hint: Addr не должен быть пустым, RPS > 0.\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" {\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 {\n\t\treturn ErrBadConfig\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): FormatConfig возвращает строку вида \"addr=...,rps=...\" для логирования.\n// Hint: используйте fmt.Sprintf.\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS)\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\nfunc Load() (Config, error) {\n\tenv := map[string]string{ // capture environment variables for deterministic parsing\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env) // delegate parsing and validation to shared helper\n}\n\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{ // start with zero-valued config\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" { // parse RPS only when provided\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err // return parsing error to caller\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)                         // fill missing values with defaults\n\tif err := ValidateConfig(cfg); err != nil { // ensure config meets constraints\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil // return validated config\n}\n\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil { // nothing to apply when pointer is nil\n\t\treturn\n\t}\n\tif cfg.RPS == 0 { // default request-per-second limit when unspecified\n\t\tcfg.RPS = 100\n\t}\n}\n\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" { // address must always be provided\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 { // RPS must be strictly positive\n\t\treturn ErrBadConfig\n\t}\n\treturn nil // configuration is valid\n}\n\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS) // render compact log-friendly string\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "testCode": "package configx\n\nimport (\n\t\"testing\"\n)\n\nfunc TestLoad(t *testing.T) {\n    t.Setenv(\"APP_ADDR\", \"127.0.0.1:8080\")\n    t.Setenv(\"APP_RPS\", \"200\")\n    c, err := Load()\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.Addr != \"127.0.0.1:8080\" || c.RPS != 200 {\n\t\tt.Fatalf(\"unexpected config: %+v\", c)\n\t}\n}\n\nfunc TestParseEnv(t *testing.T) {\n\tt.Parallel()\n\tc, err := ParseEnv(map[string]string{\"APP_ADDR\": \"localhost:80\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS=100, got %d\", c.RPS)\n\t}\n}\n\nfunc TestApplyDefaults(t *testing.T) {\n\tt.Parallel()\n\tc := Config{Addr: \"a\"}\n\tApplyDefaults(&c)\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS, got %d\", c.RPS)\n\t}\n}\n\nfunc TestValidateConfig(t *testing.T) {\n\tt.Parallel()\n\tif err := ValidateConfig(Config{Addr: \"a\", RPS: 1}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := ValidateConfig(Config{}); err == nil {\n\t\tt.Fatal(\"expected validation error for empty config\")\n\t}\n}\n\nfunc TestFormatConfig(t *testing.T) {\n\tt.Parallel()\n\tcfg := Config{Addr: \"a\", RPS: 10}\n\tif out := FormatConfig(cfg); out != \"addr=a,rps=10\" {\n\t\tt.Fatalf(\"unexpected format: %q\", out)\n\t}\n}\n",
        "tags": [
          "go",
          "configx"
        ],
        "order": 2
      },
      {
        "package": "configx",
        "slug": "go-configx-applydefaults",
        "title": "ApplyDefaults заполняет отсутствующие значения (Addr обязательный, RPS=100 по умолчанию).",
        "description": "Level 4 (medium): ApplyDefaults заполняет отсутствующие значения (Addr обязательный, RPS=100 по умолчанию).\nHint: меняйте структуру по месту.",
        "difficulty": "medium",
        "hint1": "меняйте структуру по месту.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\n// Level 1 (easy): структура Config хранит Addr и RPS.\n// Hint: значения приходят из переменных окружения APP_ADDR и APP_RPS.\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\n// Level 2 (easy+): Load читает переменные окружения, задаёт значения по умолчанию и валидирует.\n// Hint: Addr обязателен, RPS по умолчанию 100, используйте strconv.Atoi.\nfunc Load() (Config, error) {\n\tenv := map[string]string{\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env)\n}\n\n// Level 3 (medium): ParseEnv принимает map env и возвращает Config, не обращаясь к os.Getenv.\n// Hint: переиспользуйте ApplyDefaults и ValidateConfig.\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" {\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)\n\tif err := ValidateConfig(cfg); err != nil {\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil\n}\n\n// Level 4 (medium): ApplyDefaults заполняет отсутствующие значения (Addr обязательный, RPS=100 по умолчанию).\n// Hint: меняйте структуру по месту.\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif cfg.RPS == 0 {\n\t\tcfg.RPS = 100\n\t}\n}\n\n// Level 5 (medium+): ValidateConfig проверяет корректность значений и возвращает ErrBadConfig.\n// Hint: Addr не должен быть пустым, RPS > 0.\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" {\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 {\n\t\treturn ErrBadConfig\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): FormatConfig возвращает строку вида \"addr=...,rps=...\" для логирования.\n// Hint: используйте fmt.Sprintf.\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS)\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\nfunc Load() (Config, error) {\n\tenv := map[string]string{ // capture environment variables for deterministic parsing\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env) // delegate parsing and validation to shared helper\n}\n\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{ // start with zero-valued config\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" { // parse RPS only when provided\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err // return parsing error to caller\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)                         // fill missing values with defaults\n\tif err := ValidateConfig(cfg); err != nil { // ensure config meets constraints\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil // return validated config\n}\n\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil { // nothing to apply when pointer is nil\n\t\treturn\n\t}\n\tif cfg.RPS == 0 { // default request-per-second limit when unspecified\n\t\tcfg.RPS = 100\n\t}\n}\n\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" { // address must always be provided\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 { // RPS must be strictly positive\n\t\treturn ErrBadConfig\n\t}\n\treturn nil // configuration is valid\n}\n\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS) // render compact log-friendly string\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "testCode": "package configx\n\nimport (\n\t\"testing\"\n)\n\nfunc TestLoad(t *testing.T) {\n    t.Setenv(\"APP_ADDR\", \"127.0.0.1:8080\")\n    t.Setenv(\"APP_RPS\", \"200\")\n    c, err := Load()\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.Addr != \"127.0.0.1:8080\" || c.RPS != 200 {\n\t\tt.Fatalf(\"unexpected config: %+v\", c)\n\t}\n}\n\nfunc TestParseEnv(t *testing.T) {\n\tt.Parallel()\n\tc, err := ParseEnv(map[string]string{\"APP_ADDR\": \"localhost:80\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS=100, got %d\", c.RPS)\n\t}\n}\n\nfunc TestApplyDefaults(t *testing.T) {\n\tt.Parallel()\n\tc := Config{Addr: \"a\"}\n\tApplyDefaults(&c)\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS, got %d\", c.RPS)\n\t}\n}\n\nfunc TestValidateConfig(t *testing.T) {\n\tt.Parallel()\n\tif err := ValidateConfig(Config{Addr: \"a\", RPS: 1}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := ValidateConfig(Config{}); err == nil {\n\t\tt.Fatal(\"expected validation error for empty config\")\n\t}\n}\n\nfunc TestFormatConfig(t *testing.T) {\n\tt.Parallel()\n\tcfg := Config{Addr: \"a\", RPS: 10}\n\tif out := FormatConfig(cfg); out != \"addr=a,rps=10\" {\n\t\tt.Fatalf(\"unexpected format: %q\", out)\n\t}\n}\n",
        "tags": [
          "go",
          "configx"
        ],
        "order": 3
      },
      {
        "package": "configx",
        "slug": "go-configx-validateconfig",
        "title": "ValidateConfig проверяет корректность значений и возвращает ErrBadConfig.",
        "description": "Level 5 (medium+): ValidateConfig проверяет корректность значений и возвращает ErrBadConfig.\nHint: Addr не должен быть пустым, RPS > 0.",
        "difficulty": "medium",
        "hint1": "Addr не должен быть пустым, RPS > 0.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\n// Level 1 (easy): структура Config хранит Addr и RPS.\n// Hint: значения приходят из переменных окружения APP_ADDR и APP_RPS.\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\n// Level 2 (easy+): Load читает переменные окружения, задаёт значения по умолчанию и валидирует.\n// Hint: Addr обязателен, RPS по умолчанию 100, используйте strconv.Atoi.\nfunc Load() (Config, error) {\n\tenv := map[string]string{\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env)\n}\n\n// Level 3 (medium): ParseEnv принимает map env и возвращает Config, не обращаясь к os.Getenv.\n// Hint: переиспользуйте ApplyDefaults и ValidateConfig.\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" {\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)\n\tif err := ValidateConfig(cfg); err != nil {\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil\n}\n\n// Level 4 (medium): ApplyDefaults заполняет отсутствующие значения (Addr обязательный, RPS=100 по умолчанию).\n// Hint: меняйте структуру по месту.\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif cfg.RPS == 0 {\n\t\tcfg.RPS = 100\n\t}\n}\n\n// Level 5 (medium+): ValidateConfig проверяет корректность значений и возвращает ErrBadConfig.\n// Hint: Addr не должен быть пустым, RPS > 0.\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" {\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 {\n\t\treturn ErrBadConfig\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): FormatConfig возвращает строку вида \"addr=...,rps=...\" для логирования.\n// Hint: используйте fmt.Sprintf.\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS)\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\nfunc Load() (Config, error) {\n\tenv := map[string]string{ // capture environment variables for deterministic parsing\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env) // delegate parsing and validation to shared helper\n}\n\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{ // start with zero-valued config\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" { // parse RPS only when provided\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err // return parsing error to caller\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)                         // fill missing values with defaults\n\tif err := ValidateConfig(cfg); err != nil { // ensure config meets constraints\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil // return validated config\n}\n\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil { // nothing to apply when pointer is nil\n\t\treturn\n\t}\n\tif cfg.RPS == 0 { // default request-per-second limit when unspecified\n\t\tcfg.RPS = 100\n\t}\n}\n\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" { // address must always be provided\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 { // RPS must be strictly positive\n\t\treturn ErrBadConfig\n\t}\n\treturn nil // configuration is valid\n}\n\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS) // render compact log-friendly string\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "testCode": "package configx\n\nimport (\n\t\"testing\"\n)\n\nfunc TestLoad(t *testing.T) {\n    t.Setenv(\"APP_ADDR\", \"127.0.0.1:8080\")\n    t.Setenv(\"APP_RPS\", \"200\")\n    c, err := Load()\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.Addr != \"127.0.0.1:8080\" || c.RPS != 200 {\n\t\tt.Fatalf(\"unexpected config: %+v\", c)\n\t}\n}\n\nfunc TestParseEnv(t *testing.T) {\n\tt.Parallel()\n\tc, err := ParseEnv(map[string]string{\"APP_ADDR\": \"localhost:80\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS=100, got %d\", c.RPS)\n\t}\n}\n\nfunc TestApplyDefaults(t *testing.T) {\n\tt.Parallel()\n\tc := Config{Addr: \"a\"}\n\tApplyDefaults(&c)\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS, got %d\", c.RPS)\n\t}\n}\n\nfunc TestValidateConfig(t *testing.T) {\n\tt.Parallel()\n\tif err := ValidateConfig(Config{Addr: \"a\", RPS: 1}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := ValidateConfig(Config{}); err == nil {\n\t\tt.Fatal(\"expected validation error for empty config\")\n\t}\n}\n\nfunc TestFormatConfig(t *testing.T) {\n\tt.Parallel()\n\tcfg := Config{Addr: \"a\", RPS: 10}\n\tif out := FormatConfig(cfg); out != \"addr=a,rps=10\" {\n\t\tt.Fatalf(\"unexpected format: %q\", out)\n\t}\n}\n",
        "tags": [
          "go",
          "configx"
        ],
        "order": 4
      },
      {
        "package": "configx",
        "slug": "go-configx-formatconfig",
        "title": "FormatConfig возвращает строку вида \"addr=...,rps=...\" для логирования.",
        "description": "Level 6 (medium+): FormatConfig возвращает строку вида \"addr=...,rps=...\" для логирования.\nHint: используйте fmt.Sprintf.",
        "difficulty": "medium",
        "hint1": "используйте fmt.Sprintf.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\n// Level 1 (easy): структура Config хранит Addr и RPS.\n// Hint: значения приходят из переменных окружения APP_ADDR и APP_RPS.\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\n// Level 2 (easy+): Load читает переменные окружения, задаёт значения по умолчанию и валидирует.\n// Hint: Addr обязателен, RPS по умолчанию 100, используйте strconv.Atoi.\nfunc Load() (Config, error) {\n\tenv := map[string]string{\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env)\n}\n\n// Level 3 (medium): ParseEnv принимает map env и возвращает Config, не обращаясь к os.Getenv.\n// Hint: переиспользуйте ApplyDefaults и ValidateConfig.\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" {\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)\n\tif err := ValidateConfig(cfg); err != nil {\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil\n}\n\n// Level 4 (medium): ApplyDefaults заполняет отсутствующие значения (Addr обязательный, RPS=100 по умолчанию).\n// Hint: меняйте структуру по месту.\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif cfg.RPS == 0 {\n\t\tcfg.RPS = 100\n\t}\n}\n\n// Level 5 (medium+): ValidateConfig проверяет корректность значений и возвращает ErrBadConfig.\n// Hint: Addr не должен быть пустым, RPS > 0.\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" {\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 {\n\t\treturn ErrBadConfig\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): FormatConfig возвращает строку вида \"addr=...,rps=...\" для логирования.\n// Hint: используйте fmt.Sprintf.\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS)\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage configx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n)\n\ntype Config struct {\n\tAddr string\n\tRPS  int\n}\n\nfunc Load() (Config, error) {\n\tenv := map[string]string{ // capture environment variables for deterministic parsing\n\t\t\"APP_ADDR\": os.Getenv(\"APP_ADDR\"),\n\t\t\"APP_RPS\":  os.Getenv(\"APP_RPS\"),\n\t}\n\treturn ParseEnv(env) // delegate parsing and validation to shared helper\n}\n\nfunc ParseEnv(env map[string]string) (Config, error) {\n\tcfg := Config{ // start with zero-valued config\n\t\tAddr: env[\"APP_ADDR\"],\n\t}\n\tif raw := env[\"APP_RPS\"]; raw != \"\" { // parse RPS only when provided\n\t\trps, err := strconv.Atoi(raw)\n\t\tif err != nil {\n\t\t\treturn cfg, err // return parsing error to caller\n\t\t}\n\t\tcfg.RPS = rps\n\t}\n\tApplyDefaults(&cfg)                         // fill missing values with defaults\n\tif err := ValidateConfig(cfg); err != nil { // ensure config meets constraints\n\t\treturn cfg, err\n\t}\n\treturn cfg, nil // return validated config\n}\n\nfunc ApplyDefaults(cfg *Config) {\n\tif cfg == nil { // nothing to apply when pointer is nil\n\t\treturn\n\t}\n\tif cfg.RPS == 0 { // default request-per-second limit when unspecified\n\t\tcfg.RPS = 100\n\t}\n}\n\nfunc ValidateConfig(cfg Config) error {\n\tif cfg.Addr == \"\" { // address must always be provided\n\t\treturn ErrBadConfig\n\t}\n\tif cfg.RPS <= 0 { // RPS must be strictly positive\n\t\treturn ErrBadConfig\n\t}\n\treturn nil // configuration is valid\n}\n\nfunc FormatConfig(cfg Config) string {\n\treturn fmt.Sprintf(\"addr=%s,rps=%d\", cfg.Addr, cfg.RPS) // render compact log-friendly string\n}\n\nvar ErrBadConfig = errors.New(\"bad config\")\n",
        "testCode": "package configx\n\nimport (\n\t\"testing\"\n)\n\nfunc TestLoad(t *testing.T) {\n    t.Setenv(\"APP_ADDR\", \"127.0.0.1:8080\")\n    t.Setenv(\"APP_RPS\", \"200\")\n    c, err := Load()\n    if err != nil {\n        t.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.Addr != \"127.0.0.1:8080\" || c.RPS != 200 {\n\t\tt.Fatalf(\"unexpected config: %+v\", c)\n\t}\n}\n\nfunc TestParseEnv(t *testing.T) {\n\tt.Parallel()\n\tc, err := ParseEnv(map[string]string{\"APP_ADDR\": \"localhost:80\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS=100, got %d\", c.RPS)\n\t}\n}\n\nfunc TestApplyDefaults(t *testing.T) {\n\tt.Parallel()\n\tc := Config{Addr: \"a\"}\n\tApplyDefaults(&c)\n\tif c.RPS != 100 {\n\t\tt.Fatalf(\"expected default RPS, got %d\", c.RPS)\n\t}\n}\n\nfunc TestValidateConfig(t *testing.T) {\n\tt.Parallel()\n\tif err := ValidateConfig(Config{Addr: \"a\", RPS: 1}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := ValidateConfig(Config{}); err == nil {\n\t\tt.Fatal(\"expected validation error for empty config\")\n\t}\n}\n\nfunc TestFormatConfig(t *testing.T) {\n\tt.Parallel()\n\tcfg := Config{Addr: \"a\", RPS: 10}\n\tif out := FormatConfig(cfg); out != \"addr=a,rps=10\" {\n\t\tt.Fatalf(\"unexpected format: %q\", out)\n\t}\n}\n",
        "tags": [
          "go",
          "configx"
        ],
        "order": 5
      }
    ],
    "category": "production"
  },
  {
    "name": "datastructsx",
    "tasks": [
      {
        "package": "datastructsx",
        "slug": "go-datastructsx-safedelete",
        "title": "SafeDelete должен возвращать копию map без ключей из списка keys, оригинал не менять.",
        "description": "Level 1 (easy): SafeDelete должен возвращать копию map без ключей из списка keys, оригинал не менять.\nHint: создайте новый словарь и скопируйте пары, пропуская ненужные ключи.",
        "difficulty": "easy",
        "hint1": "создайте новый словарь и скопируйте пары, пропуская ненужные ключи.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage datastructsx\n\nimport (\n\t\"strings\"\n)\n\n// Level 1 (easy): SafeDelete должен возвращать копию map без ключей из списка keys, оригинал не менять.\n// Hint: создайте новый словарь и скопируйте пары, пропуская ненужные ключи.\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, k := range keys {\n\n\t\ttoDelete[k] = struct{}{}\n\t}\n\n\tcloned := make(map[K]V, len(m))\n\tfor k, v := range m {\n\t\tif _, skip := toDelete[k]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[k] = v\n\t}\n\n\treturn M(cloned)\n}\n\n// Level 2 (easy+): Unique устраняет дубликаты в слайсе, сохраняя порядок появлений.\n// Hint: используйте map для отслеживания встреченных значений.\nfunc Unique[T comparable](in []T) []T {\n\tseen := make(map[T]struct{}, len(in))\n\tunique := make([]T, 0, len(in))\n\tfor _, e := range in {\n\t\tif _, ok := seen[e]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[e] = struct{}{}\n\t\tunique = append(unique, e)\n\t}\n\n\treturn unique\n}\n\n// Level 3 (medium): ReverseInPlace разворачивает слайс без дополнительной памяти.\n// Hint: меняйте элементы in-place, двигаясь навстречу с концов.\nfunc ReverseInPlace[T any](in []T) {\n\tfor l, r := 0, len(in)-1; l < r; l, r = l+1, r-1 {\n\t\tin[l], in[r] = in[r], in[l]\n\t}\n}\n\n// Level 4 (medium): Batch разбивает слайс на чанки размера n.\n// Hint: обработайте крайние случаи n<=0 и последний неполный чанк.\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, len(in)+n-1/n)\n\tfor i := 0; i < len(in); i += n {\n\t\tj := i + n\n\t\tif j > len(in) {\n\t\t\tj = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[i:j])\n\t}\n\treturn chunks\n}\n\n// Level 5 (medium+): JoinEfficient объединяет строки без конкатенации в цикле с '+'.\n// Hint: используйте strings.Builder с заранее вычисленным размером буфера.\nfunc JoinEfficient(parts []string) string {\n\tif len(parts) == 0 {\n\t\treturn \"\"\n\t}\n\tif len(parts) == 1 {\n\t\treturn parts[0]\n\t}\n\n\tvar sz int\n\tfor _, part := range parts {\n\t\tsz += len([]rune(part))\n\t}\n\n\tvar sb strings.Builder\n\tsb.Grow(sz)\n\tfor _, part := range parts {\n\t\tsb.WriteString(part)\n\t}\n\n\treturn sb.String()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage datastructsx\n\nimport \"strings\"\n\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, key := range keys {\n\t\ttoDelete[key] = struct{}{}\n\t}\n\tcloned := make(map[K]V, len(m))\n\tfor key, value := range m {\n\t\tif _, skip := toDelete[key]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[key] = value\n\t}\n\treturn M(cloned)\n}\n\nfunc Unique[T comparable](in []T) []T {\n\tif len(in) == 0 {\n\t\treturn nil\n\t}\n\tseen := make(map[T]struct{}, len(in))\n\tresult := make([]T, 0, len(in))\n\tfor _, value := range in {\n\t\tif _, ok := seen[value]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[value] = struct{}{}\n\t\tresult = append(result, value)\n\t}\n\treturn result\n}\n\nfunc ReverseInPlace[T any](in []T) {\n\tfor left, right := 0, len(in)-1; left < right; left, right = left+1, right-1 {\n\t\tin[left], in[right] = in[right], in[left]\n\t}\n}\n\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, (len(in)+n-1)/n)\n\tfor start := 0; start < len(in); start += n {\n\t\tend := start + n\n\t\tif end > len(in) {\n\t\t\tend = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[start:end])\n\t}\n\treturn chunks\n}\n\nfunc JoinEfficient(parts []string) string {\n\tswitch len(parts) {\n\tcase 0:\n\t\treturn \"\"\n\tcase 1:\n\t\treturn parts[0]\n\t}\n\ttotalLen := 0\n\tfor _, part := range parts {\n\t\ttotalLen += len(part)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(totalLen)\n\tfor _, part := range parts {\n\t\tbuilder.WriteString(part)\n\t}\n\treturn builder.String()\n}\n",
        "testCode": "package datastructsx\n\nimport \"testing\"\n\nfunc TestSafeDelete(t *testing.T) {\n\tm := map[string]int{\"a\":1,\"b\":2,\"c\":3}\n\tres := SafeDelete(m, []string{\"b\",\"x\"})\n\tif _, ok := res[\"b\"]; ok { t.Fatal(\"b must be removed\") }\n\tif _, ok := m[\"b\"]; !ok { t.Fatal(\"original must be intact\") }\n}\n\nfunc TestUniqueReverseBatchJoin(t *testing.T) {\n\tu := Unique([]int{1,2,2,3,1})\n\tif len(u)!=3 || u[0]!=1 || u[2]!=3 { t.Fatalf(\"bad unique %v\", u) }\n\tx := []int{1,2,3,4}\n\tReverseInPlace(x)\n\tif x[0]!=4 || x[3]!=1 { t.Fatalf(\"bad reverse %v\", x) }\n\tb := Batch([]int{1,2,3,4,5}, 2)\n\tif len(b)!=3 || len(b[2])!=1 || b[0][0]!=1 || b[1][1]!=4 { t.Fatalf(\"bad batch %v\", b) }\n\tif JoinEfficient([]string{\"ab\",\"cd\",\"ef\"}) != \"abcdef\" { t.Fatal(\"bad join\") }\n}\n",
        "tags": [
          "go",
          "datastructsx"
        ],
        "order": 0
      },
      {
        "package": "datastructsx",
        "slug": "go-datastructsx-unique",
        "title": "Unique устраняет дубликаты в слайсе, сохраняя порядок появлений.",
        "description": "Level 2 (easy+): Unique устраняет дубликаты в слайсе, сохраняя порядок появлений.\nHint: используйте map для отслеживания встреченных значений.",
        "difficulty": "easy",
        "hint1": "используйте map для отслеживания встреченных значений.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage datastructsx\n\nimport (\n\t\"strings\"\n)\n\n// Level 1 (easy): SafeDelete должен возвращать копию map без ключей из списка keys, оригинал не менять.\n// Hint: создайте новый словарь и скопируйте пары, пропуская ненужные ключи.\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, k := range keys {\n\n\t\ttoDelete[k] = struct{}{}\n\t}\n\n\tcloned := make(map[K]V, len(m))\n\tfor k, v := range m {\n\t\tif _, skip := toDelete[k]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[k] = v\n\t}\n\n\treturn M(cloned)\n}\n\n// Level 2 (easy+): Unique устраняет дубликаты в слайсе, сохраняя порядок появлений.\n// Hint: используйте map для отслеживания встреченных значений.\nfunc Unique[T comparable](in []T) []T {\n\tseen := make(map[T]struct{}, len(in))\n\tunique := make([]T, 0, len(in))\n\tfor _, e := range in {\n\t\tif _, ok := seen[e]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[e] = struct{}{}\n\t\tunique = append(unique, e)\n\t}\n\n\treturn unique\n}\n\n// Level 3 (medium): ReverseInPlace разворачивает слайс без дополнительной памяти.\n// Hint: меняйте элементы in-place, двигаясь навстречу с концов.\nfunc ReverseInPlace[T any](in []T) {\n\tfor l, r := 0, len(in)-1; l < r; l, r = l+1, r-1 {\n\t\tin[l], in[r] = in[r], in[l]\n\t}\n}\n\n// Level 4 (medium): Batch разбивает слайс на чанки размера n.\n// Hint: обработайте крайние случаи n<=0 и последний неполный чанк.\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, len(in)+n-1/n)\n\tfor i := 0; i < len(in); i += n {\n\t\tj := i + n\n\t\tif j > len(in) {\n\t\t\tj = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[i:j])\n\t}\n\treturn chunks\n}\n\n// Level 5 (medium+): JoinEfficient объединяет строки без конкатенации в цикле с '+'.\n// Hint: используйте strings.Builder с заранее вычисленным размером буфера.\nfunc JoinEfficient(parts []string) string {\n\tif len(parts) == 0 {\n\t\treturn \"\"\n\t}\n\tif len(parts) == 1 {\n\t\treturn parts[0]\n\t}\n\n\tvar sz int\n\tfor _, part := range parts {\n\t\tsz += len([]rune(part))\n\t}\n\n\tvar sb strings.Builder\n\tsb.Grow(sz)\n\tfor _, part := range parts {\n\t\tsb.WriteString(part)\n\t}\n\n\treturn sb.String()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage datastructsx\n\nimport \"strings\"\n\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, key := range keys {\n\t\ttoDelete[key] = struct{}{}\n\t}\n\tcloned := make(map[K]V, len(m))\n\tfor key, value := range m {\n\t\tif _, skip := toDelete[key]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[key] = value\n\t}\n\treturn M(cloned)\n}\n\nfunc Unique[T comparable](in []T) []T {\n\tif len(in) == 0 {\n\t\treturn nil\n\t}\n\tseen := make(map[T]struct{}, len(in))\n\tresult := make([]T, 0, len(in))\n\tfor _, value := range in {\n\t\tif _, ok := seen[value]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[value] = struct{}{}\n\t\tresult = append(result, value)\n\t}\n\treturn result\n}\n\nfunc ReverseInPlace[T any](in []T) {\n\tfor left, right := 0, len(in)-1; left < right; left, right = left+1, right-1 {\n\t\tin[left], in[right] = in[right], in[left]\n\t}\n}\n\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, (len(in)+n-1)/n)\n\tfor start := 0; start < len(in); start += n {\n\t\tend := start + n\n\t\tif end > len(in) {\n\t\t\tend = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[start:end])\n\t}\n\treturn chunks\n}\n\nfunc JoinEfficient(parts []string) string {\n\tswitch len(parts) {\n\tcase 0:\n\t\treturn \"\"\n\tcase 1:\n\t\treturn parts[0]\n\t}\n\ttotalLen := 0\n\tfor _, part := range parts {\n\t\ttotalLen += len(part)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(totalLen)\n\tfor _, part := range parts {\n\t\tbuilder.WriteString(part)\n\t}\n\treturn builder.String()\n}\n",
        "testCode": "package datastructsx\n\nimport \"testing\"\n\nfunc TestSafeDelete(t *testing.T) {\n\tm := map[string]int{\"a\":1,\"b\":2,\"c\":3}\n\tres := SafeDelete(m, []string{\"b\",\"x\"})\n\tif _, ok := res[\"b\"]; ok { t.Fatal(\"b must be removed\") }\n\tif _, ok := m[\"b\"]; !ok { t.Fatal(\"original must be intact\") }\n}\n\nfunc TestUniqueReverseBatchJoin(t *testing.T) {\n\tu := Unique([]int{1,2,2,3,1})\n\tif len(u)!=3 || u[0]!=1 || u[2]!=3 { t.Fatalf(\"bad unique %v\", u) }\n\tx := []int{1,2,3,4}\n\tReverseInPlace(x)\n\tif x[0]!=4 || x[3]!=1 { t.Fatalf(\"bad reverse %v\", x) }\n\tb := Batch([]int{1,2,3,4,5}, 2)\n\tif len(b)!=3 || len(b[2])!=1 || b[0][0]!=1 || b[1][1]!=4 { t.Fatalf(\"bad batch %v\", b) }\n\tif JoinEfficient([]string{\"ab\",\"cd\",\"ef\"}) != \"abcdef\" { t.Fatal(\"bad join\") }\n}\n",
        "tags": [
          "go",
          "datastructsx"
        ],
        "order": 1
      },
      {
        "package": "datastructsx",
        "slug": "go-datastructsx-reverseinplace",
        "title": "ReverseInPlace разворачивает слайс без дополнительной памяти.",
        "description": "Level 3 (medium): ReverseInPlace разворачивает слайс без дополнительной памяти.\nHint: меняйте элементы in-place, двигаясь навстречу с концов.",
        "difficulty": "medium",
        "hint1": "меняйте элементы in-place, двигаясь навстречу с концов.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage datastructsx\n\nimport (\n\t\"strings\"\n)\n\n// Level 1 (easy): SafeDelete должен возвращать копию map без ключей из списка keys, оригинал не менять.\n// Hint: создайте новый словарь и скопируйте пары, пропуская ненужные ключи.\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, k := range keys {\n\n\t\ttoDelete[k] = struct{}{}\n\t}\n\n\tcloned := make(map[K]V, len(m))\n\tfor k, v := range m {\n\t\tif _, skip := toDelete[k]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[k] = v\n\t}\n\n\treturn M(cloned)\n}\n\n// Level 2 (easy+): Unique устраняет дубликаты в слайсе, сохраняя порядок появлений.\n// Hint: используйте map для отслеживания встреченных значений.\nfunc Unique[T comparable](in []T) []T {\n\tseen := make(map[T]struct{}, len(in))\n\tunique := make([]T, 0, len(in))\n\tfor _, e := range in {\n\t\tif _, ok := seen[e]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[e] = struct{}{}\n\t\tunique = append(unique, e)\n\t}\n\n\treturn unique\n}\n\n// Level 3 (medium): ReverseInPlace разворачивает слайс без дополнительной памяти.\n// Hint: меняйте элементы in-place, двигаясь навстречу с концов.\nfunc ReverseInPlace[T any](in []T) {\n\tfor l, r := 0, len(in)-1; l < r; l, r = l+1, r-1 {\n\t\tin[l], in[r] = in[r], in[l]\n\t}\n}\n\n// Level 4 (medium): Batch разбивает слайс на чанки размера n.\n// Hint: обработайте крайние случаи n<=0 и последний неполный чанк.\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, len(in)+n-1/n)\n\tfor i := 0; i < len(in); i += n {\n\t\tj := i + n\n\t\tif j > len(in) {\n\t\t\tj = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[i:j])\n\t}\n\treturn chunks\n}\n\n// Level 5 (medium+): JoinEfficient объединяет строки без конкатенации в цикле с '+'.\n// Hint: используйте strings.Builder с заранее вычисленным размером буфера.\nfunc JoinEfficient(parts []string) string {\n\tif len(parts) == 0 {\n\t\treturn \"\"\n\t}\n\tif len(parts) == 1 {\n\t\treturn parts[0]\n\t}\n\n\tvar sz int\n\tfor _, part := range parts {\n\t\tsz += len([]rune(part))\n\t}\n\n\tvar sb strings.Builder\n\tsb.Grow(sz)\n\tfor _, part := range parts {\n\t\tsb.WriteString(part)\n\t}\n\n\treturn sb.String()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage datastructsx\n\nimport \"strings\"\n\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, key := range keys {\n\t\ttoDelete[key] = struct{}{}\n\t}\n\tcloned := make(map[K]V, len(m))\n\tfor key, value := range m {\n\t\tif _, skip := toDelete[key]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[key] = value\n\t}\n\treturn M(cloned)\n}\n\nfunc Unique[T comparable](in []T) []T {\n\tif len(in) == 0 {\n\t\treturn nil\n\t}\n\tseen := make(map[T]struct{}, len(in))\n\tresult := make([]T, 0, len(in))\n\tfor _, value := range in {\n\t\tif _, ok := seen[value]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[value] = struct{}{}\n\t\tresult = append(result, value)\n\t}\n\treturn result\n}\n\nfunc ReverseInPlace[T any](in []T) {\n\tfor left, right := 0, len(in)-1; left < right; left, right = left+1, right-1 {\n\t\tin[left], in[right] = in[right], in[left]\n\t}\n}\n\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, (len(in)+n-1)/n)\n\tfor start := 0; start < len(in); start += n {\n\t\tend := start + n\n\t\tif end > len(in) {\n\t\t\tend = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[start:end])\n\t}\n\treturn chunks\n}\n\nfunc JoinEfficient(parts []string) string {\n\tswitch len(parts) {\n\tcase 0:\n\t\treturn \"\"\n\tcase 1:\n\t\treturn parts[0]\n\t}\n\ttotalLen := 0\n\tfor _, part := range parts {\n\t\ttotalLen += len(part)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(totalLen)\n\tfor _, part := range parts {\n\t\tbuilder.WriteString(part)\n\t}\n\treturn builder.String()\n}\n",
        "testCode": "package datastructsx\n\nimport \"testing\"\n\nfunc TestSafeDelete(t *testing.T) {\n\tm := map[string]int{\"a\":1,\"b\":2,\"c\":3}\n\tres := SafeDelete(m, []string{\"b\",\"x\"})\n\tif _, ok := res[\"b\"]; ok { t.Fatal(\"b must be removed\") }\n\tif _, ok := m[\"b\"]; !ok { t.Fatal(\"original must be intact\") }\n}\n\nfunc TestUniqueReverseBatchJoin(t *testing.T) {\n\tu := Unique([]int{1,2,2,3,1})\n\tif len(u)!=3 || u[0]!=1 || u[2]!=3 { t.Fatalf(\"bad unique %v\", u) }\n\tx := []int{1,2,3,4}\n\tReverseInPlace(x)\n\tif x[0]!=4 || x[3]!=1 { t.Fatalf(\"bad reverse %v\", x) }\n\tb := Batch([]int{1,2,3,4,5}, 2)\n\tif len(b)!=3 || len(b[2])!=1 || b[0][0]!=1 || b[1][1]!=4 { t.Fatalf(\"bad batch %v\", b) }\n\tif JoinEfficient([]string{\"ab\",\"cd\",\"ef\"}) != \"abcdef\" { t.Fatal(\"bad join\") }\n}\n",
        "tags": [
          "go",
          "datastructsx"
        ],
        "order": 2
      },
      {
        "package": "datastructsx",
        "slug": "go-datastructsx-batch",
        "title": "Batch разбивает слайс на чанки размера n.",
        "description": "Level 4 (medium): Batch разбивает слайс на чанки размера n.\nHint: обработайте крайние случаи n<=0 и последний неполный чанк.",
        "difficulty": "medium",
        "hint1": "обработайте крайние случаи n<=0 и последний неполный чанк.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage datastructsx\n\nimport (\n\t\"strings\"\n)\n\n// Level 1 (easy): SafeDelete должен возвращать копию map без ключей из списка keys, оригинал не менять.\n// Hint: создайте новый словарь и скопируйте пары, пропуская ненужные ключи.\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, k := range keys {\n\n\t\ttoDelete[k] = struct{}{}\n\t}\n\n\tcloned := make(map[K]V, len(m))\n\tfor k, v := range m {\n\t\tif _, skip := toDelete[k]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[k] = v\n\t}\n\n\treturn M(cloned)\n}\n\n// Level 2 (easy+): Unique устраняет дубликаты в слайсе, сохраняя порядок появлений.\n// Hint: используйте map для отслеживания встреченных значений.\nfunc Unique[T comparable](in []T) []T {\n\tseen := make(map[T]struct{}, len(in))\n\tunique := make([]T, 0, len(in))\n\tfor _, e := range in {\n\t\tif _, ok := seen[e]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[e] = struct{}{}\n\t\tunique = append(unique, e)\n\t}\n\n\treturn unique\n}\n\n// Level 3 (medium): ReverseInPlace разворачивает слайс без дополнительной памяти.\n// Hint: меняйте элементы in-place, двигаясь навстречу с концов.\nfunc ReverseInPlace[T any](in []T) {\n\tfor l, r := 0, len(in)-1; l < r; l, r = l+1, r-1 {\n\t\tin[l], in[r] = in[r], in[l]\n\t}\n}\n\n// Level 4 (medium): Batch разбивает слайс на чанки размера n.\n// Hint: обработайте крайние случаи n<=0 и последний неполный чанк.\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, len(in)+n-1/n)\n\tfor i := 0; i < len(in); i += n {\n\t\tj := i + n\n\t\tif j > len(in) {\n\t\t\tj = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[i:j])\n\t}\n\treturn chunks\n}\n\n// Level 5 (medium+): JoinEfficient объединяет строки без конкатенации в цикле с '+'.\n// Hint: используйте strings.Builder с заранее вычисленным размером буфера.\nfunc JoinEfficient(parts []string) string {\n\tif len(parts) == 0 {\n\t\treturn \"\"\n\t}\n\tif len(parts) == 1 {\n\t\treturn parts[0]\n\t}\n\n\tvar sz int\n\tfor _, part := range parts {\n\t\tsz += len([]rune(part))\n\t}\n\n\tvar sb strings.Builder\n\tsb.Grow(sz)\n\tfor _, part := range parts {\n\t\tsb.WriteString(part)\n\t}\n\n\treturn sb.String()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage datastructsx\n\nimport \"strings\"\n\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, key := range keys {\n\t\ttoDelete[key] = struct{}{}\n\t}\n\tcloned := make(map[K]V, len(m))\n\tfor key, value := range m {\n\t\tif _, skip := toDelete[key]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[key] = value\n\t}\n\treturn M(cloned)\n}\n\nfunc Unique[T comparable](in []T) []T {\n\tif len(in) == 0 {\n\t\treturn nil\n\t}\n\tseen := make(map[T]struct{}, len(in))\n\tresult := make([]T, 0, len(in))\n\tfor _, value := range in {\n\t\tif _, ok := seen[value]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[value] = struct{}{}\n\t\tresult = append(result, value)\n\t}\n\treturn result\n}\n\nfunc ReverseInPlace[T any](in []T) {\n\tfor left, right := 0, len(in)-1; left < right; left, right = left+1, right-1 {\n\t\tin[left], in[right] = in[right], in[left]\n\t}\n}\n\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, (len(in)+n-1)/n)\n\tfor start := 0; start < len(in); start += n {\n\t\tend := start + n\n\t\tif end > len(in) {\n\t\t\tend = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[start:end])\n\t}\n\treturn chunks\n}\n\nfunc JoinEfficient(parts []string) string {\n\tswitch len(parts) {\n\tcase 0:\n\t\treturn \"\"\n\tcase 1:\n\t\treturn parts[0]\n\t}\n\ttotalLen := 0\n\tfor _, part := range parts {\n\t\ttotalLen += len(part)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(totalLen)\n\tfor _, part := range parts {\n\t\tbuilder.WriteString(part)\n\t}\n\treturn builder.String()\n}\n",
        "testCode": "package datastructsx\n\nimport \"testing\"\n\nfunc TestSafeDelete(t *testing.T) {\n\tm := map[string]int{\"a\":1,\"b\":2,\"c\":3}\n\tres := SafeDelete(m, []string{\"b\",\"x\"})\n\tif _, ok := res[\"b\"]; ok { t.Fatal(\"b must be removed\") }\n\tif _, ok := m[\"b\"]; !ok { t.Fatal(\"original must be intact\") }\n}\n\nfunc TestUniqueReverseBatchJoin(t *testing.T) {\n\tu := Unique([]int{1,2,2,3,1})\n\tif len(u)!=3 || u[0]!=1 || u[2]!=3 { t.Fatalf(\"bad unique %v\", u) }\n\tx := []int{1,2,3,4}\n\tReverseInPlace(x)\n\tif x[0]!=4 || x[3]!=1 { t.Fatalf(\"bad reverse %v\", x) }\n\tb := Batch([]int{1,2,3,4,5}, 2)\n\tif len(b)!=3 || len(b[2])!=1 || b[0][0]!=1 || b[1][1]!=4 { t.Fatalf(\"bad batch %v\", b) }\n\tif JoinEfficient([]string{\"ab\",\"cd\",\"ef\"}) != \"abcdef\" { t.Fatal(\"bad join\") }\n}\n",
        "tags": [
          "go",
          "datastructsx"
        ],
        "order": 3
      },
      {
        "package": "datastructsx",
        "slug": "go-datastructsx-joinefficient",
        "title": "JoinEfficient объединяет строки без конкатенации в цикле с '+'.",
        "description": "Level 5 (medium+): JoinEfficient объединяет строки без конкатенации в цикле с '+'.\nHint: используйте strings.Builder с заранее вычисленным размером буфера.",
        "difficulty": "medium",
        "hint1": "используйте strings.Builder с заранее вычисленным размером буфера.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage datastructsx\n\nimport (\n\t\"strings\"\n)\n\n// Level 1 (easy): SafeDelete должен возвращать копию map без ключей из списка keys, оригинал не менять.\n// Hint: создайте новый словарь и скопируйте пары, пропуская ненужные ключи.\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, k := range keys {\n\n\t\ttoDelete[k] = struct{}{}\n\t}\n\n\tcloned := make(map[K]V, len(m))\n\tfor k, v := range m {\n\t\tif _, skip := toDelete[k]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[k] = v\n\t}\n\n\treturn M(cloned)\n}\n\n// Level 2 (easy+): Unique устраняет дубликаты в слайсе, сохраняя порядок появлений.\n// Hint: используйте map для отслеживания встреченных значений.\nfunc Unique[T comparable](in []T) []T {\n\tseen := make(map[T]struct{}, len(in))\n\tunique := make([]T, 0, len(in))\n\tfor _, e := range in {\n\t\tif _, ok := seen[e]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[e] = struct{}{}\n\t\tunique = append(unique, e)\n\t}\n\n\treturn unique\n}\n\n// Level 3 (medium): ReverseInPlace разворачивает слайс без дополнительной памяти.\n// Hint: меняйте элементы in-place, двигаясь навстречу с концов.\nfunc ReverseInPlace[T any](in []T) {\n\tfor l, r := 0, len(in)-1; l < r; l, r = l+1, r-1 {\n\t\tin[l], in[r] = in[r], in[l]\n\t}\n}\n\n// Level 4 (medium): Batch разбивает слайс на чанки размера n.\n// Hint: обработайте крайние случаи n<=0 и последний неполный чанк.\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, len(in)+n-1/n)\n\tfor i := 0; i < len(in); i += n {\n\t\tj := i + n\n\t\tif j > len(in) {\n\t\t\tj = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[i:j])\n\t}\n\treturn chunks\n}\n\n// Level 5 (medium+): JoinEfficient объединяет строки без конкатенации в цикле с '+'.\n// Hint: используйте strings.Builder с заранее вычисленным размером буфера.\nfunc JoinEfficient(parts []string) string {\n\tif len(parts) == 0 {\n\t\treturn \"\"\n\t}\n\tif len(parts) == 1 {\n\t\treturn parts[0]\n\t}\n\n\tvar sz int\n\tfor _, part := range parts {\n\t\tsz += len([]rune(part))\n\t}\n\n\tvar sb strings.Builder\n\tsb.Grow(sz)\n\tfor _, part := range parts {\n\t\tsb.WriteString(part)\n\t}\n\n\treturn sb.String()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage datastructsx\n\nimport \"strings\"\n\nfunc SafeDelete[M ~map[K]V, K comparable, V any](m M, keys []K) M {\n\tif m == nil {\n\t\tvar zero M\n\t\treturn zero\n\t}\n\ttoDelete := make(map[K]struct{}, len(keys))\n\tfor _, key := range keys {\n\t\ttoDelete[key] = struct{}{}\n\t}\n\tcloned := make(map[K]V, len(m))\n\tfor key, value := range m {\n\t\tif _, skip := toDelete[key]; skip {\n\t\t\tcontinue\n\t\t}\n\t\tcloned[key] = value\n\t}\n\treturn M(cloned)\n}\n\nfunc Unique[T comparable](in []T) []T {\n\tif len(in) == 0 {\n\t\treturn nil\n\t}\n\tseen := make(map[T]struct{}, len(in))\n\tresult := make([]T, 0, len(in))\n\tfor _, value := range in {\n\t\tif _, ok := seen[value]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tseen[value] = struct{}{}\n\t\tresult = append(result, value)\n\t}\n\treturn result\n}\n\nfunc ReverseInPlace[T any](in []T) {\n\tfor left, right := 0, len(in)-1; left < right; left, right = left+1, right-1 {\n\t\tin[left], in[right] = in[right], in[left]\n\t}\n}\n\nfunc Batch[T any](in []T, n int) [][]T {\n\tif n <= 0 || len(in) == 0 {\n\t\treturn nil\n\t}\n\tchunks := make([][]T, 0, (len(in)+n-1)/n)\n\tfor start := 0; start < len(in); start += n {\n\t\tend := start + n\n\t\tif end > len(in) {\n\t\t\tend = len(in)\n\t\t}\n\t\tchunks = append(chunks, in[start:end])\n\t}\n\treturn chunks\n}\n\nfunc JoinEfficient(parts []string) string {\n\tswitch len(parts) {\n\tcase 0:\n\t\treturn \"\"\n\tcase 1:\n\t\treturn parts[0]\n\t}\n\ttotalLen := 0\n\tfor _, part := range parts {\n\t\ttotalLen += len(part)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(totalLen)\n\tfor _, part := range parts {\n\t\tbuilder.WriteString(part)\n\t}\n\treturn builder.String()\n}\n",
        "testCode": "package datastructsx\n\nimport \"testing\"\n\nfunc TestSafeDelete(t *testing.T) {\n\tm := map[string]int{\"a\":1,\"b\":2,\"c\":3}\n\tres := SafeDelete(m, []string{\"b\",\"x\"})\n\tif _, ok := res[\"b\"]; ok { t.Fatal(\"b must be removed\") }\n\tif _, ok := m[\"b\"]; !ok { t.Fatal(\"original must be intact\") }\n}\n\nfunc TestUniqueReverseBatchJoin(t *testing.T) {\n\tu := Unique([]int{1,2,2,3,1})\n\tif len(u)!=3 || u[0]!=1 || u[2]!=3 { t.Fatalf(\"bad unique %v\", u) }\n\tx := []int{1,2,3,4}\n\tReverseInPlace(x)\n\tif x[0]!=4 || x[3]!=1 { t.Fatalf(\"bad reverse %v\", x) }\n\tb := Batch([]int{1,2,3,4,5}, 2)\n\tif len(b)!=3 || len(b[2])!=1 || b[0][0]!=1 || b[1][1]!=4 { t.Fatalf(\"bad batch %v\", b) }\n\tif JoinEfficient([]string{\"ab\",\"cd\",\"ef\"}) != \"abcdef\" { t.Fatal(\"bad join\") }\n}\n",
        "tags": [
          "go",
          "datastructsx"
        ],
        "order": 4
      }
    ],
    "category": "core"
  },
  {
    "name": "encodingx",
    "tasks": [
      {
        "package": "encodingx",
        "slug": "go-encodingx-strictdecode",
        "title": "StrictDecode должен использовать json.Decoder и запрещать неизвестные поля.",
        "description": "Level 2 (easy+): StrictDecode должен использовать json.Decoder и запрещать неизвестные поля.\nHint: вызовите DisallowUnknownFields перед Decode.\nLevel 3 (medium): валидацию обязательных полей вынесите в ValidateUser.\nHint: верните ErrBadInput при нарушении правил.\nLevel 4 (medium+): проверяйте отсутствие лишних токенов после Decode.\nHint: убедитесь, что decoder возвращает io.EOF.",
        "difficulty": "easy",
        "hint1": "убедитесь, что decoder возвращает io.EOF.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\n// Level 1 (easy): опишите DTO c JSON-тегами для id, name, age.\n// Hint: структура уже объявлена, доработайте StrictDecode.\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\n// Level 2 (easy+): StrictDecode должен использовать json.Decoder и запрещать неизвестные поля.\n// Hint: вызовите DisallowUnknownFields перед Decode.\n// Level 3 (medium): валидацию обязательных полей вынесите в ValidateUser.\n// Hint: верните ErrBadInput при нарушении правил.\n// Level 4 (medium+): проверяйте отсутствие лишних токенов после Decode.\n// Hint: убедитесь, что decoder возвращает io.EOF.\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar dto UserDTO\n\tif err := dec.Decode(&dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ValidateUser(dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\treturn dto, nil\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\n// Level 5 (medium): ValidateUser проверяет бизнес-ограничения id/name/age.\n// Hint: age может быть nil, но если указана, должна быть >= 0.\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 {\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" {\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 {\n\t\treturn ErrBadInput\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): StrictDecodeList парсит массив пользователей по правилам StrictDecode.\n// Hint: перевызывайте StrictDecode для каждого элемента, чтобы переиспользовать проверки.\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar rawItems []json.RawMessage\n\tif err := dec.Decode(&rawItems); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn nil, err\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems))\n\tfor _, raw := range rawItems {\n\t\tuser, err := StrictDecode(raw)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user)\n\t}\n\treturn users, nil\n}\n\n// Level 7 (medium+): MarshalUser сериализует DTO в JSON после успешной валидации.\n// Hint: используйте json.Marshal и пробрасывайте ошибки.\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil {\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn payload, nil\n}\n\n// Level 8 (medium+): MustStrictDecode паникует при ошибке StrictDecode.\n// Hint: переиспользуйте StrictDecode и оборачивайте ошибку через panic.\nfunc MustStrictDecode(data []byte) UserDTO {\n\tu, err := StrictDecode(data)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn u\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil {\n\t\tif errors.Is(err, io.EOF) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\treturn ErrBadInput\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // stream JSON input through decoder to control strictness\n\tdec.DisallowUnknownFields()                   // reject payloads containing unknown fields\n\tvar dto UserDTO                               // allocate DTO to fill with decoded data\n\tif err := dec.Decode(&dto); err != nil {      // decode the first JSON object into dto\n\t\treturn UserDTO{}, err // propagate decoding error to caller\n\t}\n\tif err := ValidateUser(dto); err != nil { // ensure DTO satisfies business constraints\n\t\treturn UserDTO{}, err // return validation error for bad input\n\t}\n\tif err := ensureEOF(dec); err != nil { // confirm there are no trailing tokens after object\n\t\treturn UserDTO{}, err // fail when unexpected extra data is present\n\t}\n\treturn dto, nil // return decoded and validated DTO\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 { // reject non-positive identifiers\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" { // require non-empty user names\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 { // forbid negative age values when provided\n\t\treturn ErrBadInput\n\t}\n\treturn nil // otherwise validation succeeds\n}\n\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // construct decoder for array payload\n\tdec.DisallowUnknownFields()                   // forbid unknown fields at the top level array\n\tvar rawItems []json.RawMessage                // hold raw JSON elements for per-item validation\n\tif err := dec.Decode(&rawItems); err != nil { // decode entire array into raw messages slice\n\t\treturn nil, err // propagate decoding errors to caller\n\t}\n\tif err := ensureEOF(dec); err != nil { // ensure no trailing tokens remain after array\n\t\treturn nil, err // fail when extra data found\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems)) // preallocate result slice with exact capacity\n\tfor _, raw := range rawItems {             // iterate over raw JSON representations\n\t\tuser, err := StrictDecode(raw) // reuse strict single-object decoder for each element\n\t\tif err != nil {                // stop iteration upon first validation failure\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user) // append valid user to result slice\n\t}\n\treturn users, nil // return fully decoded user collection\n}\n\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil { // forbid serializing invalid DTOs\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u) // encode DTO into JSON bytes\n\tif err != nil {                 // handle potential marshaling errors\n\t\treturn nil, err\n\t}\n\treturn payload, nil // pass serialized representation to caller\n}\n\nfunc MustStrictDecode(data []byte) UserDTO {\n\tuser, err := StrictDecode(data) // attempt strict decoding using shared logic\n\tif err != nil {                 // panic when decoding fails to satisfy strict contract\n\t\tpanic(err)\n\t}\n\treturn user // return decoded DTO when parsing succeeds\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil { // attempt to consume next token from decoder\n\t\tif errors.Is(err, io.EOF) { // io.EOF indicates proper end of stream\n\t\t\treturn nil\n\t\t}\n\t\treturn err // propagate unexpected errors\n\t}\n\treturn ErrBadInput // return validation error when extra tokens exist\n}\n",
        "testCode": "package encodingx\n\nimport (\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nfunc TestStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tuser, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\"}`))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif user.ID != 1 || user.Name != \"Ann\" {\n\t\tt.Fatalf(\"decoded user mismatch: %+v\", user)\n\t}\n\tif _, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\",\"extra\":true}`)); err == nil {\n\t\tt.Fatal(\"expected error on unknown field\")\n\t}\n}\n\nfunc TestValidateUser(t *testing.T) {\n\tt.Parallel()\n\tvalidAge := 30\n\tif err := ValidateUser(UserDTO{ID: 1, Name: \"Ann\", Age: &validAge}); err != nil {\n\t\tt.Fatalf(\"unexpected validation error: %v\", err)\n\t}\n\tif err := ValidateUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n\tnegative := -1\n\tif err := ValidateUser(UserDTO{ID: 2, Name: \"Bob\", Age: &negative}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput for negative age, got %v\", err)\n\t}\n}\n\nfunc TestStrictDecodeList(t *testing.T) {\n\tt.Parallel()\n\tdata := []byte(`[{\"id\":1,\"name\":\"Ann\"},{\"id\":2,\"name\":\"Bob\"}]`)\n\tusers, err := StrictDecodeList(data)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif len(users) != 2 || users[1].Name != \"Bob\" {\n\t\tt.Fatalf(\"unexpected list result: %+v\", users)\n\t}\n\tif _, err := StrictDecodeList([]byte(`[{\"id\":0,\"name\":\"\"}]`)); err == nil {\n\t\tt.Fatal(\"expected validation error for invalid user\")\n\t}\n}\n\nfunc TestMarshalUser(t *testing.T) {\n\tt.Parallel()\n\tu := UserDTO{ID: 5, Name: \"Alice\"}\n\tdata, err := MarshalUser(u)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected marshal error: %v\", err)\n\t}\n\tvar decoded UserDTO\n\tif err := json.Unmarshal(data, &decoded); err != nil {\n\t\tt.Fatalf(\"failed to unmarshal: %v\", err)\n\t}\n\tif decoded.ID != u.ID || decoded.Name != u.Name {\n\t\tt.Fatalf(\"round trip mismatch: %+v\", decoded)\n\t}\n\tif _, err := MarshalUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n}\n\nfunc TestMustStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tif user := MustStrictDecode([]byte(`{\"id\":9,\"name\":\"Nine\"}`)); user.ID != 9 {\n\t\tt.Fatalf(\"unexpected user: %+v\", user)\n\t}\n\tdefer func() {\n\t\tif recover() == nil {\n\t\t\tt.Fatal(\"expected panic on invalid input\")\n\t\t}\n\t}()\n\tMustStrictDecode([]byte(`{\"id\":0}`))\n}\n",
        "tags": [
          "go",
          "encodingx"
        ],
        "order": 1
      },
      {
        "package": "encodingx",
        "slug": "go-encodingx-validateuser",
        "title": "ValidateUser проверяет бизнес-ограничения id/name/age.",
        "description": "Level 5 (medium): ValidateUser проверяет бизнес-ограничения id/name/age.\nHint: age может быть nil, но если указана, должна быть >= 0.",
        "difficulty": "medium",
        "hint1": "age может быть nil, но если указана, должна быть >= 0.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\n// Level 1 (easy): опишите DTO c JSON-тегами для id, name, age.\n// Hint: структура уже объявлена, доработайте StrictDecode.\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\n// Level 2 (easy+): StrictDecode должен использовать json.Decoder и запрещать неизвестные поля.\n// Hint: вызовите DisallowUnknownFields перед Decode.\n// Level 3 (medium): валидацию обязательных полей вынесите в ValidateUser.\n// Hint: верните ErrBadInput при нарушении правил.\n// Level 4 (medium+): проверяйте отсутствие лишних токенов после Decode.\n// Hint: убедитесь, что decoder возвращает io.EOF.\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar dto UserDTO\n\tif err := dec.Decode(&dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ValidateUser(dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\treturn dto, nil\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\n// Level 5 (medium): ValidateUser проверяет бизнес-ограничения id/name/age.\n// Hint: age может быть nil, но если указана, должна быть >= 0.\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 {\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" {\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 {\n\t\treturn ErrBadInput\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): StrictDecodeList парсит массив пользователей по правилам StrictDecode.\n// Hint: перевызывайте StrictDecode для каждого элемента, чтобы переиспользовать проверки.\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar rawItems []json.RawMessage\n\tif err := dec.Decode(&rawItems); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn nil, err\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems))\n\tfor _, raw := range rawItems {\n\t\tuser, err := StrictDecode(raw)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user)\n\t}\n\treturn users, nil\n}\n\n// Level 7 (medium+): MarshalUser сериализует DTO в JSON после успешной валидации.\n// Hint: используйте json.Marshal и пробрасывайте ошибки.\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil {\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn payload, nil\n}\n\n// Level 8 (medium+): MustStrictDecode паникует при ошибке StrictDecode.\n// Hint: переиспользуйте StrictDecode и оборачивайте ошибку через panic.\nfunc MustStrictDecode(data []byte) UserDTO {\n\tu, err := StrictDecode(data)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn u\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil {\n\t\tif errors.Is(err, io.EOF) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\treturn ErrBadInput\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // stream JSON input through decoder to control strictness\n\tdec.DisallowUnknownFields()                   // reject payloads containing unknown fields\n\tvar dto UserDTO                               // allocate DTO to fill with decoded data\n\tif err := dec.Decode(&dto); err != nil {      // decode the first JSON object into dto\n\t\treturn UserDTO{}, err // propagate decoding error to caller\n\t}\n\tif err := ValidateUser(dto); err != nil { // ensure DTO satisfies business constraints\n\t\treturn UserDTO{}, err // return validation error for bad input\n\t}\n\tif err := ensureEOF(dec); err != nil { // confirm there are no trailing tokens after object\n\t\treturn UserDTO{}, err // fail when unexpected extra data is present\n\t}\n\treturn dto, nil // return decoded and validated DTO\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 { // reject non-positive identifiers\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" { // require non-empty user names\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 { // forbid negative age values when provided\n\t\treturn ErrBadInput\n\t}\n\treturn nil // otherwise validation succeeds\n}\n\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // construct decoder for array payload\n\tdec.DisallowUnknownFields()                   // forbid unknown fields at the top level array\n\tvar rawItems []json.RawMessage                // hold raw JSON elements for per-item validation\n\tif err := dec.Decode(&rawItems); err != nil { // decode entire array into raw messages slice\n\t\treturn nil, err // propagate decoding errors to caller\n\t}\n\tif err := ensureEOF(dec); err != nil { // ensure no trailing tokens remain after array\n\t\treturn nil, err // fail when extra data found\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems)) // preallocate result slice with exact capacity\n\tfor _, raw := range rawItems {             // iterate over raw JSON representations\n\t\tuser, err := StrictDecode(raw) // reuse strict single-object decoder for each element\n\t\tif err != nil {                // stop iteration upon first validation failure\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user) // append valid user to result slice\n\t}\n\treturn users, nil // return fully decoded user collection\n}\n\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil { // forbid serializing invalid DTOs\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u) // encode DTO into JSON bytes\n\tif err != nil {                 // handle potential marshaling errors\n\t\treturn nil, err\n\t}\n\treturn payload, nil // pass serialized representation to caller\n}\n\nfunc MustStrictDecode(data []byte) UserDTO {\n\tuser, err := StrictDecode(data) // attempt strict decoding using shared logic\n\tif err != nil {                 // panic when decoding fails to satisfy strict contract\n\t\tpanic(err)\n\t}\n\treturn user // return decoded DTO when parsing succeeds\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil { // attempt to consume next token from decoder\n\t\tif errors.Is(err, io.EOF) { // io.EOF indicates proper end of stream\n\t\t\treturn nil\n\t\t}\n\t\treturn err // propagate unexpected errors\n\t}\n\treturn ErrBadInput // return validation error when extra tokens exist\n}\n",
        "testCode": "package encodingx\n\nimport (\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nfunc TestStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tuser, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\"}`))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif user.ID != 1 || user.Name != \"Ann\" {\n\t\tt.Fatalf(\"decoded user mismatch: %+v\", user)\n\t}\n\tif _, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\",\"extra\":true}`)); err == nil {\n\t\tt.Fatal(\"expected error on unknown field\")\n\t}\n}\n\nfunc TestValidateUser(t *testing.T) {\n\tt.Parallel()\n\tvalidAge := 30\n\tif err := ValidateUser(UserDTO{ID: 1, Name: \"Ann\", Age: &validAge}); err != nil {\n\t\tt.Fatalf(\"unexpected validation error: %v\", err)\n\t}\n\tif err := ValidateUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n\tnegative := -1\n\tif err := ValidateUser(UserDTO{ID: 2, Name: \"Bob\", Age: &negative}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput for negative age, got %v\", err)\n\t}\n}\n\nfunc TestStrictDecodeList(t *testing.T) {\n\tt.Parallel()\n\tdata := []byte(`[{\"id\":1,\"name\":\"Ann\"},{\"id\":2,\"name\":\"Bob\"}]`)\n\tusers, err := StrictDecodeList(data)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif len(users) != 2 || users[1].Name != \"Bob\" {\n\t\tt.Fatalf(\"unexpected list result: %+v\", users)\n\t}\n\tif _, err := StrictDecodeList([]byte(`[{\"id\":0,\"name\":\"\"}]`)); err == nil {\n\t\tt.Fatal(\"expected validation error for invalid user\")\n\t}\n}\n\nfunc TestMarshalUser(t *testing.T) {\n\tt.Parallel()\n\tu := UserDTO{ID: 5, Name: \"Alice\"}\n\tdata, err := MarshalUser(u)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected marshal error: %v\", err)\n\t}\n\tvar decoded UserDTO\n\tif err := json.Unmarshal(data, &decoded); err != nil {\n\t\tt.Fatalf(\"failed to unmarshal: %v\", err)\n\t}\n\tif decoded.ID != u.ID || decoded.Name != u.Name {\n\t\tt.Fatalf(\"round trip mismatch: %+v\", decoded)\n\t}\n\tif _, err := MarshalUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n}\n\nfunc TestMustStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tif user := MustStrictDecode([]byte(`{\"id\":9,\"name\":\"Nine\"}`)); user.ID != 9 {\n\t\tt.Fatalf(\"unexpected user: %+v\", user)\n\t}\n\tdefer func() {\n\t\tif recover() == nil {\n\t\t\tt.Fatal(\"expected panic on invalid input\")\n\t\t}\n\t}()\n\tMustStrictDecode([]byte(`{\"id\":0}`))\n}\n",
        "tags": [
          "go",
          "encodingx"
        ],
        "order": 4
      },
      {
        "package": "encodingx",
        "slug": "go-encodingx-strictdecodelist",
        "title": "StrictDecodeList парсит массив пользователей по правилам StrictDecode.",
        "description": "Level 6 (medium+): StrictDecodeList парсит массив пользователей по правилам StrictDecode.\nHint: перевызывайте StrictDecode для каждого элемента, чтобы переиспользовать проверки.",
        "difficulty": "medium",
        "hint1": "перевызывайте StrictDecode для каждого элемента, чтобы переиспользовать проверки.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\n// Level 1 (easy): опишите DTO c JSON-тегами для id, name, age.\n// Hint: структура уже объявлена, доработайте StrictDecode.\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\n// Level 2 (easy+): StrictDecode должен использовать json.Decoder и запрещать неизвестные поля.\n// Hint: вызовите DisallowUnknownFields перед Decode.\n// Level 3 (medium): валидацию обязательных полей вынесите в ValidateUser.\n// Hint: верните ErrBadInput при нарушении правил.\n// Level 4 (medium+): проверяйте отсутствие лишних токенов после Decode.\n// Hint: убедитесь, что decoder возвращает io.EOF.\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar dto UserDTO\n\tif err := dec.Decode(&dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ValidateUser(dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\treturn dto, nil\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\n// Level 5 (medium): ValidateUser проверяет бизнес-ограничения id/name/age.\n// Hint: age может быть nil, но если указана, должна быть >= 0.\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 {\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" {\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 {\n\t\treturn ErrBadInput\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): StrictDecodeList парсит массив пользователей по правилам StrictDecode.\n// Hint: перевызывайте StrictDecode для каждого элемента, чтобы переиспользовать проверки.\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar rawItems []json.RawMessage\n\tif err := dec.Decode(&rawItems); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn nil, err\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems))\n\tfor _, raw := range rawItems {\n\t\tuser, err := StrictDecode(raw)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user)\n\t}\n\treturn users, nil\n}\n\n// Level 7 (medium+): MarshalUser сериализует DTO в JSON после успешной валидации.\n// Hint: используйте json.Marshal и пробрасывайте ошибки.\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil {\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn payload, nil\n}\n\n// Level 8 (medium+): MustStrictDecode паникует при ошибке StrictDecode.\n// Hint: переиспользуйте StrictDecode и оборачивайте ошибку через panic.\nfunc MustStrictDecode(data []byte) UserDTO {\n\tu, err := StrictDecode(data)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn u\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil {\n\t\tif errors.Is(err, io.EOF) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\treturn ErrBadInput\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // stream JSON input through decoder to control strictness\n\tdec.DisallowUnknownFields()                   // reject payloads containing unknown fields\n\tvar dto UserDTO                               // allocate DTO to fill with decoded data\n\tif err := dec.Decode(&dto); err != nil {      // decode the first JSON object into dto\n\t\treturn UserDTO{}, err // propagate decoding error to caller\n\t}\n\tif err := ValidateUser(dto); err != nil { // ensure DTO satisfies business constraints\n\t\treturn UserDTO{}, err // return validation error for bad input\n\t}\n\tif err := ensureEOF(dec); err != nil { // confirm there are no trailing tokens after object\n\t\treturn UserDTO{}, err // fail when unexpected extra data is present\n\t}\n\treturn dto, nil // return decoded and validated DTO\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 { // reject non-positive identifiers\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" { // require non-empty user names\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 { // forbid negative age values when provided\n\t\treturn ErrBadInput\n\t}\n\treturn nil // otherwise validation succeeds\n}\n\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // construct decoder for array payload\n\tdec.DisallowUnknownFields()                   // forbid unknown fields at the top level array\n\tvar rawItems []json.RawMessage                // hold raw JSON elements for per-item validation\n\tif err := dec.Decode(&rawItems); err != nil { // decode entire array into raw messages slice\n\t\treturn nil, err // propagate decoding errors to caller\n\t}\n\tif err := ensureEOF(dec); err != nil { // ensure no trailing tokens remain after array\n\t\treturn nil, err // fail when extra data found\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems)) // preallocate result slice with exact capacity\n\tfor _, raw := range rawItems {             // iterate over raw JSON representations\n\t\tuser, err := StrictDecode(raw) // reuse strict single-object decoder for each element\n\t\tif err != nil {                // stop iteration upon first validation failure\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user) // append valid user to result slice\n\t}\n\treturn users, nil // return fully decoded user collection\n}\n\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil { // forbid serializing invalid DTOs\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u) // encode DTO into JSON bytes\n\tif err != nil {                 // handle potential marshaling errors\n\t\treturn nil, err\n\t}\n\treturn payload, nil // pass serialized representation to caller\n}\n\nfunc MustStrictDecode(data []byte) UserDTO {\n\tuser, err := StrictDecode(data) // attempt strict decoding using shared logic\n\tif err != nil {                 // panic when decoding fails to satisfy strict contract\n\t\tpanic(err)\n\t}\n\treturn user // return decoded DTO when parsing succeeds\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil { // attempt to consume next token from decoder\n\t\tif errors.Is(err, io.EOF) { // io.EOF indicates proper end of stream\n\t\t\treturn nil\n\t\t}\n\t\treturn err // propagate unexpected errors\n\t}\n\treturn ErrBadInput // return validation error when extra tokens exist\n}\n",
        "testCode": "package encodingx\n\nimport (\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nfunc TestStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tuser, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\"}`))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif user.ID != 1 || user.Name != \"Ann\" {\n\t\tt.Fatalf(\"decoded user mismatch: %+v\", user)\n\t}\n\tif _, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\",\"extra\":true}`)); err == nil {\n\t\tt.Fatal(\"expected error on unknown field\")\n\t}\n}\n\nfunc TestValidateUser(t *testing.T) {\n\tt.Parallel()\n\tvalidAge := 30\n\tif err := ValidateUser(UserDTO{ID: 1, Name: \"Ann\", Age: &validAge}); err != nil {\n\t\tt.Fatalf(\"unexpected validation error: %v\", err)\n\t}\n\tif err := ValidateUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n\tnegative := -1\n\tif err := ValidateUser(UserDTO{ID: 2, Name: \"Bob\", Age: &negative}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput for negative age, got %v\", err)\n\t}\n}\n\nfunc TestStrictDecodeList(t *testing.T) {\n\tt.Parallel()\n\tdata := []byte(`[{\"id\":1,\"name\":\"Ann\"},{\"id\":2,\"name\":\"Bob\"}]`)\n\tusers, err := StrictDecodeList(data)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif len(users) != 2 || users[1].Name != \"Bob\" {\n\t\tt.Fatalf(\"unexpected list result: %+v\", users)\n\t}\n\tif _, err := StrictDecodeList([]byte(`[{\"id\":0,\"name\":\"\"}]`)); err == nil {\n\t\tt.Fatal(\"expected validation error for invalid user\")\n\t}\n}\n\nfunc TestMarshalUser(t *testing.T) {\n\tt.Parallel()\n\tu := UserDTO{ID: 5, Name: \"Alice\"}\n\tdata, err := MarshalUser(u)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected marshal error: %v\", err)\n\t}\n\tvar decoded UserDTO\n\tif err := json.Unmarshal(data, &decoded); err != nil {\n\t\tt.Fatalf(\"failed to unmarshal: %v\", err)\n\t}\n\tif decoded.ID != u.ID || decoded.Name != u.Name {\n\t\tt.Fatalf(\"round trip mismatch: %+v\", decoded)\n\t}\n\tif _, err := MarshalUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n}\n\nfunc TestMustStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tif user := MustStrictDecode([]byte(`{\"id\":9,\"name\":\"Nine\"}`)); user.ID != 9 {\n\t\tt.Fatalf(\"unexpected user: %+v\", user)\n\t}\n\tdefer func() {\n\t\tif recover() == nil {\n\t\t\tt.Fatal(\"expected panic on invalid input\")\n\t\t}\n\t}()\n\tMustStrictDecode([]byte(`{\"id\":0}`))\n}\n",
        "tags": [
          "go",
          "encodingx"
        ],
        "order": 5
      },
      {
        "package": "encodingx",
        "slug": "go-encodingx-marshaluser",
        "title": "MarshalUser сериализует DTO в JSON после успешной валидации.",
        "description": "Level 7 (medium+): MarshalUser сериализует DTO в JSON после успешной валидации.\nHint: используйте json.Marshal и пробрасывайте ошибки.",
        "difficulty": "medium",
        "hint1": "используйте json.Marshal и пробрасывайте ошибки.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\n// Level 1 (easy): опишите DTO c JSON-тегами для id, name, age.\n// Hint: структура уже объявлена, доработайте StrictDecode.\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\n// Level 2 (easy+): StrictDecode должен использовать json.Decoder и запрещать неизвестные поля.\n// Hint: вызовите DisallowUnknownFields перед Decode.\n// Level 3 (medium): валидацию обязательных полей вынесите в ValidateUser.\n// Hint: верните ErrBadInput при нарушении правил.\n// Level 4 (medium+): проверяйте отсутствие лишних токенов после Decode.\n// Hint: убедитесь, что decoder возвращает io.EOF.\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar dto UserDTO\n\tif err := dec.Decode(&dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ValidateUser(dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\treturn dto, nil\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\n// Level 5 (medium): ValidateUser проверяет бизнес-ограничения id/name/age.\n// Hint: age может быть nil, но если указана, должна быть >= 0.\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 {\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" {\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 {\n\t\treturn ErrBadInput\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): StrictDecodeList парсит массив пользователей по правилам StrictDecode.\n// Hint: перевызывайте StrictDecode для каждого элемента, чтобы переиспользовать проверки.\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar rawItems []json.RawMessage\n\tif err := dec.Decode(&rawItems); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn nil, err\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems))\n\tfor _, raw := range rawItems {\n\t\tuser, err := StrictDecode(raw)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user)\n\t}\n\treturn users, nil\n}\n\n// Level 7 (medium+): MarshalUser сериализует DTO в JSON после успешной валидации.\n// Hint: используйте json.Marshal и пробрасывайте ошибки.\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil {\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn payload, nil\n}\n\n// Level 8 (medium+): MustStrictDecode паникует при ошибке StrictDecode.\n// Hint: переиспользуйте StrictDecode и оборачивайте ошибку через panic.\nfunc MustStrictDecode(data []byte) UserDTO {\n\tu, err := StrictDecode(data)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn u\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil {\n\t\tif errors.Is(err, io.EOF) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\treturn ErrBadInput\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // stream JSON input through decoder to control strictness\n\tdec.DisallowUnknownFields()                   // reject payloads containing unknown fields\n\tvar dto UserDTO                               // allocate DTO to fill with decoded data\n\tif err := dec.Decode(&dto); err != nil {      // decode the first JSON object into dto\n\t\treturn UserDTO{}, err // propagate decoding error to caller\n\t}\n\tif err := ValidateUser(dto); err != nil { // ensure DTO satisfies business constraints\n\t\treturn UserDTO{}, err // return validation error for bad input\n\t}\n\tif err := ensureEOF(dec); err != nil { // confirm there are no trailing tokens after object\n\t\treturn UserDTO{}, err // fail when unexpected extra data is present\n\t}\n\treturn dto, nil // return decoded and validated DTO\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 { // reject non-positive identifiers\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" { // require non-empty user names\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 { // forbid negative age values when provided\n\t\treturn ErrBadInput\n\t}\n\treturn nil // otherwise validation succeeds\n}\n\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // construct decoder for array payload\n\tdec.DisallowUnknownFields()                   // forbid unknown fields at the top level array\n\tvar rawItems []json.RawMessage                // hold raw JSON elements for per-item validation\n\tif err := dec.Decode(&rawItems); err != nil { // decode entire array into raw messages slice\n\t\treturn nil, err // propagate decoding errors to caller\n\t}\n\tif err := ensureEOF(dec); err != nil { // ensure no trailing tokens remain after array\n\t\treturn nil, err // fail when extra data found\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems)) // preallocate result slice with exact capacity\n\tfor _, raw := range rawItems {             // iterate over raw JSON representations\n\t\tuser, err := StrictDecode(raw) // reuse strict single-object decoder for each element\n\t\tif err != nil {                // stop iteration upon first validation failure\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user) // append valid user to result slice\n\t}\n\treturn users, nil // return fully decoded user collection\n}\n\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil { // forbid serializing invalid DTOs\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u) // encode DTO into JSON bytes\n\tif err != nil {                 // handle potential marshaling errors\n\t\treturn nil, err\n\t}\n\treturn payload, nil // pass serialized representation to caller\n}\n\nfunc MustStrictDecode(data []byte) UserDTO {\n\tuser, err := StrictDecode(data) // attempt strict decoding using shared logic\n\tif err != nil {                 // panic when decoding fails to satisfy strict contract\n\t\tpanic(err)\n\t}\n\treturn user // return decoded DTO when parsing succeeds\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil { // attempt to consume next token from decoder\n\t\tif errors.Is(err, io.EOF) { // io.EOF indicates proper end of stream\n\t\t\treturn nil\n\t\t}\n\t\treturn err // propagate unexpected errors\n\t}\n\treturn ErrBadInput // return validation error when extra tokens exist\n}\n",
        "testCode": "package encodingx\n\nimport (\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nfunc TestStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tuser, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\"}`))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif user.ID != 1 || user.Name != \"Ann\" {\n\t\tt.Fatalf(\"decoded user mismatch: %+v\", user)\n\t}\n\tif _, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\",\"extra\":true}`)); err == nil {\n\t\tt.Fatal(\"expected error on unknown field\")\n\t}\n}\n\nfunc TestValidateUser(t *testing.T) {\n\tt.Parallel()\n\tvalidAge := 30\n\tif err := ValidateUser(UserDTO{ID: 1, Name: \"Ann\", Age: &validAge}); err != nil {\n\t\tt.Fatalf(\"unexpected validation error: %v\", err)\n\t}\n\tif err := ValidateUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n\tnegative := -1\n\tif err := ValidateUser(UserDTO{ID: 2, Name: \"Bob\", Age: &negative}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput for negative age, got %v\", err)\n\t}\n}\n\nfunc TestStrictDecodeList(t *testing.T) {\n\tt.Parallel()\n\tdata := []byte(`[{\"id\":1,\"name\":\"Ann\"},{\"id\":2,\"name\":\"Bob\"}]`)\n\tusers, err := StrictDecodeList(data)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif len(users) != 2 || users[1].Name != \"Bob\" {\n\t\tt.Fatalf(\"unexpected list result: %+v\", users)\n\t}\n\tif _, err := StrictDecodeList([]byte(`[{\"id\":0,\"name\":\"\"}]`)); err == nil {\n\t\tt.Fatal(\"expected validation error for invalid user\")\n\t}\n}\n\nfunc TestMarshalUser(t *testing.T) {\n\tt.Parallel()\n\tu := UserDTO{ID: 5, Name: \"Alice\"}\n\tdata, err := MarshalUser(u)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected marshal error: %v\", err)\n\t}\n\tvar decoded UserDTO\n\tif err := json.Unmarshal(data, &decoded); err != nil {\n\t\tt.Fatalf(\"failed to unmarshal: %v\", err)\n\t}\n\tif decoded.ID != u.ID || decoded.Name != u.Name {\n\t\tt.Fatalf(\"round trip mismatch: %+v\", decoded)\n\t}\n\tif _, err := MarshalUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n}\n\nfunc TestMustStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tif user := MustStrictDecode([]byte(`{\"id\":9,\"name\":\"Nine\"}`)); user.ID != 9 {\n\t\tt.Fatalf(\"unexpected user: %+v\", user)\n\t}\n\tdefer func() {\n\t\tif recover() == nil {\n\t\t\tt.Fatal(\"expected panic on invalid input\")\n\t\t}\n\t}()\n\tMustStrictDecode([]byte(`{\"id\":0}`))\n}\n",
        "tags": [
          "go",
          "encodingx"
        ],
        "order": 6
      },
      {
        "package": "encodingx",
        "slug": "go-encodingx-muststrictdecode",
        "title": "MustStrictDecode паникует при ошибке StrictDecode.",
        "description": "Level 8 (medium+): MustStrictDecode паникует при ошибке StrictDecode.\nHint: переиспользуйте StrictDecode и оборачивайте ошибку через panic.",
        "difficulty": "medium",
        "hint1": "переиспользуйте StrictDecode и оборачивайте ошибку через panic.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\n// Level 1 (easy): опишите DTO c JSON-тегами для id, name, age.\n// Hint: структура уже объявлена, доработайте StrictDecode.\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\n// Level 2 (easy+): StrictDecode должен использовать json.Decoder и запрещать неизвестные поля.\n// Hint: вызовите DisallowUnknownFields перед Decode.\n// Level 3 (medium): валидацию обязательных полей вынесите в ValidateUser.\n// Hint: верните ErrBadInput при нарушении правил.\n// Level 4 (medium+): проверяйте отсутствие лишних токенов после Decode.\n// Hint: убедитесь, что decoder возвращает io.EOF.\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar dto UserDTO\n\tif err := dec.Decode(&dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ValidateUser(dto); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn UserDTO{}, err\n\t}\n\treturn dto, nil\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\n// Level 5 (medium): ValidateUser проверяет бизнес-ограничения id/name/age.\n// Hint: age может быть nil, но если указана, должна быть >= 0.\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 {\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" {\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 {\n\t\treturn ErrBadInput\n\t}\n\treturn nil\n}\n\n// Level 6 (medium+): StrictDecodeList парсит массив пользователей по правилам StrictDecode.\n// Hint: перевызывайте StrictDecode для каждого элемента, чтобы переиспользовать проверки.\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\tvar rawItems []json.RawMessage\n\tif err := dec.Decode(&rawItems); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := ensureEOF(dec); err != nil {\n\t\treturn nil, err\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems))\n\tfor _, raw := range rawItems {\n\t\tuser, err := StrictDecode(raw)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user)\n\t}\n\treturn users, nil\n}\n\n// Level 7 (medium+): MarshalUser сериализует DTO в JSON после успешной валидации.\n// Hint: используйте json.Marshal и пробрасывайте ошибки.\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil {\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn payload, nil\n}\n\n// Level 8 (medium+): MustStrictDecode паникует при ошибке StrictDecode.\n// Hint: переиспользуйте StrictDecode и оборачивайте ошибку через panic.\nfunc MustStrictDecode(data []byte) UserDTO {\n\tu, err := StrictDecode(data)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn u\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil {\n\t\tif errors.Is(err, io.EOF) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\treturn ErrBadInput\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage encodingx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io\"\n)\n\ntype UserDTO struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n\tAge  *int   `json:\"age,omitempty\"`\n}\n\nfunc StrictDecode(data []byte) (UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // stream JSON input through decoder to control strictness\n\tdec.DisallowUnknownFields()                   // reject payloads containing unknown fields\n\tvar dto UserDTO                               // allocate DTO to fill with decoded data\n\tif err := dec.Decode(&dto); err != nil {      // decode the first JSON object into dto\n\t\treturn UserDTO{}, err // propagate decoding error to caller\n\t}\n\tif err := ValidateUser(dto); err != nil { // ensure DTO satisfies business constraints\n\t\treturn UserDTO{}, err // return validation error for bad input\n\t}\n\tif err := ensureEOF(dec); err != nil { // confirm there are no trailing tokens after object\n\t\treturn UserDTO{}, err // fail when unexpected extra data is present\n\t}\n\treturn dto, nil // return decoded and validated DTO\n}\n\nvar ErrBadInput = errors.New(\"bad input\")\n\nfunc ValidateUser(u UserDTO) error {\n\tif u.ID <= 0 { // reject non-positive identifiers\n\t\treturn ErrBadInput\n\t}\n\tif u.Name == \"\" { // require non-empty user names\n\t\treturn ErrBadInput\n\t}\n\tif u.Age != nil && *u.Age < 0 { // forbid negative age values when provided\n\t\treturn ErrBadInput\n\t}\n\treturn nil // otherwise validation succeeds\n}\n\nfunc StrictDecodeList(data []byte) ([]UserDTO, error) {\n\tdec := json.NewDecoder(bytes.NewReader(data)) // construct decoder for array payload\n\tdec.DisallowUnknownFields()                   // forbid unknown fields at the top level array\n\tvar rawItems []json.RawMessage                // hold raw JSON elements for per-item validation\n\tif err := dec.Decode(&rawItems); err != nil { // decode entire array into raw messages slice\n\t\treturn nil, err // propagate decoding errors to caller\n\t}\n\tif err := ensureEOF(dec); err != nil { // ensure no trailing tokens remain after array\n\t\treturn nil, err // fail when extra data found\n\t}\n\tusers := make([]UserDTO, 0, len(rawItems)) // preallocate result slice with exact capacity\n\tfor _, raw := range rawItems {             // iterate over raw JSON representations\n\t\tuser, err := StrictDecode(raw) // reuse strict single-object decoder for each element\n\t\tif err != nil {                // stop iteration upon first validation failure\n\t\t\treturn nil, err\n\t\t}\n\t\tusers = append(users, user) // append valid user to result slice\n\t}\n\treturn users, nil // return fully decoded user collection\n}\n\nfunc MarshalUser(u UserDTO) ([]byte, error) {\n\tif err := ValidateUser(u); err != nil { // forbid serializing invalid DTOs\n\t\treturn nil, err\n\t}\n\tpayload, err := json.Marshal(u) // encode DTO into JSON bytes\n\tif err != nil {                 // handle potential marshaling errors\n\t\treturn nil, err\n\t}\n\treturn payload, nil // pass serialized representation to caller\n}\n\nfunc MustStrictDecode(data []byte) UserDTO {\n\tuser, err := StrictDecode(data) // attempt strict decoding using shared logic\n\tif err != nil {                 // panic when decoding fails to satisfy strict contract\n\t\tpanic(err)\n\t}\n\treturn user // return decoded DTO when parsing succeeds\n}\n\nfunc ensureEOF(dec *json.Decoder) error {\n\tif err := dec.Decode(&struct{}{}); err != nil { // attempt to consume next token from decoder\n\t\tif errors.Is(err, io.EOF) { // io.EOF indicates proper end of stream\n\t\t\treturn nil\n\t\t}\n\t\treturn err // propagate unexpected errors\n\t}\n\treturn ErrBadInput // return validation error when extra tokens exist\n}\n",
        "testCode": "package encodingx\n\nimport (\n\t\"encoding/json\"\n\t\"testing\"\n)\n\nfunc TestStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tuser, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\"}`))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif user.ID != 1 || user.Name != \"Ann\" {\n\t\tt.Fatalf(\"decoded user mismatch: %+v\", user)\n\t}\n\tif _, err := StrictDecode([]byte(`{\"id\":1,\"name\":\"Ann\",\"extra\":true}`)); err == nil {\n\t\tt.Fatal(\"expected error on unknown field\")\n\t}\n}\n\nfunc TestValidateUser(t *testing.T) {\n\tt.Parallel()\n\tvalidAge := 30\n\tif err := ValidateUser(UserDTO{ID: 1, Name: \"Ann\", Age: &validAge}); err != nil {\n\t\tt.Fatalf(\"unexpected validation error: %v\", err)\n\t}\n\tif err := ValidateUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n\tnegative := -1\n\tif err := ValidateUser(UserDTO{ID: 2, Name: \"Bob\", Age: &negative}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput for negative age, got %v\", err)\n\t}\n}\n\nfunc TestStrictDecodeList(t *testing.T) {\n\tt.Parallel()\n\tdata := []byte(`[{\"id\":1,\"name\":\"Ann\"},{\"id\":2,\"name\":\"Bob\"}]`)\n\tusers, err := StrictDecodeList(data)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif len(users) != 2 || users[1].Name != \"Bob\" {\n\t\tt.Fatalf(\"unexpected list result: %+v\", users)\n\t}\n\tif _, err := StrictDecodeList([]byte(`[{\"id\":0,\"name\":\"\"}]`)); err == nil {\n\t\tt.Fatal(\"expected validation error for invalid user\")\n\t}\n}\n\nfunc TestMarshalUser(t *testing.T) {\n\tt.Parallel()\n\tu := UserDTO{ID: 5, Name: \"Alice\"}\n\tdata, err := MarshalUser(u)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected marshal error: %v\", err)\n\t}\n\tvar decoded UserDTO\n\tif err := json.Unmarshal(data, &decoded); err != nil {\n\t\tt.Fatalf(\"failed to unmarshal: %v\", err)\n\t}\n\tif decoded.ID != u.ID || decoded.Name != u.Name {\n\t\tt.Fatalf(\"round trip mismatch: %+v\", decoded)\n\t}\n\tif _, err := MarshalUser(UserDTO{}); err != ErrBadInput {\n\t\tt.Fatalf(\"expected ErrBadInput, got %v\", err)\n\t}\n}\n\nfunc TestMustStrictDecode(t *testing.T) {\n\tt.Parallel()\n\tif user := MustStrictDecode([]byte(`{\"id\":9,\"name\":\"Nine\"}`)); user.ID != 9 {\n\t\tt.Fatalf(\"unexpected user: %+v\", user)\n\t}\n\tdefer func() {\n\t\tif recover() == nil {\n\t\t\tt.Fatal(\"expected panic on invalid input\")\n\t\t}\n\t}()\n\tMustStrictDecode([]byte(`{\"id\":0}`))\n}\n",
        "tags": [
          "go",
          "encodingx"
        ],
        "order": 7
      }
    ],
    "category": "core"
  },
  {
    "name": "errorsx",
    "tasks": [
      {
        "package": "errorsx",
        "slug": "go-errorsx-unwrap",
        "title": "реализуйте метод Unwrap для AppError, чтобы поддерживать errors.Is/As.",
        "description": "Level 3 (medium): реализуйте метод Unwrap для AppError, чтобы поддерживать errors.Is/As.\nHint: верните вложенную ошибку Err.",
        "difficulty": "medium",
        "hint1": "верните вложенную ошибку Err.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): объявите два sentinel-объекта ошибок ErrNotFound и ErrUnauthorized.\n// Hint: используйте errors.New с разными строками и сделайте их package-level переменными.\nvar (\n\tErrNotFound     error = errors.New(\"not found\")\n\tErrUnauthorized error = errors.New(\"unauthorized\")\n)\n\n// Level 2 (easy+): опишите тип AppError с полями Code, Op и Err и реализуйте метод Error.\n// Hint: метод Error должен возвращать удобочитаемую строку с данными полей.\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"exception occured %v\", e.Error())\n}\n\n// Level 3 (medium): реализуйте метод Unwrap для AppError, чтобы поддерживать errors.Is/As.\n// Hint: верните вложенную ошибку Err.\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\n// Level 4 (medium): функция Wrap опционально оборачивает err в AppError с указанной операцией.\n// Hint: на входе nil возвращайте nil, иначе создавайте новый AppError.\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\n// Level 5 (medium): функция E собирает AppError c кодом и операцией, прокидывая первоначальную err.\n// Hint: допускается, что err может быть nil — возвращайте nil.\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\n// Level 6 (medium+): IsNotFound проверяет, содержит ли цепочка ошибок ErrNotFound.\n// Hint: воспользуйтесь errors.Is.\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\n// Level 7 (medium+): FormatNotFound форматирует ошибку вида \"entity <id>: ErrNotFound\".\n// Hint: используйте fmt.Errorf с %w для оборачивания.\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\tErrNotFound     = errors.New(\"not found\")\n\tErrUnauthorized = errors.New(\"unauthorized\")\n)\n\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"op=%s, code=%s, err=%v\", e.Op, e.Code, e.Err)\n}\n\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "testCode": "package errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestSentinels(t *testing.T) {\n\tif ErrNotFound == nil || ErrUnauthorized == nil {\n\t\tt.Fatal(\"sentinel errors must be defined\")\n\t}\n\tif ErrNotFound == ErrUnauthorized {\n\t\tt.Fatal(\"different sentinels must not be equal\")\n\t}\n}\n\nfunc TestAppErrorWrapAndIs(t *testing.T) {\n\tbase := ErrNotFound\n\te := Wrap(\"repo.GetUser\", base)\n\tif e == nil {\n\t\tt.Fatalf(\"Wrap returned nil\")\n\t}\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"errors.Is must work through AppError\")\n\t}\n\tif ae, ok := e.(*AppError); ok {\n\t\tif ae.Op != \"repo.GetUser\" {\n\t\t\tt.Fatalf(\"Op not set\")\n\t\t}\n\t} else {\n\t\tt.Fatalf(\"must return *AppError\")\n\t}\n}\n\nfunc TestEWithCode(t *testing.T) {\n\te := E(\"NOT_FOUND\", \"svc.Load\", ErrNotFound)\n\tif e == nil {\n\t\tt.Fatalf(\"E returned nil\")\n\t}\n\tvar ae *AppError\n\tif !errors.As(e, &ae) {\n\t\tt.Fatalf(\"must be AppError\")\n\t}\n\tif ae.Code != \"NOT_FOUND\" || ae.Op != \"svc.Load\" || !errors.Is(ae, ErrNotFound) {\n\t\tt.Fatalf(\"fields not set correctly\")\n\t}\n}\n\nfunc TestFormatNotFound(t *testing.T) {\n\te := FormatNotFound(\"42\")\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"must wrap ErrNotFound\")\n\t}\n\texp := fmt.Sprintf(\"entity %s: %v\", \"42\", ErrNotFound)\n\tif e.Error() != exp {\n\t\tt.Fatalf(\"unexpected error string: %q\", e.Error())\n\t}\n}\n",
        "tags": [
          "go",
          "errorsx"
        ],
        "order": 2
      },
      {
        "package": "errorsx",
        "slug": "go-errorsx-wrap",
        "title": "функция Wrap опционально оборачивает err в AppError с указанной операцией.",
        "description": "Level 4 (medium): функция Wrap опционально оборачивает err в AppError с указанной операцией.\nHint: на входе nil возвращайте nil, иначе создавайте новый AppError.",
        "difficulty": "medium",
        "hint1": "на входе nil возвращайте nil, иначе создавайте новый AppError.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): объявите два sentinel-объекта ошибок ErrNotFound и ErrUnauthorized.\n// Hint: используйте errors.New с разными строками и сделайте их package-level переменными.\nvar (\n\tErrNotFound     error = errors.New(\"not found\")\n\tErrUnauthorized error = errors.New(\"unauthorized\")\n)\n\n// Level 2 (easy+): опишите тип AppError с полями Code, Op и Err и реализуйте метод Error.\n// Hint: метод Error должен возвращать удобочитаемую строку с данными полей.\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"exception occured %v\", e.Error())\n}\n\n// Level 3 (medium): реализуйте метод Unwrap для AppError, чтобы поддерживать errors.Is/As.\n// Hint: верните вложенную ошибку Err.\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\n// Level 4 (medium): функция Wrap опционально оборачивает err в AppError с указанной операцией.\n// Hint: на входе nil возвращайте nil, иначе создавайте новый AppError.\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\n// Level 5 (medium): функция E собирает AppError c кодом и операцией, прокидывая первоначальную err.\n// Hint: допускается, что err может быть nil — возвращайте nil.\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\n// Level 6 (medium+): IsNotFound проверяет, содержит ли цепочка ошибок ErrNotFound.\n// Hint: воспользуйтесь errors.Is.\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\n// Level 7 (medium+): FormatNotFound форматирует ошибку вида \"entity <id>: ErrNotFound\".\n// Hint: используйте fmt.Errorf с %w для оборачивания.\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\tErrNotFound     = errors.New(\"not found\")\n\tErrUnauthorized = errors.New(\"unauthorized\")\n)\n\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"op=%s, code=%s, err=%v\", e.Op, e.Code, e.Err)\n}\n\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "testCode": "package errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestSentinels(t *testing.T) {\n\tif ErrNotFound == nil || ErrUnauthorized == nil {\n\t\tt.Fatal(\"sentinel errors must be defined\")\n\t}\n\tif ErrNotFound == ErrUnauthorized {\n\t\tt.Fatal(\"different sentinels must not be equal\")\n\t}\n}\n\nfunc TestAppErrorWrapAndIs(t *testing.T) {\n\tbase := ErrNotFound\n\te := Wrap(\"repo.GetUser\", base)\n\tif e == nil {\n\t\tt.Fatalf(\"Wrap returned nil\")\n\t}\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"errors.Is must work through AppError\")\n\t}\n\tif ae, ok := e.(*AppError); ok {\n\t\tif ae.Op != \"repo.GetUser\" {\n\t\t\tt.Fatalf(\"Op not set\")\n\t\t}\n\t} else {\n\t\tt.Fatalf(\"must return *AppError\")\n\t}\n}\n\nfunc TestEWithCode(t *testing.T) {\n\te := E(\"NOT_FOUND\", \"svc.Load\", ErrNotFound)\n\tif e == nil {\n\t\tt.Fatalf(\"E returned nil\")\n\t}\n\tvar ae *AppError\n\tif !errors.As(e, &ae) {\n\t\tt.Fatalf(\"must be AppError\")\n\t}\n\tif ae.Code != \"NOT_FOUND\" || ae.Op != \"svc.Load\" || !errors.Is(ae, ErrNotFound) {\n\t\tt.Fatalf(\"fields not set correctly\")\n\t}\n}\n\nfunc TestFormatNotFound(t *testing.T) {\n\te := FormatNotFound(\"42\")\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"must wrap ErrNotFound\")\n\t}\n\texp := fmt.Sprintf(\"entity %s: %v\", \"42\", ErrNotFound)\n\tif e.Error() != exp {\n\t\tt.Fatalf(\"unexpected error string: %q\", e.Error())\n\t}\n}\n",
        "tags": [
          "go",
          "errorsx"
        ],
        "order": 3
      },
      {
        "package": "errorsx",
        "slug": "go-errorsx-e",
        "title": "функция E собирает AppError c кодом и операцией, прокидывая первоначальную err.",
        "description": "Level 5 (medium): функция E собирает AppError c кодом и операцией, прокидывая первоначальную err.\nHint: допускается, что err может быть nil — возвращайте nil.",
        "difficulty": "medium",
        "hint1": "допускается, что err может быть nil — возвращайте nil.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): объявите два sentinel-объекта ошибок ErrNotFound и ErrUnauthorized.\n// Hint: используйте errors.New с разными строками и сделайте их package-level переменными.\nvar (\n\tErrNotFound     error = errors.New(\"not found\")\n\tErrUnauthorized error = errors.New(\"unauthorized\")\n)\n\n// Level 2 (easy+): опишите тип AppError с полями Code, Op и Err и реализуйте метод Error.\n// Hint: метод Error должен возвращать удобочитаемую строку с данными полей.\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"exception occured %v\", e.Error())\n}\n\n// Level 3 (medium): реализуйте метод Unwrap для AppError, чтобы поддерживать errors.Is/As.\n// Hint: верните вложенную ошибку Err.\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\n// Level 4 (medium): функция Wrap опционально оборачивает err в AppError с указанной операцией.\n// Hint: на входе nil возвращайте nil, иначе создавайте новый AppError.\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\n// Level 5 (medium): функция E собирает AppError c кодом и операцией, прокидывая первоначальную err.\n// Hint: допускается, что err может быть nil — возвращайте nil.\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\n// Level 6 (medium+): IsNotFound проверяет, содержит ли цепочка ошибок ErrNotFound.\n// Hint: воспользуйтесь errors.Is.\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\n// Level 7 (medium+): FormatNotFound форматирует ошибку вида \"entity <id>: ErrNotFound\".\n// Hint: используйте fmt.Errorf с %w для оборачивания.\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\tErrNotFound     = errors.New(\"not found\")\n\tErrUnauthorized = errors.New(\"unauthorized\")\n)\n\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"op=%s, code=%s, err=%v\", e.Op, e.Code, e.Err)\n}\n\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "testCode": "package errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestSentinels(t *testing.T) {\n\tif ErrNotFound == nil || ErrUnauthorized == nil {\n\t\tt.Fatal(\"sentinel errors must be defined\")\n\t}\n\tif ErrNotFound == ErrUnauthorized {\n\t\tt.Fatal(\"different sentinels must not be equal\")\n\t}\n}\n\nfunc TestAppErrorWrapAndIs(t *testing.T) {\n\tbase := ErrNotFound\n\te := Wrap(\"repo.GetUser\", base)\n\tif e == nil {\n\t\tt.Fatalf(\"Wrap returned nil\")\n\t}\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"errors.Is must work through AppError\")\n\t}\n\tif ae, ok := e.(*AppError); ok {\n\t\tif ae.Op != \"repo.GetUser\" {\n\t\t\tt.Fatalf(\"Op not set\")\n\t\t}\n\t} else {\n\t\tt.Fatalf(\"must return *AppError\")\n\t}\n}\n\nfunc TestEWithCode(t *testing.T) {\n\te := E(\"NOT_FOUND\", \"svc.Load\", ErrNotFound)\n\tif e == nil {\n\t\tt.Fatalf(\"E returned nil\")\n\t}\n\tvar ae *AppError\n\tif !errors.As(e, &ae) {\n\t\tt.Fatalf(\"must be AppError\")\n\t}\n\tif ae.Code != \"NOT_FOUND\" || ae.Op != \"svc.Load\" || !errors.Is(ae, ErrNotFound) {\n\t\tt.Fatalf(\"fields not set correctly\")\n\t}\n}\n\nfunc TestFormatNotFound(t *testing.T) {\n\te := FormatNotFound(\"42\")\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"must wrap ErrNotFound\")\n\t}\n\texp := fmt.Sprintf(\"entity %s: %v\", \"42\", ErrNotFound)\n\tif e.Error() != exp {\n\t\tt.Fatalf(\"unexpected error string: %q\", e.Error())\n\t}\n}\n",
        "tags": [
          "go",
          "errorsx"
        ],
        "order": 4
      },
      {
        "package": "errorsx",
        "slug": "go-errorsx-isnotfound",
        "title": "IsNotFound проверяет, содержит ли цепочка ошибок ErrNotFound.",
        "description": "Level 6 (medium+): IsNotFound проверяет, содержит ли цепочка ошибок ErrNotFound.\nHint: воспользуйтесь errors.Is.",
        "difficulty": "medium",
        "hint1": "воспользуйтесь errors.Is.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): объявите два sentinel-объекта ошибок ErrNotFound и ErrUnauthorized.\n// Hint: используйте errors.New с разными строками и сделайте их package-level переменными.\nvar (\n\tErrNotFound     error = errors.New(\"not found\")\n\tErrUnauthorized error = errors.New(\"unauthorized\")\n)\n\n// Level 2 (easy+): опишите тип AppError с полями Code, Op и Err и реализуйте метод Error.\n// Hint: метод Error должен возвращать удобочитаемую строку с данными полей.\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"exception occured %v\", e.Error())\n}\n\n// Level 3 (medium): реализуйте метод Unwrap для AppError, чтобы поддерживать errors.Is/As.\n// Hint: верните вложенную ошибку Err.\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\n// Level 4 (medium): функция Wrap опционально оборачивает err в AppError с указанной операцией.\n// Hint: на входе nil возвращайте nil, иначе создавайте новый AppError.\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\n// Level 5 (medium): функция E собирает AppError c кодом и операцией, прокидывая первоначальную err.\n// Hint: допускается, что err может быть nil — возвращайте nil.\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\n// Level 6 (medium+): IsNotFound проверяет, содержит ли цепочка ошибок ErrNotFound.\n// Hint: воспользуйтесь errors.Is.\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\n// Level 7 (medium+): FormatNotFound форматирует ошибку вида \"entity <id>: ErrNotFound\".\n// Hint: используйте fmt.Errorf с %w для оборачивания.\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\tErrNotFound     = errors.New(\"not found\")\n\tErrUnauthorized = errors.New(\"unauthorized\")\n)\n\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"op=%s, code=%s, err=%v\", e.Op, e.Code, e.Err)\n}\n\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "testCode": "package errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestSentinels(t *testing.T) {\n\tif ErrNotFound == nil || ErrUnauthorized == nil {\n\t\tt.Fatal(\"sentinel errors must be defined\")\n\t}\n\tif ErrNotFound == ErrUnauthorized {\n\t\tt.Fatal(\"different sentinels must not be equal\")\n\t}\n}\n\nfunc TestAppErrorWrapAndIs(t *testing.T) {\n\tbase := ErrNotFound\n\te := Wrap(\"repo.GetUser\", base)\n\tif e == nil {\n\t\tt.Fatalf(\"Wrap returned nil\")\n\t}\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"errors.Is must work through AppError\")\n\t}\n\tif ae, ok := e.(*AppError); ok {\n\t\tif ae.Op != \"repo.GetUser\" {\n\t\t\tt.Fatalf(\"Op not set\")\n\t\t}\n\t} else {\n\t\tt.Fatalf(\"must return *AppError\")\n\t}\n}\n\nfunc TestEWithCode(t *testing.T) {\n\te := E(\"NOT_FOUND\", \"svc.Load\", ErrNotFound)\n\tif e == nil {\n\t\tt.Fatalf(\"E returned nil\")\n\t}\n\tvar ae *AppError\n\tif !errors.As(e, &ae) {\n\t\tt.Fatalf(\"must be AppError\")\n\t}\n\tif ae.Code != \"NOT_FOUND\" || ae.Op != \"svc.Load\" || !errors.Is(ae, ErrNotFound) {\n\t\tt.Fatalf(\"fields not set correctly\")\n\t}\n}\n\nfunc TestFormatNotFound(t *testing.T) {\n\te := FormatNotFound(\"42\")\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"must wrap ErrNotFound\")\n\t}\n\texp := fmt.Sprintf(\"entity %s: %v\", \"42\", ErrNotFound)\n\tif e.Error() != exp {\n\t\tt.Fatalf(\"unexpected error string: %q\", e.Error())\n\t}\n}\n",
        "tags": [
          "go",
          "errorsx"
        ],
        "order": 5
      },
      {
        "package": "errorsx",
        "slug": "go-errorsx-formatnotfound",
        "title": "FormatNotFound форматирует ошибку вида \"entity <id>: ErrNotFound\".",
        "description": "Level 7 (medium+): FormatNotFound форматирует ошибку вида \"entity <id>: ErrNotFound\".\nHint: используйте fmt.Errorf с %w для оборачивания.",
        "difficulty": "medium",
        "hint1": "используйте fmt.Errorf с %w для оборачивания.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): объявите два sentinel-объекта ошибок ErrNotFound и ErrUnauthorized.\n// Hint: используйте errors.New с разными строками и сделайте их package-level переменными.\nvar (\n\tErrNotFound     error = errors.New(\"not found\")\n\tErrUnauthorized error = errors.New(\"unauthorized\")\n)\n\n// Level 2 (easy+): опишите тип AppError с полями Code, Op и Err и реализуйте метод Error.\n// Hint: метод Error должен возвращать удобочитаемую строку с данными полей.\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"exception occured %v\", e.Error())\n}\n\n// Level 3 (medium): реализуйте метод Unwrap для AppError, чтобы поддерживать errors.Is/As.\n// Hint: верните вложенную ошибку Err.\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\n// Level 4 (medium): функция Wrap опционально оборачивает err в AppError с указанной операцией.\n// Hint: на входе nil возвращайте nil, иначе создавайте новый AppError.\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\n// Level 5 (medium): функция E собирает AppError c кодом и операцией, прокидывая первоначальную err.\n// Hint: допускается, что err может быть nil — возвращайте nil.\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\n// Level 6 (medium+): IsNotFound проверяет, содержит ли цепочка ошибок ErrNotFound.\n// Hint: воспользуйтесь errors.Is.\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\n// Level 7 (medium+): FormatNotFound форматирует ошибку вида \"entity <id>: ErrNotFound\".\n// Hint: используйте fmt.Errorf с %w для оборачивания.\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\tErrNotFound     = errors.New(\"not found\")\n\tErrUnauthorized = errors.New(\"unauthorized\")\n)\n\ntype AppError struct {\n\tCode string\n\tOp   string\n\tErr  error\n}\n\nfunc (e *AppError) Error() string {\n\tif e == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn fmt.Sprintf(\"op=%s, code=%s, err=%v\", e.Op, e.Code, e.Err)\n}\n\nfunc (e *AppError) Unwrap() error {\n\tif e == nil {\n\t\treturn nil\n\t}\n\treturn e.Err\n}\n\nfunc Wrap(op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tOp:  op,\n\t\tErr: err,\n\t}\n}\n\nfunc E(code, op string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn &AppError{\n\t\tCode: code,\n\t\tOp:   op,\n\t\tErr:  err,\n\t}\n}\n\nfunc IsNotFound(err error) bool {\n\treturn errors.Is(err, ErrNotFound)\n}\n\nfunc FormatNotFound(id string) error {\n\treturn fmt.Errorf(\"entity %s: %w\", id, ErrNotFound)\n}\n",
        "testCode": "package errorsx\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestSentinels(t *testing.T) {\n\tif ErrNotFound == nil || ErrUnauthorized == nil {\n\t\tt.Fatal(\"sentinel errors must be defined\")\n\t}\n\tif ErrNotFound == ErrUnauthorized {\n\t\tt.Fatal(\"different sentinels must not be equal\")\n\t}\n}\n\nfunc TestAppErrorWrapAndIs(t *testing.T) {\n\tbase := ErrNotFound\n\te := Wrap(\"repo.GetUser\", base)\n\tif e == nil {\n\t\tt.Fatalf(\"Wrap returned nil\")\n\t}\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"errors.Is must work through AppError\")\n\t}\n\tif ae, ok := e.(*AppError); ok {\n\t\tif ae.Op != \"repo.GetUser\" {\n\t\t\tt.Fatalf(\"Op not set\")\n\t\t}\n\t} else {\n\t\tt.Fatalf(\"must return *AppError\")\n\t}\n}\n\nfunc TestEWithCode(t *testing.T) {\n\te := E(\"NOT_FOUND\", \"svc.Load\", ErrNotFound)\n\tif e == nil {\n\t\tt.Fatalf(\"E returned nil\")\n\t}\n\tvar ae *AppError\n\tif !errors.As(e, &ae) {\n\t\tt.Fatalf(\"must be AppError\")\n\t}\n\tif ae.Code != \"NOT_FOUND\" || ae.Op != \"svc.Load\" || !errors.Is(ae, ErrNotFound) {\n\t\tt.Fatalf(\"fields not set correctly\")\n\t}\n}\n\nfunc TestFormatNotFound(t *testing.T) {\n\te := FormatNotFound(\"42\")\n\tif !errors.Is(e, ErrNotFound) {\n\t\tt.Fatalf(\"must wrap ErrNotFound\")\n\t}\n\texp := fmt.Sprintf(\"entity %s: %v\", \"42\", ErrNotFound)\n\tif e.Error() != exp {\n\t\tt.Fatalf(\"unexpected error string: %q\", e.Error())\n\t}\n}\n",
        "tags": [
          "go",
          "errorsx"
        ],
        "order": 6
      }
    ],
    "category": "core"
  },
  {
    "name": "genericsx",
    "tasks": [
      {
        "package": "genericsx",
        "slug": "go-genericsx-map",
        "title": "Map применяет функцию к каждому элементу и возвращает новый слайс.",
        "description": "Level 1 (easy): Map применяет функцию к каждому элементу и возвращает новый слайс.\nHint: выделите результат нужной длины и заполните его.",
        "difficulty": "easy",
        "hint1": "выделите результат нужной длины и заполните его.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage genericsx\n\n// Level 1 (easy): Map применяет функцию к каждому элементу и возвращает новый слайс.\n// Hint: выделите результат нужной длины и заполните его.\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in))\n\tfor i, e := range in {\n\t\tout[i] = f(e)\n\t}\n\treturn out\n}\n\n// Level 2 (easy+): Reduce сворачивает слайс, начиная с zero.\n// Hint: проходите по всем элементам, обновляя аккумулятор f(acc, value).\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tfor _, e := range in {\n\t\tzero = f(zero, e)\n\t}\n\treturn zero\n}\n\n// Level 3 (medium): Set предоставляет методы Add/Has для сравнимых типов.\n// Hint: используйте map[T]struct{} как внутреннее хранилище.\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil {\n\t\treturn\n\t}\n\ts[v] = struct{}{}\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil {\n\t\treturn false\n\t}\n\t_, exist := s[v]\n\treturn exist\n}\n\n// Level 4 (medium+): Filter возвращает слайс из элементов, удовлетворяющих pred.\n// Hint: инициализируйте результирующий слайс и добавляйте выбранные элементы.\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tvar out []T\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tout = append(out, e)\n\t\t}\n\t}\n\treturn out\n}\n\n// Level 5 (medium): Partition разделяет входной слайс на два — удовлетворяющие предикату и остальные.\n// Hint: поддерживайте два выходных слайса и возвращайте их, сохраняя порядок элементов.\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tmatches = append(matches, e)\n\t\t} else {\n\t\t\trest = append(rest, e)\n\t\t}\n\t}\n\treturn matches, rest\n}\n\n// Level 6 (medium+): GroupBy группирует элементы по ключу, построенному функцией key.\n// Hint: инициализируйте карту заранее и добавляйте элементы в соответствующие слайсы через append.\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in))\n\tfor _, e := range in {\n\t\tk := key(e)\n\t\tout[k] = append(out[k], e)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage genericsx\n\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in)) // allocate result slice with exact length\n\tfor i, v := range in {    // iterate over every element with its index\n\t\tout[i] = f(v) // apply mapper to each element and store in output position\n\t}\n\treturn out // return fully transformed slice\n}\n\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tacc := zero            // initialize accumulator with provided zero value\n\tfor _, v := range in { // walk through elements sequentially\n\t\tacc = f(acc, v) // fold current element into accumulator via reducer\n\t}\n\treturn acc // return the final accumulated value\n}\n\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil { // guard against nil map to avoid panic\n\t\treturn\n\t}\n\ts[v] = struct{}{} // store value with empty struct payload\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil { // nil set cannot contain any values\n\t\treturn false\n\t}\n\t_, ok := s[v] // probe underlying map for key presence\n\treturn ok     // return membership result\n}\n\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tout := make([]T, 0, len(in)) // allocate output with maximum possible capacity\n\tfor _, v := range in {       // iterate over all input elements\n\t\tif pred(v) { // include element when predicate permits\n\t\t\tout = append(out, v) // append qualifying value to result slice\n\t\t}\n\t}\n\treturn out // deliver filtered slice to caller\n}\n\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tmatches = make([]T, 0, len(in)) // prepare slices to preserve input order\n\trest = make([]T, 0, len(in))\n\tfor _, v := range in { // split elements based on predicate outcome\n\t\tif pred(v) {\n\t\t\tmatches = append(matches, v) // collect positives\n\t\t\tcontinue\n\t\t}\n\t\trest = append(rest, v) // collect negatives\n\t}\n\treturn matches, rest // return both partitions\n}\n\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in)) // pre-size map to avoid repeated growth\n\tfor _, v := range in {          // assign each value to group based on its key\n\t\tk := key(v)\n\t\tout[k] = append(out[k], v) // append keeps stable order per group\n\t}\n\treturn out // provide grouped collection\n}\n",
        "testCode": "package genericsx\n\nimport \"testing\"\n\nfunc TestMap(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3}\n\tsquared := Map(input, func(v int) int { return v * v })\n\tif len(squared) != len(input) || squared[2] != 9 {\n\t\tt.Fatalf(\"unexpected map result: %v\", squared)\n\t}\n}\n\nfunc TestReduce(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4}\n\tsum := Reduce(input, 0, func(acc, v int) int { return acc + v })\n\tif sum != 10 {\n\t\tt.Fatalf(\"expected reduce sum=10, got %d\", sum)\n\t}\n}\n\nfunc TestSetAdd(t *testing.T) {\n\tt.Parallel()\n\tset := Set[int]{}\n\tset.Add(5)\n\tif _, ok := set[5]; !ok {\n\t\tt.Fatalf(\"expected internal storage to contain value after Add\")\n\t}\n}\n\nfunc TestSetHas(t *testing.T) {\n\tt.Parallel()\n\tset := Set[string]{\"foo\": {}}\n\tif !set.Has(\"foo\") {\n\t\tt.Fatal(\"expected Has to report true for existing value\")\n\t}\n\tif set.Has(\"bar\") {\n\t\tt.Fatal(\"expected Has to report false for missing value\")\n\t}\n}\n\nfunc TestFilter(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4, 5}\n\tevens := Filter(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected filter result: %v\", evens)\n\t}\n}\n\nfunc TestPartition(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{5, 2, 7, 4, 9}\n\tevens, odds := Partition(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected matches result: %v\", evens)\n\t}\n\tif len(odds) != 3 || odds[0] != 5 || odds[1] != 7 || odds[2] != 9 {\n\t\tt.Fatalf(\"unexpected rest result: %v\", odds)\n\t}\n}\n\nfunc TestGroupBy(t *testing.T) {\n\tt.Parallel()\n\tinput := []string{\"go\", \"lang\", \"to\", \"run\"}\n\tbyLen := GroupBy(input, func(v string) int { return len(v) })\n\tif len(byLen) != 3 {\n\t\tt.Fatalf(\"expected 3 groups, got %d\", len(byLen))\n\t}\n\ttwo := byLen[2]\n\tif len(two) != 2 || two[0] != \"go\" || two[1] != \"to\" {\n\t\tt.Fatalf(\"unexpected group for length=2: %v\", two)\n\t}\n\tif len(byLen[4]) != 1 || byLen[4][0] != \"lang\" {\n\t\tt.Fatalf(\"unexpected group for length=4: %v\", byLen[4])\n\t}\n\tif len(byLen[3]) != 1 || byLen[3][0] != \"run\" {\n\t\tt.Fatalf(\"unexpected group for length=3: %v\", byLen[3])\n\t}\n}\n",
        "tags": [
          "go",
          "genericsx"
        ],
        "order": 0
      },
      {
        "package": "genericsx",
        "slug": "go-genericsx-reduce",
        "title": "Reduce сворачивает слайс, начиная с zero.",
        "description": "Level 2 (easy+): Reduce сворачивает слайс, начиная с zero.\nHint: проходите по всем элементам, обновляя аккумулятор f(acc, value).",
        "difficulty": "easy",
        "hint1": "проходите по всем элементам, обновляя аккумулятор f(acc, value).",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage genericsx\n\n// Level 1 (easy): Map применяет функцию к каждому элементу и возвращает новый слайс.\n// Hint: выделите результат нужной длины и заполните его.\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in))\n\tfor i, e := range in {\n\t\tout[i] = f(e)\n\t}\n\treturn out\n}\n\n// Level 2 (easy+): Reduce сворачивает слайс, начиная с zero.\n// Hint: проходите по всем элементам, обновляя аккумулятор f(acc, value).\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tfor _, e := range in {\n\t\tzero = f(zero, e)\n\t}\n\treturn zero\n}\n\n// Level 3 (medium): Set предоставляет методы Add/Has для сравнимых типов.\n// Hint: используйте map[T]struct{} как внутреннее хранилище.\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil {\n\t\treturn\n\t}\n\ts[v] = struct{}{}\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil {\n\t\treturn false\n\t}\n\t_, exist := s[v]\n\treturn exist\n}\n\n// Level 4 (medium+): Filter возвращает слайс из элементов, удовлетворяющих pred.\n// Hint: инициализируйте результирующий слайс и добавляйте выбранные элементы.\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tvar out []T\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tout = append(out, e)\n\t\t}\n\t}\n\treturn out\n}\n\n// Level 5 (medium): Partition разделяет входной слайс на два — удовлетворяющие предикату и остальные.\n// Hint: поддерживайте два выходных слайса и возвращайте их, сохраняя порядок элементов.\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tmatches = append(matches, e)\n\t\t} else {\n\t\t\trest = append(rest, e)\n\t\t}\n\t}\n\treturn matches, rest\n}\n\n// Level 6 (medium+): GroupBy группирует элементы по ключу, построенному функцией key.\n// Hint: инициализируйте карту заранее и добавляйте элементы в соответствующие слайсы через append.\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in))\n\tfor _, e := range in {\n\t\tk := key(e)\n\t\tout[k] = append(out[k], e)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage genericsx\n\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in)) // allocate result slice with exact length\n\tfor i, v := range in {    // iterate over every element with its index\n\t\tout[i] = f(v) // apply mapper to each element and store in output position\n\t}\n\treturn out // return fully transformed slice\n}\n\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tacc := zero            // initialize accumulator with provided zero value\n\tfor _, v := range in { // walk through elements sequentially\n\t\tacc = f(acc, v) // fold current element into accumulator via reducer\n\t}\n\treturn acc // return the final accumulated value\n}\n\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil { // guard against nil map to avoid panic\n\t\treturn\n\t}\n\ts[v] = struct{}{} // store value with empty struct payload\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil { // nil set cannot contain any values\n\t\treturn false\n\t}\n\t_, ok := s[v] // probe underlying map for key presence\n\treturn ok     // return membership result\n}\n\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tout := make([]T, 0, len(in)) // allocate output with maximum possible capacity\n\tfor _, v := range in {       // iterate over all input elements\n\t\tif pred(v) { // include element when predicate permits\n\t\t\tout = append(out, v) // append qualifying value to result slice\n\t\t}\n\t}\n\treturn out // deliver filtered slice to caller\n}\n\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tmatches = make([]T, 0, len(in)) // prepare slices to preserve input order\n\trest = make([]T, 0, len(in))\n\tfor _, v := range in { // split elements based on predicate outcome\n\t\tif pred(v) {\n\t\t\tmatches = append(matches, v) // collect positives\n\t\t\tcontinue\n\t\t}\n\t\trest = append(rest, v) // collect negatives\n\t}\n\treturn matches, rest // return both partitions\n}\n\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in)) // pre-size map to avoid repeated growth\n\tfor _, v := range in {          // assign each value to group based on its key\n\t\tk := key(v)\n\t\tout[k] = append(out[k], v) // append keeps stable order per group\n\t}\n\treturn out // provide grouped collection\n}\n",
        "testCode": "package genericsx\n\nimport \"testing\"\n\nfunc TestMap(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3}\n\tsquared := Map(input, func(v int) int { return v * v })\n\tif len(squared) != len(input) || squared[2] != 9 {\n\t\tt.Fatalf(\"unexpected map result: %v\", squared)\n\t}\n}\n\nfunc TestReduce(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4}\n\tsum := Reduce(input, 0, func(acc, v int) int { return acc + v })\n\tif sum != 10 {\n\t\tt.Fatalf(\"expected reduce sum=10, got %d\", sum)\n\t}\n}\n\nfunc TestSetAdd(t *testing.T) {\n\tt.Parallel()\n\tset := Set[int]{}\n\tset.Add(5)\n\tif _, ok := set[5]; !ok {\n\t\tt.Fatalf(\"expected internal storage to contain value after Add\")\n\t}\n}\n\nfunc TestSetHas(t *testing.T) {\n\tt.Parallel()\n\tset := Set[string]{\"foo\": {}}\n\tif !set.Has(\"foo\") {\n\t\tt.Fatal(\"expected Has to report true for existing value\")\n\t}\n\tif set.Has(\"bar\") {\n\t\tt.Fatal(\"expected Has to report false for missing value\")\n\t}\n}\n\nfunc TestFilter(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4, 5}\n\tevens := Filter(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected filter result: %v\", evens)\n\t}\n}\n\nfunc TestPartition(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{5, 2, 7, 4, 9}\n\tevens, odds := Partition(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected matches result: %v\", evens)\n\t}\n\tif len(odds) != 3 || odds[0] != 5 || odds[1] != 7 || odds[2] != 9 {\n\t\tt.Fatalf(\"unexpected rest result: %v\", odds)\n\t}\n}\n\nfunc TestGroupBy(t *testing.T) {\n\tt.Parallel()\n\tinput := []string{\"go\", \"lang\", \"to\", \"run\"}\n\tbyLen := GroupBy(input, func(v string) int { return len(v) })\n\tif len(byLen) != 3 {\n\t\tt.Fatalf(\"expected 3 groups, got %d\", len(byLen))\n\t}\n\ttwo := byLen[2]\n\tif len(two) != 2 || two[0] != \"go\" || two[1] != \"to\" {\n\t\tt.Fatalf(\"unexpected group for length=2: %v\", two)\n\t}\n\tif len(byLen[4]) != 1 || byLen[4][0] != \"lang\" {\n\t\tt.Fatalf(\"unexpected group for length=4: %v\", byLen[4])\n\t}\n\tif len(byLen[3]) != 1 || byLen[3][0] != \"run\" {\n\t\tt.Fatalf(\"unexpected group for length=3: %v\", byLen[3])\n\t}\n}\n",
        "tags": [
          "go",
          "genericsx"
        ],
        "order": 1
      },
      {
        "package": "genericsx",
        "slug": "go-genericsx-filter",
        "title": "Filter возвращает слайс из элементов, удовлетворяющих pred.",
        "description": "Level 4 (medium+): Filter возвращает слайс из элементов, удовлетворяющих pred.\nHint: инициализируйте результирующий слайс и добавляйте выбранные элементы.",
        "difficulty": "medium",
        "hint1": "инициализируйте результирующий слайс и добавляйте выбранные элементы.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage genericsx\n\n// Level 1 (easy): Map применяет функцию к каждому элементу и возвращает новый слайс.\n// Hint: выделите результат нужной длины и заполните его.\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in))\n\tfor i, e := range in {\n\t\tout[i] = f(e)\n\t}\n\treturn out\n}\n\n// Level 2 (easy+): Reduce сворачивает слайс, начиная с zero.\n// Hint: проходите по всем элементам, обновляя аккумулятор f(acc, value).\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tfor _, e := range in {\n\t\tzero = f(zero, e)\n\t}\n\treturn zero\n}\n\n// Level 3 (medium): Set предоставляет методы Add/Has для сравнимых типов.\n// Hint: используйте map[T]struct{} как внутреннее хранилище.\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil {\n\t\treturn\n\t}\n\ts[v] = struct{}{}\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil {\n\t\treturn false\n\t}\n\t_, exist := s[v]\n\treturn exist\n}\n\n// Level 4 (medium+): Filter возвращает слайс из элементов, удовлетворяющих pred.\n// Hint: инициализируйте результирующий слайс и добавляйте выбранные элементы.\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tvar out []T\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tout = append(out, e)\n\t\t}\n\t}\n\treturn out\n}\n\n// Level 5 (medium): Partition разделяет входной слайс на два — удовлетворяющие предикату и остальные.\n// Hint: поддерживайте два выходных слайса и возвращайте их, сохраняя порядок элементов.\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tmatches = append(matches, e)\n\t\t} else {\n\t\t\trest = append(rest, e)\n\t\t}\n\t}\n\treturn matches, rest\n}\n\n// Level 6 (medium+): GroupBy группирует элементы по ключу, построенному функцией key.\n// Hint: инициализируйте карту заранее и добавляйте элементы в соответствующие слайсы через append.\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in))\n\tfor _, e := range in {\n\t\tk := key(e)\n\t\tout[k] = append(out[k], e)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage genericsx\n\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in)) // allocate result slice with exact length\n\tfor i, v := range in {    // iterate over every element with its index\n\t\tout[i] = f(v) // apply mapper to each element and store in output position\n\t}\n\treturn out // return fully transformed slice\n}\n\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tacc := zero            // initialize accumulator with provided zero value\n\tfor _, v := range in { // walk through elements sequentially\n\t\tacc = f(acc, v) // fold current element into accumulator via reducer\n\t}\n\treturn acc // return the final accumulated value\n}\n\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil { // guard against nil map to avoid panic\n\t\treturn\n\t}\n\ts[v] = struct{}{} // store value with empty struct payload\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil { // nil set cannot contain any values\n\t\treturn false\n\t}\n\t_, ok := s[v] // probe underlying map for key presence\n\treturn ok     // return membership result\n}\n\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tout := make([]T, 0, len(in)) // allocate output with maximum possible capacity\n\tfor _, v := range in {       // iterate over all input elements\n\t\tif pred(v) { // include element when predicate permits\n\t\t\tout = append(out, v) // append qualifying value to result slice\n\t\t}\n\t}\n\treturn out // deliver filtered slice to caller\n}\n\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tmatches = make([]T, 0, len(in)) // prepare slices to preserve input order\n\trest = make([]T, 0, len(in))\n\tfor _, v := range in { // split elements based on predicate outcome\n\t\tif pred(v) {\n\t\t\tmatches = append(matches, v) // collect positives\n\t\t\tcontinue\n\t\t}\n\t\trest = append(rest, v) // collect negatives\n\t}\n\treturn matches, rest // return both partitions\n}\n\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in)) // pre-size map to avoid repeated growth\n\tfor _, v := range in {          // assign each value to group based on its key\n\t\tk := key(v)\n\t\tout[k] = append(out[k], v) // append keeps stable order per group\n\t}\n\treturn out // provide grouped collection\n}\n",
        "testCode": "package genericsx\n\nimport \"testing\"\n\nfunc TestMap(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3}\n\tsquared := Map(input, func(v int) int { return v * v })\n\tif len(squared) != len(input) || squared[2] != 9 {\n\t\tt.Fatalf(\"unexpected map result: %v\", squared)\n\t}\n}\n\nfunc TestReduce(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4}\n\tsum := Reduce(input, 0, func(acc, v int) int { return acc + v })\n\tif sum != 10 {\n\t\tt.Fatalf(\"expected reduce sum=10, got %d\", sum)\n\t}\n}\n\nfunc TestSetAdd(t *testing.T) {\n\tt.Parallel()\n\tset := Set[int]{}\n\tset.Add(5)\n\tif _, ok := set[5]; !ok {\n\t\tt.Fatalf(\"expected internal storage to contain value after Add\")\n\t}\n}\n\nfunc TestSetHas(t *testing.T) {\n\tt.Parallel()\n\tset := Set[string]{\"foo\": {}}\n\tif !set.Has(\"foo\") {\n\t\tt.Fatal(\"expected Has to report true for existing value\")\n\t}\n\tif set.Has(\"bar\") {\n\t\tt.Fatal(\"expected Has to report false for missing value\")\n\t}\n}\n\nfunc TestFilter(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4, 5}\n\tevens := Filter(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected filter result: %v\", evens)\n\t}\n}\n\nfunc TestPartition(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{5, 2, 7, 4, 9}\n\tevens, odds := Partition(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected matches result: %v\", evens)\n\t}\n\tif len(odds) != 3 || odds[0] != 5 || odds[1] != 7 || odds[2] != 9 {\n\t\tt.Fatalf(\"unexpected rest result: %v\", odds)\n\t}\n}\n\nfunc TestGroupBy(t *testing.T) {\n\tt.Parallel()\n\tinput := []string{\"go\", \"lang\", \"to\", \"run\"}\n\tbyLen := GroupBy(input, func(v string) int { return len(v) })\n\tif len(byLen) != 3 {\n\t\tt.Fatalf(\"expected 3 groups, got %d\", len(byLen))\n\t}\n\ttwo := byLen[2]\n\tif len(two) != 2 || two[0] != \"go\" || two[1] != \"to\" {\n\t\tt.Fatalf(\"unexpected group for length=2: %v\", two)\n\t}\n\tif len(byLen[4]) != 1 || byLen[4][0] != \"lang\" {\n\t\tt.Fatalf(\"unexpected group for length=4: %v\", byLen[4])\n\t}\n\tif len(byLen[3]) != 1 || byLen[3][0] != \"run\" {\n\t\tt.Fatalf(\"unexpected group for length=3: %v\", byLen[3])\n\t}\n}\n",
        "tags": [
          "go",
          "genericsx"
        ],
        "order": 3
      },
      {
        "package": "genericsx",
        "slug": "go-genericsx-partition",
        "title": "Partition разделяет входной слайс на два — удовлетворяющие предикату и остальные.",
        "description": "Level 5 (medium): Partition разделяет входной слайс на два — удовлетворяющие предикату и остальные.\nHint: поддерживайте два выходных слайса и возвращайте их, сохраняя порядок элементов.",
        "difficulty": "medium",
        "hint1": "поддерживайте два выходных слайса и возвращайте их, сохраняя порядок элементов.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage genericsx\n\n// Level 1 (easy): Map применяет функцию к каждому элементу и возвращает новый слайс.\n// Hint: выделите результат нужной длины и заполните его.\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in))\n\tfor i, e := range in {\n\t\tout[i] = f(e)\n\t}\n\treturn out\n}\n\n// Level 2 (easy+): Reduce сворачивает слайс, начиная с zero.\n// Hint: проходите по всем элементам, обновляя аккумулятор f(acc, value).\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tfor _, e := range in {\n\t\tzero = f(zero, e)\n\t}\n\treturn zero\n}\n\n// Level 3 (medium): Set предоставляет методы Add/Has для сравнимых типов.\n// Hint: используйте map[T]struct{} как внутреннее хранилище.\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil {\n\t\treturn\n\t}\n\ts[v] = struct{}{}\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil {\n\t\treturn false\n\t}\n\t_, exist := s[v]\n\treturn exist\n}\n\n// Level 4 (medium+): Filter возвращает слайс из элементов, удовлетворяющих pred.\n// Hint: инициализируйте результирующий слайс и добавляйте выбранные элементы.\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tvar out []T\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tout = append(out, e)\n\t\t}\n\t}\n\treturn out\n}\n\n// Level 5 (medium): Partition разделяет входной слайс на два — удовлетворяющие предикату и остальные.\n// Hint: поддерживайте два выходных слайса и возвращайте их, сохраняя порядок элементов.\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tmatches = append(matches, e)\n\t\t} else {\n\t\t\trest = append(rest, e)\n\t\t}\n\t}\n\treturn matches, rest\n}\n\n// Level 6 (medium+): GroupBy группирует элементы по ключу, построенному функцией key.\n// Hint: инициализируйте карту заранее и добавляйте элементы в соответствующие слайсы через append.\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in))\n\tfor _, e := range in {\n\t\tk := key(e)\n\t\tout[k] = append(out[k], e)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage genericsx\n\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in)) // allocate result slice with exact length\n\tfor i, v := range in {    // iterate over every element with its index\n\t\tout[i] = f(v) // apply mapper to each element and store in output position\n\t}\n\treturn out // return fully transformed slice\n}\n\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tacc := zero            // initialize accumulator with provided zero value\n\tfor _, v := range in { // walk through elements sequentially\n\t\tacc = f(acc, v) // fold current element into accumulator via reducer\n\t}\n\treturn acc // return the final accumulated value\n}\n\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil { // guard against nil map to avoid panic\n\t\treturn\n\t}\n\ts[v] = struct{}{} // store value with empty struct payload\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil { // nil set cannot contain any values\n\t\treturn false\n\t}\n\t_, ok := s[v] // probe underlying map for key presence\n\treturn ok     // return membership result\n}\n\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tout := make([]T, 0, len(in)) // allocate output with maximum possible capacity\n\tfor _, v := range in {       // iterate over all input elements\n\t\tif pred(v) { // include element when predicate permits\n\t\t\tout = append(out, v) // append qualifying value to result slice\n\t\t}\n\t}\n\treturn out // deliver filtered slice to caller\n}\n\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tmatches = make([]T, 0, len(in)) // prepare slices to preserve input order\n\trest = make([]T, 0, len(in))\n\tfor _, v := range in { // split elements based on predicate outcome\n\t\tif pred(v) {\n\t\t\tmatches = append(matches, v) // collect positives\n\t\t\tcontinue\n\t\t}\n\t\trest = append(rest, v) // collect negatives\n\t}\n\treturn matches, rest // return both partitions\n}\n\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in)) // pre-size map to avoid repeated growth\n\tfor _, v := range in {          // assign each value to group based on its key\n\t\tk := key(v)\n\t\tout[k] = append(out[k], v) // append keeps stable order per group\n\t}\n\treturn out // provide grouped collection\n}\n",
        "testCode": "package genericsx\n\nimport \"testing\"\n\nfunc TestMap(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3}\n\tsquared := Map(input, func(v int) int { return v * v })\n\tif len(squared) != len(input) || squared[2] != 9 {\n\t\tt.Fatalf(\"unexpected map result: %v\", squared)\n\t}\n}\n\nfunc TestReduce(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4}\n\tsum := Reduce(input, 0, func(acc, v int) int { return acc + v })\n\tif sum != 10 {\n\t\tt.Fatalf(\"expected reduce sum=10, got %d\", sum)\n\t}\n}\n\nfunc TestSetAdd(t *testing.T) {\n\tt.Parallel()\n\tset := Set[int]{}\n\tset.Add(5)\n\tif _, ok := set[5]; !ok {\n\t\tt.Fatalf(\"expected internal storage to contain value after Add\")\n\t}\n}\n\nfunc TestSetHas(t *testing.T) {\n\tt.Parallel()\n\tset := Set[string]{\"foo\": {}}\n\tif !set.Has(\"foo\") {\n\t\tt.Fatal(\"expected Has to report true for existing value\")\n\t}\n\tif set.Has(\"bar\") {\n\t\tt.Fatal(\"expected Has to report false for missing value\")\n\t}\n}\n\nfunc TestFilter(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4, 5}\n\tevens := Filter(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected filter result: %v\", evens)\n\t}\n}\n\nfunc TestPartition(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{5, 2, 7, 4, 9}\n\tevens, odds := Partition(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected matches result: %v\", evens)\n\t}\n\tif len(odds) != 3 || odds[0] != 5 || odds[1] != 7 || odds[2] != 9 {\n\t\tt.Fatalf(\"unexpected rest result: %v\", odds)\n\t}\n}\n\nfunc TestGroupBy(t *testing.T) {\n\tt.Parallel()\n\tinput := []string{\"go\", \"lang\", \"to\", \"run\"}\n\tbyLen := GroupBy(input, func(v string) int { return len(v) })\n\tif len(byLen) != 3 {\n\t\tt.Fatalf(\"expected 3 groups, got %d\", len(byLen))\n\t}\n\ttwo := byLen[2]\n\tif len(two) != 2 || two[0] != \"go\" || two[1] != \"to\" {\n\t\tt.Fatalf(\"unexpected group for length=2: %v\", two)\n\t}\n\tif len(byLen[4]) != 1 || byLen[4][0] != \"lang\" {\n\t\tt.Fatalf(\"unexpected group for length=4: %v\", byLen[4])\n\t}\n\tif len(byLen[3]) != 1 || byLen[3][0] != \"run\" {\n\t\tt.Fatalf(\"unexpected group for length=3: %v\", byLen[3])\n\t}\n}\n",
        "tags": [
          "go",
          "genericsx"
        ],
        "order": 4
      },
      {
        "package": "genericsx",
        "slug": "go-genericsx-groupby",
        "title": "GroupBy группирует элементы по ключу, построенному функцией key.",
        "description": "Level 6 (medium+): GroupBy группирует элементы по ключу, построенному функцией key.\nHint: инициализируйте карту заранее и добавляйте элементы в соответствующие слайсы через append.",
        "difficulty": "medium",
        "hint1": "инициализируйте карту заранее и добавляйте элементы в соответствующие слайсы через append.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage genericsx\n\n// Level 1 (easy): Map применяет функцию к каждому элементу и возвращает новый слайс.\n// Hint: выделите результат нужной длины и заполните его.\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in))\n\tfor i, e := range in {\n\t\tout[i] = f(e)\n\t}\n\treturn out\n}\n\n// Level 2 (easy+): Reduce сворачивает слайс, начиная с zero.\n// Hint: проходите по всем элементам, обновляя аккумулятор f(acc, value).\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tfor _, e := range in {\n\t\tzero = f(zero, e)\n\t}\n\treturn zero\n}\n\n// Level 3 (medium): Set предоставляет методы Add/Has для сравнимых типов.\n// Hint: используйте map[T]struct{} как внутреннее хранилище.\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil {\n\t\treturn\n\t}\n\ts[v] = struct{}{}\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil {\n\t\treturn false\n\t}\n\t_, exist := s[v]\n\treturn exist\n}\n\n// Level 4 (medium+): Filter возвращает слайс из элементов, удовлетворяющих pred.\n// Hint: инициализируйте результирующий слайс и добавляйте выбранные элементы.\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tvar out []T\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tout = append(out, e)\n\t\t}\n\t}\n\treturn out\n}\n\n// Level 5 (medium): Partition разделяет входной слайс на два — удовлетворяющие предикату и остальные.\n// Hint: поддерживайте два выходных слайса и возвращайте их, сохраняя порядок элементов.\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tfor _, e := range in {\n\t\tif pred(e) {\n\t\t\tmatches = append(matches, e)\n\t\t} else {\n\t\t\trest = append(rest, e)\n\t\t}\n\t}\n\treturn matches, rest\n}\n\n// Level 6 (medium+): GroupBy группирует элементы по ключу, построенному функцией key.\n// Hint: инициализируйте карту заранее и добавляйте элементы в соответствующие слайсы через append.\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in))\n\tfor _, e := range in {\n\t\tk := key(e)\n\t\tout[k] = append(out[k], e)\n\t}\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage genericsx\n\nfunc Map[T any, R any](in []T, f func(T) R) []R {\n\tout := make([]R, len(in)) // allocate result slice with exact length\n\tfor i, v := range in {    // iterate over every element with its index\n\t\tout[i] = f(v) // apply mapper to each element and store in output position\n\t}\n\treturn out // return fully transformed slice\n}\n\nfunc Reduce[T any](in []T, zero T, f func(T, T) T) T {\n\tacc := zero            // initialize accumulator with provided zero value\n\tfor _, v := range in { // walk through elements sequentially\n\t\tacc = f(acc, v) // fold current element into accumulator via reducer\n\t}\n\treturn acc // return the final accumulated value\n}\n\ntype Set[T comparable] map[T]struct{}\n\nfunc (s Set[T]) Add(v T) {\n\tif s == nil { // guard against nil map to avoid panic\n\t\treturn\n\t}\n\ts[v] = struct{}{} // store value with empty struct payload\n}\n\nfunc (s Set[T]) Has(v T) bool {\n\tif s == nil { // nil set cannot contain any values\n\t\treturn false\n\t}\n\t_, ok := s[v] // probe underlying map for key presence\n\treturn ok     // return membership result\n}\n\nfunc Filter[T any](in []T, pred func(T) bool) []T {\n\tout := make([]T, 0, len(in)) // allocate output with maximum possible capacity\n\tfor _, v := range in {       // iterate over all input elements\n\t\tif pred(v) { // include element when predicate permits\n\t\t\tout = append(out, v) // append qualifying value to result slice\n\t\t}\n\t}\n\treturn out // deliver filtered slice to caller\n}\n\nfunc Partition[T any](in []T, pred func(T) bool) (matches []T, rest []T) {\n\tmatches = make([]T, 0, len(in)) // prepare slices to preserve input order\n\trest = make([]T, 0, len(in))\n\tfor _, v := range in { // split elements based on predicate outcome\n\t\tif pred(v) {\n\t\t\tmatches = append(matches, v) // collect positives\n\t\t\tcontinue\n\t\t}\n\t\trest = append(rest, v) // collect negatives\n\t}\n\treturn matches, rest // return both partitions\n}\n\nfunc GroupBy[T any, K comparable](in []T, key func(T) K) map[K][]T {\n\tout := make(map[K][]T, len(in)) // pre-size map to avoid repeated growth\n\tfor _, v := range in {          // assign each value to group based on its key\n\t\tk := key(v)\n\t\tout[k] = append(out[k], v) // append keeps stable order per group\n\t}\n\treturn out // provide grouped collection\n}\n",
        "testCode": "package genericsx\n\nimport \"testing\"\n\nfunc TestMap(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3}\n\tsquared := Map(input, func(v int) int { return v * v })\n\tif len(squared) != len(input) || squared[2] != 9 {\n\t\tt.Fatalf(\"unexpected map result: %v\", squared)\n\t}\n}\n\nfunc TestReduce(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4}\n\tsum := Reduce(input, 0, func(acc, v int) int { return acc + v })\n\tif sum != 10 {\n\t\tt.Fatalf(\"expected reduce sum=10, got %d\", sum)\n\t}\n}\n\nfunc TestSetAdd(t *testing.T) {\n\tt.Parallel()\n\tset := Set[int]{}\n\tset.Add(5)\n\tif _, ok := set[5]; !ok {\n\t\tt.Fatalf(\"expected internal storage to contain value after Add\")\n\t}\n}\n\nfunc TestSetHas(t *testing.T) {\n\tt.Parallel()\n\tset := Set[string]{\"foo\": {}}\n\tif !set.Has(\"foo\") {\n\t\tt.Fatal(\"expected Has to report true for existing value\")\n\t}\n\tif set.Has(\"bar\") {\n\t\tt.Fatal(\"expected Has to report false for missing value\")\n\t}\n}\n\nfunc TestFilter(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{1, 2, 3, 4, 5}\n\tevens := Filter(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected filter result: %v\", evens)\n\t}\n}\n\nfunc TestPartition(t *testing.T) {\n\tt.Parallel()\n\tinput := []int{5, 2, 7, 4, 9}\n\tevens, odds := Partition(input, func(v int) bool { return v%2 == 0 })\n\tif len(evens) != 2 || evens[0] != 2 || evens[1] != 4 {\n\t\tt.Fatalf(\"unexpected matches result: %v\", evens)\n\t}\n\tif len(odds) != 3 || odds[0] != 5 || odds[1] != 7 || odds[2] != 9 {\n\t\tt.Fatalf(\"unexpected rest result: %v\", odds)\n\t}\n}\n\nfunc TestGroupBy(t *testing.T) {\n\tt.Parallel()\n\tinput := []string{\"go\", \"lang\", \"to\", \"run\"}\n\tbyLen := GroupBy(input, func(v string) int { return len(v) })\n\tif len(byLen) != 3 {\n\t\tt.Fatalf(\"expected 3 groups, got %d\", len(byLen))\n\t}\n\ttwo := byLen[2]\n\tif len(two) != 2 || two[0] != \"go\" || two[1] != \"to\" {\n\t\tt.Fatalf(\"unexpected group for length=2: %v\", two)\n\t}\n\tif len(byLen[4]) != 1 || byLen[4][0] != \"lang\" {\n\t\tt.Fatalf(\"unexpected group for length=4: %v\", byLen[4])\n\t}\n\tif len(byLen[3]) != 1 || byLen[3][0] != \"run\" {\n\t\tt.Fatalf(\"unexpected group for length=3: %v\", byLen[3])\n\t}\n}\n",
        "tags": [
          "go",
          "genericsx"
        ],
        "order": 5
      }
    ],
    "category": "core"
  },
  {
    "name": "goroutinesx",
    "tasks": [
      {
        "package": "goroutinesx",
        "slug": "go-goroutinesx-watcher",
        "title": "Watcher слушает ctx.Done() и входной канал, проксируя значения во вновь созданный канал.",
        "description": "Level 1 (medium): Watcher слушает ctx.Done() и входной канал, проксируя значения во вновь созданный канал.\nHint: создайте out := make(chan T) и закройте его при завершении.",
        "difficulty": "medium",
        "hint1": "создайте out := make(chan T) и закройте его при завершении.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (medium): Watcher слушает ctx.Done() и входной канал, проксируя значения во вновь созданный канал.\n// Hint: создайте out := make(chan T) и закройте его при завершении.\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(in))\n\tif in == nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 2 (medium): FanIn объединяет несколько входных каналов в один выходной.\n// Hint: запустите горутину на канал и закройте выход, когда все входы завершены или ctx.Done().\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(inputs))\n\tif len(inputs) == 0 {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tvar wg sync.WaitGroup\n\tworkers := 3\n\tsem := make(chan struct{}, workers)\n\tfor _, in := range inputs {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\tsem <- struct{}{}\n\t\twg.Add(1)\n\t\tgo func(ch <-chan T) {\n\t\t\tdefer func() {\n\t\t\t\twg.Done()\n\t\t\t\t<-sem\n\t\t\t}()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-ch:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): Take собирает до n значений из канала или пока не завершится контекст.\n// Hint: возвращайте срез собранных элементов.\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn []T{}\n\t}\n\tif n <= 0 {\n\t\tn = 1\n\t}\n\n\tout := make([]T, 0, n)\n\tfor len(out) < n {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn out\n\t\tcase v, ok := <-in:\n\t\t\tif !ok {\n\t\t\t\treturn out\n\t\t\t}\n\t\t\tout = append(out, v)\n\t\t}\n\t}\n\n\treturn out\n}\n\n// Level 4 (medium+): Drain вычитывает канал до конца или отмены контекста, предотвращая утечки.\n// Hint: запускайте горутину и следите за ctx.Done().\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn\n\t}\n\tfor range in {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): ContextTicker возвращает канал тиков, который прекращает работу при ctx.Done().\n// Hint: используйте time.NewTicker и обязательно останавливайте его.\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time)\n\tticker := time.NewTicker(d)\n\n\tgo func() {\n\t\tdefer ticker.Stop()\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- t:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tout := make(chan T) // allocate output channel for forwarded values\n\tgo func() {\n\t\tdefer close(out) // close output when forwarding completes\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop forwarding once context is canceled\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok { // exit when input channel closes\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // honor cancellation before sending value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // expose channel to caller immediately\n}\n\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tout := make(chan T)   // unified output channel\n\tvar wg sync.WaitGroup // wait group tracks feeder completion\n\twg.Add(len(inputs))   // expect completion signal from each input\n\tforward := func(ch <-chan T) {\n\t\tdefer wg.Done() // signal completion regardless of exit path\n\t\tif ch == nil {  // skip nil channels without blocking\n\t\t\treturn\n\t\t}\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // cancel forwarding when context is done\n\t\t\tcase v, ok := <-ch:\n\t\t\t\tif !ok { // input closed; stop forwarding from this channel\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // re-check cancellation before publishing value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, ch := range inputs { // launch forwarder for each channel\n\t\tgo forward(ch)\n\t}\n\tgo func() {\n\t\twg.Wait()  // wait until all forwarders finish\n\t\tclose(out) // close output once no more values forthcoming\n\t}()\n\treturn out // return merged channel to caller\n}\n\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif n <= 0 { // nothing to collect when limit is non-positive\n\t\treturn nil\n\t}\n\tcollected := make([]T, 0, n) // preallocate slice up to requested count\n\tfor len(collected) < n {     // continue until requested number gathered\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn collected // stop early when context cancels\n\t\tcase v, ok := <-in:\n\t\t\tif !ok { // exit if channel closes\n\t\t\t\treturn collected\n\t\t\t}\n\t\t\tcollected = append(collected, v) // accumulate received value\n\t\t}\n\t}\n\treturn collected // return collected values once quota satisfied\n}\n\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn // stop draining when context cancels\n\t\tcase _, ok := <-in:\n\t\t\tif !ok { // exit once channel closed and fully drained\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time) // channel delivering tick timestamps\n\tticker := time.NewTicker(d) // underlying ticker producing periodic ticks\n\tgo func() {\n\t\tdefer ticker.Stop() // ensure ticker resources freed on exit\n\t\tdefer close(out)    // close output channel when stopping\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop producing ticks after cancellation\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // avoid sending tick if cancellation arrived meanwhile\n\t\t\t\tcase out <- t: // forward tick timestamp to consumers\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // give caller read-only access to ticker channel\n}\n",
        "testCode": "package goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestWatcher(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tout := Watcher(ctx, in)\n\tgo func() {\n\t\tin <- 1\n\t\tin <- 2\n\t\tclose(in)\n\t}()\n\tif v := <-out; v != 1 {\n\t\tt.Fatalf(\"expected first value 1, got %d\", v)\n\t}\n\tif v := <-out; v != 2 {\n\t\tt.Fatalf(\"expected second value 2, got %d\", v)\n\t}\n\tselect {\n\tcase _, ok := <-out:\n\t\tif ok {\n\t\t\tt.Fatal(\"expected closed channel after input close\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for watcher to close\")\n\t}\n}\n\nfunc TestFanIn(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch1 := make(chan int, 1)\n\tch2 := make(chan int, 1)\n\tch1 <- 1\n\tch2 <- 2\n\tclose(ch1)\n\tclose(ch2)\n\tout := FanIn(ctx, ch1, ch2)\n\tvals := map[int]bool{}\n\tfor v := range out {\n\t\tvals[v] = true\n\t}\n\tif len(vals) != 2 || !vals[1] || !vals[2] {\n\t\tt.Fatalf(\"unexpected fan-in values: %v\", vals)\n\t}\n}\n\nfunc TestTake(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 5)\n\tfor i := 0; i < 5; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tout := Take(ctx, in, 3)\n\tif len(out) != 3 || out[2] != 2 {\n\t\tt.Fatalf(\"unexpected take result: %v\", out)\n\t}\n}\n\nfunc TestDrain(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 2)\n\tin <- 1\n\tin <- 2\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tDrain(ctx, in)\n\t}()\n\tclose(in)\n\tif waitTimeout(&wg, time.Second) {\n\t\tt.Fatal(\"drain did not finish in time\")\n\t}\n}\n\nfunc TestContextTicker(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\tdefer cancel()\n\tticks := ContextTicker(ctx, 5*time.Millisecond)\n\tcount := 0\n\tfor range ticks {\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\tt.Fatal(\"expected at least one tick before context cancellation\")\n\t}\n}\n\nfunc waitTimeout(wg *sync.WaitGroup, d time.Duration) bool {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ch:\n\t\treturn false\n\tcase <-time.After(d):\n\t\treturn true\n\t}\n}\n",
        "tags": [
          "go",
          "goroutinesx"
        ],
        "order": 0
      },
      {
        "package": "goroutinesx",
        "slug": "go-goroutinesx-fanin",
        "title": "FanIn объединяет несколько входных каналов в один выходной.",
        "description": "Level 2 (medium): FanIn объединяет несколько входных каналов в один выходной.\nHint: запустите горутину на канал и закройте выход, когда все входы завершены или ctx.Done().",
        "difficulty": "medium",
        "hint1": "запустите горутину на канал и закройте выход, когда все входы завершены или ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (medium): Watcher слушает ctx.Done() и входной канал, проксируя значения во вновь созданный канал.\n// Hint: создайте out := make(chan T) и закройте его при завершении.\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(in))\n\tif in == nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 2 (medium): FanIn объединяет несколько входных каналов в один выходной.\n// Hint: запустите горутину на канал и закройте выход, когда все входы завершены или ctx.Done().\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(inputs))\n\tif len(inputs) == 0 {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tvar wg sync.WaitGroup\n\tworkers := 3\n\tsem := make(chan struct{}, workers)\n\tfor _, in := range inputs {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\tsem <- struct{}{}\n\t\twg.Add(1)\n\t\tgo func(ch <-chan T) {\n\t\t\tdefer func() {\n\t\t\t\twg.Done()\n\t\t\t\t<-sem\n\t\t\t}()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-ch:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): Take собирает до n значений из канала или пока не завершится контекст.\n// Hint: возвращайте срез собранных элементов.\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn []T{}\n\t}\n\tif n <= 0 {\n\t\tn = 1\n\t}\n\n\tout := make([]T, 0, n)\n\tfor len(out) < n {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn out\n\t\tcase v, ok := <-in:\n\t\t\tif !ok {\n\t\t\t\treturn out\n\t\t\t}\n\t\t\tout = append(out, v)\n\t\t}\n\t}\n\n\treturn out\n}\n\n// Level 4 (medium+): Drain вычитывает канал до конца или отмены контекста, предотвращая утечки.\n// Hint: запускайте горутину и следите за ctx.Done().\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn\n\t}\n\tfor range in {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): ContextTicker возвращает канал тиков, который прекращает работу при ctx.Done().\n// Hint: используйте time.NewTicker и обязательно останавливайте его.\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time)\n\tticker := time.NewTicker(d)\n\n\tgo func() {\n\t\tdefer ticker.Stop()\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- t:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tout := make(chan T) // allocate output channel for forwarded values\n\tgo func() {\n\t\tdefer close(out) // close output when forwarding completes\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop forwarding once context is canceled\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok { // exit when input channel closes\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // honor cancellation before sending value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // expose channel to caller immediately\n}\n\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tout := make(chan T)   // unified output channel\n\tvar wg sync.WaitGroup // wait group tracks feeder completion\n\twg.Add(len(inputs))   // expect completion signal from each input\n\tforward := func(ch <-chan T) {\n\t\tdefer wg.Done() // signal completion regardless of exit path\n\t\tif ch == nil {  // skip nil channels without blocking\n\t\t\treturn\n\t\t}\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // cancel forwarding when context is done\n\t\t\tcase v, ok := <-ch:\n\t\t\t\tif !ok { // input closed; stop forwarding from this channel\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // re-check cancellation before publishing value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, ch := range inputs { // launch forwarder for each channel\n\t\tgo forward(ch)\n\t}\n\tgo func() {\n\t\twg.Wait()  // wait until all forwarders finish\n\t\tclose(out) // close output once no more values forthcoming\n\t}()\n\treturn out // return merged channel to caller\n}\n\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif n <= 0 { // nothing to collect when limit is non-positive\n\t\treturn nil\n\t}\n\tcollected := make([]T, 0, n) // preallocate slice up to requested count\n\tfor len(collected) < n {     // continue until requested number gathered\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn collected // stop early when context cancels\n\t\tcase v, ok := <-in:\n\t\t\tif !ok { // exit if channel closes\n\t\t\t\treturn collected\n\t\t\t}\n\t\t\tcollected = append(collected, v) // accumulate received value\n\t\t}\n\t}\n\treturn collected // return collected values once quota satisfied\n}\n\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn // stop draining when context cancels\n\t\tcase _, ok := <-in:\n\t\t\tif !ok { // exit once channel closed and fully drained\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time) // channel delivering tick timestamps\n\tticker := time.NewTicker(d) // underlying ticker producing periodic ticks\n\tgo func() {\n\t\tdefer ticker.Stop() // ensure ticker resources freed on exit\n\t\tdefer close(out)    // close output channel when stopping\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop producing ticks after cancellation\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // avoid sending tick if cancellation arrived meanwhile\n\t\t\t\tcase out <- t: // forward tick timestamp to consumers\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // give caller read-only access to ticker channel\n}\n",
        "testCode": "package goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestWatcher(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tout := Watcher(ctx, in)\n\tgo func() {\n\t\tin <- 1\n\t\tin <- 2\n\t\tclose(in)\n\t}()\n\tif v := <-out; v != 1 {\n\t\tt.Fatalf(\"expected first value 1, got %d\", v)\n\t}\n\tif v := <-out; v != 2 {\n\t\tt.Fatalf(\"expected second value 2, got %d\", v)\n\t}\n\tselect {\n\tcase _, ok := <-out:\n\t\tif ok {\n\t\t\tt.Fatal(\"expected closed channel after input close\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for watcher to close\")\n\t}\n}\n\nfunc TestFanIn(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch1 := make(chan int, 1)\n\tch2 := make(chan int, 1)\n\tch1 <- 1\n\tch2 <- 2\n\tclose(ch1)\n\tclose(ch2)\n\tout := FanIn(ctx, ch1, ch2)\n\tvals := map[int]bool{}\n\tfor v := range out {\n\t\tvals[v] = true\n\t}\n\tif len(vals) != 2 || !vals[1] || !vals[2] {\n\t\tt.Fatalf(\"unexpected fan-in values: %v\", vals)\n\t}\n}\n\nfunc TestTake(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 5)\n\tfor i := 0; i < 5; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tout := Take(ctx, in, 3)\n\tif len(out) != 3 || out[2] != 2 {\n\t\tt.Fatalf(\"unexpected take result: %v\", out)\n\t}\n}\n\nfunc TestDrain(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 2)\n\tin <- 1\n\tin <- 2\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tDrain(ctx, in)\n\t}()\n\tclose(in)\n\tif waitTimeout(&wg, time.Second) {\n\t\tt.Fatal(\"drain did not finish in time\")\n\t}\n}\n\nfunc TestContextTicker(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\tdefer cancel()\n\tticks := ContextTicker(ctx, 5*time.Millisecond)\n\tcount := 0\n\tfor range ticks {\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\tt.Fatal(\"expected at least one tick before context cancellation\")\n\t}\n}\n\nfunc waitTimeout(wg *sync.WaitGroup, d time.Duration) bool {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ch:\n\t\treturn false\n\tcase <-time.After(d):\n\t\treturn true\n\t}\n}\n",
        "tags": [
          "go",
          "goroutinesx"
        ],
        "order": 1
      },
      {
        "package": "goroutinesx",
        "slug": "go-goroutinesx-take",
        "title": "Take собирает до n значений из канала или пока не завершится контекст.",
        "description": "Level 3 (medium): Take собирает до n значений из канала или пока не завершится контекст.\nHint: возвращайте срез собранных элементов.",
        "difficulty": "medium",
        "hint1": "возвращайте срез собранных элементов.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (medium): Watcher слушает ctx.Done() и входной канал, проксируя значения во вновь созданный канал.\n// Hint: создайте out := make(chan T) и закройте его при завершении.\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(in))\n\tif in == nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 2 (medium): FanIn объединяет несколько входных каналов в один выходной.\n// Hint: запустите горутину на канал и закройте выход, когда все входы завершены или ctx.Done().\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(inputs))\n\tif len(inputs) == 0 {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tvar wg sync.WaitGroup\n\tworkers := 3\n\tsem := make(chan struct{}, workers)\n\tfor _, in := range inputs {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\tsem <- struct{}{}\n\t\twg.Add(1)\n\t\tgo func(ch <-chan T) {\n\t\t\tdefer func() {\n\t\t\t\twg.Done()\n\t\t\t\t<-sem\n\t\t\t}()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-ch:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): Take собирает до n значений из канала или пока не завершится контекст.\n// Hint: возвращайте срез собранных элементов.\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn []T{}\n\t}\n\tif n <= 0 {\n\t\tn = 1\n\t}\n\n\tout := make([]T, 0, n)\n\tfor len(out) < n {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn out\n\t\tcase v, ok := <-in:\n\t\t\tif !ok {\n\t\t\t\treturn out\n\t\t\t}\n\t\t\tout = append(out, v)\n\t\t}\n\t}\n\n\treturn out\n}\n\n// Level 4 (medium+): Drain вычитывает канал до конца или отмены контекста, предотвращая утечки.\n// Hint: запускайте горутину и следите за ctx.Done().\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn\n\t}\n\tfor range in {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): ContextTicker возвращает канал тиков, который прекращает работу при ctx.Done().\n// Hint: используйте time.NewTicker и обязательно останавливайте его.\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time)\n\tticker := time.NewTicker(d)\n\n\tgo func() {\n\t\tdefer ticker.Stop()\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- t:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tout := make(chan T) // allocate output channel for forwarded values\n\tgo func() {\n\t\tdefer close(out) // close output when forwarding completes\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop forwarding once context is canceled\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok { // exit when input channel closes\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // honor cancellation before sending value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // expose channel to caller immediately\n}\n\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tout := make(chan T)   // unified output channel\n\tvar wg sync.WaitGroup // wait group tracks feeder completion\n\twg.Add(len(inputs))   // expect completion signal from each input\n\tforward := func(ch <-chan T) {\n\t\tdefer wg.Done() // signal completion regardless of exit path\n\t\tif ch == nil {  // skip nil channels without blocking\n\t\t\treturn\n\t\t}\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // cancel forwarding when context is done\n\t\t\tcase v, ok := <-ch:\n\t\t\t\tif !ok { // input closed; stop forwarding from this channel\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // re-check cancellation before publishing value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, ch := range inputs { // launch forwarder for each channel\n\t\tgo forward(ch)\n\t}\n\tgo func() {\n\t\twg.Wait()  // wait until all forwarders finish\n\t\tclose(out) // close output once no more values forthcoming\n\t}()\n\treturn out // return merged channel to caller\n}\n\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif n <= 0 { // nothing to collect when limit is non-positive\n\t\treturn nil\n\t}\n\tcollected := make([]T, 0, n) // preallocate slice up to requested count\n\tfor len(collected) < n {     // continue until requested number gathered\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn collected // stop early when context cancels\n\t\tcase v, ok := <-in:\n\t\t\tif !ok { // exit if channel closes\n\t\t\t\treturn collected\n\t\t\t}\n\t\t\tcollected = append(collected, v) // accumulate received value\n\t\t}\n\t}\n\treturn collected // return collected values once quota satisfied\n}\n\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn // stop draining when context cancels\n\t\tcase _, ok := <-in:\n\t\t\tif !ok { // exit once channel closed and fully drained\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time) // channel delivering tick timestamps\n\tticker := time.NewTicker(d) // underlying ticker producing periodic ticks\n\tgo func() {\n\t\tdefer ticker.Stop() // ensure ticker resources freed on exit\n\t\tdefer close(out)    // close output channel when stopping\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop producing ticks after cancellation\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // avoid sending tick if cancellation arrived meanwhile\n\t\t\t\tcase out <- t: // forward tick timestamp to consumers\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // give caller read-only access to ticker channel\n}\n",
        "testCode": "package goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestWatcher(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tout := Watcher(ctx, in)\n\tgo func() {\n\t\tin <- 1\n\t\tin <- 2\n\t\tclose(in)\n\t}()\n\tif v := <-out; v != 1 {\n\t\tt.Fatalf(\"expected first value 1, got %d\", v)\n\t}\n\tif v := <-out; v != 2 {\n\t\tt.Fatalf(\"expected second value 2, got %d\", v)\n\t}\n\tselect {\n\tcase _, ok := <-out:\n\t\tif ok {\n\t\t\tt.Fatal(\"expected closed channel after input close\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for watcher to close\")\n\t}\n}\n\nfunc TestFanIn(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch1 := make(chan int, 1)\n\tch2 := make(chan int, 1)\n\tch1 <- 1\n\tch2 <- 2\n\tclose(ch1)\n\tclose(ch2)\n\tout := FanIn(ctx, ch1, ch2)\n\tvals := map[int]bool{}\n\tfor v := range out {\n\t\tvals[v] = true\n\t}\n\tif len(vals) != 2 || !vals[1] || !vals[2] {\n\t\tt.Fatalf(\"unexpected fan-in values: %v\", vals)\n\t}\n}\n\nfunc TestTake(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 5)\n\tfor i := 0; i < 5; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tout := Take(ctx, in, 3)\n\tif len(out) != 3 || out[2] != 2 {\n\t\tt.Fatalf(\"unexpected take result: %v\", out)\n\t}\n}\n\nfunc TestDrain(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 2)\n\tin <- 1\n\tin <- 2\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tDrain(ctx, in)\n\t}()\n\tclose(in)\n\tif waitTimeout(&wg, time.Second) {\n\t\tt.Fatal(\"drain did not finish in time\")\n\t}\n}\n\nfunc TestContextTicker(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\tdefer cancel()\n\tticks := ContextTicker(ctx, 5*time.Millisecond)\n\tcount := 0\n\tfor range ticks {\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\tt.Fatal(\"expected at least one tick before context cancellation\")\n\t}\n}\n\nfunc waitTimeout(wg *sync.WaitGroup, d time.Duration) bool {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ch:\n\t\treturn false\n\tcase <-time.After(d):\n\t\treturn true\n\t}\n}\n",
        "tags": [
          "go",
          "goroutinesx"
        ],
        "order": 2
      },
      {
        "package": "goroutinesx",
        "slug": "go-goroutinesx-drain",
        "title": "Drain вычитывает канал до конца или отмены контекста, предотвращая утечки.",
        "description": "Level 4 (medium+): Drain вычитывает канал до конца или отмены контекста, предотвращая утечки.\nHint: запускайте горутину и следите за ctx.Done().",
        "difficulty": "medium",
        "hint1": "запускайте горутину и следите за ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (medium): Watcher слушает ctx.Done() и входной канал, проксируя значения во вновь созданный канал.\n// Hint: создайте out := make(chan T) и закройте его при завершении.\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(in))\n\tif in == nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 2 (medium): FanIn объединяет несколько входных каналов в один выходной.\n// Hint: запустите горутину на канал и закройте выход, когда все входы завершены или ctx.Done().\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(inputs))\n\tif len(inputs) == 0 {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tvar wg sync.WaitGroup\n\tworkers := 3\n\tsem := make(chan struct{}, workers)\n\tfor _, in := range inputs {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\tsem <- struct{}{}\n\t\twg.Add(1)\n\t\tgo func(ch <-chan T) {\n\t\t\tdefer func() {\n\t\t\t\twg.Done()\n\t\t\t\t<-sem\n\t\t\t}()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-ch:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): Take собирает до n значений из канала или пока не завершится контекст.\n// Hint: возвращайте срез собранных элементов.\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn []T{}\n\t}\n\tif n <= 0 {\n\t\tn = 1\n\t}\n\n\tout := make([]T, 0, n)\n\tfor len(out) < n {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn out\n\t\tcase v, ok := <-in:\n\t\t\tif !ok {\n\t\t\t\treturn out\n\t\t\t}\n\t\t\tout = append(out, v)\n\t\t}\n\t}\n\n\treturn out\n}\n\n// Level 4 (medium+): Drain вычитывает канал до конца или отмены контекста, предотвращая утечки.\n// Hint: запускайте горутину и следите за ctx.Done().\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn\n\t}\n\tfor range in {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): ContextTicker возвращает канал тиков, который прекращает работу при ctx.Done().\n// Hint: используйте time.NewTicker и обязательно останавливайте его.\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time)\n\tticker := time.NewTicker(d)\n\n\tgo func() {\n\t\tdefer ticker.Stop()\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- t:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tout := make(chan T) // allocate output channel for forwarded values\n\tgo func() {\n\t\tdefer close(out) // close output when forwarding completes\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop forwarding once context is canceled\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok { // exit when input channel closes\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // honor cancellation before sending value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // expose channel to caller immediately\n}\n\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tout := make(chan T)   // unified output channel\n\tvar wg sync.WaitGroup // wait group tracks feeder completion\n\twg.Add(len(inputs))   // expect completion signal from each input\n\tforward := func(ch <-chan T) {\n\t\tdefer wg.Done() // signal completion regardless of exit path\n\t\tif ch == nil {  // skip nil channels without blocking\n\t\t\treturn\n\t\t}\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // cancel forwarding when context is done\n\t\t\tcase v, ok := <-ch:\n\t\t\t\tif !ok { // input closed; stop forwarding from this channel\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // re-check cancellation before publishing value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, ch := range inputs { // launch forwarder for each channel\n\t\tgo forward(ch)\n\t}\n\tgo func() {\n\t\twg.Wait()  // wait until all forwarders finish\n\t\tclose(out) // close output once no more values forthcoming\n\t}()\n\treturn out // return merged channel to caller\n}\n\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif n <= 0 { // nothing to collect when limit is non-positive\n\t\treturn nil\n\t}\n\tcollected := make([]T, 0, n) // preallocate slice up to requested count\n\tfor len(collected) < n {     // continue until requested number gathered\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn collected // stop early when context cancels\n\t\tcase v, ok := <-in:\n\t\t\tif !ok { // exit if channel closes\n\t\t\t\treturn collected\n\t\t\t}\n\t\t\tcollected = append(collected, v) // accumulate received value\n\t\t}\n\t}\n\treturn collected // return collected values once quota satisfied\n}\n\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn // stop draining when context cancels\n\t\tcase _, ok := <-in:\n\t\t\tif !ok { // exit once channel closed and fully drained\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time) // channel delivering tick timestamps\n\tticker := time.NewTicker(d) // underlying ticker producing periodic ticks\n\tgo func() {\n\t\tdefer ticker.Stop() // ensure ticker resources freed on exit\n\t\tdefer close(out)    // close output channel when stopping\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop producing ticks after cancellation\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // avoid sending tick if cancellation arrived meanwhile\n\t\t\t\tcase out <- t: // forward tick timestamp to consumers\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // give caller read-only access to ticker channel\n}\n",
        "testCode": "package goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestWatcher(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tout := Watcher(ctx, in)\n\tgo func() {\n\t\tin <- 1\n\t\tin <- 2\n\t\tclose(in)\n\t}()\n\tif v := <-out; v != 1 {\n\t\tt.Fatalf(\"expected first value 1, got %d\", v)\n\t}\n\tif v := <-out; v != 2 {\n\t\tt.Fatalf(\"expected second value 2, got %d\", v)\n\t}\n\tselect {\n\tcase _, ok := <-out:\n\t\tif ok {\n\t\t\tt.Fatal(\"expected closed channel after input close\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for watcher to close\")\n\t}\n}\n\nfunc TestFanIn(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch1 := make(chan int, 1)\n\tch2 := make(chan int, 1)\n\tch1 <- 1\n\tch2 <- 2\n\tclose(ch1)\n\tclose(ch2)\n\tout := FanIn(ctx, ch1, ch2)\n\tvals := map[int]bool{}\n\tfor v := range out {\n\t\tvals[v] = true\n\t}\n\tif len(vals) != 2 || !vals[1] || !vals[2] {\n\t\tt.Fatalf(\"unexpected fan-in values: %v\", vals)\n\t}\n}\n\nfunc TestTake(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 5)\n\tfor i := 0; i < 5; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tout := Take(ctx, in, 3)\n\tif len(out) != 3 || out[2] != 2 {\n\t\tt.Fatalf(\"unexpected take result: %v\", out)\n\t}\n}\n\nfunc TestDrain(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 2)\n\tin <- 1\n\tin <- 2\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tDrain(ctx, in)\n\t}()\n\tclose(in)\n\tif waitTimeout(&wg, time.Second) {\n\t\tt.Fatal(\"drain did not finish in time\")\n\t}\n}\n\nfunc TestContextTicker(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\tdefer cancel()\n\tticks := ContextTicker(ctx, 5*time.Millisecond)\n\tcount := 0\n\tfor range ticks {\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\tt.Fatal(\"expected at least one tick before context cancellation\")\n\t}\n}\n\nfunc waitTimeout(wg *sync.WaitGroup, d time.Duration) bool {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ch:\n\t\treturn false\n\tcase <-time.After(d):\n\t\treturn true\n\t}\n}\n",
        "tags": [
          "go",
          "goroutinesx"
        ],
        "order": 3
      },
      {
        "package": "goroutinesx",
        "slug": "go-goroutinesx-contextticker",
        "title": "ContextTicker возвращает канал тиков, который прекращает работу при ctx.Done().",
        "description": "Level 5 (medium+): ContextTicker возвращает канал тиков, который прекращает работу при ctx.Done().\nHint: используйте time.NewTicker и обязательно останавливайте его.",
        "difficulty": "medium",
        "hint1": "используйте time.NewTicker и обязательно останавливайте его.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (medium): Watcher слушает ctx.Done() и входной канал, проксируя значения во вновь созданный канал.\n// Hint: создайте out := make(chan T) и закройте его при завершении.\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(in))\n\tif in == nil {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out\n}\n\n// Level 2 (medium): FanIn объединяет несколько входных каналов в один выходной.\n// Hint: запустите горутину на канал и закройте выход, когда все входы завершены или ctx.Done().\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan T, len(inputs))\n\tif len(inputs) == 0 {\n\t\tclose(out)\n\t\treturn out\n\t}\n\n\tvar wg sync.WaitGroup\n\tworkers := 3\n\tsem := make(chan struct{}, workers)\n\tfor _, in := range inputs {\n\t\tif in == nil {\n\t\t\tcontinue\n\t\t}\n\t\tsem <- struct{}{}\n\t\twg.Add(1)\n\t\tgo func(ch <-chan T) {\n\t\t\tdefer func() {\n\t\t\t\twg.Done()\n\t\t\t\t<-sem\n\t\t\t}()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase v, ok := <-ch:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn\n\t\t\t\t\tcase out <- v:\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}(in)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\n\treturn out\n}\n\n// Level 3 (medium): Take собирает до n значений из канала или пока не завершится контекст.\n// Hint: возвращайте срез собранных элементов.\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn []T{}\n\t}\n\tif n <= 0 {\n\t\tn = 1\n\t}\n\n\tout := make([]T, 0, n)\n\tfor len(out) < n {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn out\n\t\tcase v, ok := <-in:\n\t\t\tif !ok {\n\t\t\t\treturn out\n\t\t\t}\n\t\t\tout = append(out, v)\n\t\t}\n\t}\n\n\treturn out\n}\n\n// Level 4 (medium+): Drain вычитывает канал до конца или отмены контекста, предотвращая утечки.\n// Hint: запускайте горутину и следите за ctx.Done().\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif in == nil {\n\t\treturn\n\t}\n\tfor range in {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): ContextTicker возвращает канал тиков, который прекращает работу при ctx.Done().\n// Hint: используйте time.NewTicker и обязательно останавливайте его.\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time)\n\tticker := time.NewTicker(d)\n\n\tgo func() {\n\t\tdefer ticker.Stop()\n\t\tdefer close(out)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase out <- t:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc Watcher[T any](ctx context.Context, in <-chan T) <-chan T {\n\tout := make(chan T) // allocate output channel for forwarded values\n\tgo func() {\n\t\tdefer close(out) // close output when forwarding completes\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop forwarding once context is canceled\n\t\t\tcase v, ok := <-in:\n\t\t\t\tif !ok { // exit when input channel closes\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // honor cancellation before sending value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // expose channel to caller immediately\n}\n\nfunc FanIn[T any](ctx context.Context, inputs ...<-chan T) <-chan T {\n\tout := make(chan T)   // unified output channel\n\tvar wg sync.WaitGroup // wait group tracks feeder completion\n\twg.Add(len(inputs))   // expect completion signal from each input\n\tforward := func(ch <-chan T) {\n\t\tdefer wg.Done() // signal completion regardless of exit path\n\t\tif ch == nil {  // skip nil channels without blocking\n\t\t\treturn\n\t\t}\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // cancel forwarding when context is done\n\t\t\tcase v, ok := <-ch:\n\t\t\t\tif !ok { // input closed; stop forwarding from this channel\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // re-check cancellation before publishing value\n\t\t\t\tcase out <- v:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor _, ch := range inputs { // launch forwarder for each channel\n\t\tgo forward(ch)\n\t}\n\tgo func() {\n\t\twg.Wait()  // wait until all forwarders finish\n\t\tclose(out) // close output once no more values forthcoming\n\t}()\n\treturn out // return merged channel to caller\n}\n\nfunc Take[T any](ctx context.Context, in <-chan T, n int) []T {\n\tif n <= 0 { // nothing to collect when limit is non-positive\n\t\treturn nil\n\t}\n\tcollected := make([]T, 0, n) // preallocate slice up to requested count\n\tfor len(collected) < n {     // continue until requested number gathered\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn collected // stop early when context cancels\n\t\tcase v, ok := <-in:\n\t\t\tif !ok { // exit if channel closes\n\t\t\t\treturn collected\n\t\t\t}\n\t\t\tcollected = append(collected, v) // accumulate received value\n\t\t}\n\t}\n\treturn collected // return collected values once quota satisfied\n}\n\nfunc Drain[T any](ctx context.Context, in <-chan T) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn // stop draining when context cancels\n\t\tcase _, ok := <-in:\n\t\t\tif !ok { // exit once channel closed and fully drained\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc ContextTicker(ctx context.Context, d time.Duration) <-chan time.Time {\n\tout := make(chan time.Time) // channel delivering tick timestamps\n\tticker := time.NewTicker(d) // underlying ticker producing periodic ticks\n\tgo func() {\n\t\tdefer ticker.Stop() // ensure ticker resources freed on exit\n\t\tdefer close(out)    // close output channel when stopping\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn // stop producing ticks after cancellation\n\t\t\tcase t := <-ticker.C:\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn // avoid sending tick if cancellation arrived meanwhile\n\t\t\t\tcase out <- t: // forward tick timestamp to consumers\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn out // give caller read-only access to ticker channel\n}\n",
        "testCode": "package goroutinesx\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestWatcher(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int)\n\tout := Watcher(ctx, in)\n\tgo func() {\n\t\tin <- 1\n\t\tin <- 2\n\t\tclose(in)\n\t}()\n\tif v := <-out; v != 1 {\n\t\tt.Fatalf(\"expected first value 1, got %d\", v)\n\t}\n\tif v := <-out; v != 2 {\n\t\tt.Fatalf(\"expected second value 2, got %d\", v)\n\t}\n\tselect {\n\tcase _, ok := <-out:\n\t\tif ok {\n\t\t\tt.Fatal(\"expected closed channel after input close\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for watcher to close\")\n\t}\n}\n\nfunc TestFanIn(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch1 := make(chan int, 1)\n\tch2 := make(chan int, 1)\n\tch1 <- 1\n\tch2 <- 2\n\tclose(ch1)\n\tclose(ch2)\n\tout := FanIn(ctx, ch1, ch2)\n\tvals := map[int]bool{}\n\tfor v := range out {\n\t\tvals[v] = true\n\t}\n\tif len(vals) != 2 || !vals[1] || !vals[2] {\n\t\tt.Fatalf(\"unexpected fan-in values: %v\", vals)\n\t}\n}\n\nfunc TestTake(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 5)\n\tfor i := 0; i < 5; i++ {\n\t\tin <- i\n\t}\n\tclose(in)\n\tout := Take(ctx, in, 3)\n\tif len(out) != 3 || out[2] != 2 {\n\t\tt.Fatalf(\"unexpected take result: %v\", out)\n\t}\n}\n\nfunc TestDrain(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tin := make(chan int, 2)\n\tin <- 1\n\tin <- 2\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tDrain(ctx, in)\n\t}()\n\tclose(in)\n\tif waitTimeout(&wg, time.Second) {\n\t\tt.Fatal(\"drain did not finish in time\")\n\t}\n}\n\nfunc TestContextTicker(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\tdefer cancel()\n\tticks := ContextTicker(ctx, 5*time.Millisecond)\n\tcount := 0\n\tfor range ticks {\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\tt.Fatal(\"expected at least one tick before context cancellation\")\n\t}\n}\n\nfunc waitTimeout(wg *sync.WaitGroup, d time.Duration) bool {\n\tch := make(chan struct{})\n\tgo func() {\n\t\tdefer close(ch)\n\t\twg.Wait()\n\t}()\n\tselect {\n\tcase <-ch:\n\t\treturn false\n\tcase <-time.After(d):\n\t\treturn true\n\t}\n}\n",
        "tags": [
          "go",
          "goroutinesx"
        ],
        "order": 4
      }
    ],
    "category": "concurrency"
  },
  {
    "name": "grpcx",
    "tasks": [
      {
        "package": "grpcx",
        "slug": "go-grpcx-logginginterceptor",
        "title": "LoggingInterceptor добавляет логирование начала/конца вызова через переданную функцию logger.",
        "description": "Level 1 (easy): LoggingInterceptor добавляет логирование начала/конца вызова через переданную функцию logger.\nHint: вызовите logger дважды: до и после next().",
        "difficulty": "easy",
        "hint1": "вызовите logger дважды: до и после next().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\n// Handler имитирует grpc.UnaryHandler.\ntype Handler func(ctx context.Context, req any) (any, error)\n\n// UnaryServerInterceptor описывает обёртку над обработчиком.\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\n// Level 1 (easy): LoggingInterceptor добавляет логирование начала/конца вызова через переданную функцию logger.\n// Hint: вызовите logger дважды: до и после next().\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil {\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")\n\t\tresp, err := next(ctx, req)\n\t\tlogger(ctx, \"finish\")\n\t\treturn resp, err\n\t}\n}\n\n// Level 2 (medium): TimeoutInterceptor оборачивает вызов в context.WithTimeout.\n// Hint: отменяйте контекст через cancel() и прокидывайте дочерний ctx в next.\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\tif d <= 0 {\n\t\td = time.Second\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctx, cancel := context.WithTimeout(ctx, d)\n\t\tdefer cancel()\n\t\treturn next(ctx, req)\n\t}\n}\n\n// Level 3 (medium+): Chain объединяет несколько интерсепторов в один.\n// Hint: применяйте их в порядке передачи, завершая фактическим handler.\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- {\n\t\t\tcurrent := interceptors[i]\n\t\t\tif current == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnext := wrapped\n\t\t\twrapped = func(c context.Context, r any) (any, error) {\n\t\t\t\treturn current(c, r, next)\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req)\n\t}\n}\n\n// Level 4 (medium+): RetryInterceptor повторяет вызов до maxRetries раз с backoff при ошибке.\n// Hint: вызывайте next и при ошибке спите в соответствии с backoff(attempt).\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 {\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tvar (\n\t\t\tresp any\n\t\t\terr  error\n\t\t)\n\t\tfor i := 0; i <= maxRetries; i++ {\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = handler(ctx, req)\n\t\t\tif err == nil {\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif i == maxRetries {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0)\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(i)\n\t\t\t}\n\t\t\tif delay > 0 {\n\t\t\t\ttimer := time.NewTimer(delay)\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err\n\t}\n}\n\n// Level 5 (medium+): ContextValueInterceptor добавляет в контекст значение перед вызовом next.\n// Hint: используйте context.WithValue и передавайте обновлённый ctx дальше.\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tctx = context.WithValue(ctx, key, value)\n\t\treturn handler(ctx, req)\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\ntype Handler func(ctx context.Context, req any) (any, error)\n\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil { // provide no-op logger when caller omitted it\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")        // announce beginning of unary call\n\t\tresp, err := next(ctx, req) // invoke next handler in chain\n\t\tlogger(ctx, \"finish\")       // record completion after handler returns\n\t\treturn resp, err            // propagate result and error\n\t}\n}\n\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tif d <= 0 { // skip wrapping when no timeout requested\n\t\t\treturn next(ctx, req)\n\t\t}\n\t\tchild, cancel := context.WithTimeout(ctx, d) // derive context with deadline\n\t\tdefer cancel()                               // release timer resources on exit\n\t\treturn next(child, req)                      // invoke handler with timeout-aware context\n\t}\n}\n\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil { // default handler returns zero values when missing\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler                            // start wrapping from the innermost handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- { // compose interceptors in reverse order\n\t\t\tcurrent := interceptors[i] // pick current interceptor\n\t\t\tif current == nil {        // skip nil interceptors gracefully\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnextHandler := wrapped                                  // capture current wrapped handler for closure\n\t\t\twrapped = func(c context.Context, r any) (any, error) { // rebuild handler pipeline\n\t\t\t\treturn current(c, r, nextHandler) // delegate handling to interceptor\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req) // execute fully composed handler chain\n\t}\n}\n\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 { // normalize negative retry counts to zero\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tvar resp any                                         // placeholder for handler response\n\t\tvar err error                                        // track last handler error\n\t\tfor attempt := 0; attempt <= maxRetries; attempt++ { // attempt invocation up to retry limit\n\t\t\tif ctx.Err() != nil { // abort retries when context already canceled\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = next(ctx, req) // call downstream handler\n\t\t\tif err == nil {            // return immediately on success\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif attempt == maxRetries { // stop retrying after exhausting attempts\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0) // compute optional delay before next attempt\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(attempt) // evaluate backoff function with current attempt number\n\t\t\t}\n\t\t\tif delay > 0 { // sleep only when delay is positive\n\t\t\t\ttimer := time.NewTimer(delay) // allocate timer for backoff duration\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done(): // exit early if context canceled during wait\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err // return last observed result after retries exhausted\n\t}\n}\n\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctxWithValue := context.WithValue(ctx, key, value) // enrich context with provided key/value pair\n\t\treturn next(ctxWithValue, req)                     // proceed with updated context\n\t}\n}\n",
        "testCode": "package grpcx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLoggingInterceptor(t *testing.T) {\n\tt.Parallel()\n\tvar calls int32\n\tlogger := func(context.Context, string) { atomic.AddInt32(&calls, 1) }\n\tinter := LoggingInterceptor(logger)\n\thandler := func(context.Context, any) (any, error) { return \"ok\", nil }\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif atomic.LoadInt32(&calls) != 2 {\n\t\tt.Fatalf(\"expected logger called twice, got %d\", calls)\n\t}\n}\n\nfunc TestTimeoutInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := TimeoutInterceptor(10 * time.Millisecond)\n\tvar deadline time.Time\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tvar ok bool\n\t\tdeadline, ok = ctx.Deadline()\n\t\tif !ok {\n\t\t\tt.Fatal(\"expected deadline to be set\")\n\t\t}\n\t\t<-ctx.Done()\n\t\treturn nil, ctx.Err()\n\t}\n\t_, err := inter(context.Background(), nil, handler)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif time.Until(deadline) > 20*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\torder := make([]string, 0, 4)\n\tappendStep := func(name string) UnaryServerInterceptor {\n\t\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\t\torder = append(order, name+\" before\")\n\t\t\tresp, err := next(ctx, req)\n\t\t\torder = append(order, name+\" after\")\n\t\t\treturn resp, err\n\t\t}\n\t}\n\tchained := Chain(appendStep(\"a\"), appendStep(\"b\"))\n\thandler := func(context.Context, any) (any, error) {\n\t\torder = append(order, \"handler\")\n\t\treturn nil, nil\n\t}\n\tif _, err := chained(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\texpected := []string{\"a before\", \"b before\", \"handler\", \"b after\", \"a after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"unexpected order at %d: got %q want %q\", i, order[i], want)\n\t\t}\n\t}\n}\n\nfunc TestRetryInterceptor(t *testing.T) {\n\tt.Parallel()\n\tretries := int32(0)\n\tfail := errors.New(\"fail\")\n\tvar attempts int32\n\thandler := func(context.Context, any) (any, error) {\n\t\tif atomic.AddInt32(&attempts, 1) <= retries {\n\t\t\treturn nil, fail\n\t\t}\n\t\treturn \"ok\", nil\n\t}\n\tfor _, retries = range []int32{0, 2} {\n\t\tattempts = 0\n\t\tinter := RetryInterceptor(int(retries)+1, func(int) time.Duration { return 0 })\n\t\t_, err := inter(context.Background(), nil, handler)\n\t\tif retries == 0 && err != nil {\n\t\t\tt.Fatalf(\"expected zero retries to succeed immediately, got %v\", err)\n\t\t}\n\t\tif retries > 0 && err != nil {\n\t\t\tt.Fatalf(\"expected retries to eventually succeed, got %v\", err)\n\t\t}\n\t}\n}\n\nfunc TestContextValueInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := ContextValueInterceptor(\"key\", \"value\")\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tif got := ctx.Value(\"key\"); got != \"value\" {\n\t\t\tt.Fatalf(\"expected value in context, got %v\", got)\n\t\t}\n\t\treturn nil, nil\n\t}\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "grpcx"
        ],
        "order": 0
      },
      {
        "package": "grpcx",
        "slug": "go-grpcx-timeoutinterceptor",
        "title": "TimeoutInterceptor оборачивает вызов в context.WithTimeout.",
        "description": "Level 2 (medium): TimeoutInterceptor оборачивает вызов в context.WithTimeout.\nHint: отменяйте контекст через cancel() и прокидывайте дочерний ctx в next.",
        "difficulty": "medium",
        "hint1": "отменяйте контекст через cancel() и прокидывайте дочерний ctx в next.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\n// Handler имитирует grpc.UnaryHandler.\ntype Handler func(ctx context.Context, req any) (any, error)\n\n// UnaryServerInterceptor описывает обёртку над обработчиком.\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\n// Level 1 (easy): LoggingInterceptor добавляет логирование начала/конца вызова через переданную функцию logger.\n// Hint: вызовите logger дважды: до и после next().\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil {\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")\n\t\tresp, err := next(ctx, req)\n\t\tlogger(ctx, \"finish\")\n\t\treturn resp, err\n\t}\n}\n\n// Level 2 (medium): TimeoutInterceptor оборачивает вызов в context.WithTimeout.\n// Hint: отменяйте контекст через cancel() и прокидывайте дочерний ctx в next.\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\tif d <= 0 {\n\t\td = time.Second\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctx, cancel := context.WithTimeout(ctx, d)\n\t\tdefer cancel()\n\t\treturn next(ctx, req)\n\t}\n}\n\n// Level 3 (medium+): Chain объединяет несколько интерсепторов в один.\n// Hint: применяйте их в порядке передачи, завершая фактическим handler.\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- {\n\t\t\tcurrent := interceptors[i]\n\t\t\tif current == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnext := wrapped\n\t\t\twrapped = func(c context.Context, r any) (any, error) {\n\t\t\t\treturn current(c, r, next)\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req)\n\t}\n}\n\n// Level 4 (medium+): RetryInterceptor повторяет вызов до maxRetries раз с backoff при ошибке.\n// Hint: вызывайте next и при ошибке спите в соответствии с backoff(attempt).\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 {\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tvar (\n\t\t\tresp any\n\t\t\terr  error\n\t\t)\n\t\tfor i := 0; i <= maxRetries; i++ {\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = handler(ctx, req)\n\t\t\tif err == nil {\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif i == maxRetries {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0)\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(i)\n\t\t\t}\n\t\t\tif delay > 0 {\n\t\t\t\ttimer := time.NewTimer(delay)\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err\n\t}\n}\n\n// Level 5 (medium+): ContextValueInterceptor добавляет в контекст значение перед вызовом next.\n// Hint: используйте context.WithValue и передавайте обновлённый ctx дальше.\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tctx = context.WithValue(ctx, key, value)\n\t\treturn handler(ctx, req)\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\ntype Handler func(ctx context.Context, req any) (any, error)\n\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil { // provide no-op logger when caller omitted it\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")        // announce beginning of unary call\n\t\tresp, err := next(ctx, req) // invoke next handler in chain\n\t\tlogger(ctx, \"finish\")       // record completion after handler returns\n\t\treturn resp, err            // propagate result and error\n\t}\n}\n\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tif d <= 0 { // skip wrapping when no timeout requested\n\t\t\treturn next(ctx, req)\n\t\t}\n\t\tchild, cancel := context.WithTimeout(ctx, d) // derive context with deadline\n\t\tdefer cancel()                               // release timer resources on exit\n\t\treturn next(child, req)                      // invoke handler with timeout-aware context\n\t}\n}\n\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil { // default handler returns zero values when missing\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler                            // start wrapping from the innermost handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- { // compose interceptors in reverse order\n\t\t\tcurrent := interceptors[i] // pick current interceptor\n\t\t\tif current == nil {        // skip nil interceptors gracefully\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnextHandler := wrapped                                  // capture current wrapped handler for closure\n\t\t\twrapped = func(c context.Context, r any) (any, error) { // rebuild handler pipeline\n\t\t\t\treturn current(c, r, nextHandler) // delegate handling to interceptor\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req) // execute fully composed handler chain\n\t}\n}\n\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 { // normalize negative retry counts to zero\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tvar resp any                                         // placeholder for handler response\n\t\tvar err error                                        // track last handler error\n\t\tfor attempt := 0; attempt <= maxRetries; attempt++ { // attempt invocation up to retry limit\n\t\t\tif ctx.Err() != nil { // abort retries when context already canceled\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = next(ctx, req) // call downstream handler\n\t\t\tif err == nil {            // return immediately on success\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif attempt == maxRetries { // stop retrying after exhausting attempts\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0) // compute optional delay before next attempt\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(attempt) // evaluate backoff function with current attempt number\n\t\t\t}\n\t\t\tif delay > 0 { // sleep only when delay is positive\n\t\t\t\ttimer := time.NewTimer(delay) // allocate timer for backoff duration\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done(): // exit early if context canceled during wait\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err // return last observed result after retries exhausted\n\t}\n}\n\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctxWithValue := context.WithValue(ctx, key, value) // enrich context with provided key/value pair\n\t\treturn next(ctxWithValue, req)                     // proceed with updated context\n\t}\n}\n",
        "testCode": "package grpcx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLoggingInterceptor(t *testing.T) {\n\tt.Parallel()\n\tvar calls int32\n\tlogger := func(context.Context, string) { atomic.AddInt32(&calls, 1) }\n\tinter := LoggingInterceptor(logger)\n\thandler := func(context.Context, any) (any, error) { return \"ok\", nil }\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif atomic.LoadInt32(&calls) != 2 {\n\t\tt.Fatalf(\"expected logger called twice, got %d\", calls)\n\t}\n}\n\nfunc TestTimeoutInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := TimeoutInterceptor(10 * time.Millisecond)\n\tvar deadline time.Time\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tvar ok bool\n\t\tdeadline, ok = ctx.Deadline()\n\t\tif !ok {\n\t\t\tt.Fatal(\"expected deadline to be set\")\n\t\t}\n\t\t<-ctx.Done()\n\t\treturn nil, ctx.Err()\n\t}\n\t_, err := inter(context.Background(), nil, handler)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif time.Until(deadline) > 20*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\torder := make([]string, 0, 4)\n\tappendStep := func(name string) UnaryServerInterceptor {\n\t\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\t\torder = append(order, name+\" before\")\n\t\t\tresp, err := next(ctx, req)\n\t\t\torder = append(order, name+\" after\")\n\t\t\treturn resp, err\n\t\t}\n\t}\n\tchained := Chain(appendStep(\"a\"), appendStep(\"b\"))\n\thandler := func(context.Context, any) (any, error) {\n\t\torder = append(order, \"handler\")\n\t\treturn nil, nil\n\t}\n\tif _, err := chained(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\texpected := []string{\"a before\", \"b before\", \"handler\", \"b after\", \"a after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"unexpected order at %d: got %q want %q\", i, order[i], want)\n\t\t}\n\t}\n}\n\nfunc TestRetryInterceptor(t *testing.T) {\n\tt.Parallel()\n\tretries := int32(0)\n\tfail := errors.New(\"fail\")\n\tvar attempts int32\n\thandler := func(context.Context, any) (any, error) {\n\t\tif atomic.AddInt32(&attempts, 1) <= retries {\n\t\t\treturn nil, fail\n\t\t}\n\t\treturn \"ok\", nil\n\t}\n\tfor _, retries = range []int32{0, 2} {\n\t\tattempts = 0\n\t\tinter := RetryInterceptor(int(retries)+1, func(int) time.Duration { return 0 })\n\t\t_, err := inter(context.Background(), nil, handler)\n\t\tif retries == 0 && err != nil {\n\t\t\tt.Fatalf(\"expected zero retries to succeed immediately, got %v\", err)\n\t\t}\n\t\tif retries > 0 && err != nil {\n\t\t\tt.Fatalf(\"expected retries to eventually succeed, got %v\", err)\n\t\t}\n\t}\n}\n\nfunc TestContextValueInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := ContextValueInterceptor(\"key\", \"value\")\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tif got := ctx.Value(\"key\"); got != \"value\" {\n\t\t\tt.Fatalf(\"expected value in context, got %v\", got)\n\t\t}\n\t\treturn nil, nil\n\t}\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "grpcx"
        ],
        "order": 1
      },
      {
        "package": "grpcx",
        "slug": "go-grpcx-chain",
        "title": "Chain объединяет несколько интерсепторов в один.",
        "description": "Level 3 (medium+): Chain объединяет несколько интерсепторов в один.\nHint: применяйте их в порядке передачи, завершая фактическим handler.",
        "difficulty": "medium",
        "hint1": "применяйте их в порядке передачи, завершая фактическим handler.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\n// Handler имитирует grpc.UnaryHandler.\ntype Handler func(ctx context.Context, req any) (any, error)\n\n// UnaryServerInterceptor описывает обёртку над обработчиком.\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\n// Level 1 (easy): LoggingInterceptor добавляет логирование начала/конца вызова через переданную функцию logger.\n// Hint: вызовите logger дважды: до и после next().\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil {\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")\n\t\tresp, err := next(ctx, req)\n\t\tlogger(ctx, \"finish\")\n\t\treturn resp, err\n\t}\n}\n\n// Level 2 (medium): TimeoutInterceptor оборачивает вызов в context.WithTimeout.\n// Hint: отменяйте контекст через cancel() и прокидывайте дочерний ctx в next.\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\tif d <= 0 {\n\t\td = time.Second\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctx, cancel := context.WithTimeout(ctx, d)\n\t\tdefer cancel()\n\t\treturn next(ctx, req)\n\t}\n}\n\n// Level 3 (medium+): Chain объединяет несколько интерсепторов в один.\n// Hint: применяйте их в порядке передачи, завершая фактическим handler.\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- {\n\t\t\tcurrent := interceptors[i]\n\t\t\tif current == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnext := wrapped\n\t\t\twrapped = func(c context.Context, r any) (any, error) {\n\t\t\t\treturn current(c, r, next)\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req)\n\t}\n}\n\n// Level 4 (medium+): RetryInterceptor повторяет вызов до maxRetries раз с backoff при ошибке.\n// Hint: вызывайте next и при ошибке спите в соответствии с backoff(attempt).\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 {\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tvar (\n\t\t\tresp any\n\t\t\terr  error\n\t\t)\n\t\tfor i := 0; i <= maxRetries; i++ {\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = handler(ctx, req)\n\t\t\tif err == nil {\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif i == maxRetries {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0)\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(i)\n\t\t\t}\n\t\t\tif delay > 0 {\n\t\t\t\ttimer := time.NewTimer(delay)\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err\n\t}\n}\n\n// Level 5 (medium+): ContextValueInterceptor добавляет в контекст значение перед вызовом next.\n// Hint: используйте context.WithValue и передавайте обновлённый ctx дальше.\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tctx = context.WithValue(ctx, key, value)\n\t\treturn handler(ctx, req)\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\ntype Handler func(ctx context.Context, req any) (any, error)\n\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil { // provide no-op logger when caller omitted it\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")        // announce beginning of unary call\n\t\tresp, err := next(ctx, req) // invoke next handler in chain\n\t\tlogger(ctx, \"finish\")       // record completion after handler returns\n\t\treturn resp, err            // propagate result and error\n\t}\n}\n\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tif d <= 0 { // skip wrapping when no timeout requested\n\t\t\treturn next(ctx, req)\n\t\t}\n\t\tchild, cancel := context.WithTimeout(ctx, d) // derive context with deadline\n\t\tdefer cancel()                               // release timer resources on exit\n\t\treturn next(child, req)                      // invoke handler with timeout-aware context\n\t}\n}\n\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil { // default handler returns zero values when missing\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler                            // start wrapping from the innermost handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- { // compose interceptors in reverse order\n\t\t\tcurrent := interceptors[i] // pick current interceptor\n\t\t\tif current == nil {        // skip nil interceptors gracefully\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnextHandler := wrapped                                  // capture current wrapped handler for closure\n\t\t\twrapped = func(c context.Context, r any) (any, error) { // rebuild handler pipeline\n\t\t\t\treturn current(c, r, nextHandler) // delegate handling to interceptor\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req) // execute fully composed handler chain\n\t}\n}\n\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 { // normalize negative retry counts to zero\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tvar resp any                                         // placeholder for handler response\n\t\tvar err error                                        // track last handler error\n\t\tfor attempt := 0; attempt <= maxRetries; attempt++ { // attempt invocation up to retry limit\n\t\t\tif ctx.Err() != nil { // abort retries when context already canceled\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = next(ctx, req) // call downstream handler\n\t\t\tif err == nil {            // return immediately on success\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif attempt == maxRetries { // stop retrying after exhausting attempts\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0) // compute optional delay before next attempt\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(attempt) // evaluate backoff function with current attempt number\n\t\t\t}\n\t\t\tif delay > 0 { // sleep only when delay is positive\n\t\t\t\ttimer := time.NewTimer(delay) // allocate timer for backoff duration\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done(): // exit early if context canceled during wait\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err // return last observed result after retries exhausted\n\t}\n}\n\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctxWithValue := context.WithValue(ctx, key, value) // enrich context with provided key/value pair\n\t\treturn next(ctxWithValue, req)                     // proceed with updated context\n\t}\n}\n",
        "testCode": "package grpcx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLoggingInterceptor(t *testing.T) {\n\tt.Parallel()\n\tvar calls int32\n\tlogger := func(context.Context, string) { atomic.AddInt32(&calls, 1) }\n\tinter := LoggingInterceptor(logger)\n\thandler := func(context.Context, any) (any, error) { return \"ok\", nil }\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif atomic.LoadInt32(&calls) != 2 {\n\t\tt.Fatalf(\"expected logger called twice, got %d\", calls)\n\t}\n}\n\nfunc TestTimeoutInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := TimeoutInterceptor(10 * time.Millisecond)\n\tvar deadline time.Time\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tvar ok bool\n\t\tdeadline, ok = ctx.Deadline()\n\t\tif !ok {\n\t\t\tt.Fatal(\"expected deadline to be set\")\n\t\t}\n\t\t<-ctx.Done()\n\t\treturn nil, ctx.Err()\n\t}\n\t_, err := inter(context.Background(), nil, handler)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif time.Until(deadline) > 20*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\torder := make([]string, 0, 4)\n\tappendStep := func(name string) UnaryServerInterceptor {\n\t\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\t\torder = append(order, name+\" before\")\n\t\t\tresp, err := next(ctx, req)\n\t\t\torder = append(order, name+\" after\")\n\t\t\treturn resp, err\n\t\t}\n\t}\n\tchained := Chain(appendStep(\"a\"), appendStep(\"b\"))\n\thandler := func(context.Context, any) (any, error) {\n\t\torder = append(order, \"handler\")\n\t\treturn nil, nil\n\t}\n\tif _, err := chained(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\texpected := []string{\"a before\", \"b before\", \"handler\", \"b after\", \"a after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"unexpected order at %d: got %q want %q\", i, order[i], want)\n\t\t}\n\t}\n}\n\nfunc TestRetryInterceptor(t *testing.T) {\n\tt.Parallel()\n\tretries := int32(0)\n\tfail := errors.New(\"fail\")\n\tvar attempts int32\n\thandler := func(context.Context, any) (any, error) {\n\t\tif atomic.AddInt32(&attempts, 1) <= retries {\n\t\t\treturn nil, fail\n\t\t}\n\t\treturn \"ok\", nil\n\t}\n\tfor _, retries = range []int32{0, 2} {\n\t\tattempts = 0\n\t\tinter := RetryInterceptor(int(retries)+1, func(int) time.Duration { return 0 })\n\t\t_, err := inter(context.Background(), nil, handler)\n\t\tif retries == 0 && err != nil {\n\t\t\tt.Fatalf(\"expected zero retries to succeed immediately, got %v\", err)\n\t\t}\n\t\tif retries > 0 && err != nil {\n\t\t\tt.Fatalf(\"expected retries to eventually succeed, got %v\", err)\n\t\t}\n\t}\n}\n\nfunc TestContextValueInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := ContextValueInterceptor(\"key\", \"value\")\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tif got := ctx.Value(\"key\"); got != \"value\" {\n\t\t\tt.Fatalf(\"expected value in context, got %v\", got)\n\t\t}\n\t\treturn nil, nil\n\t}\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "grpcx"
        ],
        "order": 2
      },
      {
        "package": "grpcx",
        "slug": "go-grpcx-retryinterceptor",
        "title": "RetryInterceptor повторяет вызов до maxRetries раз с backoff при ошибке.",
        "description": "Level 4 (medium+): RetryInterceptor повторяет вызов до maxRetries раз с backoff при ошибке.\nHint: вызывайте next и при ошибке спите в соответствии с backoff(attempt).",
        "difficulty": "medium",
        "hint1": "вызывайте next и при ошибке спите в соответствии с backoff(attempt).",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\n// Handler имитирует grpc.UnaryHandler.\ntype Handler func(ctx context.Context, req any) (any, error)\n\n// UnaryServerInterceptor описывает обёртку над обработчиком.\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\n// Level 1 (easy): LoggingInterceptor добавляет логирование начала/конца вызова через переданную функцию logger.\n// Hint: вызовите logger дважды: до и после next().\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil {\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")\n\t\tresp, err := next(ctx, req)\n\t\tlogger(ctx, \"finish\")\n\t\treturn resp, err\n\t}\n}\n\n// Level 2 (medium): TimeoutInterceptor оборачивает вызов в context.WithTimeout.\n// Hint: отменяйте контекст через cancel() и прокидывайте дочерний ctx в next.\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\tif d <= 0 {\n\t\td = time.Second\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctx, cancel := context.WithTimeout(ctx, d)\n\t\tdefer cancel()\n\t\treturn next(ctx, req)\n\t}\n}\n\n// Level 3 (medium+): Chain объединяет несколько интерсепторов в один.\n// Hint: применяйте их в порядке передачи, завершая фактическим handler.\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- {\n\t\t\tcurrent := interceptors[i]\n\t\t\tif current == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnext := wrapped\n\t\t\twrapped = func(c context.Context, r any) (any, error) {\n\t\t\t\treturn current(c, r, next)\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req)\n\t}\n}\n\n// Level 4 (medium+): RetryInterceptor повторяет вызов до maxRetries раз с backoff при ошибке.\n// Hint: вызывайте next и при ошибке спите в соответствии с backoff(attempt).\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 {\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tvar (\n\t\t\tresp any\n\t\t\terr  error\n\t\t)\n\t\tfor i := 0; i <= maxRetries; i++ {\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = handler(ctx, req)\n\t\t\tif err == nil {\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif i == maxRetries {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0)\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(i)\n\t\t\t}\n\t\t\tif delay > 0 {\n\t\t\t\ttimer := time.NewTimer(delay)\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err\n\t}\n}\n\n// Level 5 (medium+): ContextValueInterceptor добавляет в контекст значение перед вызовом next.\n// Hint: используйте context.WithValue и передавайте обновлённый ctx дальше.\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tctx = context.WithValue(ctx, key, value)\n\t\treturn handler(ctx, req)\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\ntype Handler func(ctx context.Context, req any) (any, error)\n\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil { // provide no-op logger when caller omitted it\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")        // announce beginning of unary call\n\t\tresp, err := next(ctx, req) // invoke next handler in chain\n\t\tlogger(ctx, \"finish\")       // record completion after handler returns\n\t\treturn resp, err            // propagate result and error\n\t}\n}\n\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tif d <= 0 { // skip wrapping when no timeout requested\n\t\t\treturn next(ctx, req)\n\t\t}\n\t\tchild, cancel := context.WithTimeout(ctx, d) // derive context with deadline\n\t\tdefer cancel()                               // release timer resources on exit\n\t\treturn next(child, req)                      // invoke handler with timeout-aware context\n\t}\n}\n\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil { // default handler returns zero values when missing\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler                            // start wrapping from the innermost handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- { // compose interceptors in reverse order\n\t\t\tcurrent := interceptors[i] // pick current interceptor\n\t\t\tif current == nil {        // skip nil interceptors gracefully\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnextHandler := wrapped                                  // capture current wrapped handler for closure\n\t\t\twrapped = func(c context.Context, r any) (any, error) { // rebuild handler pipeline\n\t\t\t\treturn current(c, r, nextHandler) // delegate handling to interceptor\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req) // execute fully composed handler chain\n\t}\n}\n\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 { // normalize negative retry counts to zero\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tvar resp any                                         // placeholder for handler response\n\t\tvar err error                                        // track last handler error\n\t\tfor attempt := 0; attempt <= maxRetries; attempt++ { // attempt invocation up to retry limit\n\t\t\tif ctx.Err() != nil { // abort retries when context already canceled\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = next(ctx, req) // call downstream handler\n\t\t\tif err == nil {            // return immediately on success\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif attempt == maxRetries { // stop retrying after exhausting attempts\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0) // compute optional delay before next attempt\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(attempt) // evaluate backoff function with current attempt number\n\t\t\t}\n\t\t\tif delay > 0 { // sleep only when delay is positive\n\t\t\t\ttimer := time.NewTimer(delay) // allocate timer for backoff duration\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done(): // exit early if context canceled during wait\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err // return last observed result after retries exhausted\n\t}\n}\n\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctxWithValue := context.WithValue(ctx, key, value) // enrich context with provided key/value pair\n\t\treturn next(ctxWithValue, req)                     // proceed with updated context\n\t}\n}\n",
        "testCode": "package grpcx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLoggingInterceptor(t *testing.T) {\n\tt.Parallel()\n\tvar calls int32\n\tlogger := func(context.Context, string) { atomic.AddInt32(&calls, 1) }\n\tinter := LoggingInterceptor(logger)\n\thandler := func(context.Context, any) (any, error) { return \"ok\", nil }\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif atomic.LoadInt32(&calls) != 2 {\n\t\tt.Fatalf(\"expected logger called twice, got %d\", calls)\n\t}\n}\n\nfunc TestTimeoutInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := TimeoutInterceptor(10 * time.Millisecond)\n\tvar deadline time.Time\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tvar ok bool\n\t\tdeadline, ok = ctx.Deadline()\n\t\tif !ok {\n\t\t\tt.Fatal(\"expected deadline to be set\")\n\t\t}\n\t\t<-ctx.Done()\n\t\treturn nil, ctx.Err()\n\t}\n\t_, err := inter(context.Background(), nil, handler)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif time.Until(deadline) > 20*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\torder := make([]string, 0, 4)\n\tappendStep := func(name string) UnaryServerInterceptor {\n\t\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\t\torder = append(order, name+\" before\")\n\t\t\tresp, err := next(ctx, req)\n\t\t\torder = append(order, name+\" after\")\n\t\t\treturn resp, err\n\t\t}\n\t}\n\tchained := Chain(appendStep(\"a\"), appendStep(\"b\"))\n\thandler := func(context.Context, any) (any, error) {\n\t\torder = append(order, \"handler\")\n\t\treturn nil, nil\n\t}\n\tif _, err := chained(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\texpected := []string{\"a before\", \"b before\", \"handler\", \"b after\", \"a after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"unexpected order at %d: got %q want %q\", i, order[i], want)\n\t\t}\n\t}\n}\n\nfunc TestRetryInterceptor(t *testing.T) {\n\tt.Parallel()\n\tretries := int32(0)\n\tfail := errors.New(\"fail\")\n\tvar attempts int32\n\thandler := func(context.Context, any) (any, error) {\n\t\tif atomic.AddInt32(&attempts, 1) <= retries {\n\t\t\treturn nil, fail\n\t\t}\n\t\treturn \"ok\", nil\n\t}\n\tfor _, retries = range []int32{0, 2} {\n\t\tattempts = 0\n\t\tinter := RetryInterceptor(int(retries)+1, func(int) time.Duration { return 0 })\n\t\t_, err := inter(context.Background(), nil, handler)\n\t\tif retries == 0 && err != nil {\n\t\t\tt.Fatalf(\"expected zero retries to succeed immediately, got %v\", err)\n\t\t}\n\t\tif retries > 0 && err != nil {\n\t\t\tt.Fatalf(\"expected retries to eventually succeed, got %v\", err)\n\t\t}\n\t}\n}\n\nfunc TestContextValueInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := ContextValueInterceptor(\"key\", \"value\")\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tif got := ctx.Value(\"key\"); got != \"value\" {\n\t\t\tt.Fatalf(\"expected value in context, got %v\", got)\n\t\t}\n\t\treturn nil, nil\n\t}\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "grpcx"
        ],
        "order": 3
      },
      {
        "package": "grpcx",
        "slug": "go-grpcx-contextvalueinterceptor",
        "title": "ContextValueInterceptor добавляет в контекст значение перед вызовом next.",
        "description": "Level 5 (medium+): ContextValueInterceptor добавляет в контекст значение перед вызовом next.\nHint: используйте context.WithValue и передавайте обновлённый ctx дальше.",
        "difficulty": "medium",
        "hint1": "используйте context.WithValue и передавайте обновлённый ctx дальше.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\n// Handler имитирует grpc.UnaryHandler.\ntype Handler func(ctx context.Context, req any) (any, error)\n\n// UnaryServerInterceptor описывает обёртку над обработчиком.\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\n// Level 1 (easy): LoggingInterceptor добавляет логирование начала/конца вызова через переданную функцию logger.\n// Hint: вызовите logger дважды: до и после next().\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil {\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")\n\t\tresp, err := next(ctx, req)\n\t\tlogger(ctx, \"finish\")\n\t\treturn resp, err\n\t}\n}\n\n// Level 2 (medium): TimeoutInterceptor оборачивает вызов в context.WithTimeout.\n// Hint: отменяйте контекст через cancel() и прокидывайте дочерний ctx в next.\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\tif d <= 0 {\n\t\td = time.Second\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctx, cancel := context.WithTimeout(ctx, d)\n\t\tdefer cancel()\n\t\treturn next(ctx, req)\n\t}\n}\n\n// Level 3 (medium+): Chain объединяет несколько интерсепторов в один.\n// Hint: применяйте их в порядке передачи, завершая фактическим handler.\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- {\n\t\t\tcurrent := interceptors[i]\n\t\t\tif current == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnext := wrapped\n\t\t\twrapped = func(c context.Context, r any) (any, error) {\n\t\t\t\treturn current(c, r, next)\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req)\n\t}\n}\n\n// Level 4 (medium+): RetryInterceptor повторяет вызов до maxRetries раз с backoff при ошибке.\n// Hint: вызывайте next и при ошибке спите в соответствии с backoff(attempt).\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 {\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tvar (\n\t\t\tresp any\n\t\t\terr  error\n\t\t)\n\t\tfor i := 0; i <= maxRetries; i++ {\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = handler(ctx, req)\n\t\t\tif err == nil {\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif i == maxRetries {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0)\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(i)\n\t\t\t}\n\t\t\tif delay > 0 {\n\t\t\t\ttimer := time.NewTimer(delay)\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err\n\t}\n}\n\n// Level 5 (medium+): ContextValueInterceptor добавляет в контекст значение перед вызовом next.\n// Hint: используйте context.WithValue и передавайте обновлённый ctx дальше.\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil {\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\tctx = context.WithValue(ctx, key, value)\n\t\treturn handler(ctx, req)\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage grpcx\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\ntype Handler func(ctx context.Context, req any) (any, error)\n\ntype UnaryServerInterceptor func(ctx context.Context, req any, next Handler) (any, error)\n\nfunc LoggingInterceptor(logger func(context.Context, string)) UnaryServerInterceptor {\n\tif logger == nil { // provide no-op logger when caller omitted it\n\t\tlogger = func(context.Context, string) {}\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tlogger(ctx, \"start\")        // announce beginning of unary call\n\t\tresp, err := next(ctx, req) // invoke next handler in chain\n\t\tlogger(ctx, \"finish\")       // record completion after handler returns\n\t\treturn resp, err            // propagate result and error\n\t}\n}\n\nfunc TimeoutInterceptor(d time.Duration) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tif d <= 0 { // skip wrapping when no timeout requested\n\t\t\treturn next(ctx, req)\n\t\t}\n\t\tchild, cancel := context.WithTimeout(ctx, d) // derive context with deadline\n\t\tdefer cancel()                               // release timer resources on exit\n\t\treturn next(child, req)                      // invoke handler with timeout-aware context\n\t}\n}\n\nfunc Chain(interceptors ...UnaryServerInterceptor) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, handler Handler) (any, error) {\n\t\tif handler == nil { // default handler returns zero values when missing\n\t\t\thandler = func(context.Context, any) (any, error) { return nil, nil }\n\t\t}\n\t\twrapped := handler                            // start wrapping from the innermost handler\n\t\tfor i := len(interceptors) - 1; i >= 0; i-- { // compose interceptors in reverse order\n\t\t\tcurrent := interceptors[i] // pick current interceptor\n\t\t\tif current == nil {        // skip nil interceptors gracefully\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnextHandler := wrapped                                  // capture current wrapped handler for closure\n\t\t\twrapped = func(c context.Context, r any) (any, error) { // rebuild handler pipeline\n\t\t\t\treturn current(c, r, nextHandler) // delegate handling to interceptor\n\t\t\t}\n\t\t}\n\t\treturn wrapped(ctx, req) // execute fully composed handler chain\n\t}\n}\n\nfunc RetryInterceptor(maxRetries int, backoff func(int) time.Duration) UnaryServerInterceptor {\n\tif maxRetries < 0 { // normalize negative retry counts to zero\n\t\tmaxRetries = 0\n\t}\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tvar resp any                                         // placeholder for handler response\n\t\tvar err error                                        // track last handler error\n\t\tfor attempt := 0; attempt <= maxRetries; attempt++ { // attempt invocation up to retry limit\n\t\t\tif ctx.Err() != nil { // abort retries when context already canceled\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\t\t\tresp, err = next(ctx, req) // call downstream handler\n\t\t\tif err == nil {            // return immediately on success\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tif attempt == maxRetries { // stop retrying after exhausting attempts\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdelay := time.Duration(0) // compute optional delay before next attempt\n\t\t\tif backoff != nil {\n\t\t\t\tdelay = backoff(attempt) // evaluate backoff function with current attempt number\n\t\t\t}\n\t\t\tif delay > 0 { // sleep only when delay is positive\n\t\t\t\ttimer := time.NewTimer(delay) // allocate timer for backoff duration\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done(): // exit early if context canceled during wait\n\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-timer.C:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resp, err // return last observed result after retries exhausted\n\t}\n}\n\nfunc ContextValueInterceptor(key any, value any) UnaryServerInterceptor {\n\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\tctxWithValue := context.WithValue(ctx, key, value) // enrich context with provided key/value pair\n\t\treturn next(ctxWithValue, req)                     // proceed with updated context\n\t}\n}\n",
        "testCode": "package grpcx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLoggingInterceptor(t *testing.T) {\n\tt.Parallel()\n\tvar calls int32\n\tlogger := func(context.Context, string) { atomic.AddInt32(&calls, 1) }\n\tinter := LoggingInterceptor(logger)\n\thandler := func(context.Context, any) (any, error) { return \"ok\", nil }\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif atomic.LoadInt32(&calls) != 2 {\n\t\tt.Fatalf(\"expected logger called twice, got %d\", calls)\n\t}\n}\n\nfunc TestTimeoutInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := TimeoutInterceptor(10 * time.Millisecond)\n\tvar deadline time.Time\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tvar ok bool\n\t\tdeadline, ok = ctx.Deadline()\n\t\tif !ok {\n\t\t\tt.Fatal(\"expected deadline to be set\")\n\t\t}\n\t\t<-ctx.Done()\n\t\treturn nil, ctx.Err()\n\t}\n\t_, err := inter(context.Background(), nil, handler)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif time.Until(deadline) > 20*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\torder := make([]string, 0, 4)\n\tappendStep := func(name string) UnaryServerInterceptor {\n\t\treturn func(ctx context.Context, req any, next Handler) (any, error) {\n\t\t\torder = append(order, name+\" before\")\n\t\t\tresp, err := next(ctx, req)\n\t\t\torder = append(order, name+\" after\")\n\t\t\treturn resp, err\n\t\t}\n\t}\n\tchained := Chain(appendStep(\"a\"), appendStep(\"b\"))\n\thandler := func(context.Context, any) (any, error) {\n\t\torder = append(order, \"handler\")\n\t\treturn nil, nil\n\t}\n\tif _, err := chained(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\texpected := []string{\"a before\", \"b before\", \"handler\", \"b after\", \"a after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"unexpected order at %d: got %q want %q\", i, order[i], want)\n\t\t}\n\t}\n}\n\nfunc TestRetryInterceptor(t *testing.T) {\n\tt.Parallel()\n\tretries := int32(0)\n\tfail := errors.New(\"fail\")\n\tvar attempts int32\n\thandler := func(context.Context, any) (any, error) {\n\t\tif atomic.AddInt32(&attempts, 1) <= retries {\n\t\t\treturn nil, fail\n\t\t}\n\t\treturn \"ok\", nil\n\t}\n\tfor _, retries = range []int32{0, 2} {\n\t\tattempts = 0\n\t\tinter := RetryInterceptor(int(retries)+1, func(int) time.Duration { return 0 })\n\t\t_, err := inter(context.Background(), nil, handler)\n\t\tif retries == 0 && err != nil {\n\t\t\tt.Fatalf(\"expected zero retries to succeed immediately, got %v\", err)\n\t\t}\n\t\tif retries > 0 && err != nil {\n\t\t\tt.Fatalf(\"expected retries to eventually succeed, got %v\", err)\n\t\t}\n\t}\n}\n\nfunc TestContextValueInterceptor(t *testing.T) {\n\tt.Parallel()\n\tinter := ContextValueInterceptor(\"key\", \"value\")\n\thandler := func(ctx context.Context, req any) (any, error) {\n\t\tif got := ctx.Value(\"key\"); got != \"value\" {\n\t\t\tt.Fatalf(\"expected value in context, got %v\", got)\n\t\t}\n\t\treturn nil, nil\n\t}\n\tif _, err := inter(context.Background(), nil, handler); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "grpcx"
        ],
        "order": 4
      }
    ],
    "category": "grpc"
  },
  {
    "name": "httpx",
    "tasks": [
      {
        "package": "httpx",
        "slug": "go-httpx-requestid",
        "title": "RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.",
        "description": "Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\nHint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.",
        "difficulty": "easy",
        "hint1": "возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 0
      },
      {
        "package": "httpx",
        "slug": "go-httpx-setheader",
        "title": "SetHeader гарантирует, что каждый ответ содержит заданный заголовок.",
        "description": "Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\nHint: установите заголовок через Header().Set перед передачей выполнения дальше.",
        "difficulty": "easy",
        "hint1": "установите заголовок через Header().Set перед передачей выполнения дальше.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 1
      },
      {
        "package": "httpx",
        "slug": "go-httpx-requiremethod",
        "title": "RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.",
        "description": "Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\nHint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.",
        "difficulty": "easy",
        "hint1": "сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 2
      },
      {
        "package": "httpx",
        "slug": "go-httpx-requireheader",
        "title": "RequireHeader проверяет, что заголовок присутствует и непустой.",
        "description": "Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\nHint: используйте Header().Get и в случае пустого значения возвращайте 400.",
        "difficulty": "easy",
        "hint1": "используйте Header().Get и в случае пустого значения возвращайте 400.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 3
      },
      {
        "package": "httpx",
        "slug": "go-httpx-logger",
        "title": "Logger измеряет время обработки запроса и пишет строку лога.",
        "description": "Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\nHint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.",
        "difficulty": "easy",
        "hint1": "сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 4
      },
      {
        "package": "httpx",
        "slug": "go-httpx-stripprefix",
        "title": "StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.",
        "description": "Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\nHint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.",
        "difficulty": "medium",
        "hint1": "проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 5
      },
      {
        "package": "httpx",
        "slug": "go-httpx-requirequeryparam",
        "title": "RequireQueryParam убеждается, что нужный query-параметр присутствует.",
        "description": "Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\nHint: используйте r.URL.Query().Get и верните 400, если значение пустое.",
        "difficulty": "medium",
        "hint1": "используйте r.URL.Query().Get и верните 400, если значение пустое.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 6
      },
      {
        "package": "httpx",
        "slug": "go-httpx-headertocontext",
        "title": "HeaderToContext прокидывает значение заголовка в контекст.",
        "description": "Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\nHint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).",
        "difficulty": "medium",
        "hint1": "получите значение и оберните запрос через r.WithContext(context.WithValue(...)).",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 7
      },
      {
        "package": "httpx",
        "slug": "go-httpx-recover",
        "title": "Recover перехватывает паники и отвечает 500.",
        "description": "Level 9 (medium): Recover перехватывает паники и отвечает 500.\nHint: оберните вызов next через defer, вызовите recover и отправьте http.Error.",
        "difficulty": "medium",
        "hint1": "оберните вызов next через defer, вызовите recover и отправьте http.Error.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 8
      },
      {
        "package": "httpx",
        "slug": "go-httpx-bodypreview",
        "title": "BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.",
        "description": "Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\nHint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.",
        "difficulty": "medium",
        "hint1": "используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 9
      },
      {
        "package": "httpx",
        "slug": "go-httpx-capturestatus",
        "title": "CaptureStatus делает статус ответа доступным в контексте.",
        "description": "Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\nHint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.",
        "difficulty": "medium",
        "hint1": "заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 10
      },
      {
        "package": "httpx",
        "slug": "go-httpx-teebody",
        "title": "TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.",
        "description": "Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\nHint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.",
        "difficulty": "medium",
        "hint1": "заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 11
      },
      {
        "package": "httpx",
        "slug": "go-httpx-prependbody",
        "title": "PrependBody добавляет префикс к телу запроса.",
        "description": "Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\nHint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.",
        "difficulty": "medium",
        "hint1": "соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 12
      },
      {
        "package": "httpx",
        "slug": "go-httpx-decompressgzip",
        "title": "DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.",
        "description": "Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\nHint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.",
        "difficulty": "medium",
        "hint1": "создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 13
      },
      {
        "package": "httpx",
        "slug": "go-httpx-concurrencylimit",
        "title": "ConcurrencyLimit ограничивает число параллельных обработчиков.",
        "description": "Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\nHint: используйте буферизированный канал как семафор и освобождайте слот после next.",
        "difficulty": "medium",
        "hint1": "используйте буферизированный канал как семафор и освобождайте слот после next.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 14
      },
      {
        "package": "httpx",
        "slug": "go-httpx-timeout",
        "title": "Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.",
        "description": "Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\nHint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().",
        "difficulty": "medium",
        "hint1": "оберните контекст через context.WithTimeout и обязательно вызовите cancel().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 15
      },
      {
        "package": "httpx",
        "slug": "go-httpx-maxbytes",
        "title": "MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.",
        "description": "Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\nHint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.",
        "difficulty": "medium",
        "hint1": "прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 16
      },
      {
        "package": "httpx",
        "slug": "go-httpx-chain",
        "title": "Chain объединяет несколько мидлварей в одну, применяя их слева направо.",
        "description": "Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\nHint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.",
        "difficulty": "medium",
        "hint1": "разворачивайте срез справа налево и последовательно оборачивайте обработчик.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\n// Level 1 (easy): RequestID добавляет уникальный идентификатор запроса в контекст и заголовок X-Request-ID.\n// Hint: возьмите UTC‑время с высокой точностью или счётчик, затем пропишите id в контекст и ответ.\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id)\n\t\tw.Header().Set(\"X-Request-ID\", id)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 2 (easy+): SetHeader гарантирует, что каждый ответ содержит заданный заголовок.\n// Hint: установите заголовок через Header().Set перед передачей выполнения дальше.\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 3 (easy+): RequireMethod разрешает только один HTTP-метод, остальные отклоняет с 405.\n// Hint: сравните r.Method c ожидаемым, при несовпадении верните ошибку и не вызывайте next.\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method))\n\tif want == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != method {\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 4 (easy+): RequireHeader проверяет, что заголовок присутствует и непустой.\n// Hint: используйте Header().Get и в случае пустого значения возвращайте 400.\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name)\n\tif headerName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" {\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 5 (easy+): Logger измеряет время обработки запроса и пишет строку лога.\n// Hint: сохраните стартовое время, вызовите next, затем залогируйте метод, путь и длительность.\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tduration := time.Since(start)\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration)\n\t})\n}\n\n// Level 6 (medium): StripPrefix снимает указанный префикс пути или отвечает 404 при несовпадении.\n// Hint: проверьте HasPrefix, обрежьте префикс и обновите Path/RawPath прежде чем вызвать next.\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix)\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (len(rawPath) >= len(r.URL.RawPath) && r.URL.RawPath != \"\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context())\n\t\tclone.URL.Path = path\n\t\tif clone.URL.RawPath != \"\" {\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 7 (medium): RequireQueryParam убеждается, что нужный query-параметр присутствует.\n// Hint: используйте r.URL.Query().Get и верните 400, если значение пустое.\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name)\n\tif paramName == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tqueryParam := strings.TrimSpace(r.URL.Query().Get(paramName))\n\t\tif queryParam == \"\" {\n\t\t\thttp.Error(w, \"missing required qurey parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 8 (medium): HeaderToContext прокидывает значение заголовка в контекст.\n// Hint: получите значение и оберните запрос через r.WithContext(context.WithValue(...)).\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)\n\t\tctx := context.WithValue(r.Context(), key, val)\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 9 (medium): Recover перехватывает паники и отвечает 500.\n// Hint: оберните вызов next через defer, вызовите recover и отправьте http.Error.\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError)\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 10 (medium): BodyPreview сохраняет в контексте первые limit байт тела запроса и не мешает чтению дальше.\n// Hint: используйте bufio.Reader и Peek, а затем передайте обёрнутый body дальше.\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)\n\t\tpeek, err := reader.Peek(limit)\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) {\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)\n\t\tclone := r.Clone(ctx)\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 11 (medium+): CaptureStatus делает статус ответа доступным в контексте.\n// Hint: заверните ResponseWriter, обновляйте статус в WriteHeader/Write и храните указатель в контексте.\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0\n\t\trec := &statusWriter{ResponseWriter: w, status: &status}\n\t\tctx := context.WithValue(r.Context(), key, rec.status)\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))\n\t\tif *rec.status == 0 {\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\n// Level 12 (medium+): TeeBody дублирует поток тела в writer и пропускает его дальше без повторного чтения.\n// Hint: заверните r.Body через io.TeeReader и восстановите io.ReadCloser для next.\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 13 (medium+): PrependBody добавляет префикс к телу запроса.\n// Hint: соберите новое тело через io.MultiReader и не забудьте закрыть исходный Body.\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 {\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)\n\t\tclone := r.Clone(r.Context())\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body}\n\t\tif clone.ContentLength >= 0 {\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 14 (medium+): DecompressGZIP распаковывает тело запроса с Content-Encoding: gzip.\n// Hint: создайте gzip.Reader, прочитайте данные, замените r.Body на распакованный io.ReadCloser.\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.WithContext(r.Context())\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tclone.ContentLength = int64(len(payload))\n\t\tif clone.Header != nil {\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone)\n\t})\n}\n\n// Level 15 (medium+): ConcurrencyLimit ограничивает число параллельных обработчиков.\n// Hint: используйте буферизированный канал как семафор и освобождайте слот после next.\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 {\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}\n\t\tdefer func() { <-sem }()\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 16 (medium+): Timeout создаёт дочерний контекст с тайм-аутом и прокидывает его дальше.\n// Hint: оберните контекст через context.WithTimeout и обязательно вызовите cancel().\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d)\n\t\tdefer cancel()\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// Level 17 (medium+): MaxBytes ограничивает размер тела запроса, отвечая 413 при превышении лимита.\n// Hint: прочитайте тело с ограничением размера, при успехе восстановите r.Body для next.\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil {\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\tpayload, err := io.ReadAll(io.LimitReader(r.Body, limit+1))\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif int64(len(payload)) > limit {\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil {\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(payload))\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n\n// Level 18 (medium+): Chain объединяет несколько мидлварей в одну, применяя их слева направо.\n// Hint: разворачивайте срез справа налево и последовательно оборачивайте обработчик.\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil {\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- {\n\t\t\tmw := middlewares[i]\n\t\t\tif mw == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped)\n\t\t}\n\t\treturn wrapped\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 {\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage httpx\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"errors\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype ctxKey string\n\nconst RequestIDKey ctxKey = \"rid\"\n\nfunc RequestID(next http.Handler) http.Handler {\n\tif next == nil { // guard against nil handler to avoid panics\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tid := time.Now().UTC().Format(time.RFC3339Nano)         // generate a timestamp-based identifier\n\t\tctx := context.WithValue(r.Context(), RequestIDKey, id) // attach request id to context for downstream usage\n\t\tw.Header().Set(\"X-Request-ID\", id)                      // surface the request id via response header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))                   // hand over to next handler with enriched context\n\t})\n}\n\nfunc SetHeader(name, value string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler always exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // normalise header name\n\tif headerName == \"\" {                 // no header to set, pass-through behaviour\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(headerName, value) // enforce consistent header before handing off\n\t\tnext.ServeHTTP(w, r)              // propagate execution to the wrapped handler\n\t})\n}\n\nfunc RequireMethod(method string, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference for downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\twant := strings.ToUpper(strings.TrimSpace(method)) // canonicalise desired method\n\tif want == \"\" {                                    // empty method means no restriction\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.ToUpper(r.Method) != want { // reject mismatched method with 405\n\t\t\tw.Header().Set(\"Allow\", want)\n\t\t\thttp.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // delegate when method matches\n\t})\n}\n\nfunc RequireHeader(name string, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op when downstream is absent\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\theaderName := strings.TrimSpace(name) // canonicalise header lookup\n\tif headerName == \"\" {                 // nothing to validate, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.Header.Get(headerName)) == \"\" { // abort when header missing or empty\n\t\t\thttp.Error(w, \"missing required header\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once header is confirmed\n\t})\n}\n\nfunc Logger(next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()                                         // capture start moment for latency measurement\n\t\tnext.ServeHTTP(w, r)                                        // execute downstream handler before logging completion\n\t\tduration := time.Since(start)                               // compute elapsed time since request start\n\t\tlog.Printf(\"%s %s took %v\", r.Method, r.URL.Path, duration) // emit structured log line with latency\n\t})\n}\n\nfunc StripPrefix(prefix string, next http.Handler) http.Handler {\n\tif next == nil { // guard against absent downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif prefix == \"\" { // no prefix means plain pass-through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tpath := strings.TrimPrefix(r.URL.Path, prefix) // trim prefix from URL path\n\t\trawPath := strings.TrimPrefix(r.URL.RawPath, prefix)\n\t\tif len(path) >= len(r.URL.Path) || (r.URL.RawPath != \"\" && len(rawPath) >= len(r.URL.RawPath)) {\n\t\t\thttp.NotFound(w, r) // prefix mismatch, respond with 404\n\t\t\treturn\n\t\t}\n\t\tclone := r.Clone(r.Context()) // duplicate request to avoid mutating original\n\t\tclone.URL.Path = path         // update path to stripped value\n\t\tif clone.URL.RawPath != \"\" {  // adjust RawPath when present\n\t\t\tclone.URL.RawPath = rawPath\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with modified request\n\t})\n}\n\nfunc RequireQueryParam(name string, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tparamName := strings.TrimSpace(name) // canonicalise param key\n\tif paramName == \"\" {                 // no parameter to enforce\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.TrimSpace(r.URL.Query().Get(paramName)) == \"\" { // validate presence of query parameter\n\t\t\thttp.Error(w, \"missing required query parameter\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r) // proceed once parameter present\n\t})\n}\n\nfunc HeaderToContext(key ctxKey, header string, next http.Handler) http.Handler {\n\tif next == nil { // ensure downstream handler exists\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif header == \"\" { // nothing to inject, short-circuit\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Header.Get(header)                     // grab header value (empty when absent)\n\t\tctx := context.WithValue(r.Context(), key, val) // enrich context with captured header\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))           // pass updated request further\n\t})\n}\n\nfunc Recover(next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when nil provided\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdefer func() {\n\t\t\tif rec := recover(); rec != nil { // check whether downstream handler panicked\n\t\t\t\thttp.Error(w, \"internal error\", http.StatusInternalServerError) // render generic error to client\n\t\t\t}\n\t\t}()\n\t\tnext.ServeHTTP(w, r) // execute next handler within recovery scope\n\t})\n}\n\nfunc BodyPreview(limit int, key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // guard against nil downstream handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 || key == \"\" { // no preview requested\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := bufio.NewReaderSize(r.Body, limit)                                       // buffer enough bytes for preview\n\t\tpeek, err := reader.Peek(limit)                                                    // inspect first N bytes without consuming stream\n\t\tif err != nil && !errors.Is(err, io.EOF) && !errors.Is(err, bufio.ErrBufferFull) { // treat short reads as success\n\t\t\thttp.Error(w, \"failed to preview body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tcopyBuf := append([]byte(nil), peek...)                      // copy preview slice before reuse\n\t\tctx := context.WithValue(r.Context(), key, copyBuf)          // attach preview to context\n\t\tclone := r.Clone(ctx)                                        // clone request with enriched context\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // reuse buffered reader while keeping original closer\n\t\tnext.ServeHTTP(w, clone)                                     // continue with wrapped request\n\t})\n}\n\nfunc CaptureStatus(key ctxKey, next http.Handler) http.Handler {\n\tif next == nil { // default to no-op handler when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstatus := 0                                              // holder that will be shared via context\n\t\trec := &statusWriter{ResponseWriter: w, status: &status} // wrap writer to record status transitions\n\t\tctx := context.WithValue(r.Context(), key, rec.status)   // expose pointer so downstream can observe live status\n\t\tnext.ServeHTTP(rec, r.WithContext(ctx))                  // run downstream with wrapped writer\n\t\tif *rec.status == 0 {                                    // set default 200 when handler never wrote status/body\n\t\t\t*rec.status = http.StatusOK\n\t\t}\n\t})\n}\n\nfunc TeeBody(dst io.Writer, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default for nil downstream\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif dst == nil { // nothing to copy to, behave transparently\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttee := io.TeeReader(r.Body, dst)                          // duplicate stream into destination on the fly\n\t\tclone := r.Clone(r.Context())                             // preserve original request metadata\n\t\tclone.Body = &bodyReadCloser{Reader: tee, closer: r.Body} // ensure downstream sees tee reader and close propagates\n\t\tnext.ServeHTTP(w, clone)                                  // pass control to wrapped handler\n\t})\n}\n\nfunc PrependBody(prefix []byte, next http.Handler) http.Handler {\n\tif next == nil { // supply noop when downstream missing\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif len(prefix) == 0 { // no prefix to add, pass through\n\t\treturn next\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\treader := io.MultiReader(bytes.NewReader(prefix), r.Body)    // new reader yields prefix then original body\n\t\tclone := r.Clone(r.Context())                                // clone to avoid mutating original request\n\t\tclone.Body = &bodyReadCloser{Reader: reader, closer: r.Body} // wrap with closer that propagates to original body\n\t\tif clone.ContentLength >= 0 {                                // adjust content length when known\n\t\t\tclone.ContentLength += int64(len(prefix))\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // forward to next handler\n\t})\n}\n\nfunc DecompressGZIP(next http.Handler) http.Handler {\n\tif next == nil { // return safe handler when downstream is nil\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !strings.EqualFold(r.Header.Get(\"Content-Encoding\"), \"gzip\") { // nothing to decompress\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\treader, err := gzip.NewReader(r.Body) // attempt to create gzip reader\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer reader.Close()\n\n\t\tpayload, err := io.ReadAll(reader) // fully read decompressed payload\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // close original body to release resources\n\t\t\thttp.Error(w, \"invalid gzip body\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tclone := r.Clone(r.Context())                       // duplicate request to avoid side effects\n\t\tclone.Body = io.NopCloser(bytes.NewReader(payload)) // replace body with decompressed data\n\t\tclone.ContentLength = int64(len(payload))           // update content length to new payload size\n\t\tif clone.Header != nil {                            // adjust headers to reflect decompressed body\n\t\t\tclone.Header.Del(\"Content-Encoding\")\n\t\t}\n\t\tnext.ServeHTTP(w, clone) // continue with decompressed body\n\t})\n}\n\nfunc ConcurrencyLimit(limit int, next http.Handler) http.Handler {\n\tif next == nil { // provide safe default when middleware receives nil handler\n\t\tnext = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\tif limit <= 0 { // non-positive limit disables throttling\n\t\treturn next\n\t}\n\tsem := make(chan struct{}, limit) // semaphore to cap concurrent executions\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tsem <- struct{}{}        // acquire slot (blocks when limit reached)\n\t\tdefer func() { <-sem }() // release slot even if downstream panics\n\t\tnext.ServeHTTP(w, r)     // invoke wrapped handler\n\t})\n}\n\nfunc Timeout(d time.Duration, next http.Handler) http.Handler {\n\tif next == nil { // protect against nil downstream handler\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d <= 0 { // skip wrapping when timeout is disabled\n\t\t\tnext.ServeHTTP(w, r) // forward request without creating child context\n\t\t\treturn\n\t\t}\n\t\tctx, cancel := context.WithTimeout(r.Context(), d) // derive child context with deadline\n\t\tdefer cancel()                                     // ensure timer resources are released after request processing\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))              // propagate deadline-aware context downstream\n\t})\n}\n\nfunc MaxBytes(limit int64, next http.Handler) http.Handler {\n\tif next == nil { // avoid nil dereference when next is absent\n\t\treturn http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t}\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif limit <= 0 { // no enforcement when limit is non-positive\n\t\t\tnext.ServeHTTP(w, r) // simply forward request when limit disabled\n\t\t\treturn\n\t\t}\n\t\tbody, err := io.ReadAll(io.LimitReader(r.Body, limit+1)) // read at most limit+1 bytes to detect overflow\n\t\tif err != nil {                                          // handle read failures explicitly\n\t\t\thttp.Error(w, \"failed to read body\", http.StatusBadRequest) // map IO error to 400 response\n\t\t\treturn\n\t\t}\n\t\tif int64(len(body)) > limit { // detect payloads larger than allowed threshold\n\t\t\thttp.Error(w, \"request entity too large\", http.StatusRequestEntityTooLarge) // emit 413 for oversized payload\n\t\t\treturn\n\t\t}\n\t\tif err := r.Body.Close(); err != nil { // ensure original body is fully closed\n\t\t\thttp.Error(w, \"failed to close body\", http.StatusBadRequest) // surface closure issues to client\n\t\t\treturn\n\t\t}\n\t\tr.Body = io.NopCloser(bytes.NewReader(body)) // replace body with reusable reader for downstream handler\n\t\tnext.ServeHTTP(w, r)                         // forward request with bounded body\n\t})\n}\n\nfunc Chain(middlewares ...func(http.Handler) http.Handler) func(http.Handler) http.Handler {\n\treturn func(final http.Handler) http.Handler {\n\t\tif final == nil { // supply default handler when final is nil\n\t\t\tfinal = http.HandlerFunc(func(http.ResponseWriter, *http.Request) {})\n\t\t}\n\t\twrapped := final                             // start composition from the final handler\n\t\tfor i := len(middlewares) - 1; i >= 0; i-- { // apply middlewares in reverse order to maintain declaration order\n\t\t\tmw := middlewares[i] // fetch current middleware from slice\n\t\t\tif mw == nil {       // skip nil middleware while keeping chain intact\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twrapped = mw(wrapped) // wrap current handler with middleware\n\t\t}\n\t\treturn wrapped // return fully composed handler ready for use\n\t}\n}\n\ntype bodyReadCloser struct {\n\tio.Reader\n\tcloser io.Closer\n}\n\nfunc (b *bodyReadCloser) Close() error {\n\tif b.closer == nil {\n\t\treturn nil\n\t}\n\treturn b.closer.Close()\n}\n\ntype statusWriter struct {\n\thttp.ResponseWriter\n\tstatus *int\n}\n\nfunc (s *statusWriter) WriteHeader(code int) {\n\t*s.status = code\n\ts.ResponseWriter.WriteHeader(code)\n}\n\nfunc (s *statusWriter) Write(b []byte) (int, error) {\n\tif *s.status == 0 { // implicit 200 when Write called before WriteHeader\n\t\t*s.status = http.StatusOK\n\t}\n\treturn s.ResponseWriter.Write(b)\n}\n\nfunc (s *statusWriter) Flush() {\n\tif flusher, ok := s.ResponseWriter.(http.Flusher); ok {\n\t\tflusher.Flush()\n\t}\n}\n\nfunc (s *statusWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\tif hj, ok := s.ResponseWriter.(http.Hijacker); ok {\n\t\treturn hj.Hijack()\n\t}\n\treturn nil, nil, http.ErrNotSupported\n}\n\nfunc (s *statusWriter) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := s.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn http.ErrNotSupported\n}\n",
        "testCode": "package httpx\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tvar capturedID string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tval := r.Context().Value(RequestIDKey)\n\t\tid, _ := val.(string)\n\t\tcapturedID = id\n\t})\n\th := RequestID(next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif capturedID == \"\" {\n\t\tt.Fatal(\"expected context to contain request id\")\n\t}\n\tif hid := w.Header().Get(\"X-Request-ID\"); hid == \"\" || hid != capturedID {\n\t\tt.Fatalf(\"header mismatch: %q vs captured %q\", hid, capturedID)\n\t}\n}\n\nfunc TestSetHeader(t *testing.T) {\n\tt.Parallel()\n\th := SetHeader(\"X-Test\", \"value\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusAccepted)\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif got := w.Header().Get(\"X-Test\"); got != \"value\" {\n\t\tt.Fatalf(\"expected header value %q, got %q\", \"value\", got)\n\t}\n\tif w.Result().StatusCode != http.StatusAccepted {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n}\n\nfunc TestRequireMethod(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"allowed\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected next handler to be called for allowed method\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t\t}\n\t})\n\n\tt.Run(\"rejected\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireMethod(http.MethodPost, http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called for rejected method\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tres := w.Result()\n\t\tif res.StatusCode != http.StatusMethodNotAllowed {\n\t\t\tt.Fatalf(\"expected 405, got %d\", res.StatusCode)\n\t\t}\n\t\tif allow := res.Header.Get(\"Allow\"); allow != http.MethodPost {\n\t\t\tt.Fatalf(\"expected Allow header %q, got %q\", http.MethodPost, allow)\n\t\t}\n\t})\n}\n\nfunc TestRequireHeader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tr.Header.Set(\"X-Token\", \"abc\")\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when header present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireHeader(\"X-Token\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when header missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestLogger(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\torig := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(orig)\n\th := Logger(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusNoContent)\n\t}))\n\tr := httptest.NewRequest(http.MethodPost, \"/log\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Result().StatusCode != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Result().StatusCode)\n\t}\n\tif logLine := buf.String(); !strings.Contains(logLine, \"POST\") || !strings.Contains(logLine, \"/log\") {\n\t\tt.Fatalf(\"log output missing fields: %q\", logLine)\n\t}\n}\n\nfunc TestStripPrefix(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"matches\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar path string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tpath = r.URL.Path\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/api/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif path != \"/users\" {\n\t\t\tt.Fatalf(\"expected path /users, got %q\", path)\n\t\t}\n\t})\n\n\tt.Run(\"missing prefix\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t})\n\t\th := StripPrefix(\"/api\", next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/v1/users\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif called {\n\t\t\tt.Fatal(\"expected handler not to be called when prefix mismatch\")\n\t\t}\n\t\tif w.Result().StatusCode != http.StatusNotFound {\n\t\t\tt.Fatalf(\"expected 404, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestRequireQueryParam(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"present\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tcalled := false\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tcalled = true\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?id=42\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif !called {\n\t\t\tt.Fatal(\"expected handler to be called when param present\")\n\t\t}\n\t})\n\n\tt.Run(\"missing\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\th := RequireQueryParam(\"id\", http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called when param missing\")\n\t\t}))\n\t\tr := httptest.NewRequest(http.MethodGet, \"/?name=foo\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestHeaderToContext(t *testing.T) {\n\tt.Parallel()\n\tvar captured string\n\tkey := ctxKey(\"header\")\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).(string); val != \"\" {\n\t\t\tcaptured = val\n\t\t}\n\t})\n\th := HeaderToContext(key, \"X-Trace\", next)\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tr.Header.Set(\"X-Trace\", \"abc123\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif captured != \"abc123\" {\n\t\tt.Fatalf(\"expected value abc123, got %q\", captured)\n\t}\n}\n\nfunc TestRecover(t *testing.T) {\n\tt.Parallel()\n\th := Recover(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tpanic(\"boom\")\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/panic\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tres := w.Result()\n\tif res.StatusCode != http.StatusInternalServerError {\n\t\tt.Fatalf(\"expected 500, got %d\", res.StatusCode)\n\t}\n}\n\nfunc TestCaptureStatus(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"status\")\n\tt.Run(\"write header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t\tw.WriteHeader(http.StatusTeapot)\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusTeapot {\n\t\t\tt.Fatalf(\"expected status %d, got %d\", http.StatusTeapot, got)\n\t\t}\n\t})\n\n\tt.Run(\"default status\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar ptr *int\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstatusPtr, _ := r.Context().Value(key).(*int)\n\t\t\tptr = statusPtr\n\t\t})\n\t\th := CaptureStatus(key, next)\n\t\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, r)\n\t\tif ptr == nil {\n\t\t\tt.Fatal(\"expected status pointer in context\")\n\t\t}\n\t\tif got := *ptr; got != http.StatusOK {\n\t\t\tt.Fatalf(\"expected default status 200, got %d\", got)\n\t\t}\n\t})\n}\n\nfunc TestBodyPreview(t *testing.T) {\n\tt.Parallel()\n\tkey := ctxKey(\"preview\")\n\tvar stored []byte\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif val, _ := r.Context().Value(key).([]byte); val != nil {\n\t\t\tstored = append([]byte(nil), val...)\n\t\t}\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t})\n\th := BodyPreview(3, key, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"abcdef\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif string(stored) != \"abc\" {\n\t\tt.Fatalf(\"expected preview abc, got %q\", string(stored))\n\t}\n\tif body != \"abcdef\" {\n\t\tt.Fatalf(\"expected body abcdef, got %q\", body)\n\t}\n}\n\nfunc TestTeeBody(t *testing.T) {\n\tt.Parallel()\n\tdst := &bytes.Buffer{}\n\tvar consumed string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tconsumed = string(data)\n\t})\n\th := TeeBody(dst, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"payload\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif consumed != \"payload\" {\n\t\tt.Fatalf(\"expected body payload, got %q\", consumed)\n\t}\n\tif dst.String() != \"payload\" {\n\t\tt.Fatalf(\"expected tee payload, got %q\", dst.String())\n\t}\n}\n\nfunc TestPrependBody(t *testing.T) {\n\tt.Parallel()\n\tprefix := []byte(\"pre:\")\n\tvar body string\n\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tdata, err := io.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t}\n\t\tbody = string(data)\n\t\texpectedLength := int64(len(prefix) + len(\"body\"))\n\t\tif r.ContentLength != expectedLength {\n\t\t\tt.Fatalf(\"expected content length %d, got %d\", expectedLength, r.ContentLength)\n\t\t}\n\t})\n\th := PrependBody(prefix, next)\n\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"body\"))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif body != \"pre:body\" {\n\t\tt.Fatalf(\"expected body pre:body, got %q\", body)\n\t}\n}\n\nfunc TestDecompressGZIP(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"valid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tvar body string\n\t\tnext := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tdata, err := io.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"read body: %v\", err)\n\t\t\t}\n\t\t\tbody = string(data)\n\t\t\tif enc := r.Header.Get(\"Content-Encoding\"); enc != \"\" {\n\t\t\t\tt.Fatalf(\"expected content-encoding to be cleared, got %q\", enc)\n\t\t\t}\n\t\t})\n\t\tvar buf bytes.Buffer\n\t\tzw := gzip.NewWriter(&buf)\n\t\tif _, err := zw.Write([]byte(\"hello\")); err != nil {\n\t\t\tt.Fatalf(\"write gzip: %v\", err)\n\t\t}\n\t\tif err := zw.Close(); err != nil {\n\t\t\tt.Fatalf(\"close gzip: %v\", err)\n\t\t}\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", bytes.NewReader(buf.Bytes()))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif body != \"hello\" {\n\t\t\tt.Fatalf(\"expected body \\\"hello\\\", got %q\", body)\n\t\t}\n\t})\n\n\tt.Run(\"invalid gzip\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\t\tt.Fatal(\"handler must not be called on invalid gzip\")\n\t\t})\n\t\tr := httptest.NewRequest(http.MethodPost, \"/\", strings.NewReader(\"broken\"))\n\t\tr.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\tw := httptest.NewRecorder()\n\t\th := DecompressGZIP(next)\n\t\th.ServeHTTP(w, r)\n\t\tif w.Result().StatusCode != http.StatusBadRequest {\n\t\t\tt.Fatalf(\"expected 400, got %d\", w.Result().StatusCode)\n\t\t}\n\t})\n}\n\nfunc TestConcurrencyLimit(t *testing.T) {\n\tt.Parallel()\n\tstart := make(chan struct{}, 2)\n\trelease := make(chan struct{})\n\tnext := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\tstart <- struct{}{}\n\t\t<-release\n\t})\n\th := ConcurrencyLimit(1, next)\n\treq1 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\treq2 := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req1)\n\t}()\n\t<-start // ensure first request entered handler\n\n\tgo func() {\n\t\tdefer wg.Done()\n\t\th.ServeHTTP(httptest.NewRecorder(), req2)\n\t}()\n\n\tselect {\n\tcase <-start:\n\t\tt.Fatal(\"second request entered handler before slot released\")\n\tcase <-time.After(20 * time.Millisecond):\n\t\t// expected: still blocked\n\t}\n\n\trelease <- struct{}{} // release first handler\n\n\tselect {\n\tcase <-start: // second handler should now proceed\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"second request did not start after slot released\")\n\t}\n\n\trelease <- struct{}{}\n\twg.Wait()\n}\n\nfunc TestTimeout(t *testing.T) {\n\tt.Parallel()\n\tvar deadline time.Time\n\th := Timeout(5*time.Millisecond, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif d, ok := r.Context().Deadline(); ok {\n\t\t\tdeadline = d\n\t\t}\n\t\t<-r.Context().Done()\n\t}))\n\tr := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif time.Until(deadline) > 10*time.Millisecond {\n\t\tt.Fatalf(\"deadline too far: %v\", deadline)\n\t}\n}\n\nfunc TestMaxBytes(t *testing.T) {\n\tt.Parallel()\n\tnextCalled := false\n\th := MaxBytes(3, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnextCalled = true\n\t\tio.Copy(io.Discard, r.Body)\n\t}))\n\treq := httptest.NewRequest(http.MethodPost, \"/\", io.NopCloser(strings.NewReader(\"abcdef\")))\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Result().StatusCode != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"expected 413, got %d\", w.Result().StatusCode)\n\t}\n\tif nextCalled {\n\t\tt.Fatal(\"next handler should not be called on overflow\")\n\t}\n}\n\nfunc TestChain(t *testing.T) {\n\tt.Parallel()\n\tvar order []string\n\tm1 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m1 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m1 after\")\n\t\t})\n\t}\n\tm2 := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\torder = append(order, \"m2 before\")\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\torder = append(order, \"m2 after\")\n\t\t})\n\t}\n\tbase := http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t\torder = append(order, \"handler\")\n\t})\n\tchain := Chain(m1, m2)\n\th := chain(base)\n\tr := httptest.NewRequest(http.MethodGet, \"/chain\", nil)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\texpected := []string{\"m1 before\", \"m2 before\", \"handler\", \"m2 after\", \"m1 after\"}\n\tif len(order) != len(expected) {\n\t\tt.Fatalf(\"unexpected order length: %v\", order)\n\t}\n\tfor i, want := range expected {\n\t\tif order[i] != want {\n\t\t\tt.Fatalf(\"at %d expected %q got %q\", i, want, order[i])\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "httpx"
        ],
        "order": 17
      }
    ],
    "category": "http"
  },
  {
    "name": "interfaces",
    "tasks": [
      {
        "package": "interfaces",
        "slug": "go-interfaces-copyn",
        "title": "реализуйте CopyN(dst, src, n) с семантикой io.CopyN, но без его использования.",
        "description": "Level 1 (easy): реализуйте CopyN(dst, src, n) с семантикой io.CopyN, но без его использования.\nHint: валидация n < 0 должна возвращать ошибку.\nLevel 2 (easy+): читайте данные из src порциями, пока не скопируете ровно n байт.\nHint: используйте промежуточный буфер и следите за количеством записанных байт.\nLevel 3 (medium): корректно обрабатывайте io.EOF и io.ErrShortWrite.\nHint: краткая запись (Write < Read) считается ошибкой io.ErrShortWrite.",
        "difficulty": "easy",
        "hint1": "краткая запись (Write < Read) считается ошибкой io.ErrShortWrite.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage interfaces\n\nimport (\n\t\"fmt\"\n\t\"io\"\n)\n\n// Level 1 (easy): реализуйте CopyN(dst, src, n) с семантикой io.CopyN, но без его использования.\n// Hint: валидация n < 0 должна возвращать ошибку.\n// Level 2 (easy+): читайте данные из src порциями, пока не скопируете ровно n байт.\n// Hint: используйте промежуточный буфер и следите за количеством записанных байт.\n// Level 3 (medium): корректно обрабатывайте io.EOF и io.ErrShortWrite.\n// Hint: краткая запись (Write < Read) считается ошибкой io.ErrShortWrite.\nfunc CopyN(dst io.Writer, src io.Reader, n int64) (written int64, err error) {\n\tif n < 0 {\n\t\treturn 0, fmt.Errorf(\"invalid length param\")\n\t}\n\tif n == 0 {\n\t\treturn 0, nil\n\t}\n\n\tbuf := make([]byte, 32*1024)\n\tfor written < n {\n\t\ttoRead := n - written\n\t\tif toRead > int64(len(buf)) {\n\t\t\ttoRead = int64(len(buf))\n\t\t}\n\t\tnr, er := src.Read(buf[:toRead])\n\t\tif nr > 0 {\n\t\t\tnw, ew := dst.Write(buf[:nr])\n\t\t\tif nw > 0 {\n\t\t\t\twritten += int64(nw)\n\t\t\t}\n\t\t\tif ew != nil {\n\t\t\t\treturn written, ew\n\t\t\t}\n\t\t\tif nr != nw {\n\t\t\t\treturn written, io.ErrShortWrite\n\t\t\t}\n\t\t}\n\t\tif er != nil {\n\t\t\tif er == io.EOF && written == n {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif err == io.EOF {\n\t\t\t\treturn written, io.EOF\n\t\t\t}\n\t\t\treturn written, er\n\t\t}\n\t}\n\n\treturn written, nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage interfaces\n\nimport (\n\t\"fmt\"\n\t\"io\"\n)\n\nfunc CopyN(dst io.Writer, src io.Reader, n int64) (written int64, err error) {\n\tif n < 0 {\n\t\treturn 0, fmt.Errorf(\"invalid length param\")\n\t}\n\tif n == 0 {\n\t\treturn 0, nil\n\t}\n\tbuf := make([]byte, 32*1024)\n\tfor written < n {\n\t\ttoRead := n - written\n\t\tif toRead > int64(len(buf)) {\n\t\t\ttoRead = int64(len(buf))\n\t\t}\n\t\tnr, er := src.Read(buf[:toRead])\n\t\tif nr > 0 {\n\t\t\tnw, ew := dst.Write(buf[:nr])\n\t\t\tif nw > 0 {\n\t\t\t\twritten += int64(nw)\n\t\t\t}\n\t\t\tif ew != nil {\n\t\t\t\treturn written, ew\n\t\t\t}\n\t\t\tif nw != nr {\n\t\t\t\treturn written, io.ErrShortWrite\n\t\t\t}\n\t\t}\n\t\tif er != nil {\n\t\t\tif er == io.EOF && written == n {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif er == io.EOF {\n\t\t\t\treturn written, io.EOF\n\t\t\t}\n\t\t\treturn written, er\n\t\t}\n\t}\n\treturn written, nil\n}\n",
        "testCode": "package interfaces\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"io\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestCopyN_OK(t *testing.T) {\n\tsrc := strings.NewReader(\"hello world\")\n\tvar dst bytes.Buffer\n\tn, err := CopyN(&dst, src, 5)\n\tif err != nil { t.Fatal(err) }\n\tif n!=5 || dst.String()!=\"hello\" { t.Fatalf(\"got n=%d dst=%q\", n, dst.String()) }\n}\n\ntype errWriter struct{}\nfunc (errWriter) Write(p []byte) (int, error) { return 0, errors.New(\"boom\") }\n\nfunc TestCopyN_DstErr(t *testing.T) {\n\tsrc := strings.NewReader(\"abcdef\")\n\tvar dst errWriter\n\t_, err := CopyN(dst, src, 3)\n\tif err==nil { t.Fatal(\"expected error\") }\n}\n\nfunc TestCopyN_ShortSrc(t *testing.T) {\n\tsrc := strings.NewReader(\"abc\")\n\tvar dst bytes.Buffer\n\t_, err := CopyN(&dst, src, 5)\n\tif !errors.Is(err, io.EOF) { t.Fatalf(\"want EOF, got %v\", err) }\n}\n",
        "tags": [
          "go",
          "interfaces"
        ],
        "order": 0
      }
    ],
    "category": "core"
  },
  {
    "name": "loggingx",
    "tasks": [
      {
        "package": "loggingx",
        "slug": "go-loggingx-withrequestid",
        "title": "WithRequestID возвращает новый контекст с сохранённым request id.",
        "description": "Level 1 (easy): WithRequestID возвращает новый контекст с сохранённым request id.\nHint: используйте context.WithValue с ключом KeyRequestID.",
        "difficulty": "easy",
        "hint1": "используйте context.WithValue с ключом KeyRequestID.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\n// Level 1 (easy): WithRequestID возвращает новый контекст с сохранённым request id.\n// Hint: используйте context.WithValue с ключом KeyRequestID.\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif rid == \"\" {\n\t\treturn ctx\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid)\n}\n\n// Level 2 (easy+): Logf печатает сообщение и, если rid присутствует в контексте, добавляет префикс.\n// Hint: получите значение через ctx.Value.\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx)\n\tif rid != \"\" {\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...)\n\t\treturn\n\t}\n\tlog.Printf(format, args...)\n}\n\n// Level 3 (medium): RequestID возвращает сохранённый идентификатор или пустую строку.\n// Hint: приведите значение к string и обработайте nil-контекст.\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil {\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string)\n\treturn val\n}\n\n// Level 4 (medium): WithFields добавляет карту лог-полей в контекст.\n// Hint: храните поля под отдельным ключом, объединяя с существующими.\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v\n\t\t}\n\t}\n\tfor k, v := range fields {\n\t\tmerged[k] = v\n\t}\n\n\treturn context.WithValue(ctx, keyFields, merged)\n}\n\n// Level 5 (medium+): LogKV печатает сообщение и поля в формате key=value с использованием log.Printf.\n// Hint: объединяйте поля из контекста с переданными и сортируйте ключи для стабильности.\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v\n\t\t}\n\t}\n\n\tfor k, v := range extra {\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" {\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined))\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\tbuilder := strings.Builder{}\n\tbuilder.WriteString(msg)\n\tfor _, k := range keys {\n\t\tbuilder.WriteString(\" \")\n\t\tbuilder.WriteString(k)\n\t\tbuilder.WriteString(\"=\")\n\t\tbuilder.WriteString(combined[k])\n\t}\n\tlog.Print(builder.String())\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil { // fall back to background context when nil supplied\n\t\tctx = context.Background()\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid) // store request id inside context for downstream readers\n}\n\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx) // fetch request identifier if present\n\tif rid != \"\" {        // include request id prefix when available\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...) // prefix message with rid before formatting\n\t\treturn\n\t}\n\tlog.Printf(format, args...) // log without prefix when request id absent\n}\n\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil { // nil context never carries values\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string) // attempt to extract stored request id\n\treturn val                                 // return identifier or empty string when missing\n}\n\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)                                 // allocate new map to avoid mutating caller state\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok { // copy any fields already present\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v // duplicate key-value pairs from original map\n\t\t}\n\t}\n\tfor k, v := range fields { // apply overrides from provided map\n\t\tmerged[k] = v // store latest value for each key\n\t}\n\treturn context.WithValue(ctx, keyFields, merged) // return new context holding merged fields\n}\n\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)                             // hold merged field set for logging\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok { // incorporate context fields when available\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v // copy stored field values\n\t\t}\n\t}\n\tfor k, v := range extra { // merge explicit extra fields overriding context\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" { // expose request id as ordinary key-value pair\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined)) // collect keys to sort for deterministic output\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)           // ensure deterministic ordering for log line\n\tbuilder := strings.Builder{} // accumulate final log message\n\tbuilder.WriteString(msg)     // start with descriptive message portion\n\tfor _, k := range keys {     // append each key-value pair in sorted order\n\t\tbuilder.WriteString(\" \")         // separate message and kv entries with space\n\t\tbuilder.WriteString(k)           // write key name\n\t\tbuilder.WriteString(\"=\")         // add equals delimiter\n\t\tbuilder.WriteString(combined[k]) // write corresponding value\n\t}\n\tlog.Print(builder.String()) // emit assembled log entry via standard logger\n}\n",
        "testCode": "package loggingx\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"log\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestWithRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"abc\")\n\tif got := ctx.Value(KeyRequestID); got != \"abc\" {\n\t\tt.Fatalf(\"expected value stored in context, got %v\", got)\n\t}\n}\n\nfunc TestLogf(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(log.Writer())\n\tctx := WithRequestID(context.Background(), \"rid-1\")\n\tLogf(ctx, \"hello %d\", 7)\n\tline := buf.String()\n\tif !strings.Contains(line, \"rid-1\") || !strings.Contains(line, \"hello 7\") {\n\t\tt.Fatalf(\"unexpected log output: %q\", line)\n\t}\n}\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"id42\")\n\tif got := RequestID(ctx); got != \"id42\" {\n\t\tt.Fatalf(\"expected id42, got %q\", got)\n\t}\n\tif got := RequestID(context.Background()); got != \"\" {\n\t\tt.Fatalf(\"expected empty string for missing id, got %q\", got)\n\t}\n}\n\nfunc TestWithFields(t *testing.T) {\n\tt.Parallel()\n\tctx := WithFields(context.Background(), map[string]string{\"a\": \"1\"})\n\tctx = WithFields(ctx, map[string]string{\"b\": \"2\"})\n\tfields, _ := ctx.Value(CtxKey(\"fields\")).(map[string]string)\n\tif len(fields) != 2 || fields[\"a\"] != \"1\" || fields[\"b\"] != \"2\" {\n\t\tt.Fatalf(\"unexpected fields state: %+v\", fields)\n\t}\n}\n\nfunc TestLogKV(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlogger := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(logger)\n\tctx := WithFields(WithRequestID(context.Background(), \"r1\"), map[string]string{\"env\": \"test\"})\n\tLogKV(ctx, \"processing\", map[string]string{\"status\": \"ok\"})\n\tline := buf.String()\n\tfor _, expected := range []string{\"processing\", \"rid=r1\", \"env=test\", \"status=ok\"} {\n\t\tif !strings.Contains(line, expected) {\n\t\t\tt.Fatalf(\"expected %q in log line %q\", expected, line)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "loggingx"
        ],
        "order": 0
      },
      {
        "package": "loggingx",
        "slug": "go-loggingx-logf",
        "title": "Logf печатает сообщение и, если rid присутствует в контексте, добавляет префикс.",
        "description": "Level 2 (easy+): Logf печатает сообщение и, если rid присутствует в контексте, добавляет префикс.\nHint: получите значение через ctx.Value.",
        "difficulty": "easy",
        "hint1": "получите значение через ctx.Value.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\n// Level 1 (easy): WithRequestID возвращает новый контекст с сохранённым request id.\n// Hint: используйте context.WithValue с ключом KeyRequestID.\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif rid == \"\" {\n\t\treturn ctx\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid)\n}\n\n// Level 2 (easy+): Logf печатает сообщение и, если rid присутствует в контексте, добавляет префикс.\n// Hint: получите значение через ctx.Value.\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx)\n\tif rid != \"\" {\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...)\n\t\treturn\n\t}\n\tlog.Printf(format, args...)\n}\n\n// Level 3 (medium): RequestID возвращает сохранённый идентификатор или пустую строку.\n// Hint: приведите значение к string и обработайте nil-контекст.\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil {\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string)\n\treturn val\n}\n\n// Level 4 (medium): WithFields добавляет карту лог-полей в контекст.\n// Hint: храните поля под отдельным ключом, объединяя с существующими.\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v\n\t\t}\n\t}\n\tfor k, v := range fields {\n\t\tmerged[k] = v\n\t}\n\n\treturn context.WithValue(ctx, keyFields, merged)\n}\n\n// Level 5 (medium+): LogKV печатает сообщение и поля в формате key=value с использованием log.Printf.\n// Hint: объединяйте поля из контекста с переданными и сортируйте ключи для стабильности.\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v\n\t\t}\n\t}\n\n\tfor k, v := range extra {\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" {\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined))\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\tbuilder := strings.Builder{}\n\tbuilder.WriteString(msg)\n\tfor _, k := range keys {\n\t\tbuilder.WriteString(\" \")\n\t\tbuilder.WriteString(k)\n\t\tbuilder.WriteString(\"=\")\n\t\tbuilder.WriteString(combined[k])\n\t}\n\tlog.Print(builder.String())\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil { // fall back to background context when nil supplied\n\t\tctx = context.Background()\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid) // store request id inside context for downstream readers\n}\n\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx) // fetch request identifier if present\n\tif rid != \"\" {        // include request id prefix when available\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...) // prefix message with rid before formatting\n\t\treturn\n\t}\n\tlog.Printf(format, args...) // log without prefix when request id absent\n}\n\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil { // nil context never carries values\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string) // attempt to extract stored request id\n\treturn val                                 // return identifier or empty string when missing\n}\n\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)                                 // allocate new map to avoid mutating caller state\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok { // copy any fields already present\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v // duplicate key-value pairs from original map\n\t\t}\n\t}\n\tfor k, v := range fields { // apply overrides from provided map\n\t\tmerged[k] = v // store latest value for each key\n\t}\n\treturn context.WithValue(ctx, keyFields, merged) // return new context holding merged fields\n}\n\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)                             // hold merged field set for logging\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok { // incorporate context fields when available\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v // copy stored field values\n\t\t}\n\t}\n\tfor k, v := range extra { // merge explicit extra fields overriding context\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" { // expose request id as ordinary key-value pair\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined)) // collect keys to sort for deterministic output\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)           // ensure deterministic ordering for log line\n\tbuilder := strings.Builder{} // accumulate final log message\n\tbuilder.WriteString(msg)     // start with descriptive message portion\n\tfor _, k := range keys {     // append each key-value pair in sorted order\n\t\tbuilder.WriteString(\" \")         // separate message and kv entries with space\n\t\tbuilder.WriteString(k)           // write key name\n\t\tbuilder.WriteString(\"=\")         // add equals delimiter\n\t\tbuilder.WriteString(combined[k]) // write corresponding value\n\t}\n\tlog.Print(builder.String()) // emit assembled log entry via standard logger\n}\n",
        "testCode": "package loggingx\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"log\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestWithRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"abc\")\n\tif got := ctx.Value(KeyRequestID); got != \"abc\" {\n\t\tt.Fatalf(\"expected value stored in context, got %v\", got)\n\t}\n}\n\nfunc TestLogf(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(log.Writer())\n\tctx := WithRequestID(context.Background(), \"rid-1\")\n\tLogf(ctx, \"hello %d\", 7)\n\tline := buf.String()\n\tif !strings.Contains(line, \"rid-1\") || !strings.Contains(line, \"hello 7\") {\n\t\tt.Fatalf(\"unexpected log output: %q\", line)\n\t}\n}\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"id42\")\n\tif got := RequestID(ctx); got != \"id42\" {\n\t\tt.Fatalf(\"expected id42, got %q\", got)\n\t}\n\tif got := RequestID(context.Background()); got != \"\" {\n\t\tt.Fatalf(\"expected empty string for missing id, got %q\", got)\n\t}\n}\n\nfunc TestWithFields(t *testing.T) {\n\tt.Parallel()\n\tctx := WithFields(context.Background(), map[string]string{\"a\": \"1\"})\n\tctx = WithFields(ctx, map[string]string{\"b\": \"2\"})\n\tfields, _ := ctx.Value(CtxKey(\"fields\")).(map[string]string)\n\tif len(fields) != 2 || fields[\"a\"] != \"1\" || fields[\"b\"] != \"2\" {\n\t\tt.Fatalf(\"unexpected fields state: %+v\", fields)\n\t}\n}\n\nfunc TestLogKV(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlogger := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(logger)\n\tctx := WithFields(WithRequestID(context.Background(), \"r1\"), map[string]string{\"env\": \"test\"})\n\tLogKV(ctx, \"processing\", map[string]string{\"status\": \"ok\"})\n\tline := buf.String()\n\tfor _, expected := range []string{\"processing\", \"rid=r1\", \"env=test\", \"status=ok\"} {\n\t\tif !strings.Contains(line, expected) {\n\t\t\tt.Fatalf(\"expected %q in log line %q\", expected, line)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "loggingx"
        ],
        "order": 1
      },
      {
        "package": "loggingx",
        "slug": "go-loggingx-requestid",
        "title": "RequestID возвращает сохранённый идентификатор или пустую строку.",
        "description": "Level 3 (medium): RequestID возвращает сохранённый идентификатор или пустую строку.\nHint: приведите значение к string и обработайте nil-контекст.",
        "difficulty": "medium",
        "hint1": "приведите значение к string и обработайте nil-контекст.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\n// Level 1 (easy): WithRequestID возвращает новый контекст с сохранённым request id.\n// Hint: используйте context.WithValue с ключом KeyRequestID.\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif rid == \"\" {\n\t\treturn ctx\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid)\n}\n\n// Level 2 (easy+): Logf печатает сообщение и, если rid присутствует в контексте, добавляет префикс.\n// Hint: получите значение через ctx.Value.\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx)\n\tif rid != \"\" {\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...)\n\t\treturn\n\t}\n\tlog.Printf(format, args...)\n}\n\n// Level 3 (medium): RequestID возвращает сохранённый идентификатор или пустую строку.\n// Hint: приведите значение к string и обработайте nil-контекст.\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil {\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string)\n\treturn val\n}\n\n// Level 4 (medium): WithFields добавляет карту лог-полей в контекст.\n// Hint: храните поля под отдельным ключом, объединяя с существующими.\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v\n\t\t}\n\t}\n\tfor k, v := range fields {\n\t\tmerged[k] = v\n\t}\n\n\treturn context.WithValue(ctx, keyFields, merged)\n}\n\n// Level 5 (medium+): LogKV печатает сообщение и поля в формате key=value с использованием log.Printf.\n// Hint: объединяйте поля из контекста с переданными и сортируйте ключи для стабильности.\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v\n\t\t}\n\t}\n\n\tfor k, v := range extra {\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" {\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined))\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\tbuilder := strings.Builder{}\n\tbuilder.WriteString(msg)\n\tfor _, k := range keys {\n\t\tbuilder.WriteString(\" \")\n\t\tbuilder.WriteString(k)\n\t\tbuilder.WriteString(\"=\")\n\t\tbuilder.WriteString(combined[k])\n\t}\n\tlog.Print(builder.String())\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil { // fall back to background context when nil supplied\n\t\tctx = context.Background()\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid) // store request id inside context for downstream readers\n}\n\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx) // fetch request identifier if present\n\tif rid != \"\" {        // include request id prefix when available\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...) // prefix message with rid before formatting\n\t\treturn\n\t}\n\tlog.Printf(format, args...) // log without prefix when request id absent\n}\n\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil { // nil context never carries values\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string) // attempt to extract stored request id\n\treturn val                                 // return identifier or empty string when missing\n}\n\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)                                 // allocate new map to avoid mutating caller state\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok { // copy any fields already present\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v // duplicate key-value pairs from original map\n\t\t}\n\t}\n\tfor k, v := range fields { // apply overrides from provided map\n\t\tmerged[k] = v // store latest value for each key\n\t}\n\treturn context.WithValue(ctx, keyFields, merged) // return new context holding merged fields\n}\n\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)                             // hold merged field set for logging\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok { // incorporate context fields when available\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v // copy stored field values\n\t\t}\n\t}\n\tfor k, v := range extra { // merge explicit extra fields overriding context\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" { // expose request id as ordinary key-value pair\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined)) // collect keys to sort for deterministic output\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)           // ensure deterministic ordering for log line\n\tbuilder := strings.Builder{} // accumulate final log message\n\tbuilder.WriteString(msg)     // start with descriptive message portion\n\tfor _, k := range keys {     // append each key-value pair in sorted order\n\t\tbuilder.WriteString(\" \")         // separate message and kv entries with space\n\t\tbuilder.WriteString(k)           // write key name\n\t\tbuilder.WriteString(\"=\")         // add equals delimiter\n\t\tbuilder.WriteString(combined[k]) // write corresponding value\n\t}\n\tlog.Print(builder.String()) // emit assembled log entry via standard logger\n}\n",
        "testCode": "package loggingx\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"log\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestWithRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"abc\")\n\tif got := ctx.Value(KeyRequestID); got != \"abc\" {\n\t\tt.Fatalf(\"expected value stored in context, got %v\", got)\n\t}\n}\n\nfunc TestLogf(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(log.Writer())\n\tctx := WithRequestID(context.Background(), \"rid-1\")\n\tLogf(ctx, \"hello %d\", 7)\n\tline := buf.String()\n\tif !strings.Contains(line, \"rid-1\") || !strings.Contains(line, \"hello 7\") {\n\t\tt.Fatalf(\"unexpected log output: %q\", line)\n\t}\n}\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"id42\")\n\tif got := RequestID(ctx); got != \"id42\" {\n\t\tt.Fatalf(\"expected id42, got %q\", got)\n\t}\n\tif got := RequestID(context.Background()); got != \"\" {\n\t\tt.Fatalf(\"expected empty string for missing id, got %q\", got)\n\t}\n}\n\nfunc TestWithFields(t *testing.T) {\n\tt.Parallel()\n\tctx := WithFields(context.Background(), map[string]string{\"a\": \"1\"})\n\tctx = WithFields(ctx, map[string]string{\"b\": \"2\"})\n\tfields, _ := ctx.Value(CtxKey(\"fields\")).(map[string]string)\n\tif len(fields) != 2 || fields[\"a\"] != \"1\" || fields[\"b\"] != \"2\" {\n\t\tt.Fatalf(\"unexpected fields state: %+v\", fields)\n\t}\n}\n\nfunc TestLogKV(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlogger := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(logger)\n\tctx := WithFields(WithRequestID(context.Background(), \"r1\"), map[string]string{\"env\": \"test\"})\n\tLogKV(ctx, \"processing\", map[string]string{\"status\": \"ok\"})\n\tline := buf.String()\n\tfor _, expected := range []string{\"processing\", \"rid=r1\", \"env=test\", \"status=ok\"} {\n\t\tif !strings.Contains(line, expected) {\n\t\t\tt.Fatalf(\"expected %q in log line %q\", expected, line)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "loggingx"
        ],
        "order": 2
      },
      {
        "package": "loggingx",
        "slug": "go-loggingx-withfields",
        "title": "WithFields добавляет карту лог-полей в контекст.",
        "description": "Level 4 (medium): WithFields добавляет карту лог-полей в контекст.\nHint: храните поля под отдельным ключом, объединяя с существующими.",
        "difficulty": "medium",
        "hint1": "храните поля под отдельным ключом, объединяя с существующими.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\n// Level 1 (easy): WithRequestID возвращает новый контекст с сохранённым request id.\n// Hint: используйте context.WithValue с ключом KeyRequestID.\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif rid == \"\" {\n\t\treturn ctx\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid)\n}\n\n// Level 2 (easy+): Logf печатает сообщение и, если rid присутствует в контексте, добавляет префикс.\n// Hint: получите значение через ctx.Value.\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx)\n\tif rid != \"\" {\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...)\n\t\treturn\n\t}\n\tlog.Printf(format, args...)\n}\n\n// Level 3 (medium): RequestID возвращает сохранённый идентификатор или пустую строку.\n// Hint: приведите значение к string и обработайте nil-контекст.\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil {\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string)\n\treturn val\n}\n\n// Level 4 (medium): WithFields добавляет карту лог-полей в контекст.\n// Hint: храните поля под отдельным ключом, объединяя с существующими.\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v\n\t\t}\n\t}\n\tfor k, v := range fields {\n\t\tmerged[k] = v\n\t}\n\n\treturn context.WithValue(ctx, keyFields, merged)\n}\n\n// Level 5 (medium+): LogKV печатает сообщение и поля в формате key=value с использованием log.Printf.\n// Hint: объединяйте поля из контекста с переданными и сортируйте ключи для стабильности.\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v\n\t\t}\n\t}\n\n\tfor k, v := range extra {\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" {\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined))\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\tbuilder := strings.Builder{}\n\tbuilder.WriteString(msg)\n\tfor _, k := range keys {\n\t\tbuilder.WriteString(\" \")\n\t\tbuilder.WriteString(k)\n\t\tbuilder.WriteString(\"=\")\n\t\tbuilder.WriteString(combined[k])\n\t}\n\tlog.Print(builder.String())\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil { // fall back to background context when nil supplied\n\t\tctx = context.Background()\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid) // store request id inside context for downstream readers\n}\n\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx) // fetch request identifier if present\n\tif rid != \"\" {        // include request id prefix when available\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...) // prefix message with rid before formatting\n\t\treturn\n\t}\n\tlog.Printf(format, args...) // log without prefix when request id absent\n}\n\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil { // nil context never carries values\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string) // attempt to extract stored request id\n\treturn val                                 // return identifier or empty string when missing\n}\n\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)                                 // allocate new map to avoid mutating caller state\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok { // copy any fields already present\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v // duplicate key-value pairs from original map\n\t\t}\n\t}\n\tfor k, v := range fields { // apply overrides from provided map\n\t\tmerged[k] = v // store latest value for each key\n\t}\n\treturn context.WithValue(ctx, keyFields, merged) // return new context holding merged fields\n}\n\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)                             // hold merged field set for logging\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok { // incorporate context fields when available\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v // copy stored field values\n\t\t}\n\t}\n\tfor k, v := range extra { // merge explicit extra fields overriding context\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" { // expose request id as ordinary key-value pair\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined)) // collect keys to sort for deterministic output\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)           // ensure deterministic ordering for log line\n\tbuilder := strings.Builder{} // accumulate final log message\n\tbuilder.WriteString(msg)     // start with descriptive message portion\n\tfor _, k := range keys {     // append each key-value pair in sorted order\n\t\tbuilder.WriteString(\" \")         // separate message and kv entries with space\n\t\tbuilder.WriteString(k)           // write key name\n\t\tbuilder.WriteString(\"=\")         // add equals delimiter\n\t\tbuilder.WriteString(combined[k]) // write corresponding value\n\t}\n\tlog.Print(builder.String()) // emit assembled log entry via standard logger\n}\n",
        "testCode": "package loggingx\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"log\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestWithRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"abc\")\n\tif got := ctx.Value(KeyRequestID); got != \"abc\" {\n\t\tt.Fatalf(\"expected value stored in context, got %v\", got)\n\t}\n}\n\nfunc TestLogf(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(log.Writer())\n\tctx := WithRequestID(context.Background(), \"rid-1\")\n\tLogf(ctx, \"hello %d\", 7)\n\tline := buf.String()\n\tif !strings.Contains(line, \"rid-1\") || !strings.Contains(line, \"hello 7\") {\n\t\tt.Fatalf(\"unexpected log output: %q\", line)\n\t}\n}\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"id42\")\n\tif got := RequestID(ctx); got != \"id42\" {\n\t\tt.Fatalf(\"expected id42, got %q\", got)\n\t}\n\tif got := RequestID(context.Background()); got != \"\" {\n\t\tt.Fatalf(\"expected empty string for missing id, got %q\", got)\n\t}\n}\n\nfunc TestWithFields(t *testing.T) {\n\tt.Parallel()\n\tctx := WithFields(context.Background(), map[string]string{\"a\": \"1\"})\n\tctx = WithFields(ctx, map[string]string{\"b\": \"2\"})\n\tfields, _ := ctx.Value(CtxKey(\"fields\")).(map[string]string)\n\tif len(fields) != 2 || fields[\"a\"] != \"1\" || fields[\"b\"] != \"2\" {\n\t\tt.Fatalf(\"unexpected fields state: %+v\", fields)\n\t}\n}\n\nfunc TestLogKV(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlogger := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(logger)\n\tctx := WithFields(WithRequestID(context.Background(), \"r1\"), map[string]string{\"env\": \"test\"})\n\tLogKV(ctx, \"processing\", map[string]string{\"status\": \"ok\"})\n\tline := buf.String()\n\tfor _, expected := range []string{\"processing\", \"rid=r1\", \"env=test\", \"status=ok\"} {\n\t\tif !strings.Contains(line, expected) {\n\t\t\tt.Fatalf(\"expected %q in log line %q\", expected, line)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "loggingx"
        ],
        "order": 3
      },
      {
        "package": "loggingx",
        "slug": "go-loggingx-logkv",
        "title": "LogKV печатает сообщение и поля в формате key=value с использованием log.Printf.",
        "description": "Level 5 (medium+): LogKV печатает сообщение и поля в формате key=value с использованием log.Printf.\nHint: объединяйте поля из контекста с переданными и сортируйте ключи для стабильности.",
        "difficulty": "medium",
        "hint1": "объединяйте поля из контекста с переданными и сортируйте ключи для стабильности.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\n// Level 1 (easy): WithRequestID возвращает новый контекст с сохранённым request id.\n// Hint: используйте context.WithValue с ключом KeyRequestID.\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif rid == \"\" {\n\t\treturn ctx\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid)\n}\n\n// Level 2 (easy+): Logf печатает сообщение и, если rid присутствует в контексте, добавляет префикс.\n// Hint: получите значение через ctx.Value.\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx)\n\tif rid != \"\" {\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...)\n\t\treturn\n\t}\n\tlog.Printf(format, args...)\n}\n\n// Level 3 (medium): RequestID возвращает сохранённый идентификатор или пустую строку.\n// Hint: приведите значение к string и обработайте nil-контекст.\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil {\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string)\n\treturn val\n}\n\n// Level 4 (medium): WithFields добавляет карту лог-полей в контекст.\n// Hint: храните поля под отдельным ключом, объединяя с существующими.\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v\n\t\t}\n\t}\n\tfor k, v := range fields {\n\t\tmerged[k] = v\n\t}\n\n\treturn context.WithValue(ctx, keyFields, merged)\n}\n\n// Level 5 (medium+): LogKV печатает сообщение и поля в формате key=value с использованием log.Printf.\n// Hint: объединяйте поля из контекста с переданными и сортируйте ключи для стабильности.\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok {\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v\n\t\t}\n\t}\n\n\tfor k, v := range extra {\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" {\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined))\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\tbuilder := strings.Builder{}\n\tbuilder.WriteString(msg)\n\tfor _, k := range keys {\n\t\tbuilder.WriteString(\" \")\n\t\tbuilder.WriteString(k)\n\t\tbuilder.WriteString(\"=\")\n\t\tbuilder.WriteString(combined[k])\n\t}\n\tlog.Print(builder.String())\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage loggingx\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype CtxKey string\n\nconst KeyRequestID CtxKey = \"rid\"\nconst keyFields CtxKey = \"fields\"\n\nfunc WithRequestID(ctx context.Context, rid string) context.Context {\n\tif ctx == nil { // fall back to background context when nil supplied\n\t\tctx = context.Background()\n\t}\n\treturn context.WithValue(ctx, KeyRequestID, rid) // store request id inside context for downstream readers\n}\n\nfunc Logf(ctx context.Context, format string, args ...any) {\n\trid := RequestID(ctx) // fetch request identifier if present\n\tif rid != \"\" {        // include request id prefix when available\n\t\tlog.Printf(\"[rid=%s] \"+format, append([]any{rid}, args...)...) // prefix message with rid before formatting\n\t\treturn\n\t}\n\tlog.Printf(format, args...) // log without prefix when request id absent\n}\n\nfunc RequestID(ctx context.Context) string {\n\tif ctx == nil { // nil context never carries values\n\t\treturn \"\"\n\t}\n\tval, _ := ctx.Value(KeyRequestID).(string) // attempt to extract stored request id\n\treturn val                                 // return identifier or empty string when missing\n}\n\nfunc WithFields(ctx context.Context, fields map[string]string) context.Context {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tmerged := make(map[string]string)                                 // allocate new map to avoid mutating caller state\n\tif existing, ok := ctx.Value(keyFields).(map[string]string); ok { // copy any fields already present\n\t\tfor k, v := range existing {\n\t\t\tmerged[k] = v // duplicate key-value pairs from original map\n\t\t}\n\t}\n\tfor k, v := range fields { // apply overrides from provided map\n\t\tmerged[k] = v // store latest value for each key\n\t}\n\treturn context.WithValue(ctx, keyFields, merged) // return new context holding merged fields\n}\n\nfunc LogKV(ctx context.Context, msg string, extra map[string]string) {\n\tcombined := make(map[string]string)                             // hold merged field set for logging\n\tif fields, ok := ctx.Value(keyFields).(map[string]string); ok { // incorporate context fields when available\n\t\tfor k, v := range fields {\n\t\t\tcombined[k] = v // copy stored field values\n\t\t}\n\t}\n\tfor k, v := range extra { // merge explicit extra fields overriding context\n\t\tcombined[k] = v\n\t}\n\tif rid := RequestID(ctx); rid != \"\" { // expose request id as ordinary key-value pair\n\t\tcombined[\"rid\"] = rid\n\t}\n\tkeys := make([]string, 0, len(combined)) // collect keys to sort for deterministic output\n\tfor k := range combined {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)           // ensure deterministic ordering for log line\n\tbuilder := strings.Builder{} // accumulate final log message\n\tbuilder.WriteString(msg)     // start with descriptive message portion\n\tfor _, k := range keys {     // append each key-value pair in sorted order\n\t\tbuilder.WriteString(\" \")         // separate message and kv entries with space\n\t\tbuilder.WriteString(k)           // write key name\n\t\tbuilder.WriteString(\"=\")         // add equals delimiter\n\t\tbuilder.WriteString(combined[k]) // write corresponding value\n\t}\n\tlog.Print(builder.String()) // emit assembled log entry via standard logger\n}\n",
        "testCode": "package loggingx\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"log\"\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc TestWithRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"abc\")\n\tif got := ctx.Value(KeyRequestID); got != \"abc\" {\n\t\tt.Fatalf(\"expected value stored in context, got %v\", got)\n\t}\n}\n\nfunc TestLogf(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(log.Writer())\n\tctx := WithRequestID(context.Background(), \"rid-1\")\n\tLogf(ctx, \"hello %d\", 7)\n\tline := buf.String()\n\tif !strings.Contains(line, \"rid-1\") || !strings.Contains(line, \"hello 7\") {\n\t\tt.Fatalf(\"unexpected log output: %q\", line)\n\t}\n}\n\nfunc TestRequestID(t *testing.T) {\n\tt.Parallel()\n\tctx := WithRequestID(context.Background(), \"id42\")\n\tif got := RequestID(ctx); got != \"id42\" {\n\t\tt.Fatalf(\"expected id42, got %q\", got)\n\t}\n\tif got := RequestID(context.Background()); got != \"\" {\n\t\tt.Fatalf(\"expected empty string for missing id, got %q\", got)\n\t}\n}\n\nfunc TestWithFields(t *testing.T) {\n\tt.Parallel()\n\tctx := WithFields(context.Background(), map[string]string{\"a\": \"1\"})\n\tctx = WithFields(ctx, map[string]string{\"b\": \"2\"})\n\tfields, _ := ctx.Value(CtxKey(\"fields\")).(map[string]string)\n\tif len(fields) != 2 || fields[\"a\"] != \"1\" || fields[\"b\"] != \"2\" {\n\t\tt.Fatalf(\"unexpected fields state: %+v\", fields)\n\t}\n}\n\nfunc TestLogKV(t *testing.T) {\n\tt.Parallel()\n\tbuf := &bytes.Buffer{}\n\tlogger := log.Writer()\n\tlog.SetOutput(buf)\n\tdefer log.SetOutput(logger)\n\tctx := WithFields(WithRequestID(context.Background(), \"r1\"), map[string]string{\"env\": \"test\"})\n\tLogKV(ctx, \"processing\", map[string]string{\"status\": \"ok\"})\n\tline := buf.String()\n\tfor _, expected := range []string{\"processing\", \"rid=r1\", \"env=test\", \"status=ok\"} {\n\t\tif !strings.Contains(line, expected) {\n\t\t\tt.Fatalf(\"expected %q in log line %q\", expected, line)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "loggingx"
        ],
        "order": 4
      }
    ],
    "category": "production"
  },
  {
    "name": "metricsx",
    "tasks": [
      {
        "package": "metricsx",
        "slug": "go-metricsx-handler",
        "title": "Handler возвращает http.Handler, который пишет Prometheus-метрику demo_up=1.",
        "description": "Level 1 (easy): Handler возвращает http.Handler, который пишет Prometheus-метрику demo_up=1.\nHint: используйте http.HandlerFunc и fmt.Fprintf.",
        "difficulty": "easy",
        "hint1": "используйте http.HandlerFunc и fmt.Fprintf.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\n// Level 1 (easy): Handler возвращает http.Handler, который пишет Prometheus-метрику demo_up=1.\n// Hint: используйте http.HandlerFunc и fmt.Fprintf.\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\")\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")\n\t})\n}\n\n// Level 2 (easy+): Counter хранит числовое значение и поддерживает конкурентный доступ.\n// Hint: используйте sync.Mutex для защиты value.\ntype Counter struct {\n\tmu    sync.RWMutex\n\tvalue float64\n}\n\n// Level 3 (medium): Inc увеличивает счётчик на delta и возвращает текущее значение.\n// Hint: обновляйте поле под блокировкой и возвращайте новое значение.\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.value += delta\n\treturn c.value\n}\n\n// Level 4 (medium): Value возвращает текущее значение счётчика.\n// Hint: читайте поле под блокировкой.\nfunc (c *Counter) Value() float64 {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.value\n}\n\n// Level 5 (medium+): Reset устанавливает счётчик в ноль и возвращает предыдущее значение.\n// Hint: работайте под мьютексом и очистите stored value.\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tout := c.value\n\tc.value = 0\n\treturn out\n}\n\n// Level 6 (medium+): RenderCounter форматирует значение счётчика в стиле Prometheus.\n// Hint: используйте fmt.Sprintf с именем метрики и текущим value.\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil {\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)                                    // signal successful scrape request\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\") // emit metric metadata lines\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")                                    // publish example gauge value\n\t})\n}\n\ntype Counter struct {\n\tmu    sync.Mutex\n\tvalue float64\n}\n\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()         // synchronize concurrent writers updating value\n\tdefer c.mu.Unlock() // release lock after mutation\n\tc.value += delta    // add delta to stored counter value\n\treturn c.value      // return new counter state to caller\n}\n\nfunc (c *Counter) Value() float64 {\n\tc.mu.Lock()         // protect read with mutex to avoid races\n\tdefer c.mu.Unlock() // release lock before returning\n\treturn c.value      // expose current counter value\n}\n\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()         // lock while mutating state\n\tdefer c.mu.Unlock() // release lock afterwards\n\tprev := c.value     // capture previous value for return\n\tc.value = 0         // zero out internal state\n\treturn prev         // provide caller with prior counter value\n}\n\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil { // handle nil counter gracefully\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()                         // read latest counter value safely\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value) // format as Prometheus sample with trailing newline\n}\n",
        "testCode": "package metricsx\n\nimport (\n\t\"net/http/httptest\"\n\t\"testing\"\n)\n\nfunc TestHandler(t *testing.T) {\n\tt.Parallel()\n\tr := httptest.NewRequest(\"GET\", \"/metrics\", nil)\n\tw := httptest.NewRecorder()\n\tHandler().ServeHTTP(w, r)\n\tif w.Result().StatusCode != 200 {\n\t\tt.Fatal(\"bad status\")\n\t}\n\tif w.Body.Len() == 0 {\n\t\tt.Fatal(\"empty body\")\n\t}\n}\n\nfunc TestCounterInc(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tif v := c.Inc(2); v != 2 {\n\t\tt.Fatalf(\"expected value 2, got %v\", v)\n\t}\n}\n\nfunc TestCounterValue(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(5)\n\tif v := c.Value(); v != 5 {\n\t\tt.Fatalf(\"expected value 5, got %v\", v)\n\t}\n}\n\nfunc TestCounterReset(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(3)\n\tprev := c.Reset()\n\tif prev != 3 || c.Value() != 0 {\n\t\tt.Fatalf(\"unexpected reset: prev=%v value=%v\", prev, c.Value())\n\t}\n}\n\nfunc TestRenderCounter(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(7)\n\toutput := RenderCounter(\"demo_total\", &c)\n\tif output == \"\" || output[len(output)-1] != '\\n' {\n\t\tt.Fatalf(\"expected prometheus formatted output, got %q\", output)\n\t}\n\tif want := \"demo_total\"; len(output) == 0 || output[:len(want)] != want {\n\t\tt.Fatalf(\"expected metric name prefix, got %q\", output)\n\t}\n}\n",
        "tags": [
          "go",
          "metricsx"
        ],
        "order": 0
      },
      {
        "package": "metricsx",
        "slug": "go-metricsx-inc",
        "title": "Inc увеличивает счётчик на delta и возвращает текущее значение.",
        "description": "Level 3 (medium): Inc увеличивает счётчик на delta и возвращает текущее значение.\nHint: обновляйте поле под блокировкой и возвращайте новое значение.",
        "difficulty": "medium",
        "hint1": "обновляйте поле под блокировкой и возвращайте новое значение.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\n// Level 1 (easy): Handler возвращает http.Handler, который пишет Prometheus-метрику demo_up=1.\n// Hint: используйте http.HandlerFunc и fmt.Fprintf.\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\")\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")\n\t})\n}\n\n// Level 2 (easy+): Counter хранит числовое значение и поддерживает конкурентный доступ.\n// Hint: используйте sync.Mutex для защиты value.\ntype Counter struct {\n\tmu    sync.RWMutex\n\tvalue float64\n}\n\n// Level 3 (medium): Inc увеличивает счётчик на delta и возвращает текущее значение.\n// Hint: обновляйте поле под блокировкой и возвращайте новое значение.\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.value += delta\n\treturn c.value\n}\n\n// Level 4 (medium): Value возвращает текущее значение счётчика.\n// Hint: читайте поле под блокировкой.\nfunc (c *Counter) Value() float64 {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.value\n}\n\n// Level 5 (medium+): Reset устанавливает счётчик в ноль и возвращает предыдущее значение.\n// Hint: работайте под мьютексом и очистите stored value.\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tout := c.value\n\tc.value = 0\n\treturn out\n}\n\n// Level 6 (medium+): RenderCounter форматирует значение счётчика в стиле Prometheus.\n// Hint: используйте fmt.Sprintf с именем метрики и текущим value.\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil {\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)                                    // signal successful scrape request\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\") // emit metric metadata lines\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")                                    // publish example gauge value\n\t})\n}\n\ntype Counter struct {\n\tmu    sync.Mutex\n\tvalue float64\n}\n\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()         // synchronize concurrent writers updating value\n\tdefer c.mu.Unlock() // release lock after mutation\n\tc.value += delta    // add delta to stored counter value\n\treturn c.value      // return new counter state to caller\n}\n\nfunc (c *Counter) Value() float64 {\n\tc.mu.Lock()         // protect read with mutex to avoid races\n\tdefer c.mu.Unlock() // release lock before returning\n\treturn c.value      // expose current counter value\n}\n\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()         // lock while mutating state\n\tdefer c.mu.Unlock() // release lock afterwards\n\tprev := c.value     // capture previous value for return\n\tc.value = 0         // zero out internal state\n\treturn prev         // provide caller with prior counter value\n}\n\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil { // handle nil counter gracefully\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()                         // read latest counter value safely\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value) // format as Prometheus sample with trailing newline\n}\n",
        "testCode": "package metricsx\n\nimport (\n\t\"net/http/httptest\"\n\t\"testing\"\n)\n\nfunc TestHandler(t *testing.T) {\n\tt.Parallel()\n\tr := httptest.NewRequest(\"GET\", \"/metrics\", nil)\n\tw := httptest.NewRecorder()\n\tHandler().ServeHTTP(w, r)\n\tif w.Result().StatusCode != 200 {\n\t\tt.Fatal(\"bad status\")\n\t}\n\tif w.Body.Len() == 0 {\n\t\tt.Fatal(\"empty body\")\n\t}\n}\n\nfunc TestCounterInc(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tif v := c.Inc(2); v != 2 {\n\t\tt.Fatalf(\"expected value 2, got %v\", v)\n\t}\n}\n\nfunc TestCounterValue(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(5)\n\tif v := c.Value(); v != 5 {\n\t\tt.Fatalf(\"expected value 5, got %v\", v)\n\t}\n}\n\nfunc TestCounterReset(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(3)\n\tprev := c.Reset()\n\tif prev != 3 || c.Value() != 0 {\n\t\tt.Fatalf(\"unexpected reset: prev=%v value=%v\", prev, c.Value())\n\t}\n}\n\nfunc TestRenderCounter(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(7)\n\toutput := RenderCounter(\"demo_total\", &c)\n\tif output == \"\" || output[len(output)-1] != '\\n' {\n\t\tt.Fatalf(\"expected prometheus formatted output, got %q\", output)\n\t}\n\tif want := \"demo_total\"; len(output) == 0 || output[:len(want)] != want {\n\t\tt.Fatalf(\"expected metric name prefix, got %q\", output)\n\t}\n}\n",
        "tags": [
          "go",
          "metricsx"
        ],
        "order": 2
      },
      {
        "package": "metricsx",
        "slug": "go-metricsx-value",
        "title": "Value возвращает текущее значение счётчика.",
        "description": "Level 4 (medium): Value возвращает текущее значение счётчика.\nHint: читайте поле под блокировкой.",
        "difficulty": "medium",
        "hint1": "читайте поле под блокировкой.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\n// Level 1 (easy): Handler возвращает http.Handler, который пишет Prometheus-метрику demo_up=1.\n// Hint: используйте http.HandlerFunc и fmt.Fprintf.\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\")\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")\n\t})\n}\n\n// Level 2 (easy+): Counter хранит числовое значение и поддерживает конкурентный доступ.\n// Hint: используйте sync.Mutex для защиты value.\ntype Counter struct {\n\tmu    sync.RWMutex\n\tvalue float64\n}\n\n// Level 3 (medium): Inc увеличивает счётчик на delta и возвращает текущее значение.\n// Hint: обновляйте поле под блокировкой и возвращайте новое значение.\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.value += delta\n\treturn c.value\n}\n\n// Level 4 (medium): Value возвращает текущее значение счётчика.\n// Hint: читайте поле под блокировкой.\nfunc (c *Counter) Value() float64 {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.value\n}\n\n// Level 5 (medium+): Reset устанавливает счётчик в ноль и возвращает предыдущее значение.\n// Hint: работайте под мьютексом и очистите stored value.\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tout := c.value\n\tc.value = 0\n\treturn out\n}\n\n// Level 6 (medium+): RenderCounter форматирует значение счётчика в стиле Prometheus.\n// Hint: используйте fmt.Sprintf с именем метрики и текущим value.\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil {\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)                                    // signal successful scrape request\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\") // emit metric metadata lines\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")                                    // publish example gauge value\n\t})\n}\n\ntype Counter struct {\n\tmu    sync.Mutex\n\tvalue float64\n}\n\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()         // synchronize concurrent writers updating value\n\tdefer c.mu.Unlock() // release lock after mutation\n\tc.value += delta    // add delta to stored counter value\n\treturn c.value      // return new counter state to caller\n}\n\nfunc (c *Counter) Value() float64 {\n\tc.mu.Lock()         // protect read with mutex to avoid races\n\tdefer c.mu.Unlock() // release lock before returning\n\treturn c.value      // expose current counter value\n}\n\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()         // lock while mutating state\n\tdefer c.mu.Unlock() // release lock afterwards\n\tprev := c.value     // capture previous value for return\n\tc.value = 0         // zero out internal state\n\treturn prev         // provide caller with prior counter value\n}\n\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil { // handle nil counter gracefully\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()                         // read latest counter value safely\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value) // format as Prometheus sample with trailing newline\n}\n",
        "testCode": "package metricsx\n\nimport (\n\t\"net/http/httptest\"\n\t\"testing\"\n)\n\nfunc TestHandler(t *testing.T) {\n\tt.Parallel()\n\tr := httptest.NewRequest(\"GET\", \"/metrics\", nil)\n\tw := httptest.NewRecorder()\n\tHandler().ServeHTTP(w, r)\n\tif w.Result().StatusCode != 200 {\n\t\tt.Fatal(\"bad status\")\n\t}\n\tif w.Body.Len() == 0 {\n\t\tt.Fatal(\"empty body\")\n\t}\n}\n\nfunc TestCounterInc(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tif v := c.Inc(2); v != 2 {\n\t\tt.Fatalf(\"expected value 2, got %v\", v)\n\t}\n}\n\nfunc TestCounterValue(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(5)\n\tif v := c.Value(); v != 5 {\n\t\tt.Fatalf(\"expected value 5, got %v\", v)\n\t}\n}\n\nfunc TestCounterReset(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(3)\n\tprev := c.Reset()\n\tif prev != 3 || c.Value() != 0 {\n\t\tt.Fatalf(\"unexpected reset: prev=%v value=%v\", prev, c.Value())\n\t}\n}\n\nfunc TestRenderCounter(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(7)\n\toutput := RenderCounter(\"demo_total\", &c)\n\tif output == \"\" || output[len(output)-1] != '\\n' {\n\t\tt.Fatalf(\"expected prometheus formatted output, got %q\", output)\n\t}\n\tif want := \"demo_total\"; len(output) == 0 || output[:len(want)] != want {\n\t\tt.Fatalf(\"expected metric name prefix, got %q\", output)\n\t}\n}\n",
        "tags": [
          "go",
          "metricsx"
        ],
        "order": 3
      },
      {
        "package": "metricsx",
        "slug": "go-metricsx-reset",
        "title": "Reset устанавливает счётчик в ноль и возвращает предыдущее значение.",
        "description": "Level 5 (medium+): Reset устанавливает счётчик в ноль и возвращает предыдущее значение.\nHint: работайте под мьютексом и очистите stored value.",
        "difficulty": "medium",
        "hint1": "работайте под мьютексом и очистите stored value.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\n// Level 1 (easy): Handler возвращает http.Handler, который пишет Prometheus-метрику demo_up=1.\n// Hint: используйте http.HandlerFunc и fmt.Fprintf.\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\")\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")\n\t})\n}\n\n// Level 2 (easy+): Counter хранит числовое значение и поддерживает конкурентный доступ.\n// Hint: используйте sync.Mutex для защиты value.\ntype Counter struct {\n\tmu    sync.RWMutex\n\tvalue float64\n}\n\n// Level 3 (medium): Inc увеличивает счётчик на delta и возвращает текущее значение.\n// Hint: обновляйте поле под блокировкой и возвращайте новое значение.\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.value += delta\n\treturn c.value\n}\n\n// Level 4 (medium): Value возвращает текущее значение счётчика.\n// Hint: читайте поле под блокировкой.\nfunc (c *Counter) Value() float64 {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.value\n}\n\n// Level 5 (medium+): Reset устанавливает счётчик в ноль и возвращает предыдущее значение.\n// Hint: работайте под мьютексом и очистите stored value.\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tout := c.value\n\tc.value = 0\n\treturn out\n}\n\n// Level 6 (medium+): RenderCounter форматирует значение счётчика в стиле Prometheus.\n// Hint: используйте fmt.Sprintf с именем метрики и текущим value.\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil {\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)                                    // signal successful scrape request\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\") // emit metric metadata lines\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")                                    // publish example gauge value\n\t})\n}\n\ntype Counter struct {\n\tmu    sync.Mutex\n\tvalue float64\n}\n\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()         // synchronize concurrent writers updating value\n\tdefer c.mu.Unlock() // release lock after mutation\n\tc.value += delta    // add delta to stored counter value\n\treturn c.value      // return new counter state to caller\n}\n\nfunc (c *Counter) Value() float64 {\n\tc.mu.Lock()         // protect read with mutex to avoid races\n\tdefer c.mu.Unlock() // release lock before returning\n\treturn c.value      // expose current counter value\n}\n\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()         // lock while mutating state\n\tdefer c.mu.Unlock() // release lock afterwards\n\tprev := c.value     // capture previous value for return\n\tc.value = 0         // zero out internal state\n\treturn prev         // provide caller with prior counter value\n}\n\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil { // handle nil counter gracefully\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()                         // read latest counter value safely\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value) // format as Prometheus sample with trailing newline\n}\n",
        "testCode": "package metricsx\n\nimport (\n\t\"net/http/httptest\"\n\t\"testing\"\n)\n\nfunc TestHandler(t *testing.T) {\n\tt.Parallel()\n\tr := httptest.NewRequest(\"GET\", \"/metrics\", nil)\n\tw := httptest.NewRecorder()\n\tHandler().ServeHTTP(w, r)\n\tif w.Result().StatusCode != 200 {\n\t\tt.Fatal(\"bad status\")\n\t}\n\tif w.Body.Len() == 0 {\n\t\tt.Fatal(\"empty body\")\n\t}\n}\n\nfunc TestCounterInc(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tif v := c.Inc(2); v != 2 {\n\t\tt.Fatalf(\"expected value 2, got %v\", v)\n\t}\n}\n\nfunc TestCounterValue(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(5)\n\tif v := c.Value(); v != 5 {\n\t\tt.Fatalf(\"expected value 5, got %v\", v)\n\t}\n}\n\nfunc TestCounterReset(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(3)\n\tprev := c.Reset()\n\tif prev != 3 || c.Value() != 0 {\n\t\tt.Fatalf(\"unexpected reset: prev=%v value=%v\", prev, c.Value())\n\t}\n}\n\nfunc TestRenderCounter(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(7)\n\toutput := RenderCounter(\"demo_total\", &c)\n\tif output == \"\" || output[len(output)-1] != '\\n' {\n\t\tt.Fatalf(\"expected prometheus formatted output, got %q\", output)\n\t}\n\tif want := \"demo_total\"; len(output) == 0 || output[:len(want)] != want {\n\t\tt.Fatalf(\"expected metric name prefix, got %q\", output)\n\t}\n}\n",
        "tags": [
          "go",
          "metricsx"
        ],
        "order": 4
      },
      {
        "package": "metricsx",
        "slug": "go-metricsx-rendercounter",
        "title": "RenderCounter форматирует значение счётчика в стиле Prometheus.",
        "description": "Level 6 (medium+): RenderCounter форматирует значение счётчика в стиле Prometheus.\nHint: используйте fmt.Sprintf с именем метрики и текущим value.",
        "difficulty": "medium",
        "hint1": "используйте fmt.Sprintf с именем метрики и текущим value.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\n// Level 1 (easy): Handler возвращает http.Handler, который пишет Prometheus-метрику demo_up=1.\n// Hint: используйте http.HandlerFunc и fmt.Fprintf.\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\")\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")\n\t})\n}\n\n// Level 2 (easy+): Counter хранит числовое значение и поддерживает конкурентный доступ.\n// Hint: используйте sync.Mutex для защиты value.\ntype Counter struct {\n\tmu    sync.RWMutex\n\tvalue float64\n}\n\n// Level 3 (medium): Inc увеличивает счётчик на delta и возвращает текущее значение.\n// Hint: обновляйте поле под блокировкой и возвращайте новое значение.\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.value += delta\n\treturn c.value\n}\n\n// Level 4 (medium): Value возвращает текущее значение счётчика.\n// Hint: читайте поле под блокировкой.\nfunc (c *Counter) Value() float64 {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.value\n}\n\n// Level 5 (medium+): Reset устанавливает счётчик в ноль и возвращает предыдущее значение.\n// Hint: работайте под мьютексом и очистите stored value.\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tout := c.value\n\tc.value = 0\n\treturn out\n}\n\n// Level 6 (medium+): RenderCounter форматирует значение счётчика в стиле Prometheus.\n// Hint: используйте fmt.Sprintf с именем метрики и текущим value.\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil {\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value)\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage metricsx\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n)\n\nfunc Handler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)                                    // signal successful scrape request\n\t\tfmt.Fprint(w, \"# HELP demo_up 1 if up\\n# TYPE demo_up gauge\\n\") // emit metric metadata lines\n\t\tfmt.Fprint(w, \"demo_up 1\\n\")                                    // publish example gauge value\n\t})\n}\n\ntype Counter struct {\n\tmu    sync.Mutex\n\tvalue float64\n}\n\nfunc (c *Counter) Inc(delta float64) float64 {\n\tc.mu.Lock()         // synchronize concurrent writers updating value\n\tdefer c.mu.Unlock() // release lock after mutation\n\tc.value += delta    // add delta to stored counter value\n\treturn c.value      // return new counter state to caller\n}\n\nfunc (c *Counter) Value() float64 {\n\tc.mu.Lock()         // protect read with mutex to avoid races\n\tdefer c.mu.Unlock() // release lock before returning\n\treturn c.value      // expose current counter value\n}\n\nfunc (c *Counter) Reset() float64 {\n\tc.mu.Lock()         // lock while mutating state\n\tdefer c.mu.Unlock() // release lock afterwards\n\tprev := c.value     // capture previous value for return\n\tc.value = 0         // zero out internal state\n\treturn prev         // provide caller with prior counter value\n}\n\nfunc RenderCounter(name string, c *Counter) string {\n\tif c == nil { // handle nil counter gracefully\n\t\treturn fmt.Sprintf(\"%s 0\\n\", name)\n\t}\n\tvalue := c.Value()                         // read latest counter value safely\n\treturn fmt.Sprintf(\"%s %g\\n\", name, value) // format as Prometheus sample with trailing newline\n}\n",
        "testCode": "package metricsx\n\nimport (\n\t\"net/http/httptest\"\n\t\"testing\"\n)\n\nfunc TestHandler(t *testing.T) {\n\tt.Parallel()\n\tr := httptest.NewRequest(\"GET\", \"/metrics\", nil)\n\tw := httptest.NewRecorder()\n\tHandler().ServeHTTP(w, r)\n\tif w.Result().StatusCode != 200 {\n\t\tt.Fatal(\"bad status\")\n\t}\n\tif w.Body.Len() == 0 {\n\t\tt.Fatal(\"empty body\")\n\t}\n}\n\nfunc TestCounterInc(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tif v := c.Inc(2); v != 2 {\n\t\tt.Fatalf(\"expected value 2, got %v\", v)\n\t}\n}\n\nfunc TestCounterValue(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(5)\n\tif v := c.Value(); v != 5 {\n\t\tt.Fatalf(\"expected value 5, got %v\", v)\n\t}\n}\n\nfunc TestCounterReset(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(3)\n\tprev := c.Reset()\n\tif prev != 3 || c.Value() != 0 {\n\t\tt.Fatalf(\"unexpected reset: prev=%v value=%v\", prev, c.Value())\n\t}\n}\n\nfunc TestRenderCounter(t *testing.T) {\n\tt.Parallel()\n\tvar c Counter\n\tc.Inc(7)\n\toutput := RenderCounter(\"demo_total\", &c)\n\tif output == \"\" || output[len(output)-1] != '\\n' {\n\t\tt.Fatalf(\"expected prometheus formatted output, got %q\", output)\n\t}\n\tif want := \"demo_total\"; len(output) == 0 || output[:len(want)] != want {\n\t\tt.Fatalf(\"expected metric name prefix, got %q\", output)\n\t}\n}\n",
        "tags": [
          "go",
          "metricsx"
        ],
        "order": 5
      }
    ],
    "category": "production"
  },
  {
    "name": "panicrecover",
    "tasks": [
      {
        "package": "panicrecover",
        "slug": "go-panicrecover-safecall",
        "title": "SafeCall вызывает f и перехватывает панику, возвращая ошибку fmt.Errorf(\"panic: %v\", x).",
        "description": "Level 1 (easy): SafeCall вызывает f и перехватывает панику, возвращая ошибку fmt.Errorf(\"panic: %v\", x).\nHint: используйте named return err и defer с recover().",
        "difficulty": "easy",
        "hint1": "используйте named return err и defer с recover().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): SafeCall вызывает f и перехватывает панику, возвращая ошибку fmt.Errorf(\"panic: %v\", x).\n// Hint: используйте named return err и defer с recover().\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn err\n}\n\n// Level 2 (easy+): SafeCallValue выполняет f, возвращает его результат и ловит панику.\n// Hint: примените SafeCall внутри и возвращайте значение только при успехе.\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T\n\tif f == nil {\n\t\treturn zero, nil\n\t}\n\tvar result T\n\terr := SafeCall(func() {\n\t\tresult = f()\n\t})\n\tif err != nil {\n\t\treturn zero, err\n\t}\n\treturn result, nil\n}\n\n// Level 3 (medium): RecoverString сообщает текст паники и факт её наличия.\n// Hint: захватите recover() в defer и преобразуйте результат в string.\nfunc RecoverString(f func()) (msg string, panicked bool) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tmsg = fmt.Sprint(r)\n\t\t\tpanicked = true\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn msg, panicked\n}\n\n// Level 4 (medium+): Guard выполняет f и преобразует панику в ошибку типа error.\n// Hint: оборачивайте f в функцию, возвращающую error, а паники переводите в fmt.Errorf.\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f == nil {\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil {\n\t\treturn callErr\n\t}\n\treturn nil\n}\n\n// Level 5 (medium+): GoSafe запускает f в горутине, возвращая канал ошибок и уважая ctx.Done().\n// Hint: при панике или ошибке отправляйте значение в канал, и закройте его после завершения.\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tvar panicked bool\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tpanicked = true\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r)\n\t\t\t}\n\t\t}()\n\t\tif f == nil {\n\t\t\tselect {\n\t\t\tcase out <- nil:\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx)\n\t\tif panicked {\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil {\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered by f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // convert panic payload into error result\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when provided\n\t\tf() // run user-supplied function in guarded scope\n\t}\n\treturn err // return nil or panic-derived error\n}\n\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T    // prepare zero value to return on failure\n\tif f == nil { // bail out early when no function supplied\n\t\treturn zero, nil\n\t}\n\tvar result T             // capture successful return value\n\terr := SafeCall(func() { // reuse SafeCall to capture panic semantics\n\t\tresult = f() // invoke original function and store its result\n\t})\n\tif err != nil { // propagate panic as error while returning zero value\n\t\treturn zero, err\n\t}\n\treturn result, nil // deliver computed value alongside nil error\n}\n\nfunc RecoverString(f func()) (string, bool) {\n\tvar message string // hold textual representation of panic\n\tvar panicked bool  // flag indicates whether panic occurred\n\tdefer func() {\n\t\tif r := recover(); r != nil { // capture panic payload if any\n\t\t\tmessage = fmt.Sprint(r) // convert payload into string form\n\t\t\tpanicked = true         // mark that panic was observed\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when present\n\t\tf() // run user function inside recovery scope\n\t}\n\treturn message, panicked // return captured message and panic flag\n}\n\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered inside f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // translate panic into error return\n\t\t}\n\t}()\n\tif f == nil { // nil function is treated as success\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil { // invoke function and check returned error\n\t\treturn callErr // forward user-supplied error without wrapping\n\t}\n\treturn nil // return success when no panic or error occurred\n}\n\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1) // buffered channel delivers single result\n\tgo func() {\n\t\tdefer close(out)  // ensure channel is closed exactly once\n\t\tvar panicked bool // track whether panic handler already wrote to channel\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil { // catch panics from user function\n\t\t\t\tpanicked = true                   // mark panic occurrence to skip further writes\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r) // send panic as error to consumer\n\t\t\t}\n\t\t}()\n\t\tif f == nil { // treat nil function as no-op success\n\t\t\tselect {\n\t\t\tcase out <- nil: // emit success to listener\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx) // execute user function with propagated context\n\t\tif panicked { // skip delivering additional value when panic already reported\n\t\t\treturn\n\t\t}\n\t\tif err != nil { // propagate explicit error returned by callback\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil { // surface context cancellation if it happened\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil // no errors encountered; report success\n\t}()\n\treturn out // expose result channel to caller\n}\n",
        "testCode": "package panicrecover\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestSafeCall(t *testing.T) {\n\tt.Parallel()\n\tif err := SafeCall(func() {}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := SafeCall(func() { panic(\"boom\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be captured as error\")\n\t}\n}\n\nfunc TestSafeCallValue(t *testing.T) {\n\tt.Parallel()\n\tv, err := SafeCallValue(func() int { return 42 })\n\tif err != nil || v != 42 {\n\t\tt.Fatalf(\"unexpected result: %v %v\", v, err)\n\t}\n\tif _, err := SafeCallValue(func() int { panic(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected panic to become error\")\n\t}\n}\n\nfunc TestRecoverString(t *testing.T) {\n\tt.Parallel()\n\tif msg, ok := RecoverString(func() {}); ok || msg != \"\" {\n\t\tt.Fatalf(\"expected no panic, got %q ok=%v\", msg, ok)\n\t}\n\tmsg, ok := RecoverString(func() { panic(\"hello\") })\n\tif !ok || msg != \"hello\" {\n\t\tt.Fatalf(\"expected panic message 'hello', got %q ok=%v\", msg, ok)\n\t}\n}\n\nfunc TestGuard(t *testing.T) {\n\tt.Parallel()\n\tif err := Guard(func() error { return nil }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := Guard(func() error { return errors.New(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected original error to propagate\")\n\t}\n\tif err := Guard(func() error { panic(\"guard\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be converted to error\")\n\t}\n}\n\nfunc TestGoSafe(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch := GoSafe(ctx, func(context.Context) error { return nil })\n\tselect {\n\tcase err, ok := <-ch:\n\t\tif !ok {\n\t\t\tt.Fatal(\"channel closed without value\")\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for GoSafe result\")\n\t}\n\tpanicCh := GoSafe(ctx, func(context.Context) error { panic(\"boom\") })\n\tselect {\n\tcase err := <-panicCh:\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expected error from panic\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for panic propagation\")\n\t}\n}\n",
        "tags": [
          "go",
          "panicrecover"
        ],
        "order": 0
      },
      {
        "package": "panicrecover",
        "slug": "go-panicrecover-safecallvalue",
        "title": "SafeCallValue выполняет f, возвращает его результат и ловит панику.",
        "description": "Level 2 (easy+): SafeCallValue выполняет f, возвращает его результат и ловит панику.\nHint: примените SafeCall внутри и возвращайте значение только при успехе.",
        "difficulty": "easy",
        "hint1": "примените SafeCall внутри и возвращайте значение только при успехе.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): SafeCall вызывает f и перехватывает панику, возвращая ошибку fmt.Errorf(\"panic: %v\", x).\n// Hint: используйте named return err и defer с recover().\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn err\n}\n\n// Level 2 (easy+): SafeCallValue выполняет f, возвращает его результат и ловит панику.\n// Hint: примените SafeCall внутри и возвращайте значение только при успехе.\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T\n\tif f == nil {\n\t\treturn zero, nil\n\t}\n\tvar result T\n\terr := SafeCall(func() {\n\t\tresult = f()\n\t})\n\tif err != nil {\n\t\treturn zero, err\n\t}\n\treturn result, nil\n}\n\n// Level 3 (medium): RecoverString сообщает текст паники и факт её наличия.\n// Hint: захватите recover() в defer и преобразуйте результат в string.\nfunc RecoverString(f func()) (msg string, panicked bool) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tmsg = fmt.Sprint(r)\n\t\t\tpanicked = true\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn msg, panicked\n}\n\n// Level 4 (medium+): Guard выполняет f и преобразует панику в ошибку типа error.\n// Hint: оборачивайте f в функцию, возвращающую error, а паники переводите в fmt.Errorf.\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f == nil {\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil {\n\t\treturn callErr\n\t}\n\treturn nil\n}\n\n// Level 5 (medium+): GoSafe запускает f в горутине, возвращая канал ошибок и уважая ctx.Done().\n// Hint: при панике или ошибке отправляйте значение в канал, и закройте его после завершения.\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tvar panicked bool\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tpanicked = true\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r)\n\t\t\t}\n\t\t}()\n\t\tif f == nil {\n\t\t\tselect {\n\t\t\tcase out <- nil:\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx)\n\t\tif panicked {\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil {\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered by f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // convert panic payload into error result\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when provided\n\t\tf() // run user-supplied function in guarded scope\n\t}\n\treturn err // return nil or panic-derived error\n}\n\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T    // prepare zero value to return on failure\n\tif f == nil { // bail out early when no function supplied\n\t\treturn zero, nil\n\t}\n\tvar result T             // capture successful return value\n\terr := SafeCall(func() { // reuse SafeCall to capture panic semantics\n\t\tresult = f() // invoke original function and store its result\n\t})\n\tif err != nil { // propagate panic as error while returning zero value\n\t\treturn zero, err\n\t}\n\treturn result, nil // deliver computed value alongside nil error\n}\n\nfunc RecoverString(f func()) (string, bool) {\n\tvar message string // hold textual representation of panic\n\tvar panicked bool  // flag indicates whether panic occurred\n\tdefer func() {\n\t\tif r := recover(); r != nil { // capture panic payload if any\n\t\t\tmessage = fmt.Sprint(r) // convert payload into string form\n\t\t\tpanicked = true         // mark that panic was observed\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when present\n\t\tf() // run user function inside recovery scope\n\t}\n\treturn message, panicked // return captured message and panic flag\n}\n\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered inside f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // translate panic into error return\n\t\t}\n\t}()\n\tif f == nil { // nil function is treated as success\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil { // invoke function and check returned error\n\t\treturn callErr // forward user-supplied error without wrapping\n\t}\n\treturn nil // return success when no panic or error occurred\n}\n\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1) // buffered channel delivers single result\n\tgo func() {\n\t\tdefer close(out)  // ensure channel is closed exactly once\n\t\tvar panicked bool // track whether panic handler already wrote to channel\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil { // catch panics from user function\n\t\t\t\tpanicked = true                   // mark panic occurrence to skip further writes\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r) // send panic as error to consumer\n\t\t\t}\n\t\t}()\n\t\tif f == nil { // treat nil function as no-op success\n\t\t\tselect {\n\t\t\tcase out <- nil: // emit success to listener\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx) // execute user function with propagated context\n\t\tif panicked { // skip delivering additional value when panic already reported\n\t\t\treturn\n\t\t}\n\t\tif err != nil { // propagate explicit error returned by callback\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil { // surface context cancellation if it happened\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil // no errors encountered; report success\n\t}()\n\treturn out // expose result channel to caller\n}\n",
        "testCode": "package panicrecover\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestSafeCall(t *testing.T) {\n\tt.Parallel()\n\tif err := SafeCall(func() {}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := SafeCall(func() { panic(\"boom\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be captured as error\")\n\t}\n}\n\nfunc TestSafeCallValue(t *testing.T) {\n\tt.Parallel()\n\tv, err := SafeCallValue(func() int { return 42 })\n\tif err != nil || v != 42 {\n\t\tt.Fatalf(\"unexpected result: %v %v\", v, err)\n\t}\n\tif _, err := SafeCallValue(func() int { panic(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected panic to become error\")\n\t}\n}\n\nfunc TestRecoverString(t *testing.T) {\n\tt.Parallel()\n\tif msg, ok := RecoverString(func() {}); ok || msg != \"\" {\n\t\tt.Fatalf(\"expected no panic, got %q ok=%v\", msg, ok)\n\t}\n\tmsg, ok := RecoverString(func() { panic(\"hello\") })\n\tif !ok || msg != \"hello\" {\n\t\tt.Fatalf(\"expected panic message 'hello', got %q ok=%v\", msg, ok)\n\t}\n}\n\nfunc TestGuard(t *testing.T) {\n\tt.Parallel()\n\tif err := Guard(func() error { return nil }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := Guard(func() error { return errors.New(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected original error to propagate\")\n\t}\n\tif err := Guard(func() error { panic(\"guard\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be converted to error\")\n\t}\n}\n\nfunc TestGoSafe(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch := GoSafe(ctx, func(context.Context) error { return nil })\n\tselect {\n\tcase err, ok := <-ch:\n\t\tif !ok {\n\t\t\tt.Fatal(\"channel closed without value\")\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for GoSafe result\")\n\t}\n\tpanicCh := GoSafe(ctx, func(context.Context) error { panic(\"boom\") })\n\tselect {\n\tcase err := <-panicCh:\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expected error from panic\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for panic propagation\")\n\t}\n}\n",
        "tags": [
          "go",
          "panicrecover"
        ],
        "order": 1
      },
      {
        "package": "panicrecover",
        "slug": "go-panicrecover-recoverstring",
        "title": "RecoverString сообщает текст паники и факт её наличия.",
        "description": "Level 3 (medium): RecoverString сообщает текст паники и факт её наличия.\nHint: захватите recover() в defer и преобразуйте результат в string.",
        "difficulty": "medium",
        "hint1": "захватите recover() в defer и преобразуйте результат в string.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): SafeCall вызывает f и перехватывает панику, возвращая ошибку fmt.Errorf(\"panic: %v\", x).\n// Hint: используйте named return err и defer с recover().\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn err\n}\n\n// Level 2 (easy+): SafeCallValue выполняет f, возвращает его результат и ловит панику.\n// Hint: примените SafeCall внутри и возвращайте значение только при успехе.\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T\n\tif f == nil {\n\t\treturn zero, nil\n\t}\n\tvar result T\n\terr := SafeCall(func() {\n\t\tresult = f()\n\t})\n\tif err != nil {\n\t\treturn zero, err\n\t}\n\treturn result, nil\n}\n\n// Level 3 (medium): RecoverString сообщает текст паники и факт её наличия.\n// Hint: захватите recover() в defer и преобразуйте результат в string.\nfunc RecoverString(f func()) (msg string, panicked bool) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tmsg = fmt.Sprint(r)\n\t\t\tpanicked = true\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn msg, panicked\n}\n\n// Level 4 (medium+): Guard выполняет f и преобразует панику в ошибку типа error.\n// Hint: оборачивайте f в функцию, возвращающую error, а паники переводите в fmt.Errorf.\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f == nil {\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil {\n\t\treturn callErr\n\t}\n\treturn nil\n}\n\n// Level 5 (medium+): GoSafe запускает f в горутине, возвращая канал ошибок и уважая ctx.Done().\n// Hint: при панике или ошибке отправляйте значение в канал, и закройте его после завершения.\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tvar panicked bool\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tpanicked = true\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r)\n\t\t\t}\n\t\t}()\n\t\tif f == nil {\n\t\t\tselect {\n\t\t\tcase out <- nil:\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx)\n\t\tif panicked {\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil {\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered by f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // convert panic payload into error result\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when provided\n\t\tf() // run user-supplied function in guarded scope\n\t}\n\treturn err // return nil or panic-derived error\n}\n\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T    // prepare zero value to return on failure\n\tif f == nil { // bail out early when no function supplied\n\t\treturn zero, nil\n\t}\n\tvar result T             // capture successful return value\n\terr := SafeCall(func() { // reuse SafeCall to capture panic semantics\n\t\tresult = f() // invoke original function and store its result\n\t})\n\tif err != nil { // propagate panic as error while returning zero value\n\t\treturn zero, err\n\t}\n\treturn result, nil // deliver computed value alongside nil error\n}\n\nfunc RecoverString(f func()) (string, bool) {\n\tvar message string // hold textual representation of panic\n\tvar panicked bool  // flag indicates whether panic occurred\n\tdefer func() {\n\t\tif r := recover(); r != nil { // capture panic payload if any\n\t\t\tmessage = fmt.Sprint(r) // convert payload into string form\n\t\t\tpanicked = true         // mark that panic was observed\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when present\n\t\tf() // run user function inside recovery scope\n\t}\n\treturn message, panicked // return captured message and panic flag\n}\n\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered inside f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // translate panic into error return\n\t\t}\n\t}()\n\tif f == nil { // nil function is treated as success\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil { // invoke function and check returned error\n\t\treturn callErr // forward user-supplied error without wrapping\n\t}\n\treturn nil // return success when no panic or error occurred\n}\n\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1) // buffered channel delivers single result\n\tgo func() {\n\t\tdefer close(out)  // ensure channel is closed exactly once\n\t\tvar panicked bool // track whether panic handler already wrote to channel\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil { // catch panics from user function\n\t\t\t\tpanicked = true                   // mark panic occurrence to skip further writes\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r) // send panic as error to consumer\n\t\t\t}\n\t\t}()\n\t\tif f == nil { // treat nil function as no-op success\n\t\t\tselect {\n\t\t\tcase out <- nil: // emit success to listener\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx) // execute user function with propagated context\n\t\tif panicked { // skip delivering additional value when panic already reported\n\t\t\treturn\n\t\t}\n\t\tif err != nil { // propagate explicit error returned by callback\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil { // surface context cancellation if it happened\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil // no errors encountered; report success\n\t}()\n\treturn out // expose result channel to caller\n}\n",
        "testCode": "package panicrecover\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestSafeCall(t *testing.T) {\n\tt.Parallel()\n\tif err := SafeCall(func() {}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := SafeCall(func() { panic(\"boom\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be captured as error\")\n\t}\n}\n\nfunc TestSafeCallValue(t *testing.T) {\n\tt.Parallel()\n\tv, err := SafeCallValue(func() int { return 42 })\n\tif err != nil || v != 42 {\n\t\tt.Fatalf(\"unexpected result: %v %v\", v, err)\n\t}\n\tif _, err := SafeCallValue(func() int { panic(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected panic to become error\")\n\t}\n}\n\nfunc TestRecoverString(t *testing.T) {\n\tt.Parallel()\n\tif msg, ok := RecoverString(func() {}); ok || msg != \"\" {\n\t\tt.Fatalf(\"expected no panic, got %q ok=%v\", msg, ok)\n\t}\n\tmsg, ok := RecoverString(func() { panic(\"hello\") })\n\tif !ok || msg != \"hello\" {\n\t\tt.Fatalf(\"expected panic message 'hello', got %q ok=%v\", msg, ok)\n\t}\n}\n\nfunc TestGuard(t *testing.T) {\n\tt.Parallel()\n\tif err := Guard(func() error { return nil }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := Guard(func() error { return errors.New(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected original error to propagate\")\n\t}\n\tif err := Guard(func() error { panic(\"guard\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be converted to error\")\n\t}\n}\n\nfunc TestGoSafe(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch := GoSafe(ctx, func(context.Context) error { return nil })\n\tselect {\n\tcase err, ok := <-ch:\n\t\tif !ok {\n\t\t\tt.Fatal(\"channel closed without value\")\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for GoSafe result\")\n\t}\n\tpanicCh := GoSafe(ctx, func(context.Context) error { panic(\"boom\") })\n\tselect {\n\tcase err := <-panicCh:\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expected error from panic\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for panic propagation\")\n\t}\n}\n",
        "tags": [
          "go",
          "panicrecover"
        ],
        "order": 2
      },
      {
        "package": "panicrecover",
        "slug": "go-panicrecover-guard",
        "title": "Guard выполняет f и преобразует панику в ошибку типа error.",
        "description": "Level 4 (medium+): Guard выполняет f и преобразует панику в ошибку типа error.\nHint: оборачивайте f в функцию, возвращающую error, а паники переводите в fmt.Errorf.",
        "difficulty": "medium",
        "hint1": "оборачивайте f в функцию, возвращающую error, а паники переводите в fmt.Errorf.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): SafeCall вызывает f и перехватывает панику, возвращая ошибку fmt.Errorf(\"panic: %v\", x).\n// Hint: используйте named return err и defer с recover().\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn err\n}\n\n// Level 2 (easy+): SafeCallValue выполняет f, возвращает его результат и ловит панику.\n// Hint: примените SafeCall внутри и возвращайте значение только при успехе.\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T\n\tif f == nil {\n\t\treturn zero, nil\n\t}\n\tvar result T\n\terr := SafeCall(func() {\n\t\tresult = f()\n\t})\n\tif err != nil {\n\t\treturn zero, err\n\t}\n\treturn result, nil\n}\n\n// Level 3 (medium): RecoverString сообщает текст паники и факт её наличия.\n// Hint: захватите recover() в defer и преобразуйте результат в string.\nfunc RecoverString(f func()) (msg string, panicked bool) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tmsg = fmt.Sprint(r)\n\t\t\tpanicked = true\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn msg, panicked\n}\n\n// Level 4 (medium+): Guard выполняет f и преобразует панику в ошибку типа error.\n// Hint: оборачивайте f в функцию, возвращающую error, а паники переводите в fmt.Errorf.\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f == nil {\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil {\n\t\treturn callErr\n\t}\n\treturn nil\n}\n\n// Level 5 (medium+): GoSafe запускает f в горутине, возвращая канал ошибок и уважая ctx.Done().\n// Hint: при панике или ошибке отправляйте значение в канал, и закройте его после завершения.\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tvar panicked bool\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tpanicked = true\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r)\n\t\t\t}\n\t\t}()\n\t\tif f == nil {\n\t\t\tselect {\n\t\t\tcase out <- nil:\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx)\n\t\tif panicked {\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil {\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered by f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // convert panic payload into error result\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when provided\n\t\tf() // run user-supplied function in guarded scope\n\t}\n\treturn err // return nil or panic-derived error\n}\n\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T    // prepare zero value to return on failure\n\tif f == nil { // bail out early when no function supplied\n\t\treturn zero, nil\n\t}\n\tvar result T             // capture successful return value\n\terr := SafeCall(func() { // reuse SafeCall to capture panic semantics\n\t\tresult = f() // invoke original function and store its result\n\t})\n\tif err != nil { // propagate panic as error while returning zero value\n\t\treturn zero, err\n\t}\n\treturn result, nil // deliver computed value alongside nil error\n}\n\nfunc RecoverString(f func()) (string, bool) {\n\tvar message string // hold textual representation of panic\n\tvar panicked bool  // flag indicates whether panic occurred\n\tdefer func() {\n\t\tif r := recover(); r != nil { // capture panic payload if any\n\t\t\tmessage = fmt.Sprint(r) // convert payload into string form\n\t\t\tpanicked = true         // mark that panic was observed\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when present\n\t\tf() // run user function inside recovery scope\n\t}\n\treturn message, panicked // return captured message and panic flag\n}\n\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered inside f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // translate panic into error return\n\t\t}\n\t}()\n\tif f == nil { // nil function is treated as success\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil { // invoke function and check returned error\n\t\treturn callErr // forward user-supplied error without wrapping\n\t}\n\treturn nil // return success when no panic or error occurred\n}\n\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1) // buffered channel delivers single result\n\tgo func() {\n\t\tdefer close(out)  // ensure channel is closed exactly once\n\t\tvar panicked bool // track whether panic handler already wrote to channel\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil { // catch panics from user function\n\t\t\t\tpanicked = true                   // mark panic occurrence to skip further writes\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r) // send panic as error to consumer\n\t\t\t}\n\t\t}()\n\t\tif f == nil { // treat nil function as no-op success\n\t\t\tselect {\n\t\t\tcase out <- nil: // emit success to listener\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx) // execute user function with propagated context\n\t\tif panicked { // skip delivering additional value when panic already reported\n\t\t\treturn\n\t\t}\n\t\tif err != nil { // propagate explicit error returned by callback\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil { // surface context cancellation if it happened\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil // no errors encountered; report success\n\t}()\n\treturn out // expose result channel to caller\n}\n",
        "testCode": "package panicrecover\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestSafeCall(t *testing.T) {\n\tt.Parallel()\n\tif err := SafeCall(func() {}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := SafeCall(func() { panic(\"boom\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be captured as error\")\n\t}\n}\n\nfunc TestSafeCallValue(t *testing.T) {\n\tt.Parallel()\n\tv, err := SafeCallValue(func() int { return 42 })\n\tif err != nil || v != 42 {\n\t\tt.Fatalf(\"unexpected result: %v %v\", v, err)\n\t}\n\tif _, err := SafeCallValue(func() int { panic(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected panic to become error\")\n\t}\n}\n\nfunc TestRecoverString(t *testing.T) {\n\tt.Parallel()\n\tif msg, ok := RecoverString(func() {}); ok || msg != \"\" {\n\t\tt.Fatalf(\"expected no panic, got %q ok=%v\", msg, ok)\n\t}\n\tmsg, ok := RecoverString(func() { panic(\"hello\") })\n\tif !ok || msg != \"hello\" {\n\t\tt.Fatalf(\"expected panic message 'hello', got %q ok=%v\", msg, ok)\n\t}\n}\n\nfunc TestGuard(t *testing.T) {\n\tt.Parallel()\n\tif err := Guard(func() error { return nil }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := Guard(func() error { return errors.New(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected original error to propagate\")\n\t}\n\tif err := Guard(func() error { panic(\"guard\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be converted to error\")\n\t}\n}\n\nfunc TestGoSafe(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch := GoSafe(ctx, func(context.Context) error { return nil })\n\tselect {\n\tcase err, ok := <-ch:\n\t\tif !ok {\n\t\t\tt.Fatal(\"channel closed without value\")\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for GoSafe result\")\n\t}\n\tpanicCh := GoSafe(ctx, func(context.Context) error { panic(\"boom\") })\n\tselect {\n\tcase err := <-panicCh:\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expected error from panic\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for panic propagation\")\n\t}\n}\n",
        "tags": [
          "go",
          "panicrecover"
        ],
        "order": 3
      },
      {
        "package": "panicrecover",
        "slug": "go-panicrecover-gosafe",
        "title": "GoSafe запускает f в горутине, возвращая канал ошибок и уважая ctx.Done().",
        "description": "Level 5 (medium+): GoSafe запускает f в горутине, возвращая канал ошибок и уважая ctx.Done().\nHint: при панике или ошибке отправляйте значение в канал, и закройте его после завершения.",
        "difficulty": "medium",
        "hint1": "при панике или ошибке отправляйте значение в канал, и закройте его после завершения.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\n// Level 1 (easy): SafeCall вызывает f и перехватывает панику, возвращая ошибку fmt.Errorf(\"panic: %v\", x).\n// Hint: используйте named return err и defer с recover().\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn err\n}\n\n// Level 2 (easy+): SafeCallValue выполняет f, возвращает его результат и ловит панику.\n// Hint: примените SafeCall внутри и возвращайте значение только при успехе.\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T\n\tif f == nil {\n\t\treturn zero, nil\n\t}\n\tvar result T\n\terr := SafeCall(func() {\n\t\tresult = f()\n\t})\n\tif err != nil {\n\t\treturn zero, err\n\t}\n\treturn result, nil\n}\n\n// Level 3 (medium): RecoverString сообщает текст паники и факт её наличия.\n// Hint: захватите recover() в defer и преобразуйте результат в string.\nfunc RecoverString(f func()) (msg string, panicked bool) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tmsg = fmt.Sprint(r)\n\t\t\tpanicked = true\n\t\t}\n\t}()\n\tif f != nil {\n\t\tf()\n\t}\n\treturn msg, panicked\n}\n\n// Level 4 (medium+): Guard выполняет f и преобразует панику в ошибку типа error.\n// Hint: оборачивайте f в функцию, возвращающую error, а паники переводите в fmt.Errorf.\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = fmt.Errorf(\"panic: %v\", r)\n\t\t}\n\t}()\n\tif f == nil {\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil {\n\t\treturn callErr\n\t}\n\treturn nil\n}\n\n// Level 5 (medium+): GoSafe запускает f в горутине, возвращая канал ошибок и уважая ctx.Done().\n// Hint: при панике или ошибке отправляйте значение в канал, и закройте его после завершения.\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1)\n\n\tgo func() {\n\t\tdefer close(out)\n\t\tvar panicked bool\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tpanicked = true\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r)\n\t\t\t}\n\t\t}()\n\t\tif f == nil {\n\t\t\tselect {\n\t\t\tcase out <- nil:\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx)\n\t\tif panicked {\n\t\t\treturn\n\t\t}\n\t\tif err != nil {\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil {\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil\n\t}()\n\n\treturn out\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage panicrecover\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\nfunc SafeCall(f func()) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered by f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // convert panic payload into error result\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when provided\n\t\tf() // run user-supplied function in guarded scope\n\t}\n\treturn err // return nil or panic-derived error\n}\n\nfunc SafeCallValue[T any](f func() T) (T, error) {\n\tvar zero T    // prepare zero value to return on failure\n\tif f == nil { // bail out early when no function supplied\n\t\treturn zero, nil\n\t}\n\tvar result T             // capture successful return value\n\terr := SafeCall(func() { // reuse SafeCall to capture panic semantics\n\t\tresult = f() // invoke original function and store its result\n\t})\n\tif err != nil { // propagate panic as error while returning zero value\n\t\treturn zero, err\n\t}\n\treturn result, nil // deliver computed value alongside nil error\n}\n\nfunc RecoverString(f func()) (string, bool) {\n\tvar message string // hold textual representation of panic\n\tvar panicked bool  // flag indicates whether panic occurred\n\tdefer func() {\n\t\tif r := recover(); r != nil { // capture panic payload if any\n\t\t\tmessage = fmt.Sprint(r) // convert payload into string form\n\t\t\tpanicked = true         // mark that panic was observed\n\t\t}\n\t}()\n\tif f != nil { // execute callback only when present\n\t\tf() // run user function inside recovery scope\n\t}\n\treturn message, panicked // return captured message and panic flag\n}\n\nfunc Guard(f func() error) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil { // intercept panic triggered inside f\n\t\t\terr = fmt.Errorf(\"panic: %v\", r) // translate panic into error return\n\t\t}\n\t}()\n\tif f == nil { // nil function is treated as success\n\t\treturn nil\n\t}\n\tif callErr := f(); callErr != nil { // invoke function and check returned error\n\t\treturn callErr // forward user-supplied error without wrapping\n\t}\n\treturn nil // return success when no panic or error occurred\n}\n\nfunc GoSafe(ctx context.Context, f func(context.Context) error) <-chan error {\n\tif ctx == nil { // default to background context when nil provided\n\t\tctx = context.Background()\n\t}\n\tout := make(chan error, 1) // buffered channel delivers single result\n\tgo func() {\n\t\tdefer close(out)  // ensure channel is closed exactly once\n\t\tvar panicked bool // track whether panic handler already wrote to channel\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil { // catch panics from user function\n\t\t\t\tpanicked = true                   // mark panic occurrence to skip further writes\n\t\t\t\tout <- fmt.Errorf(\"panic: %v\", r) // send panic as error to consumer\n\t\t\t}\n\t\t}()\n\t\tif f == nil { // treat nil function as no-op success\n\t\t\tselect {\n\t\t\tcase out <- nil: // emit success to listener\n\t\t\tdefault:\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\terr := f(ctx) // execute user function with propagated context\n\t\tif panicked { // skip delivering additional value when panic already reported\n\t\t\treturn\n\t\t}\n\t\tif err != nil { // propagate explicit error returned by callback\n\t\t\tout <- err\n\t\t\treturn\n\t\t}\n\t\tif ctxErr := ctx.Err(); ctxErr != nil { // surface context cancellation if it happened\n\t\t\tout <- ctxErr\n\t\t\treturn\n\t\t}\n\t\tout <- nil // no errors encountered; report success\n\t}()\n\treturn out // expose result channel to caller\n}\n",
        "testCode": "package panicrecover\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestSafeCall(t *testing.T) {\n\tt.Parallel()\n\tif err := SafeCall(func() {}); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := SafeCall(func() { panic(\"boom\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be captured as error\")\n\t}\n}\n\nfunc TestSafeCallValue(t *testing.T) {\n\tt.Parallel()\n\tv, err := SafeCallValue(func() int { return 42 })\n\tif err != nil || v != 42 {\n\t\tt.Fatalf(\"unexpected result: %v %v\", v, err)\n\t}\n\tif _, err := SafeCallValue(func() int { panic(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected panic to become error\")\n\t}\n}\n\nfunc TestRecoverString(t *testing.T) {\n\tt.Parallel()\n\tif msg, ok := RecoverString(func() {}); ok || msg != \"\" {\n\t\tt.Fatalf(\"expected no panic, got %q ok=%v\", msg, ok)\n\t}\n\tmsg, ok := RecoverString(func() { panic(\"hello\") })\n\tif !ok || msg != \"hello\" {\n\t\tt.Fatalf(\"expected panic message 'hello', got %q ok=%v\", msg, ok)\n\t}\n}\n\nfunc TestGuard(t *testing.T) {\n\tt.Parallel()\n\tif err := Guard(func() error { return nil }); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif err := Guard(func() error { return errors.New(\"fail\") }); err == nil {\n\t\tt.Fatal(\"expected original error to propagate\")\n\t}\n\tif err := Guard(func() error { panic(\"guard\") }); err == nil {\n\t\tt.Fatal(\"expected panic to be converted to error\")\n\t}\n}\n\nfunc TestGoSafe(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tch := GoSafe(ctx, func(context.Context) error { return nil })\n\tselect {\n\tcase err, ok := <-ch:\n\t\tif !ok {\n\t\t\tt.Fatal(\"channel closed without value\")\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for GoSafe result\")\n\t}\n\tpanicCh := GoSafe(ctx, func(context.Context) error { panic(\"boom\") })\n\tselect {\n\tcase err := <-panicCh:\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expected error from panic\")\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timeout waiting for panic propagation\")\n\t}\n}\n",
        "tags": [
          "go",
          "panicrecover"
        ],
        "order": 4
      }
    ],
    "category": "production"
  },
  {
    "name": "pointersx",
    "tasks": [
      {
        "package": "pointersx",
        "slug": "go-pointersx-zeroint",
        "title": "ZeroInt устанавливает значение по указателю в 0.",
        "description": "Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\nHint: проверьте указатель на nil и разыменуйте его.",
        "difficulty": "easy",
        "hint1": "проверьте указатель на nil и разыменуйте его.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 0
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-swapstrings",
        "title": "SwapStrings меняет местами строки по указателям.",
        "description": "Level 1 (easy): SwapStrings меняет местами строки по указателям.\nHint: работайте только если оба указателя не nil.",
        "difficulty": "easy",
        "hint1": "работайте только если оба указателя не nil.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 0
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-applydiscount",
        "title": "ApplyDiscount уменьшает цену на percent процентов.",
        "description": "Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\nHint: процент приходит в диапазоне 0..100, учтите nil указатель.",
        "difficulty": "easy",
        "hint1": "процент приходит в диапазоне 0..100, учтите nil указатель.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 0
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-normalizeuser",
        "title": "NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.",
        "description": "Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\nHint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.",
        "difficulty": "easy",
        "hint1": "используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 1
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-increment",
        "title": "Increment увеличивает значение счётчика на 1.",
        "description": "Level 2 (easy+): Increment увеличивает значение счётчика на 1.\nHint: методы с указателем получают nil при вызове на nil-переменной.",
        "difficulty": "easy",
        "hint1": "методы с указателем получают nil при вызове на nil-переменной.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 1
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-add",
        "title": "Add добавляет delta к счётчику и возвращает новое значение.",
        "description": "Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\nHint: измените поле Value и верните результат; защититесь от nil-получателя.",
        "difficulty": "medium",
        "hint1": "измените поле Value и верните результат; защититесь от nil-получателя.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 2
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-ensuremetadata",
        "title": "EnsureMetadata гарантирует готовую map у документа.",
        "description": "Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\nHint: верните управление для nil-указателя; при nil-карте выделите новую map.",
        "difficulty": "medium",
        "hint1": "верните управление для nil-указателя; при nil-карте выделите новую map.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 2
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-attachtag",
        "title": "AttachTag добавляет пару ключ/значение в метаданные документа.",
        "description": "Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\nHint: позаботьтесь об инициализации карты и обработайте nil-указатель.",
        "difficulty": "medium",
        "hint1": "позаботьтесь об инициализации карты и обработайте nil-указатель.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 3
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-ensureconfig",
        "title": "EnsureConfig гарантирует наличие Config с данными по умолчанию.",
        "description": "Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\nHint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.",
        "difficulty": "medium",
        "hint1": "если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 3
      },
      {
        "package": "pointersx",
        "slug": "go-pointersx-walknodes",
        "title": "WalkNodes обходит список, вызывая visit для каждого узла.",
        "description": "Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\nHint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.",
        "difficulty": "hard",
        "hint1": "аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage pointersx\n\nimport \"strings\"\n\n// Level 1 (easy): ZeroInt устанавливает значение по указателю в 0.\n// Hint: проверьте указатель на nil и разыменуйте его.\nfunc ZeroInt(p *int) {\n\tif p == nil {\n\t\treturn\n\t}\n\t*p = 0\n}\n\n// Level 1 (easy): SwapStrings меняет местами строки по указателям.\n// Hint: работайте только если оба указателя не nil.\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil {\n\t\treturn\n\t}\n\t*a, *b = *b, *a\n}\n\n// Level 1 (easy): ApplyDiscount уменьшает цену на percent процентов.\n// Hint: процент приходит в диапазоне 0..100, учтите nil указатель.\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil {\n\t\treturn\n\t}\n\t*price = *price - (*price / 100 * percent)\n}\n\n// User описывает пользователя с именем и email.\ntype User struct {\n\tName  string\n\tEmail string\n}\n\n// Level 2 (easy+): NormalizeUser приводит имя к trimmed виду, а email к нижнему регистру.\n// Hint: используйте strings.TrimSpace и strings.ToLower, аккуратно обрабатывая nil указатель.\nfunc NormalizeUser(u *User) {\n\tif u == nil {\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name)\n\tu.Email = strings.ToLower(u.Email)\n}\n\n// Counter хранит числовое значение для демонстрации методов с указателями.\ntype Counter struct {\n\tValue int\n}\n\n// Level 2 (easy+): Increment увеличивает значение счётчика на 1.\n// Hint: методы с указателем получают nil при вызове на nil-переменной.\nfunc (c *Counter) Increment() {\n\tif c == nil {\n\t\treturn\n\t}\n\tc.Value++\n}\n\n// Level 3 (medium): Add добавляет delta к счётчику и возвращает новое значение.\n// Hint: измените поле Value и верните результат; защититесь от nil-получателя.\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil {\n\t\treturn 0\n\t}\n\tc.Value += delta\n\treturn c.Value\n}\n\n// Document описывает документ с динамическими метаданными.\ntype Document struct {\n\tTitle    string\n\tMetadata map[string]string\n}\n\n// Level 3 (medium): EnsureMetadata гарантирует готовую map у документа.\n// Hint: верните управление для nil-указателя; при nil-карте выделите новую map.\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil {\n\t\treturn\n\t}\n\tdoc.Metadata = make(map[string]string)\n}\n\n// Level 4 (medium+): AttachTag добавляет пару ключ/значение в метаданные документа.\n// Hint: позаботьтесь об инициализации карты и обработайте nil-указатель.\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil || key == \"\" || value == \"\" {\n\t\treturn\n\t}\n\tif doc.Metadata == nil {\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value\n}\n\n// Config описывает сетевые параметры.\ntype Config struct {\n\tHost string\n\tPort int\n}\n\n// Level 4 (medium+): EnsureConfig гарантирует наличие Config с данными по умолчанию.\n// Hint: если cfg nil или *cfg == nil — выделите новую структуру с Host localhost и Port 8080.\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil {\n\t\treturn\n\t}\n\tif *cfg == nil {\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\",\n\t\t\tPort: 8080,\n\t\t}\n\t}\n\n}\n\n// Node представляет узел односвязного списка.\ntype Node struct {\n\tValue int\n\tNext  *Node\n}\n\n// Level 5 (hard): WalkNodes обходит список, вызывая visit для каждого узла.\n// Hint: аккуратно обойдите nil-голову и nil-функцию; двигайтесь по Next пока он не nil.\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif head == nil || visit == nil {\n\t\treturn\n\t}\n\tfor head != nil {\n\t\tvisit(head)\n\t\thead = head.Next\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage pointersx\n\nimport \"strings\"\n\ntype User struct {\n\tName  string // store displayable user name\n\tEmail string // store raw email address\n}\n\ntype Counter struct {\n\tValue int // accumulated integer value\n}\n\ntype Document struct {\n\tTitle    string            // human readable title of the document\n\tMetadata map[string]string // arbitrary metadata key/value pairs\n}\n\ntype Config struct {\n\tHost string // host the client should connect to\n\tPort int    // port exposed by the service\n}\n\ntype Node struct {\n\tValue int   // payload stored in this list node\n\tNext  *Node // pointer to the next element in the chain\n}\n\nfunc ZeroInt(p *int) {\n\tif p == nil { // guard against nil pointer to avoid panic\n\t\treturn\n\t}\n\t*p = 0 // overwrite pointed value with zero\n}\n\nfunc SwapStrings(a, b *string) {\n\tif a == nil || b == nil { // swap only possible when both pointers are valid\n\t\treturn\n\t}\n\t*a, *b = *b, *a // perform tuple swap via parallel assignment\n}\n\nfunc ApplyDiscount(price *float64, percent float64) {\n\tif price == nil { // nothing to discount when pointer is nil\n\t\treturn\n\t}\n\tdiscount := *price * percent / 100 // compute discount amount as fraction of the price\n\t*price = *price - discount         // subtract discount from original price\n}\n\nfunc NormalizeUser(u *User) {\n\tif u == nil { // do nothing for nil pointer receiver\n\t\treturn\n\t}\n\tu.Name = strings.TrimSpace(u.Name) // remove leading and trailing whitespace from name\n\tu.Email = strings.ToLower(u.Email) // convert email to lower case for normalization\n}\n\nfunc (c *Counter) Increment() {\n\tif c == nil { // protect against method call on nil pointer\n\t\treturn\n\t}\n\tc.Value++ // increase internal counter value by one\n}\n\nfunc (c *Counter) Add(delta int) int {\n\tif c == nil { // nil receiver cannot store state, return neutral result\n\t\treturn 0\n\t}\n\tc.Value += delta // mutate stored value by adding delta\n\treturn c.Value   // report updated value back to caller\n}\n\nfunc EnsureMetadata(doc *Document) {\n\tif doc == nil { // nil pointer cannot be fixed, exit early\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // allocate metadata map when absent\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n}\n\nfunc AttachTag(doc *Document, key, value string) {\n\tif doc == nil { // nothing to attach to when pointer is nil\n\t\treturn\n\t}\n\tif doc.Metadata == nil { // lazily allocate metadata container\n\t\tdoc.Metadata = make(map[string]string)\n\t}\n\tdoc.Metadata[key] = value // store provided key/value pair in metadata\n}\n\nfunc EnsureConfig(cfg **Config) {\n\tif cfg == nil { // cannot modify through nil double pointer\n\t\treturn\n\t}\n\tif *cfg == nil { // instantiate config when underlying pointer is absent\n\t\t*cfg = &Config{\n\t\t\tHost: \"localhost\", // default host value\n\t\t\tPort: 8080,        // default port value\n\t\t}\n\t}\n}\n\nfunc WalkNodes(head *Node, visit func(*Node)) {\n\tif visit == nil { // visiting requires a callback, skip when absent\n\t\treturn\n\t}\n\tfor node := head; node != nil; node = node.Next { // iterate through linked list until tail\n\t\tvisit(node) // invoke callback on each encountered node\n\t}\n}\n",
        "testCode": "package pointersx\n\nimport (\n\t\"math\"\n\t\"testing\"\n)\n\nfunc TestZeroInt(t *testing.T) {\n\tt.Parallel()\n\tvalue := 42\n\tZeroInt(&value)\n\tif value != 0 {\n\t\tt.Fatalf(\"expected value to be zeroed, got %d\", value)\n\t}\n\tZeroInt(nil) // should be no-op without panic\n}\n\nfunc TestSwapStrings(t *testing.T) {\n\tt.Parallel()\n\ta := \"left\"\n\tb := \"right\"\n\tSwapStrings(&a, &b)\n\tif a != \"right\" || b != \"left\" {\n\t\tt.Fatalf(\"expected strings to be swapped, got a=%q b=%q\", a, b)\n\t}\n\torig := a\n\tSwapStrings(nil, &b)\n\tif a != orig || b != \"left\" {\n\t\tt.Fatalf(\"unexpected mutation when one pointer is nil, a=%q b=%q\", a, b)\n\t}\n}\n\nfunc TestApplyDiscount(t *testing.T) {\n\tt.Parallel()\n\tprice := 200.0\n\tApplyDiscount(&price, 25)\n\tif diff := math.Abs(price - 150.0); diff > 1e-9 {\n\t\tt.Fatalf(\"expected discounted price 150, got %.2f\", price)\n\t}\n\tApplyDiscount(nil, 10) // should safely do nothing\n}\n\nfunc TestNormalizeUser(t *testing.T) {\n\tt.Parallel()\n\tuser := &User{Name: \"  Alice  \", Email: \"ALICE@EXAMPLE.COM\"}\n\tNormalizeUser(user)\n\tif user.Name != \"Alice\" {\n\t\tt.Fatalf(\"expected trimmed name, got %q\", user.Name)\n\t}\n\tif user.Email != \"alice@example.com\" {\n\t\tt.Fatalf(\"expected lower-cased email, got %q\", user.Email)\n\t}\n\tNormalizeUser(nil) // should be safe for nil pointer\n}\n\nfunc TestCounterIncrement(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{}\n\tcounter.Increment()\n\tif counter.Value != 1 {\n\t\tt.Fatalf(\"expected counter to increment to 1, got %d\", counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tnilCounter.Increment() // should not panic\n}\n\nfunc TestCounterAdd(t *testing.T) {\n\tt.Parallel()\n\tcounter := &Counter{Value: 10}\n\tif newValue := counter.Add(5); newValue != 15 || counter.Value != 15 {\n\t\tt.Fatalf(\"expected counter to reach 15, got value=%d stored=%d\", newValue, counter.Value)\n\t}\n\tvar nilCounter *Counter\n\tif result := nilCounter.Add(3); result != 0 {\n\t\tt.Fatalf(\"expected zero from Add on nil receiver, got %d\", result)\n\t}\n}\n\nfunc TestEnsureMetadata(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"spec\"}\n\tEnsureMetadata(doc)\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to be initialized\")\n\t}\n\tEnsureMetadata(nil) // should not panic\n}\n\nfunc TestAttachTag(t *testing.T) {\n\tt.Parallel()\n\tdoc := &Document{Title: \"post\"}\n\tAttachTag(doc, \"type\", \"blog\")\n\tif doc.Metadata == nil {\n\t\tt.Fatal(\"expected metadata map to exist after AttachTag\")\n\t}\n\tif val := doc.Metadata[\"type\"]; val != \"blog\" {\n\t\tt.Fatalf(\"expected metadata value blog, got %q\", val)\n\t}\n\tAttachTag(nil, \"ignored\", \"value\") // should be safe\n}\n\nfunc TestEnsureConfig(t *testing.T) {\n\tt.Parallel()\n\tvar cfg *Config\n\tEnsureConfig(&cfg)\n\tif cfg == nil {\n\t\tt.Fatal(\"expected config pointer to be allocated\")\n\t}\n\tif cfg.Host != \"localhost\" || cfg.Port != 8080 {\n\t\tt.Fatalf(\"expected default config, got host=%q port=%d\", cfg.Host, cfg.Port)\n\t}\n\texisting := &Config{Host: \"remote\", Port: 9000}\n\tptr := existing\n\tEnsureConfig(&ptr)\n\tif ptr != existing {\n\t\tt.Fatal(\"expected existing config pointer to remain unchanged\")\n\t}\n\tif ptr.Host != \"remote\" || ptr.Port != 9000 {\n\t\tt.Fatal(\"expected existing config values to be preserved\")\n\t}\n\tEnsureConfig(nil) // should not panic\n}\n\nfunc TestWalkNodes(t *testing.T) {\n\tt.Parallel()\n\tthird := &Node{Value: 3}\n\tsecond := &Node{Value: 2, Next: third}\n\tfirst := &Node{Value: 1, Next: second}\n\n\tvar visited []int\n\tWalkNodes(first, func(node *Node) {\n\t\tvisited = append(visited, node.Value)\n\t})\n\texpected := []int{1, 2, 3}\n\tif len(visited) != len(expected) {\n\t\tt.Fatalf(\"expected %d nodes, visited %d\", len(expected), len(visited))\n\t}\n\tfor i, v := range expected {\n\t\tif visited[i] != v {\n\t\t\tt.Fatalf(\"expected visit order %v, got %v\", expected, visited)\n\t\t}\n\t}\n\n\tWalkNodes(nil, func(*Node) { t.Fatal(\"visit should not be called for nil head\") })\n\tWalkNodes(first, nil) // should not panic if visitor is nil\n}\n",
        "tags": [
          "go",
          "pointersx"
        ],
        "order": 4
      }
    ],
    "category": "core"
  },
  {
    "name": "profilingx",
    "tasks": [
      {
        "package": "profilingx",
        "slug": "go-profilingx-betterconcat",
        "title": "BetterConcat должен использовать strings.Builder и предварительно резервировать ёмкость.",
        "description": "Level 1 (easy+): BetterConcat должен использовать strings.Builder и предварительно резервировать ёмкость.\nHint: посчитайте суммарную длину и вызовите builder.Grow.",
        "difficulty": "easy",
        "hint1": "посчитайте суммарную длину и вызовите builder.Grow.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Требования и подсказки по профилированию:\n// 1. Сначала зафиксируйте базовые показатели на наивных реализациях:\n//    go test -run '^$' -bench Concat -benchmem ./internal/profilingx\n//    go test -run '^$' -bench Alloc -benchmem ./internal/profilingx\n// 2. Соберите CPU-профиль, чтобы увидеть горячие участки:\n//    go test -run '^$' -bench . -benchmem -cpuprofile=cpu.out ./internal/profilingx\n//    go tool pprof cpu.out\n//    go tool pprof -http=:8080 cpu.out     (удобный веб-интерфейс)\n// 3. Проанализируйте распределение памяти:\n//    go test -run '^$' -bench . -benchmem -memprofile=mem.out ./internal/profilingx\n//    go tool pprof mem.out\n// 4. Для сравнения с эталонным решением запустите:\n//    go test -tags solution -run '^$' -bench . -benchmem ./internal/profilingx\n// Эти команды помогут понять, какие оптимизации нужны для BetterConcat, BetterAlloc,\n// AcquireBuffer, ReleaseBuffer и CloneStrings, и проверить эффект от изменений.\n\n// NaiveConcat демонстрирует неоптимальное поведение и остаётся реализованной для сравнения.\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\n// NaiveAlloc — эталон неэффективного подхода.\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\n// Level 1 (easy+): BetterConcat должен использовать strings.Builder и предварительно резервировать ёмкость.\n// Hint: посчитайте суммарную длину и вызовите builder.Grow.\nfunc BetterConcat(parts []string) string {\n\tn := 0\n\n\tfor _, p := range parts {\n\t\tn += len(p)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(n)\n\n\tfor _, p := range parts {\n\t\tbuilder.WriteString(p)\n\t}\n\treturn builder.String()\n}\n\n// Level 2 (medium): BetterAlloc создаёт слайс с нужной capacity и заполняет случайными числами без лишних аллокаций.\n// Hint: используйте make([]int, 0, n) или make([]int, n) и присваивание по индексам.\nfunc BetterAlloc(n int) []int {\n\tout := make([]int, n)\n\treturn out\n}\n\n// Level 3 (medium): AcquireBuffer берёт []byte из sync.Pool, гарантируя minCap вместимость.\n// Hint: расширьте buffer если текущей ёмкости недостаточно.\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte\n\tif pool != nil {\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte)\n\t\t}\n\t}\n\tif cap(buf) < minCap {\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0]\n}\n\n// Level 4 (medium+): ReleaseBuffer обнуляет длину слайса и возвращает его в пул.\n// Hint: приведите buf[:0] перед передачей в pool.Put.\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil {\n\t\treturn\n\t}\n\tbuf = buf[:0]\n\tpool.Put(&buf)\n}\n\n// Level 5 (medium+): CloneStrings создаёт копию слайса строк без повторных аллокаций элементов.\n// Hint: выделите новый слайс нужной длины и используйте copy.\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src))\n\tcopy(clone, src)\n\treturn clone\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\nfunc BetterConcat(parts []string) string {\n\tswitch len(parts) { // handle trivial cases without extra work\n\tcase 0:\n\t\treturn \"\" // empty slice yields empty string\n\tcase 1:\n\t\treturn parts[0] // single element already concatenated\n\t}\n\ttotal := 0                   // track total length of all input fragments\n\tfor _, part := range parts { // accumulate length of each component\n\t\ttotal += len(part)\n\t}\n\tvar builder strings.Builder  // builder avoids repeated reallocations\n\tbuilder.Grow(total)          // preallocate exact capacity to prevent growth\n\tfor _, part := range parts { // append every piece in order\n\t\tbuilder.WriteString(part) // write fragment into builder buffer\n\t}\n\treturn builder.String() // produce final concatenated string from builder\n}\n\nfunc BetterAlloc(n int) []int {\n\tif n <= 0 { // guard against negative or zero sizes\n\t\treturn nil\n\t}\n\tout := make([]int, n) // allocate slice with final capacity upfront\n\tfor i := range out {  // fill each element without changing length\n\t\tout[i] = rand.Intn(1000) // populate slice with random numbers\n\t}\n\treturn out // return fully initialized slice\n}\n\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte   // placeholder for buffer retrieved from pool\n\tif pool != nil { // attempt to reuse pooled slice when pool provided\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte) // type assert retrieved value to []byte\n\t\t}\n\t}\n\tif cap(buf) < minCap { // allocate fresh slice when capacity insufficient\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0] // reuse buffer with length reset to zero\n}\n\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil { // nothing to do when pool is absent\n\t\treturn\n\t}\n\tpool.Put(buf[:0]) // reset length and put slice back into pool\n}\n\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src)) // allocate slice with identical length\n\tcopy(clone, src)                  // duplicate contents in one pass\n\treturn clone                      // return independent copy of data\n}\n",
        "testCode": "package profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestBetterConcat(t *testing.T) {\n\tt.Parallel()\n\tparts := []string{\"a\", \"b\", \"c\"}\n\tif res := BetterConcat(parts); res != \"abc\" {\n\t\tt.Fatalf(\"unexpected concat result: %q\", res)\n\t}\n}\n\nfunc TestBetterAlloc(t *testing.T) {\n\tt.Parallel()\n\tout := BetterAlloc(8)\n\tif len(out) != 8 {\n\t\tt.Fatalf(\"expected len 8, got %d\", len(out))\n\t}\n}\n\nfunc TestAcquireBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := AcquireBuffer(pool, 8)\n\tif cap(buf) < 8 {\n\t\tt.Fatalf(\"expected capacity >=8, got %d\", cap(buf))\n\t}\n}\n\nfunc TestReleaseBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := []byte(\"hello\")\n\tReleaseBuffer(pool, buf)\n\tgot := pool.Get().([]byte)\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"expected reset slice, got len=%d\", len(got))\n\t}\n}\n\nfunc TestCloneStrings(t *testing.T) {\n\tt.Parallel()\n\tsrc := []string{\"a\", \"b\", \"c\"}\n\tclone := CloneStrings(src)\n\tif len(clone) != len(src) || clone[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected clone result: %v\", clone)\n\t}\n\tclone[0] = \"z\"\n\tif src[0] == \"z\" {\n\t\tt.Fatal(\"expected deep copy, original modified\")\n\t}\n}\n\nfunc BenchmarkConcat_Naive(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveConcat(parts)\n\t}\n}\n\nfunc BenchmarkConcat_Better(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterConcat(parts)\n\t}\n}\n\nfunc BenchmarkAlloc_Naive(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveAlloc(1_000)\n\t}\n}\n\nfunc BenchmarkAlloc_Better(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterAlloc(1_000)\n\t\tfor j := 0; j < 1_000; j++ {\n\t\t\t_ = rand.Intn(1000)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "profilingx"
        ],
        "order": 0
      },
      {
        "package": "profilingx",
        "slug": "go-profilingx-betteralloc",
        "title": "BetterAlloc создаёт слайс с нужной capacity и заполняет случайными числами без лишних аллокаций.",
        "description": "Level 2 (medium): BetterAlloc создаёт слайс с нужной capacity и заполняет случайными числами без лишних аллокаций.\nHint: используйте make([]int, 0, n) или make([]int, n) и присваивание по индексам.",
        "difficulty": "medium",
        "hint1": "используйте make([]int, 0, n) или make([]int, n) и присваивание по индексам.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Требования и подсказки по профилированию:\n// 1. Сначала зафиксируйте базовые показатели на наивных реализациях:\n//    go test -run '^$' -bench Concat -benchmem ./internal/profilingx\n//    go test -run '^$' -bench Alloc -benchmem ./internal/profilingx\n// 2. Соберите CPU-профиль, чтобы увидеть горячие участки:\n//    go test -run '^$' -bench . -benchmem -cpuprofile=cpu.out ./internal/profilingx\n//    go tool pprof cpu.out\n//    go tool pprof -http=:8080 cpu.out     (удобный веб-интерфейс)\n// 3. Проанализируйте распределение памяти:\n//    go test -run '^$' -bench . -benchmem -memprofile=mem.out ./internal/profilingx\n//    go tool pprof mem.out\n// 4. Для сравнения с эталонным решением запустите:\n//    go test -tags solution -run '^$' -bench . -benchmem ./internal/profilingx\n// Эти команды помогут понять, какие оптимизации нужны для BetterConcat, BetterAlloc,\n// AcquireBuffer, ReleaseBuffer и CloneStrings, и проверить эффект от изменений.\n\n// NaiveConcat демонстрирует неоптимальное поведение и остаётся реализованной для сравнения.\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\n// NaiveAlloc — эталон неэффективного подхода.\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\n// Level 1 (easy+): BetterConcat должен использовать strings.Builder и предварительно резервировать ёмкость.\n// Hint: посчитайте суммарную длину и вызовите builder.Grow.\nfunc BetterConcat(parts []string) string {\n\tn := 0\n\n\tfor _, p := range parts {\n\t\tn += len(p)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(n)\n\n\tfor _, p := range parts {\n\t\tbuilder.WriteString(p)\n\t}\n\treturn builder.String()\n}\n\n// Level 2 (medium): BetterAlloc создаёт слайс с нужной capacity и заполняет случайными числами без лишних аллокаций.\n// Hint: используйте make([]int, 0, n) или make([]int, n) и присваивание по индексам.\nfunc BetterAlloc(n int) []int {\n\tout := make([]int, n)\n\treturn out\n}\n\n// Level 3 (medium): AcquireBuffer берёт []byte из sync.Pool, гарантируя minCap вместимость.\n// Hint: расширьте buffer если текущей ёмкости недостаточно.\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte\n\tif pool != nil {\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte)\n\t\t}\n\t}\n\tif cap(buf) < minCap {\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0]\n}\n\n// Level 4 (medium+): ReleaseBuffer обнуляет длину слайса и возвращает его в пул.\n// Hint: приведите buf[:0] перед передачей в pool.Put.\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil {\n\t\treturn\n\t}\n\tbuf = buf[:0]\n\tpool.Put(&buf)\n}\n\n// Level 5 (medium+): CloneStrings создаёт копию слайса строк без повторных аллокаций элементов.\n// Hint: выделите новый слайс нужной длины и используйте copy.\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src))\n\tcopy(clone, src)\n\treturn clone\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\nfunc BetterConcat(parts []string) string {\n\tswitch len(parts) { // handle trivial cases without extra work\n\tcase 0:\n\t\treturn \"\" // empty slice yields empty string\n\tcase 1:\n\t\treturn parts[0] // single element already concatenated\n\t}\n\ttotal := 0                   // track total length of all input fragments\n\tfor _, part := range parts { // accumulate length of each component\n\t\ttotal += len(part)\n\t}\n\tvar builder strings.Builder  // builder avoids repeated reallocations\n\tbuilder.Grow(total)          // preallocate exact capacity to prevent growth\n\tfor _, part := range parts { // append every piece in order\n\t\tbuilder.WriteString(part) // write fragment into builder buffer\n\t}\n\treturn builder.String() // produce final concatenated string from builder\n}\n\nfunc BetterAlloc(n int) []int {\n\tif n <= 0 { // guard against negative or zero sizes\n\t\treturn nil\n\t}\n\tout := make([]int, n) // allocate slice with final capacity upfront\n\tfor i := range out {  // fill each element without changing length\n\t\tout[i] = rand.Intn(1000) // populate slice with random numbers\n\t}\n\treturn out // return fully initialized slice\n}\n\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte   // placeholder for buffer retrieved from pool\n\tif pool != nil { // attempt to reuse pooled slice when pool provided\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte) // type assert retrieved value to []byte\n\t\t}\n\t}\n\tif cap(buf) < minCap { // allocate fresh slice when capacity insufficient\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0] // reuse buffer with length reset to zero\n}\n\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil { // nothing to do when pool is absent\n\t\treturn\n\t}\n\tpool.Put(buf[:0]) // reset length and put slice back into pool\n}\n\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src)) // allocate slice with identical length\n\tcopy(clone, src)                  // duplicate contents in one pass\n\treturn clone                      // return independent copy of data\n}\n",
        "testCode": "package profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestBetterConcat(t *testing.T) {\n\tt.Parallel()\n\tparts := []string{\"a\", \"b\", \"c\"}\n\tif res := BetterConcat(parts); res != \"abc\" {\n\t\tt.Fatalf(\"unexpected concat result: %q\", res)\n\t}\n}\n\nfunc TestBetterAlloc(t *testing.T) {\n\tt.Parallel()\n\tout := BetterAlloc(8)\n\tif len(out) != 8 {\n\t\tt.Fatalf(\"expected len 8, got %d\", len(out))\n\t}\n}\n\nfunc TestAcquireBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := AcquireBuffer(pool, 8)\n\tif cap(buf) < 8 {\n\t\tt.Fatalf(\"expected capacity >=8, got %d\", cap(buf))\n\t}\n}\n\nfunc TestReleaseBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := []byte(\"hello\")\n\tReleaseBuffer(pool, buf)\n\tgot := pool.Get().([]byte)\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"expected reset slice, got len=%d\", len(got))\n\t}\n}\n\nfunc TestCloneStrings(t *testing.T) {\n\tt.Parallel()\n\tsrc := []string{\"a\", \"b\", \"c\"}\n\tclone := CloneStrings(src)\n\tif len(clone) != len(src) || clone[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected clone result: %v\", clone)\n\t}\n\tclone[0] = \"z\"\n\tif src[0] == \"z\" {\n\t\tt.Fatal(\"expected deep copy, original modified\")\n\t}\n}\n\nfunc BenchmarkConcat_Naive(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveConcat(parts)\n\t}\n}\n\nfunc BenchmarkConcat_Better(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterConcat(parts)\n\t}\n}\n\nfunc BenchmarkAlloc_Naive(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveAlloc(1_000)\n\t}\n}\n\nfunc BenchmarkAlloc_Better(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterAlloc(1_000)\n\t\tfor j := 0; j < 1_000; j++ {\n\t\t\t_ = rand.Intn(1000)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "profilingx"
        ],
        "order": 1
      },
      {
        "package": "profilingx",
        "slug": "go-profilingx-acquirebuffer",
        "title": "AcquireBuffer берёт []byte из sync.Pool, гарантируя minCap вместимость.",
        "description": "Level 3 (medium): AcquireBuffer берёт []byte из sync.Pool, гарантируя minCap вместимость.\nHint: расширьте buffer если текущей ёмкости недостаточно.",
        "difficulty": "medium",
        "hint1": "расширьте buffer если текущей ёмкости недостаточно.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Требования и подсказки по профилированию:\n// 1. Сначала зафиксируйте базовые показатели на наивных реализациях:\n//    go test -run '^$' -bench Concat -benchmem ./internal/profilingx\n//    go test -run '^$' -bench Alloc -benchmem ./internal/profilingx\n// 2. Соберите CPU-профиль, чтобы увидеть горячие участки:\n//    go test -run '^$' -bench . -benchmem -cpuprofile=cpu.out ./internal/profilingx\n//    go tool pprof cpu.out\n//    go tool pprof -http=:8080 cpu.out     (удобный веб-интерфейс)\n// 3. Проанализируйте распределение памяти:\n//    go test -run '^$' -bench . -benchmem -memprofile=mem.out ./internal/profilingx\n//    go tool pprof mem.out\n// 4. Для сравнения с эталонным решением запустите:\n//    go test -tags solution -run '^$' -bench . -benchmem ./internal/profilingx\n// Эти команды помогут понять, какие оптимизации нужны для BetterConcat, BetterAlloc,\n// AcquireBuffer, ReleaseBuffer и CloneStrings, и проверить эффект от изменений.\n\n// NaiveConcat демонстрирует неоптимальное поведение и остаётся реализованной для сравнения.\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\n// NaiveAlloc — эталон неэффективного подхода.\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\n// Level 1 (easy+): BetterConcat должен использовать strings.Builder и предварительно резервировать ёмкость.\n// Hint: посчитайте суммарную длину и вызовите builder.Grow.\nfunc BetterConcat(parts []string) string {\n\tn := 0\n\n\tfor _, p := range parts {\n\t\tn += len(p)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(n)\n\n\tfor _, p := range parts {\n\t\tbuilder.WriteString(p)\n\t}\n\treturn builder.String()\n}\n\n// Level 2 (medium): BetterAlloc создаёт слайс с нужной capacity и заполняет случайными числами без лишних аллокаций.\n// Hint: используйте make([]int, 0, n) или make([]int, n) и присваивание по индексам.\nfunc BetterAlloc(n int) []int {\n\tout := make([]int, n)\n\treturn out\n}\n\n// Level 3 (medium): AcquireBuffer берёт []byte из sync.Pool, гарантируя minCap вместимость.\n// Hint: расширьте buffer если текущей ёмкости недостаточно.\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte\n\tif pool != nil {\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte)\n\t\t}\n\t}\n\tif cap(buf) < minCap {\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0]\n}\n\n// Level 4 (medium+): ReleaseBuffer обнуляет длину слайса и возвращает его в пул.\n// Hint: приведите buf[:0] перед передачей в pool.Put.\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil {\n\t\treturn\n\t}\n\tbuf = buf[:0]\n\tpool.Put(&buf)\n}\n\n// Level 5 (medium+): CloneStrings создаёт копию слайса строк без повторных аллокаций элементов.\n// Hint: выделите новый слайс нужной длины и используйте copy.\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src))\n\tcopy(clone, src)\n\treturn clone\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\nfunc BetterConcat(parts []string) string {\n\tswitch len(parts) { // handle trivial cases without extra work\n\tcase 0:\n\t\treturn \"\" // empty slice yields empty string\n\tcase 1:\n\t\treturn parts[0] // single element already concatenated\n\t}\n\ttotal := 0                   // track total length of all input fragments\n\tfor _, part := range parts { // accumulate length of each component\n\t\ttotal += len(part)\n\t}\n\tvar builder strings.Builder  // builder avoids repeated reallocations\n\tbuilder.Grow(total)          // preallocate exact capacity to prevent growth\n\tfor _, part := range parts { // append every piece in order\n\t\tbuilder.WriteString(part) // write fragment into builder buffer\n\t}\n\treturn builder.String() // produce final concatenated string from builder\n}\n\nfunc BetterAlloc(n int) []int {\n\tif n <= 0 { // guard against negative or zero sizes\n\t\treturn nil\n\t}\n\tout := make([]int, n) // allocate slice with final capacity upfront\n\tfor i := range out {  // fill each element without changing length\n\t\tout[i] = rand.Intn(1000) // populate slice with random numbers\n\t}\n\treturn out // return fully initialized slice\n}\n\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte   // placeholder for buffer retrieved from pool\n\tif pool != nil { // attempt to reuse pooled slice when pool provided\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte) // type assert retrieved value to []byte\n\t\t}\n\t}\n\tif cap(buf) < minCap { // allocate fresh slice when capacity insufficient\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0] // reuse buffer with length reset to zero\n}\n\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil { // nothing to do when pool is absent\n\t\treturn\n\t}\n\tpool.Put(buf[:0]) // reset length and put slice back into pool\n}\n\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src)) // allocate slice with identical length\n\tcopy(clone, src)                  // duplicate contents in one pass\n\treturn clone                      // return independent copy of data\n}\n",
        "testCode": "package profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestBetterConcat(t *testing.T) {\n\tt.Parallel()\n\tparts := []string{\"a\", \"b\", \"c\"}\n\tif res := BetterConcat(parts); res != \"abc\" {\n\t\tt.Fatalf(\"unexpected concat result: %q\", res)\n\t}\n}\n\nfunc TestBetterAlloc(t *testing.T) {\n\tt.Parallel()\n\tout := BetterAlloc(8)\n\tif len(out) != 8 {\n\t\tt.Fatalf(\"expected len 8, got %d\", len(out))\n\t}\n}\n\nfunc TestAcquireBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := AcquireBuffer(pool, 8)\n\tif cap(buf) < 8 {\n\t\tt.Fatalf(\"expected capacity >=8, got %d\", cap(buf))\n\t}\n}\n\nfunc TestReleaseBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := []byte(\"hello\")\n\tReleaseBuffer(pool, buf)\n\tgot := pool.Get().([]byte)\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"expected reset slice, got len=%d\", len(got))\n\t}\n}\n\nfunc TestCloneStrings(t *testing.T) {\n\tt.Parallel()\n\tsrc := []string{\"a\", \"b\", \"c\"}\n\tclone := CloneStrings(src)\n\tif len(clone) != len(src) || clone[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected clone result: %v\", clone)\n\t}\n\tclone[0] = \"z\"\n\tif src[0] == \"z\" {\n\t\tt.Fatal(\"expected deep copy, original modified\")\n\t}\n}\n\nfunc BenchmarkConcat_Naive(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveConcat(parts)\n\t}\n}\n\nfunc BenchmarkConcat_Better(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterConcat(parts)\n\t}\n}\n\nfunc BenchmarkAlloc_Naive(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveAlloc(1_000)\n\t}\n}\n\nfunc BenchmarkAlloc_Better(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterAlloc(1_000)\n\t\tfor j := 0; j < 1_000; j++ {\n\t\t\t_ = rand.Intn(1000)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "profilingx"
        ],
        "order": 2
      },
      {
        "package": "profilingx",
        "slug": "go-profilingx-releasebuffer",
        "title": "ReleaseBuffer обнуляет длину слайса и возвращает его в пул.",
        "description": "Level 4 (medium+): ReleaseBuffer обнуляет длину слайса и возвращает его в пул.\nHint: приведите buf[:0] перед передачей в pool.Put.",
        "difficulty": "medium",
        "hint1": "приведите buf[:0] перед передачей в pool.Put.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Требования и подсказки по профилированию:\n// 1. Сначала зафиксируйте базовые показатели на наивных реализациях:\n//    go test -run '^$' -bench Concat -benchmem ./internal/profilingx\n//    go test -run '^$' -bench Alloc -benchmem ./internal/profilingx\n// 2. Соберите CPU-профиль, чтобы увидеть горячие участки:\n//    go test -run '^$' -bench . -benchmem -cpuprofile=cpu.out ./internal/profilingx\n//    go tool pprof cpu.out\n//    go tool pprof -http=:8080 cpu.out     (удобный веб-интерфейс)\n// 3. Проанализируйте распределение памяти:\n//    go test -run '^$' -bench . -benchmem -memprofile=mem.out ./internal/profilingx\n//    go tool pprof mem.out\n// 4. Для сравнения с эталонным решением запустите:\n//    go test -tags solution -run '^$' -bench . -benchmem ./internal/profilingx\n// Эти команды помогут понять, какие оптимизации нужны для BetterConcat, BetterAlloc,\n// AcquireBuffer, ReleaseBuffer и CloneStrings, и проверить эффект от изменений.\n\n// NaiveConcat демонстрирует неоптимальное поведение и остаётся реализованной для сравнения.\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\n// NaiveAlloc — эталон неэффективного подхода.\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\n// Level 1 (easy+): BetterConcat должен использовать strings.Builder и предварительно резервировать ёмкость.\n// Hint: посчитайте суммарную длину и вызовите builder.Grow.\nfunc BetterConcat(parts []string) string {\n\tn := 0\n\n\tfor _, p := range parts {\n\t\tn += len(p)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(n)\n\n\tfor _, p := range parts {\n\t\tbuilder.WriteString(p)\n\t}\n\treturn builder.String()\n}\n\n// Level 2 (medium): BetterAlloc создаёт слайс с нужной capacity и заполняет случайными числами без лишних аллокаций.\n// Hint: используйте make([]int, 0, n) или make([]int, n) и присваивание по индексам.\nfunc BetterAlloc(n int) []int {\n\tout := make([]int, n)\n\treturn out\n}\n\n// Level 3 (medium): AcquireBuffer берёт []byte из sync.Pool, гарантируя minCap вместимость.\n// Hint: расширьте buffer если текущей ёмкости недостаточно.\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte\n\tif pool != nil {\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte)\n\t\t}\n\t}\n\tif cap(buf) < minCap {\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0]\n}\n\n// Level 4 (medium+): ReleaseBuffer обнуляет длину слайса и возвращает его в пул.\n// Hint: приведите buf[:0] перед передачей в pool.Put.\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil {\n\t\treturn\n\t}\n\tbuf = buf[:0]\n\tpool.Put(&buf)\n}\n\n// Level 5 (medium+): CloneStrings создаёт копию слайса строк без повторных аллокаций элементов.\n// Hint: выделите новый слайс нужной длины и используйте copy.\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src))\n\tcopy(clone, src)\n\treturn clone\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\nfunc BetterConcat(parts []string) string {\n\tswitch len(parts) { // handle trivial cases without extra work\n\tcase 0:\n\t\treturn \"\" // empty slice yields empty string\n\tcase 1:\n\t\treturn parts[0] // single element already concatenated\n\t}\n\ttotal := 0                   // track total length of all input fragments\n\tfor _, part := range parts { // accumulate length of each component\n\t\ttotal += len(part)\n\t}\n\tvar builder strings.Builder  // builder avoids repeated reallocations\n\tbuilder.Grow(total)          // preallocate exact capacity to prevent growth\n\tfor _, part := range parts { // append every piece in order\n\t\tbuilder.WriteString(part) // write fragment into builder buffer\n\t}\n\treturn builder.String() // produce final concatenated string from builder\n}\n\nfunc BetterAlloc(n int) []int {\n\tif n <= 0 { // guard against negative or zero sizes\n\t\treturn nil\n\t}\n\tout := make([]int, n) // allocate slice with final capacity upfront\n\tfor i := range out {  // fill each element without changing length\n\t\tout[i] = rand.Intn(1000) // populate slice with random numbers\n\t}\n\treturn out // return fully initialized slice\n}\n\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte   // placeholder for buffer retrieved from pool\n\tif pool != nil { // attempt to reuse pooled slice when pool provided\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte) // type assert retrieved value to []byte\n\t\t}\n\t}\n\tif cap(buf) < minCap { // allocate fresh slice when capacity insufficient\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0] // reuse buffer with length reset to zero\n}\n\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil { // nothing to do when pool is absent\n\t\treturn\n\t}\n\tpool.Put(buf[:0]) // reset length and put slice back into pool\n}\n\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src)) // allocate slice with identical length\n\tcopy(clone, src)                  // duplicate contents in one pass\n\treturn clone                      // return independent copy of data\n}\n",
        "testCode": "package profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestBetterConcat(t *testing.T) {\n\tt.Parallel()\n\tparts := []string{\"a\", \"b\", \"c\"}\n\tif res := BetterConcat(parts); res != \"abc\" {\n\t\tt.Fatalf(\"unexpected concat result: %q\", res)\n\t}\n}\n\nfunc TestBetterAlloc(t *testing.T) {\n\tt.Parallel()\n\tout := BetterAlloc(8)\n\tif len(out) != 8 {\n\t\tt.Fatalf(\"expected len 8, got %d\", len(out))\n\t}\n}\n\nfunc TestAcquireBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := AcquireBuffer(pool, 8)\n\tif cap(buf) < 8 {\n\t\tt.Fatalf(\"expected capacity >=8, got %d\", cap(buf))\n\t}\n}\n\nfunc TestReleaseBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := []byte(\"hello\")\n\tReleaseBuffer(pool, buf)\n\tgot := pool.Get().([]byte)\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"expected reset slice, got len=%d\", len(got))\n\t}\n}\n\nfunc TestCloneStrings(t *testing.T) {\n\tt.Parallel()\n\tsrc := []string{\"a\", \"b\", \"c\"}\n\tclone := CloneStrings(src)\n\tif len(clone) != len(src) || clone[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected clone result: %v\", clone)\n\t}\n\tclone[0] = \"z\"\n\tif src[0] == \"z\" {\n\t\tt.Fatal(\"expected deep copy, original modified\")\n\t}\n}\n\nfunc BenchmarkConcat_Naive(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveConcat(parts)\n\t}\n}\n\nfunc BenchmarkConcat_Better(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterConcat(parts)\n\t}\n}\n\nfunc BenchmarkAlloc_Naive(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveAlloc(1_000)\n\t}\n}\n\nfunc BenchmarkAlloc_Better(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterAlloc(1_000)\n\t\tfor j := 0; j < 1_000; j++ {\n\t\t\t_ = rand.Intn(1000)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "profilingx"
        ],
        "order": 3
      },
      {
        "package": "profilingx",
        "slug": "go-profilingx-clonestrings",
        "title": "CloneStrings создаёт копию слайса строк без повторных аллокаций элементов.",
        "description": "Level 5 (medium+): CloneStrings создаёт копию слайса строк без повторных аллокаций элементов.\nHint: выделите новый слайс нужной длины и используйте copy.",
        "difficulty": "medium",
        "hint1": "выделите новый слайс нужной длины и используйте copy.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Требования и подсказки по профилированию:\n// 1. Сначала зафиксируйте базовые показатели на наивных реализациях:\n//    go test -run '^$' -bench Concat -benchmem ./internal/profilingx\n//    go test -run '^$' -bench Alloc -benchmem ./internal/profilingx\n// 2. Соберите CPU-профиль, чтобы увидеть горячие участки:\n//    go test -run '^$' -bench . -benchmem -cpuprofile=cpu.out ./internal/profilingx\n//    go tool pprof cpu.out\n//    go tool pprof -http=:8080 cpu.out     (удобный веб-интерфейс)\n// 3. Проанализируйте распределение памяти:\n//    go test -run '^$' -bench . -benchmem -memprofile=mem.out ./internal/profilingx\n//    go tool pprof mem.out\n// 4. Для сравнения с эталонным решением запустите:\n//    go test -tags solution -run '^$' -bench . -benchmem ./internal/profilingx\n// Эти команды помогут понять, какие оптимизации нужны для BetterConcat, BetterAlloc,\n// AcquireBuffer, ReleaseBuffer и CloneStrings, и проверить эффект от изменений.\n\n// NaiveConcat демонстрирует неоптимальное поведение и остаётся реализованной для сравнения.\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\n// NaiveAlloc — эталон неэффективного подхода.\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\n// Level 1 (easy+): BetterConcat должен использовать strings.Builder и предварительно резервировать ёмкость.\n// Hint: посчитайте суммарную длину и вызовите builder.Grow.\nfunc BetterConcat(parts []string) string {\n\tn := 0\n\n\tfor _, p := range parts {\n\t\tn += len(p)\n\t}\n\tvar builder strings.Builder\n\tbuilder.Grow(n)\n\n\tfor _, p := range parts {\n\t\tbuilder.WriteString(p)\n\t}\n\treturn builder.String()\n}\n\n// Level 2 (medium): BetterAlloc создаёт слайс с нужной capacity и заполняет случайными числами без лишних аллокаций.\n// Hint: используйте make([]int, 0, n) или make([]int, n) и присваивание по индексам.\nfunc BetterAlloc(n int) []int {\n\tout := make([]int, n)\n\treturn out\n}\n\n// Level 3 (medium): AcquireBuffer берёт []byte из sync.Pool, гарантируя minCap вместимость.\n// Hint: расширьте buffer если текущей ёмкости недостаточно.\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte\n\tif pool != nil {\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte)\n\t\t}\n\t}\n\tif cap(buf) < minCap {\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0]\n}\n\n// Level 4 (medium+): ReleaseBuffer обнуляет длину слайса и возвращает его в пул.\n// Hint: приведите buf[:0] перед передачей в pool.Put.\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil {\n\t\treturn\n\t}\n\tbuf = buf[:0]\n\tpool.Put(&buf)\n}\n\n// Level 5 (medium+): CloneStrings создаёт копию слайса строк без повторных аллокаций элементов.\n// Hint: выделите новый слайс нужной длины и используйте copy.\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src))\n\tcopy(clone, src)\n\treturn clone\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc NaiveConcat(parts []string) string {\n\tvar s string\n\tfor _, p := range parts {\n\t\ts += p\n\t}\n\treturn s\n}\n\nfunc NaiveAlloc(n int) []int {\n\tvar out []int\n\tfor i := 0; i < n; i++ {\n\t\tout = append(out, rand.Intn(1000))\n\t}\n\treturn out\n}\n\nfunc BetterConcat(parts []string) string {\n\tswitch len(parts) { // handle trivial cases without extra work\n\tcase 0:\n\t\treturn \"\" // empty slice yields empty string\n\tcase 1:\n\t\treturn parts[0] // single element already concatenated\n\t}\n\ttotal := 0                   // track total length of all input fragments\n\tfor _, part := range parts { // accumulate length of each component\n\t\ttotal += len(part)\n\t}\n\tvar builder strings.Builder  // builder avoids repeated reallocations\n\tbuilder.Grow(total)          // preallocate exact capacity to prevent growth\n\tfor _, part := range parts { // append every piece in order\n\t\tbuilder.WriteString(part) // write fragment into builder buffer\n\t}\n\treturn builder.String() // produce final concatenated string from builder\n}\n\nfunc BetterAlloc(n int) []int {\n\tif n <= 0 { // guard against negative or zero sizes\n\t\treturn nil\n\t}\n\tout := make([]int, n) // allocate slice with final capacity upfront\n\tfor i := range out {  // fill each element without changing length\n\t\tout[i] = rand.Intn(1000) // populate slice with random numbers\n\t}\n\treturn out // return fully initialized slice\n}\n\nfunc AcquireBuffer(pool *sync.Pool, minCap int) []byte {\n\tvar buf []byte   // placeholder for buffer retrieved from pool\n\tif pool != nil { // attempt to reuse pooled slice when pool provided\n\t\tif v := pool.Get(); v != nil {\n\t\t\tbuf, _ = v.([]byte) // type assert retrieved value to []byte\n\t\t}\n\t}\n\tif cap(buf) < minCap { // allocate fresh slice when capacity insufficient\n\t\treturn make([]byte, 0, minCap)\n\t}\n\treturn buf[:0] // reuse buffer with length reset to zero\n}\n\nfunc ReleaseBuffer(pool *sync.Pool, buf []byte) {\n\tif pool == nil { // nothing to do when pool is absent\n\t\treturn\n\t}\n\tpool.Put(buf[:0]) // reset length and put slice back into pool\n}\n\nfunc CloneStrings(src []string) []string {\n\tclone := make([]string, len(src)) // allocate slice with identical length\n\tcopy(clone, src)                  // duplicate contents in one pass\n\treturn clone                      // return independent copy of data\n}\n",
        "testCode": "package profilingx\n\nimport (\n\t\"math/rand\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc TestBetterConcat(t *testing.T) {\n\tt.Parallel()\n\tparts := []string{\"a\", \"b\", \"c\"}\n\tif res := BetterConcat(parts); res != \"abc\" {\n\t\tt.Fatalf(\"unexpected concat result: %q\", res)\n\t}\n}\n\nfunc TestBetterAlloc(t *testing.T) {\n\tt.Parallel()\n\tout := BetterAlloc(8)\n\tif len(out) != 8 {\n\t\tt.Fatalf(\"expected len 8, got %d\", len(out))\n\t}\n}\n\nfunc TestAcquireBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := AcquireBuffer(pool, 8)\n\tif cap(buf) < 8 {\n\t\tt.Fatalf(\"expected capacity >=8, got %d\", cap(buf))\n\t}\n}\n\nfunc TestReleaseBuffer(t *testing.T) {\n\tt.Parallel()\n\tpool := &sync.Pool{New: func() any { return make([]byte, 0, 4) }}\n\tbuf := []byte(\"hello\")\n\tReleaseBuffer(pool, buf)\n\tgot := pool.Get().([]byte)\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"expected reset slice, got len=%d\", len(got))\n\t}\n}\n\nfunc TestCloneStrings(t *testing.T) {\n\tt.Parallel()\n\tsrc := []string{\"a\", \"b\", \"c\"}\n\tclone := CloneStrings(src)\n\tif len(clone) != len(src) || clone[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected clone result: %v\", clone)\n\t}\n\tclone[0] = \"z\"\n\tif src[0] == \"z\" {\n\t\tt.Fatal(\"expected deep copy, original modified\")\n\t}\n}\n\nfunc BenchmarkConcat_Naive(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveConcat(parts)\n\t}\n}\n\nfunc BenchmarkConcat_Better(b *testing.B) {\n\tparts := make([]string, 1000)\n\tfor i := range parts {\n\t\tparts[i] = strings.Repeat(\"x\", 10)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterConcat(parts)\n\t}\n}\n\nfunc BenchmarkAlloc_Naive(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = NaiveAlloc(1_000)\n\t}\n}\n\nfunc BenchmarkAlloc_Better(b *testing.B) {\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\t_ = BetterAlloc(1_000)\n\t\tfor j := 0; j < 1_000; j++ {\n\t\t\t_ = rand.Intn(1000)\n\t\t}\n\t}\n}\n",
        "tags": [
          "go",
          "profilingx"
        ],
        "order": 4
      }
    ],
    "category": "production"
  },
  {
    "name": "ratelimit",
    "tasks": [
      {
        "package": "ratelimit",
        "slug": "go-ratelimit-new",
        "title": "конструктор New настраивает native rate limiter.",
        "description": "Level 2 (easy+): конструктор New настраивает native rate limiter.\n  - нормализуйте отрицательные rps/burst (защищайтесь от деления на ноль);\n  - готовьте слайс под burst значений;\n  - не используйте внешний пакет rate.\n\nHint: храните время последующей доступности токена как time.Time и обновляйте его через Add.",
        "difficulty": "easy",
        "hint1": "храните время последующей доступности токена как time.Time и обновляйте его через Add.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage ratelimit\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): спроектируйте структуру Limiter, которая хранит конфигурацию\n// (заданную скорость rps и burst) и состояние исполнения. Для управления доступом\n// без сторонних библиотек понадобятся:\n//   - длительность между токенами (i.e. time.Second / rps),\n//   - слайс с моментами времени, когда занятые токены станут доступны снова.\n//\n// Hint: держите данные под мьютексом, чтобы несколько горутин не портили очередь.\ntype Limiter struct {\n\tmu           sync.Mutex\n\tinterval     time.Duration\n\tburst        int\n\treservations []time.Time\n}\n\n// Level 2 (easy+): конструктор New настраивает native rate limiter.\n//   - нормализуйте отрицательные rps/burst (защищайтесь от деления на ноль);\n//   - готовьте слайс под burst значений;\n//   - не используйте внешний пакет rate.\n//\n// Hint: храните время последующей доступности токена как time.Time и обновляйте его через Add.\nfunc New(rps float64, burst int) *Limiter {\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\tperToken := time.Duration(float64(time.Second) / rps)\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0),\n\t}\n}\n\n// Level 3 (medium): реализуйте метод резервирования токена, который возвращает\n// оставшееся ожидание. Он должен:\n//   * удалять из слайса все времена, уже наступившие (token free);\n//   * если токен доступен — добавлять новую запись и возвращать (0, true);\n//   * иначе вернуть время до ближайшего освобождения (delay, false).\n// Hint: используйте time.Now внутри Allow/AllowWithin, а не храните глобальные таймеры.\n\n// Level 4 (medium+): Allow дожидается токена, пока контекст не отменён.\n//   - повторно вызывайте резервирование, пока не получите токен;\n//   - если нужно ждать — ставьте таймер через time.NewTimer и проверяйте ctx.Done.\n//\n// Hint: всегда корректно останавливайте таймер и не забывайте про nil-контексты.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\twait, ok := l.reserve(time.Now())\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): AllowWithin ограничивает ожидание maxWait.\n//   - при maxWait <= 0 попытайтесь получить токен немедленно;\n//   - иначе оборачивайте исходный контекст через context.WithTimeout и переиспользуйте Allow.\n//\n// Hint: не теряйте исходную ошибку контекста (DeadlineExceeded / Canceled).\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif maxWait <= 0 {\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\treturn context.DeadlineExceeded\n\t}\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\tdefer cancel()\n\treturn l.Allow(ctx)\n}\n\n// Level 6 (medium+): Wrap лимитирует вызовы произвольной функции fn.\n//   - сперва запросите токен через Allow;\n//   - передайте исходный контекст внутрь fn;\n//   - аккуратно обработайте nil-параметры.\n//\n// Hint: возвращайте nil вместо обёртки, если fn равен nil — так легче заметить ошибку.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\tif fn == nil {\n\t\treturn nil\n\t}\n\treturn func(ctx context.Context) error {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn fn(ctx)\n\t}\n}\n\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\twait := l.reservations[0].Sub(now)\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\treturn wait, false\n}\n\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\tidx := 0\n\tfor _, r := range l.reservations {\n\t\tif r.After(now) {\n\t\t\tbreak\n\t\t}\n\t\tidx++\n\t}\n\tif idx == 0 {\n\t\treturn\n\t}\n\tcopy(l.reservations, l.reservations[idx:])\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t}\n\treturn ctx.Err()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\n// Вариант с тегом solution содержит полностью реализованный токен-бакет.\npackage ratelimit\n\nimport (\n\t// context нужен для поддержки отмены/дедлайнов при ожидании токенов.\n\t\"context\"\n\t// sync предоставляет мьютекс, чтобы синхронизировать доступ к очереди резервов.\n\t\"sync\"\n\t// time отвечает за работу со временем и таймерами.\n\t\"time\"\n)\n\n// Limiter описывает состояние и конфигурацию собственного rate limiter.\ntype Limiter struct {\n\t// mu защищает поля структуры от гонок при конкурентных вызовах.\n\tmu sync.Mutex\n\t// interval хранит длительность между выдачами токенов (обратная величина rps).\n\tinterval time.Duration\n\t// burst указывает максимальное число одновременно занятых токенов.\n\tburst int\n\t// reservations — очередь моментов времени, когда занятые токены освободятся.\n\treservations []time.Time\n}\n\n// New настраивает лимитер с учетом требуемой скорости rps и всплеска burst.\nfunc New(rps float64, burst int) *Limiter {\n\t// Нормализуем burst, чтобы он был хотя бы единицей.\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\t// Нормализуем rps, чтобы избежать деления на ноль и отрицательных скоростей.\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\t// Вычисляем длительность между токенами как обратную величину rps.\n\tperToken := time.Duration(float64(time.Second) / rps)\n\t// Страхуемся от нулевых/отрицательных значений из-за округления.\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\t// Возвращаем инициализированную структуру с подготовленным буфером под очередь.\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0, burst),\n\t}\n}\n\n// Allow ждёт появления токена или возвращает ошибку контекста, если ожидание прерывают.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\t// nil-лимитер считаем всегда разрешающим и ничего не делаем.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Подменяем отсутствующий контекст фоновой реализацией.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Повторяем попытки резервирования, пока не получим токен или контекст не завершится.\n\tfor {\n\t\t// reserve возвращает, нужно ли ждать, и удалось ли сразу занять токен.\n\t\twait, ok := l.reserve(time.Now())\n\t\t// Если токен получен, можно выходить без ожидания.\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\t// Отрицательная задержка означает, что очередь уже освобождена — пробуем ещё раз.\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Ждём нужную длительность, уважая отмену через контекст.\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// AllowWithin ограничивает ожидание верхней границей maxWait.\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\t// nil-лимитер по-прежнему не накладывает ограничений.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Гарантируем ненулевой контекст для дальнейшей работы.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Если ждать нельзя совсем, пробуем занять токен немедленно.\n\tif maxWait <= 0 {\n\t\t// tryImmediate проверяет наличие свободного токена без блокировки.\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\t// Токен взять не удалось — значит, превышен дедлайн ожидания.\n\t\treturn context.DeadlineExceeded\n\t}\n\t// Создаем контекст с таймаутом, чтобы ограничить суммарное ожидание.\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\t// Освобождаем ресурсы таймера при выходе.\n\tdefer cancel()\n\t// Используем базовую реализацию Allow, которая уже обрабатывает ожидание токена.\n\treturn l.Allow(ctx)\n}\n\n// Wrap возвращает функцию, которая сначала ждёт токен, а затем вызывает fn.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\t// Если исходной функции нет, нечего оборачивать — возвращаем nil.\n\tif fn == nil {\n\t\treturn nil\n\t}\n\t// Возвращаем замыкание, внутри которого сначала происходит лимитирование.\n\treturn func(ctx context.Context) error {\n\t\t// Allow выдаёт токен; ошибка сразу прерывает выполнение fn.\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Если токен получен, выполняем исходную функцию с тем же контекстом.\n\t\treturn fn(ctx)\n\t}\n}\n\n// reserve — вспомогательная функция: пытается занять токен и сообщить, сколько ждать.\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\t// Защищаем работу с состоянием мьютексом.\n\tl.mu.Lock()\n\t// Убедимся, что разблокируем мьютекс при любом выходе.\n\tdefer l.mu.Unlock()\n\t// Очищаем из очереди токены, которые уже «освободились» к текущему моменту.\n\tl.releaseExpiredLocked(now)\n\t// Если есть свободный слот (меньше burst), резервируем токен немедленно.\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\t// Иначе считаем время до ближайшего освобождения.\n\twait := l.reservations[0].Sub(now)\n\t// Отрицательные значения трактуем как готовность без ожидания (следующая итерация цикла).\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\t// Возвращаем задержку и флаг, что токен пока недоступен.\n\treturn wait, false\n}\n\n// tryImmediate проверяет, можно ли прямо сейчас занять токен, без ожидания.\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\t// Блокируем структуру, чтобы безопасно работать с очередью.\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\t// Удаляем устаревшие записи, чтобы информация была актуальна.\n\tl.releaseExpiredLocked(now)\n\t// Если очередь уже заполнена до burst, моментального токена нет.\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\t// Иначе резервируем токен и фиксируем момент, когда он будет доступен снова.\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\n// releaseExpiredLocked чистит очередь от токенов, «вернувшихся» к моменту now.\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\t// idx считает, сколько элементов в начале слайса уже освободилось.\n\tidx := 0\n\t// Двигаем idx, пока встречаем времена, не позже текущего момента.\n\tfor idx < len(l.reservations) && !l.reservations[idx].After(now) {\n\t\tidx++\n\t}\n\t// Если ничего не освободилось — просто выходим.\n\tif idx == 0 {\n\t\treturn\n\t}\n\t// Сдвигаем оставшиеся активные записи в начало слайса.\n\tcopy(l.reservations, l.reservations[idx:])\n\t// Укорачиваем слайс, устраняя освободившиеся элементы.\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\n// waitOnContext ожидает длительность d и отменяется, если контекст завершён раньше.\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\t// Если ждать нечего, просто проверяем состояние контекста.\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\t// Создаём таймер, чтобы заснуть на требуемый промежуток.\n\ttimer := time.NewTimer(d)\n\t// Гарантируем освобождение ресурсов таймера.\n\tdefer timer.Stop()\n\t// Ждём либо истечения таймера, либо сигнала отмены.\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\t// Стараемся остановить таймер и почистить канал, если он уже сработал.\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn ctx.Err()\n\t}\n}\n",
        "testCode": "package ratelimit\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLimiter(t *testing.T) {\n\tl := New(5, 2) // ~5 rps\n\tctx, cancel := context.WithTimeout(context.Background(), 200*time.Millisecond)\n\tdefer cancel()\n\n\tstart := time.Now()\n\tfor i := 0; i < 3; i++ {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\telapsed := time.Since(start)\n\tif elapsed < 150*time.Millisecond {\n\t\tt.Fatalf(\"limiter too permissive, elapsed=%v\", elapsed)\n\t}\n}\n\nfunc TestLimiterAllowWithin(t *testing.T) {\n\tl := New(50, 1) // token roughly every 20ms\n\tctx := context.Background()\n\n\tif err := l.AllowWithin(ctx, 0); err != nil {\n\t\tt.Fatalf(\"expected immediate allowance, got %v\", err)\n\t}\n\n\tstart := time.Now()\n\terr := l.AllowWithin(ctx, 5*time.Millisecond)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed < 5*time.Millisecond {\n\t\tt.Fatalf(\"expected to wait at least maxWait, elapsed=%v\", elapsed)\n\t}\n\n\ttime.Sleep(30 * time.Millisecond) // allow token to replenish\n\tif err := l.AllowWithin(ctx, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"expected allowance after replenish, got %v\", err)\n\t}\n}\n\nfunc TestLimiterAllowCanceled(t *testing.T) {\n\tl := New(2, 1)\n\tif err := l.Allow(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected error on first token: %v\", err)\n\t}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := l.Allow(ctx); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context canceled, got %v\", err)\n\t}\n}\n\nfunc TestLimiterWrap(t *testing.T) {\n\tl := New(1, 1)\n\ttype ctxKey string\n\tconst key ctxKey = \"test-key\"\n\n\tvar calls int\n\twrapped := l.Wrap(func(ctx context.Context) error {\n\t\tcalls++\n\t\tif got, want := ctx.Value(key), \"value\"; got != want {\n\t\t\tt.Fatalf(\"expected context value %q, got %v\", want, got)\n\t\t}\n\t\treturn nil\n\t})\n\tif wrapped == nil {\n\t\tt.Fatal(\"expected non-nil wrapped function\")\n\t}\n\n\tctx := context.WithValue(context.Background(), key, \"value\")\n\tif err := wrapped(ctx); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"expected fn to run once, got %d\", calls)\n\t}\n\n\tdeadlineCtx, cancel := context.WithTimeout(context.Background(), 20*time.Millisecond)\n\tdefer cancel()\n\tif err := wrapped(deadlineCtx); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded from limiter, got %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"fn should not run when limiter blocks, got calls=%d\", calls)\n\t}\n}\n\nfunc TestLimiterWrapNil(t *testing.T) {\n\tvar l *Limiter\n\tif wrapped := l.Wrap(nil); wrapped != nil {\n\t\tt.Fatal(\"expected nil result for nil fn\")\n\t}\n}\n",
        "tags": [
          "go",
          "ratelimit"
        ],
        "order": 1
      },
      {
        "package": "ratelimit",
        "slug": "go-ratelimit-allow",
        "title": "Allow дожидается токена, пока контекст не отменён.",
        "description": "Level 4 (medium+): Allow дожидается токена, пока контекст не отменён.\n  - повторно вызывайте резервирование, пока не получите токен;\n  - если нужно ждать — ставьте таймер через time.NewTimer и проверяйте ctx.Done.\n\nHint: всегда корректно останавливайте таймер и не забывайте про nil-контексты.",
        "difficulty": "medium",
        "hint1": "всегда корректно останавливайте таймер и не забывайте про nil-контексты.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage ratelimit\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): спроектируйте структуру Limiter, которая хранит конфигурацию\n// (заданную скорость rps и burst) и состояние исполнения. Для управления доступом\n// без сторонних библиотек понадобятся:\n//   - длительность между токенами (i.e. time.Second / rps),\n//   - слайс с моментами времени, когда занятые токены станут доступны снова.\n//\n// Hint: держите данные под мьютексом, чтобы несколько горутин не портили очередь.\ntype Limiter struct {\n\tmu           sync.Mutex\n\tinterval     time.Duration\n\tburst        int\n\treservations []time.Time\n}\n\n// Level 2 (easy+): конструктор New настраивает native rate limiter.\n//   - нормализуйте отрицательные rps/burst (защищайтесь от деления на ноль);\n//   - готовьте слайс под burst значений;\n//   - не используйте внешний пакет rate.\n//\n// Hint: храните время последующей доступности токена как time.Time и обновляйте его через Add.\nfunc New(rps float64, burst int) *Limiter {\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\tperToken := time.Duration(float64(time.Second) / rps)\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0),\n\t}\n}\n\n// Level 3 (medium): реализуйте метод резервирования токена, который возвращает\n// оставшееся ожидание. Он должен:\n//   * удалять из слайса все времена, уже наступившие (token free);\n//   * если токен доступен — добавлять новую запись и возвращать (0, true);\n//   * иначе вернуть время до ближайшего освобождения (delay, false).\n// Hint: используйте time.Now внутри Allow/AllowWithin, а не храните глобальные таймеры.\n\n// Level 4 (medium+): Allow дожидается токена, пока контекст не отменён.\n//   - повторно вызывайте резервирование, пока не получите токен;\n//   - если нужно ждать — ставьте таймер через time.NewTimer и проверяйте ctx.Done.\n//\n// Hint: всегда корректно останавливайте таймер и не забывайте про nil-контексты.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\twait, ok := l.reserve(time.Now())\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): AllowWithin ограничивает ожидание maxWait.\n//   - при maxWait <= 0 попытайтесь получить токен немедленно;\n//   - иначе оборачивайте исходный контекст через context.WithTimeout и переиспользуйте Allow.\n//\n// Hint: не теряйте исходную ошибку контекста (DeadlineExceeded / Canceled).\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif maxWait <= 0 {\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\treturn context.DeadlineExceeded\n\t}\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\tdefer cancel()\n\treturn l.Allow(ctx)\n}\n\n// Level 6 (medium+): Wrap лимитирует вызовы произвольной функции fn.\n//   - сперва запросите токен через Allow;\n//   - передайте исходный контекст внутрь fn;\n//   - аккуратно обработайте nil-параметры.\n//\n// Hint: возвращайте nil вместо обёртки, если fn равен nil — так легче заметить ошибку.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\tif fn == nil {\n\t\treturn nil\n\t}\n\treturn func(ctx context.Context) error {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn fn(ctx)\n\t}\n}\n\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\twait := l.reservations[0].Sub(now)\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\treturn wait, false\n}\n\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\tidx := 0\n\tfor _, r := range l.reservations {\n\t\tif r.After(now) {\n\t\t\tbreak\n\t\t}\n\t\tidx++\n\t}\n\tif idx == 0 {\n\t\treturn\n\t}\n\tcopy(l.reservations, l.reservations[idx:])\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t}\n\treturn ctx.Err()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\n// Вариант с тегом solution содержит полностью реализованный токен-бакет.\npackage ratelimit\n\nimport (\n\t// context нужен для поддержки отмены/дедлайнов при ожидании токенов.\n\t\"context\"\n\t// sync предоставляет мьютекс, чтобы синхронизировать доступ к очереди резервов.\n\t\"sync\"\n\t// time отвечает за работу со временем и таймерами.\n\t\"time\"\n)\n\n// Limiter описывает состояние и конфигурацию собственного rate limiter.\ntype Limiter struct {\n\t// mu защищает поля структуры от гонок при конкурентных вызовах.\n\tmu sync.Mutex\n\t// interval хранит длительность между выдачами токенов (обратная величина rps).\n\tinterval time.Duration\n\t// burst указывает максимальное число одновременно занятых токенов.\n\tburst int\n\t// reservations — очередь моментов времени, когда занятые токены освободятся.\n\treservations []time.Time\n}\n\n// New настраивает лимитер с учетом требуемой скорости rps и всплеска burst.\nfunc New(rps float64, burst int) *Limiter {\n\t// Нормализуем burst, чтобы он был хотя бы единицей.\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\t// Нормализуем rps, чтобы избежать деления на ноль и отрицательных скоростей.\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\t// Вычисляем длительность между токенами как обратную величину rps.\n\tperToken := time.Duration(float64(time.Second) / rps)\n\t// Страхуемся от нулевых/отрицательных значений из-за округления.\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\t// Возвращаем инициализированную структуру с подготовленным буфером под очередь.\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0, burst),\n\t}\n}\n\n// Allow ждёт появления токена или возвращает ошибку контекста, если ожидание прерывают.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\t// nil-лимитер считаем всегда разрешающим и ничего не делаем.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Подменяем отсутствующий контекст фоновой реализацией.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Повторяем попытки резервирования, пока не получим токен или контекст не завершится.\n\tfor {\n\t\t// reserve возвращает, нужно ли ждать, и удалось ли сразу занять токен.\n\t\twait, ok := l.reserve(time.Now())\n\t\t// Если токен получен, можно выходить без ожидания.\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\t// Отрицательная задержка означает, что очередь уже освобождена — пробуем ещё раз.\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Ждём нужную длительность, уважая отмену через контекст.\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// AllowWithin ограничивает ожидание верхней границей maxWait.\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\t// nil-лимитер по-прежнему не накладывает ограничений.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Гарантируем ненулевой контекст для дальнейшей работы.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Если ждать нельзя совсем, пробуем занять токен немедленно.\n\tif maxWait <= 0 {\n\t\t// tryImmediate проверяет наличие свободного токена без блокировки.\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\t// Токен взять не удалось — значит, превышен дедлайн ожидания.\n\t\treturn context.DeadlineExceeded\n\t}\n\t// Создаем контекст с таймаутом, чтобы ограничить суммарное ожидание.\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\t// Освобождаем ресурсы таймера при выходе.\n\tdefer cancel()\n\t// Используем базовую реализацию Allow, которая уже обрабатывает ожидание токена.\n\treturn l.Allow(ctx)\n}\n\n// Wrap возвращает функцию, которая сначала ждёт токен, а затем вызывает fn.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\t// Если исходной функции нет, нечего оборачивать — возвращаем nil.\n\tif fn == nil {\n\t\treturn nil\n\t}\n\t// Возвращаем замыкание, внутри которого сначала происходит лимитирование.\n\treturn func(ctx context.Context) error {\n\t\t// Allow выдаёт токен; ошибка сразу прерывает выполнение fn.\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Если токен получен, выполняем исходную функцию с тем же контекстом.\n\t\treturn fn(ctx)\n\t}\n}\n\n// reserve — вспомогательная функция: пытается занять токен и сообщить, сколько ждать.\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\t// Защищаем работу с состоянием мьютексом.\n\tl.mu.Lock()\n\t// Убедимся, что разблокируем мьютекс при любом выходе.\n\tdefer l.mu.Unlock()\n\t// Очищаем из очереди токены, которые уже «освободились» к текущему моменту.\n\tl.releaseExpiredLocked(now)\n\t// Если есть свободный слот (меньше burst), резервируем токен немедленно.\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\t// Иначе считаем время до ближайшего освобождения.\n\twait := l.reservations[0].Sub(now)\n\t// Отрицательные значения трактуем как готовность без ожидания (следующая итерация цикла).\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\t// Возвращаем задержку и флаг, что токен пока недоступен.\n\treturn wait, false\n}\n\n// tryImmediate проверяет, можно ли прямо сейчас занять токен, без ожидания.\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\t// Блокируем структуру, чтобы безопасно работать с очередью.\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\t// Удаляем устаревшие записи, чтобы информация была актуальна.\n\tl.releaseExpiredLocked(now)\n\t// Если очередь уже заполнена до burst, моментального токена нет.\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\t// Иначе резервируем токен и фиксируем момент, когда он будет доступен снова.\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\n// releaseExpiredLocked чистит очередь от токенов, «вернувшихся» к моменту now.\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\t// idx считает, сколько элементов в начале слайса уже освободилось.\n\tidx := 0\n\t// Двигаем idx, пока встречаем времена, не позже текущего момента.\n\tfor idx < len(l.reservations) && !l.reservations[idx].After(now) {\n\t\tidx++\n\t}\n\t// Если ничего не освободилось — просто выходим.\n\tif idx == 0 {\n\t\treturn\n\t}\n\t// Сдвигаем оставшиеся активные записи в начало слайса.\n\tcopy(l.reservations, l.reservations[idx:])\n\t// Укорачиваем слайс, устраняя освободившиеся элементы.\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\n// waitOnContext ожидает длительность d и отменяется, если контекст завершён раньше.\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\t// Если ждать нечего, просто проверяем состояние контекста.\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\t// Создаём таймер, чтобы заснуть на требуемый промежуток.\n\ttimer := time.NewTimer(d)\n\t// Гарантируем освобождение ресурсов таймера.\n\tdefer timer.Stop()\n\t// Ждём либо истечения таймера, либо сигнала отмены.\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\t// Стараемся остановить таймер и почистить канал, если он уже сработал.\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn ctx.Err()\n\t}\n}\n",
        "testCode": "package ratelimit\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLimiter(t *testing.T) {\n\tl := New(5, 2) // ~5 rps\n\tctx, cancel := context.WithTimeout(context.Background(), 200*time.Millisecond)\n\tdefer cancel()\n\n\tstart := time.Now()\n\tfor i := 0; i < 3; i++ {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\telapsed := time.Since(start)\n\tif elapsed < 150*time.Millisecond {\n\t\tt.Fatalf(\"limiter too permissive, elapsed=%v\", elapsed)\n\t}\n}\n\nfunc TestLimiterAllowWithin(t *testing.T) {\n\tl := New(50, 1) // token roughly every 20ms\n\tctx := context.Background()\n\n\tif err := l.AllowWithin(ctx, 0); err != nil {\n\t\tt.Fatalf(\"expected immediate allowance, got %v\", err)\n\t}\n\n\tstart := time.Now()\n\terr := l.AllowWithin(ctx, 5*time.Millisecond)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed < 5*time.Millisecond {\n\t\tt.Fatalf(\"expected to wait at least maxWait, elapsed=%v\", elapsed)\n\t}\n\n\ttime.Sleep(30 * time.Millisecond) // allow token to replenish\n\tif err := l.AllowWithin(ctx, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"expected allowance after replenish, got %v\", err)\n\t}\n}\n\nfunc TestLimiterAllowCanceled(t *testing.T) {\n\tl := New(2, 1)\n\tif err := l.Allow(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected error on first token: %v\", err)\n\t}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := l.Allow(ctx); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context canceled, got %v\", err)\n\t}\n}\n\nfunc TestLimiterWrap(t *testing.T) {\n\tl := New(1, 1)\n\ttype ctxKey string\n\tconst key ctxKey = \"test-key\"\n\n\tvar calls int\n\twrapped := l.Wrap(func(ctx context.Context) error {\n\t\tcalls++\n\t\tif got, want := ctx.Value(key), \"value\"; got != want {\n\t\t\tt.Fatalf(\"expected context value %q, got %v\", want, got)\n\t\t}\n\t\treturn nil\n\t})\n\tif wrapped == nil {\n\t\tt.Fatal(\"expected non-nil wrapped function\")\n\t}\n\n\tctx := context.WithValue(context.Background(), key, \"value\")\n\tif err := wrapped(ctx); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"expected fn to run once, got %d\", calls)\n\t}\n\n\tdeadlineCtx, cancel := context.WithTimeout(context.Background(), 20*time.Millisecond)\n\tdefer cancel()\n\tif err := wrapped(deadlineCtx); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded from limiter, got %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"fn should not run when limiter blocks, got calls=%d\", calls)\n\t}\n}\n\nfunc TestLimiterWrapNil(t *testing.T) {\n\tvar l *Limiter\n\tif wrapped := l.Wrap(nil); wrapped != nil {\n\t\tt.Fatal(\"expected nil result for nil fn\")\n\t}\n}\n",
        "tags": [
          "go",
          "ratelimit"
        ],
        "order": 3
      },
      {
        "package": "ratelimit",
        "slug": "go-ratelimit-allowwithin",
        "title": "AllowWithin ограничивает ожидание maxWait.",
        "description": "Level 5 (medium+): AllowWithin ограничивает ожидание maxWait.\n  - при maxWait <= 0 попытайтесь получить токен немедленно;\n  - иначе оборачивайте исходный контекст через context.WithTimeout и переиспользуйте Allow.\n\nHint: не теряйте исходную ошибку контекста (DeadlineExceeded / Canceled).",
        "difficulty": "medium",
        "hint1": "не теряйте исходную ошибку контекста (DeadlineExceeded / Canceled).",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage ratelimit\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): спроектируйте структуру Limiter, которая хранит конфигурацию\n// (заданную скорость rps и burst) и состояние исполнения. Для управления доступом\n// без сторонних библиотек понадобятся:\n//   - длительность между токенами (i.e. time.Second / rps),\n//   - слайс с моментами времени, когда занятые токены станут доступны снова.\n//\n// Hint: держите данные под мьютексом, чтобы несколько горутин не портили очередь.\ntype Limiter struct {\n\tmu           sync.Mutex\n\tinterval     time.Duration\n\tburst        int\n\treservations []time.Time\n}\n\n// Level 2 (easy+): конструктор New настраивает native rate limiter.\n//   - нормализуйте отрицательные rps/burst (защищайтесь от деления на ноль);\n//   - готовьте слайс под burst значений;\n//   - не используйте внешний пакет rate.\n//\n// Hint: храните время последующей доступности токена как time.Time и обновляйте его через Add.\nfunc New(rps float64, burst int) *Limiter {\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\tperToken := time.Duration(float64(time.Second) / rps)\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0),\n\t}\n}\n\n// Level 3 (medium): реализуйте метод резервирования токена, который возвращает\n// оставшееся ожидание. Он должен:\n//   * удалять из слайса все времена, уже наступившие (token free);\n//   * если токен доступен — добавлять новую запись и возвращать (0, true);\n//   * иначе вернуть время до ближайшего освобождения (delay, false).\n// Hint: используйте time.Now внутри Allow/AllowWithin, а не храните глобальные таймеры.\n\n// Level 4 (medium+): Allow дожидается токена, пока контекст не отменён.\n//   - повторно вызывайте резервирование, пока не получите токен;\n//   - если нужно ждать — ставьте таймер через time.NewTimer и проверяйте ctx.Done.\n//\n// Hint: всегда корректно останавливайте таймер и не забывайте про nil-контексты.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\twait, ok := l.reserve(time.Now())\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): AllowWithin ограничивает ожидание maxWait.\n//   - при maxWait <= 0 попытайтесь получить токен немедленно;\n//   - иначе оборачивайте исходный контекст через context.WithTimeout и переиспользуйте Allow.\n//\n// Hint: не теряйте исходную ошибку контекста (DeadlineExceeded / Canceled).\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif maxWait <= 0 {\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\treturn context.DeadlineExceeded\n\t}\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\tdefer cancel()\n\treturn l.Allow(ctx)\n}\n\n// Level 6 (medium+): Wrap лимитирует вызовы произвольной функции fn.\n//   - сперва запросите токен через Allow;\n//   - передайте исходный контекст внутрь fn;\n//   - аккуратно обработайте nil-параметры.\n//\n// Hint: возвращайте nil вместо обёртки, если fn равен nil — так легче заметить ошибку.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\tif fn == nil {\n\t\treturn nil\n\t}\n\treturn func(ctx context.Context) error {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn fn(ctx)\n\t}\n}\n\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\twait := l.reservations[0].Sub(now)\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\treturn wait, false\n}\n\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\tidx := 0\n\tfor _, r := range l.reservations {\n\t\tif r.After(now) {\n\t\t\tbreak\n\t\t}\n\t\tidx++\n\t}\n\tif idx == 0 {\n\t\treturn\n\t}\n\tcopy(l.reservations, l.reservations[idx:])\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t}\n\treturn ctx.Err()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\n// Вариант с тегом solution содержит полностью реализованный токен-бакет.\npackage ratelimit\n\nimport (\n\t// context нужен для поддержки отмены/дедлайнов при ожидании токенов.\n\t\"context\"\n\t// sync предоставляет мьютекс, чтобы синхронизировать доступ к очереди резервов.\n\t\"sync\"\n\t// time отвечает за работу со временем и таймерами.\n\t\"time\"\n)\n\n// Limiter описывает состояние и конфигурацию собственного rate limiter.\ntype Limiter struct {\n\t// mu защищает поля структуры от гонок при конкурентных вызовах.\n\tmu sync.Mutex\n\t// interval хранит длительность между выдачами токенов (обратная величина rps).\n\tinterval time.Duration\n\t// burst указывает максимальное число одновременно занятых токенов.\n\tburst int\n\t// reservations — очередь моментов времени, когда занятые токены освободятся.\n\treservations []time.Time\n}\n\n// New настраивает лимитер с учетом требуемой скорости rps и всплеска burst.\nfunc New(rps float64, burst int) *Limiter {\n\t// Нормализуем burst, чтобы он был хотя бы единицей.\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\t// Нормализуем rps, чтобы избежать деления на ноль и отрицательных скоростей.\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\t// Вычисляем длительность между токенами как обратную величину rps.\n\tperToken := time.Duration(float64(time.Second) / rps)\n\t// Страхуемся от нулевых/отрицательных значений из-за округления.\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\t// Возвращаем инициализированную структуру с подготовленным буфером под очередь.\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0, burst),\n\t}\n}\n\n// Allow ждёт появления токена или возвращает ошибку контекста, если ожидание прерывают.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\t// nil-лимитер считаем всегда разрешающим и ничего не делаем.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Подменяем отсутствующий контекст фоновой реализацией.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Повторяем попытки резервирования, пока не получим токен или контекст не завершится.\n\tfor {\n\t\t// reserve возвращает, нужно ли ждать, и удалось ли сразу занять токен.\n\t\twait, ok := l.reserve(time.Now())\n\t\t// Если токен получен, можно выходить без ожидания.\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\t// Отрицательная задержка означает, что очередь уже освобождена — пробуем ещё раз.\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Ждём нужную длительность, уважая отмену через контекст.\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// AllowWithin ограничивает ожидание верхней границей maxWait.\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\t// nil-лимитер по-прежнему не накладывает ограничений.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Гарантируем ненулевой контекст для дальнейшей работы.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Если ждать нельзя совсем, пробуем занять токен немедленно.\n\tif maxWait <= 0 {\n\t\t// tryImmediate проверяет наличие свободного токена без блокировки.\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\t// Токен взять не удалось — значит, превышен дедлайн ожидания.\n\t\treturn context.DeadlineExceeded\n\t}\n\t// Создаем контекст с таймаутом, чтобы ограничить суммарное ожидание.\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\t// Освобождаем ресурсы таймера при выходе.\n\tdefer cancel()\n\t// Используем базовую реализацию Allow, которая уже обрабатывает ожидание токена.\n\treturn l.Allow(ctx)\n}\n\n// Wrap возвращает функцию, которая сначала ждёт токен, а затем вызывает fn.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\t// Если исходной функции нет, нечего оборачивать — возвращаем nil.\n\tif fn == nil {\n\t\treturn nil\n\t}\n\t// Возвращаем замыкание, внутри которого сначала происходит лимитирование.\n\treturn func(ctx context.Context) error {\n\t\t// Allow выдаёт токен; ошибка сразу прерывает выполнение fn.\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Если токен получен, выполняем исходную функцию с тем же контекстом.\n\t\treturn fn(ctx)\n\t}\n}\n\n// reserve — вспомогательная функция: пытается занять токен и сообщить, сколько ждать.\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\t// Защищаем работу с состоянием мьютексом.\n\tl.mu.Lock()\n\t// Убедимся, что разблокируем мьютекс при любом выходе.\n\tdefer l.mu.Unlock()\n\t// Очищаем из очереди токены, которые уже «освободились» к текущему моменту.\n\tl.releaseExpiredLocked(now)\n\t// Если есть свободный слот (меньше burst), резервируем токен немедленно.\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\t// Иначе считаем время до ближайшего освобождения.\n\twait := l.reservations[0].Sub(now)\n\t// Отрицательные значения трактуем как готовность без ожидания (следующая итерация цикла).\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\t// Возвращаем задержку и флаг, что токен пока недоступен.\n\treturn wait, false\n}\n\n// tryImmediate проверяет, можно ли прямо сейчас занять токен, без ожидания.\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\t// Блокируем структуру, чтобы безопасно работать с очередью.\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\t// Удаляем устаревшие записи, чтобы информация была актуальна.\n\tl.releaseExpiredLocked(now)\n\t// Если очередь уже заполнена до burst, моментального токена нет.\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\t// Иначе резервируем токен и фиксируем момент, когда он будет доступен снова.\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\n// releaseExpiredLocked чистит очередь от токенов, «вернувшихся» к моменту now.\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\t// idx считает, сколько элементов в начале слайса уже освободилось.\n\tidx := 0\n\t// Двигаем idx, пока встречаем времена, не позже текущего момента.\n\tfor idx < len(l.reservations) && !l.reservations[idx].After(now) {\n\t\tidx++\n\t}\n\t// Если ничего не освободилось — просто выходим.\n\tif idx == 0 {\n\t\treturn\n\t}\n\t// Сдвигаем оставшиеся активные записи в начало слайса.\n\tcopy(l.reservations, l.reservations[idx:])\n\t// Укорачиваем слайс, устраняя освободившиеся элементы.\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\n// waitOnContext ожидает длительность d и отменяется, если контекст завершён раньше.\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\t// Если ждать нечего, просто проверяем состояние контекста.\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\t// Создаём таймер, чтобы заснуть на требуемый промежуток.\n\ttimer := time.NewTimer(d)\n\t// Гарантируем освобождение ресурсов таймера.\n\tdefer timer.Stop()\n\t// Ждём либо истечения таймера, либо сигнала отмены.\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\t// Стараемся остановить таймер и почистить канал, если он уже сработал.\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn ctx.Err()\n\t}\n}\n",
        "testCode": "package ratelimit\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLimiter(t *testing.T) {\n\tl := New(5, 2) // ~5 rps\n\tctx, cancel := context.WithTimeout(context.Background(), 200*time.Millisecond)\n\tdefer cancel()\n\n\tstart := time.Now()\n\tfor i := 0; i < 3; i++ {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\telapsed := time.Since(start)\n\tif elapsed < 150*time.Millisecond {\n\t\tt.Fatalf(\"limiter too permissive, elapsed=%v\", elapsed)\n\t}\n}\n\nfunc TestLimiterAllowWithin(t *testing.T) {\n\tl := New(50, 1) // token roughly every 20ms\n\tctx := context.Background()\n\n\tif err := l.AllowWithin(ctx, 0); err != nil {\n\t\tt.Fatalf(\"expected immediate allowance, got %v\", err)\n\t}\n\n\tstart := time.Now()\n\terr := l.AllowWithin(ctx, 5*time.Millisecond)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed < 5*time.Millisecond {\n\t\tt.Fatalf(\"expected to wait at least maxWait, elapsed=%v\", elapsed)\n\t}\n\n\ttime.Sleep(30 * time.Millisecond) // allow token to replenish\n\tif err := l.AllowWithin(ctx, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"expected allowance after replenish, got %v\", err)\n\t}\n}\n\nfunc TestLimiterAllowCanceled(t *testing.T) {\n\tl := New(2, 1)\n\tif err := l.Allow(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected error on first token: %v\", err)\n\t}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := l.Allow(ctx); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context canceled, got %v\", err)\n\t}\n}\n\nfunc TestLimiterWrap(t *testing.T) {\n\tl := New(1, 1)\n\ttype ctxKey string\n\tconst key ctxKey = \"test-key\"\n\n\tvar calls int\n\twrapped := l.Wrap(func(ctx context.Context) error {\n\t\tcalls++\n\t\tif got, want := ctx.Value(key), \"value\"; got != want {\n\t\t\tt.Fatalf(\"expected context value %q, got %v\", want, got)\n\t\t}\n\t\treturn nil\n\t})\n\tif wrapped == nil {\n\t\tt.Fatal(\"expected non-nil wrapped function\")\n\t}\n\n\tctx := context.WithValue(context.Background(), key, \"value\")\n\tif err := wrapped(ctx); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"expected fn to run once, got %d\", calls)\n\t}\n\n\tdeadlineCtx, cancel := context.WithTimeout(context.Background(), 20*time.Millisecond)\n\tdefer cancel()\n\tif err := wrapped(deadlineCtx); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded from limiter, got %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"fn should not run when limiter blocks, got calls=%d\", calls)\n\t}\n}\n\nfunc TestLimiterWrapNil(t *testing.T) {\n\tvar l *Limiter\n\tif wrapped := l.Wrap(nil); wrapped != nil {\n\t\tt.Fatal(\"expected nil result for nil fn\")\n\t}\n}\n",
        "tags": [
          "go",
          "ratelimit"
        ],
        "order": 4
      },
      {
        "package": "ratelimit",
        "slug": "go-ratelimit-wrap",
        "title": "Wrap лимитирует вызовы произвольной функции fn.",
        "description": "Level 6 (medium+): Wrap лимитирует вызовы произвольной функции fn.\n  - сперва запросите токен через Allow;\n  - передайте исходный контекст внутрь fn;\n  - аккуратно обработайте nil-параметры.\n\nHint: возвращайте nil вместо обёртки, если fn равен nil — так легче заметить ошибку.",
        "difficulty": "medium",
        "hint1": "возвращайте nil вместо обёртки, если fn равен nil — так легче заметить ошибку.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage ratelimit\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): спроектируйте структуру Limiter, которая хранит конфигурацию\n// (заданную скорость rps и burst) и состояние исполнения. Для управления доступом\n// без сторонних библиотек понадобятся:\n//   - длительность между токенами (i.e. time.Second / rps),\n//   - слайс с моментами времени, когда занятые токены станут доступны снова.\n//\n// Hint: держите данные под мьютексом, чтобы несколько горутин не портили очередь.\ntype Limiter struct {\n\tmu           sync.Mutex\n\tinterval     time.Duration\n\tburst        int\n\treservations []time.Time\n}\n\n// Level 2 (easy+): конструктор New настраивает native rate limiter.\n//   - нормализуйте отрицательные rps/burst (защищайтесь от деления на ноль);\n//   - готовьте слайс под burst значений;\n//   - не используйте внешний пакет rate.\n//\n// Hint: храните время последующей доступности токена как time.Time и обновляйте его через Add.\nfunc New(rps float64, burst int) *Limiter {\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\tperToken := time.Duration(float64(time.Second) / rps)\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0),\n\t}\n}\n\n// Level 3 (medium): реализуйте метод резервирования токена, который возвращает\n// оставшееся ожидание. Он должен:\n//   * удалять из слайса все времена, уже наступившие (token free);\n//   * если токен доступен — добавлять новую запись и возвращать (0, true);\n//   * иначе вернуть время до ближайшего освобождения (delay, false).\n// Hint: используйте time.Now внутри Allow/AllowWithin, а не храните глобальные таймеры.\n\n// Level 4 (medium+): Allow дожидается токена, пока контекст не отменён.\n//   - повторно вызывайте резервирование, пока не получите токен;\n//   - если нужно ждать — ставьте таймер через time.NewTimer и проверяйте ctx.Done.\n//\n// Hint: всегда корректно останавливайте таймер и не забывайте про nil-контексты.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tfor {\n\t\twait, ok := l.reserve(time.Now())\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// Level 5 (medium+): AllowWithin ограничивает ожидание maxWait.\n//   - при maxWait <= 0 попытайтесь получить токен немедленно;\n//   - иначе оборачивайте исходный контекст через context.WithTimeout и переиспользуйте Allow.\n//\n// Hint: не теряйте исходную ошибку контекста (DeadlineExceeded / Canceled).\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\tif l == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif maxWait <= 0 {\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\treturn context.DeadlineExceeded\n\t}\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\tdefer cancel()\n\treturn l.Allow(ctx)\n}\n\n// Level 6 (medium+): Wrap лимитирует вызовы произвольной функции fn.\n//   - сперва запросите токен через Allow;\n//   - передайте исходный контекст внутрь fn;\n//   - аккуратно обработайте nil-параметры.\n//\n// Hint: возвращайте nil вместо обёртки, если fn равен nil — так легче заметить ошибку.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\tif fn == nil {\n\t\treturn nil\n\t}\n\treturn func(ctx context.Context) error {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn fn(ctx)\n\t}\n}\n\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\twait := l.reservations[0].Sub(now)\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\treturn wait, false\n}\n\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.releaseExpiredLocked(now)\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\tidx := 0\n\tfor _, r := range l.reservations {\n\t\tif r.After(now) {\n\t\t\tbreak\n\t\t}\n\t\tidx++\n\t}\n\tif idx == 0 {\n\t\treturn\n\t}\n\tcopy(l.reservations, l.reservations[idx:])\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t}\n\treturn ctx.Err()\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\n// Вариант с тегом solution содержит полностью реализованный токен-бакет.\npackage ratelimit\n\nimport (\n\t// context нужен для поддержки отмены/дедлайнов при ожидании токенов.\n\t\"context\"\n\t// sync предоставляет мьютекс, чтобы синхронизировать доступ к очереди резервов.\n\t\"sync\"\n\t// time отвечает за работу со временем и таймерами.\n\t\"time\"\n)\n\n// Limiter описывает состояние и конфигурацию собственного rate limiter.\ntype Limiter struct {\n\t// mu защищает поля структуры от гонок при конкурентных вызовах.\n\tmu sync.Mutex\n\t// interval хранит длительность между выдачами токенов (обратная величина rps).\n\tinterval time.Duration\n\t// burst указывает максимальное число одновременно занятых токенов.\n\tburst int\n\t// reservations — очередь моментов времени, когда занятые токены освободятся.\n\treservations []time.Time\n}\n\n// New настраивает лимитер с учетом требуемой скорости rps и всплеска burst.\nfunc New(rps float64, burst int) *Limiter {\n\t// Нормализуем burst, чтобы он был хотя бы единицей.\n\tif burst <= 0 {\n\t\tburst = 1\n\t}\n\t// Нормализуем rps, чтобы избежать деления на ноль и отрицательных скоростей.\n\tif rps <= 0 {\n\t\trps = 1\n\t}\n\t// Вычисляем длительность между токенами как обратную величину rps.\n\tperToken := time.Duration(float64(time.Second) / rps)\n\t// Страхуемся от нулевых/отрицательных значений из-за округления.\n\tif perToken <= 0 {\n\t\tperToken = time.Nanosecond\n\t}\n\t// Возвращаем инициализированную структуру с подготовленным буфером под очередь.\n\treturn &Limiter{\n\t\tinterval:     perToken,\n\t\tburst:        burst,\n\t\treservations: make([]time.Time, 0, burst),\n\t}\n}\n\n// Allow ждёт появления токена или возвращает ошибку контекста, если ожидание прерывают.\nfunc (l *Limiter) Allow(ctx context.Context) error {\n\t// nil-лимитер считаем всегда разрешающим и ничего не делаем.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Подменяем отсутствующий контекст фоновой реализацией.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Повторяем попытки резервирования, пока не получим токен или контекст не завершится.\n\tfor {\n\t\t// reserve возвращает, нужно ли ждать, и удалось ли сразу занять токен.\n\t\twait, ok := l.reserve(time.Now())\n\t\t// Если токен получен, можно выходить без ожидания.\n\t\tif ok {\n\t\t\treturn nil\n\t\t}\n\t\t// Отрицательная задержка означает, что очередь уже освобождена — пробуем ещё раз.\n\t\tif wait <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Ждём нужную длительность, уважая отмену через контекст.\n\t\tif err := waitOnContext(ctx, wait); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n// AllowWithin ограничивает ожидание верхней границей maxWait.\nfunc (l *Limiter) AllowWithin(ctx context.Context, maxWait time.Duration) error {\n\t// nil-лимитер по-прежнему не накладывает ограничений.\n\tif l == nil {\n\t\treturn nil\n\t}\n\t// Гарантируем ненулевой контекст для дальнейшей работы.\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\t// Если ждать нельзя совсем, пробуем занять токен немедленно.\n\tif maxWait <= 0 {\n\t\t// tryImmediate проверяет наличие свободного токена без блокировки.\n\t\tif l.tryImmediate(time.Now()) {\n\t\t\treturn nil\n\t\t}\n\t\t// Токен взять не удалось — значит, превышен дедлайн ожидания.\n\t\treturn context.DeadlineExceeded\n\t}\n\t// Создаем контекст с таймаутом, чтобы ограничить суммарное ожидание.\n\tctx, cancel := context.WithTimeout(ctx, maxWait)\n\t// Освобождаем ресурсы таймера при выходе.\n\tdefer cancel()\n\t// Используем базовую реализацию Allow, которая уже обрабатывает ожидание токена.\n\treturn l.Allow(ctx)\n}\n\n// Wrap возвращает функцию, которая сначала ждёт токен, а затем вызывает fn.\nfunc (l *Limiter) Wrap(fn func(ctx context.Context) error) func(ctx context.Context) error {\n\t// Если исходной функции нет, нечего оборачивать — возвращаем nil.\n\tif fn == nil {\n\t\treturn nil\n\t}\n\t// Возвращаем замыкание, внутри которого сначала происходит лимитирование.\n\treturn func(ctx context.Context) error {\n\t\t// Allow выдаёт токен; ошибка сразу прерывает выполнение fn.\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Если токен получен, выполняем исходную функцию с тем же контекстом.\n\t\treturn fn(ctx)\n\t}\n}\n\n// reserve — вспомогательная функция: пытается занять токен и сообщить, сколько ждать.\nfunc (l *Limiter) reserve(now time.Time) (time.Duration, bool) {\n\t// Защищаем работу с состоянием мьютексом.\n\tl.mu.Lock()\n\t// Убедимся, что разблокируем мьютекс при любом выходе.\n\tdefer l.mu.Unlock()\n\t// Очищаем из очереди токены, которые уже «освободились» к текущему моменту.\n\tl.releaseExpiredLocked(now)\n\t// Если есть свободный слот (меньше burst), резервируем токен немедленно.\n\tif len(l.reservations) < l.burst {\n\t\tl.reservations = append(l.reservations, now.Add(l.interval))\n\t\treturn 0, true\n\t}\n\t// Иначе считаем время до ближайшего освобождения.\n\twait := l.reservations[0].Sub(now)\n\t// Отрицательные значения трактуем как готовность без ожидания (следующая итерация цикла).\n\tif wait < 0 {\n\t\treturn 0, false\n\t}\n\t// Возвращаем задержку и флаг, что токен пока недоступен.\n\treturn wait, false\n}\n\n// tryImmediate проверяет, можно ли прямо сейчас занять токен, без ожидания.\nfunc (l *Limiter) tryImmediate(now time.Time) bool {\n\t// Блокируем структуру, чтобы безопасно работать с очередью.\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\t// Удаляем устаревшие записи, чтобы информация была актуальна.\n\tl.releaseExpiredLocked(now)\n\t// Если очередь уже заполнена до burst, моментального токена нет.\n\tif len(l.reservations) >= l.burst {\n\t\treturn false\n\t}\n\t// Иначе резервируем токен и фиксируем момент, когда он будет доступен снова.\n\tl.reservations = append(l.reservations, now.Add(l.interval))\n\treturn true\n}\n\n// releaseExpiredLocked чистит очередь от токенов, «вернувшихся» к моменту now.\nfunc (l *Limiter) releaseExpiredLocked(now time.Time) {\n\t// idx считает, сколько элементов в начале слайса уже освободилось.\n\tidx := 0\n\t// Двигаем idx, пока встречаем времена, не позже текущего момента.\n\tfor idx < len(l.reservations) && !l.reservations[idx].After(now) {\n\t\tidx++\n\t}\n\t// Если ничего не освободилось — просто выходим.\n\tif idx == 0 {\n\t\treturn\n\t}\n\t// Сдвигаем оставшиеся активные записи в начало слайса.\n\tcopy(l.reservations, l.reservations[idx:])\n\t// Укорачиваем слайс, устраняя освободившиеся элементы.\n\tl.reservations = l.reservations[:len(l.reservations)-idx]\n}\n\n// waitOnContext ожидает длительность d и отменяется, если контекст завершён раньше.\nfunc waitOnContext(ctx context.Context, d time.Duration) error {\n\t// Если ждать нечего, просто проверяем состояние контекста.\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\t// Создаём таймер, чтобы заснуть на требуемый промежуток.\n\ttimer := time.NewTimer(d)\n\t// Гарантируем освобождение ресурсов таймера.\n\tdefer timer.Stop()\n\t// Ждём либо истечения таймера, либо сигнала отмены.\n\tselect {\n\tcase <-timer.C:\n\t\treturn nil\n\tcase <-ctx.Done():\n\t\t// Стараемся остановить таймер и почистить канал, если он уже сработал.\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn ctx.Err()\n\t}\n}\n",
        "testCode": "package ratelimit\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLimiter(t *testing.T) {\n\tl := New(5, 2) // ~5 rps\n\tctx, cancel := context.WithTimeout(context.Background(), 200*time.Millisecond)\n\tdefer cancel()\n\n\tstart := time.Now()\n\tfor i := 0; i < 3; i++ {\n\t\tif err := l.Allow(ctx); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\telapsed := time.Since(start)\n\tif elapsed < 150*time.Millisecond {\n\t\tt.Fatalf(\"limiter too permissive, elapsed=%v\", elapsed)\n\t}\n}\n\nfunc TestLimiterAllowWithin(t *testing.T) {\n\tl := New(50, 1) // token roughly every 20ms\n\tctx := context.Background()\n\n\tif err := l.AllowWithin(ctx, 0); err != nil {\n\t\tt.Fatalf(\"expected immediate allowance, got %v\", err)\n\t}\n\n\tstart := time.Now()\n\terr := l.AllowWithin(ctx, 5*time.Millisecond)\n\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed < 5*time.Millisecond {\n\t\tt.Fatalf(\"expected to wait at least maxWait, elapsed=%v\", elapsed)\n\t}\n\n\ttime.Sleep(30 * time.Millisecond) // allow token to replenish\n\tif err := l.AllowWithin(ctx, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"expected allowance after replenish, got %v\", err)\n\t}\n}\n\nfunc TestLimiterAllowCanceled(t *testing.T) {\n\tl := New(2, 1)\n\tif err := l.Allow(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected error on first token: %v\", err)\n\t}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := l.Allow(ctx); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context canceled, got %v\", err)\n\t}\n}\n\nfunc TestLimiterWrap(t *testing.T) {\n\tl := New(1, 1)\n\ttype ctxKey string\n\tconst key ctxKey = \"test-key\"\n\n\tvar calls int\n\twrapped := l.Wrap(func(ctx context.Context) error {\n\t\tcalls++\n\t\tif got, want := ctx.Value(key), \"value\"; got != want {\n\t\t\tt.Fatalf(\"expected context value %q, got %v\", want, got)\n\t\t}\n\t\treturn nil\n\t})\n\tif wrapped == nil {\n\t\tt.Fatal(\"expected non-nil wrapped function\")\n\t}\n\n\tctx := context.WithValue(context.Background(), key, \"value\")\n\tif err := wrapped(ctx); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"expected fn to run once, got %d\", calls)\n\t}\n\n\tdeadlineCtx, cancel := context.WithTimeout(context.Background(), 20*time.Millisecond)\n\tdefer cancel()\n\tif err := wrapped(deadlineCtx); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded from limiter, got %v\", err)\n\t}\n\tif calls != 1 {\n\t\tt.Fatalf(\"fn should not run when limiter blocks, got calls=%d\", calls)\n\t}\n}\n\nfunc TestLimiterWrapNil(t *testing.T) {\n\tvar l *Limiter\n\tif wrapped := l.Wrap(nil); wrapped != nil {\n\t\tt.Fatal(\"expected nil result for nil fn\")\n\t}\n}\n",
        "tags": [
          "go",
          "ratelimit"
        ],
        "order": 5
      }
    ],
    "category": "production"
  },
  {
    "name": "retryx",
    "tasks": [
      {
        "package": "retryx",
        "slug": "go-retryx-backoff",
        "title": "Backoff рассчитывает экспоненциальную задержку base * 2^attempt с джиттером.",
        "description": "Level 1 (easy): Backoff рассчитывает экспоненциальную задержку base * 2^attempt с джиттером.\nHint: добавьте случайный множитель в диапазоне [0.5, 1.5].",
        "difficulty": "easy",
        "hint1": "добавьте случайный множитель в диапазоне [0.5, 1.5].",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\n// Level 1 (easy): Backoff рассчитывает экспоненциальную задержку base * 2^attempt с джиттером.\n// Hint: добавьте случайный множитель в диапазоне [0.5, 1.5].\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 {\n\t\tattempt = 0\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt\n\tjitter := 0.5 + rand.Float64()\n\treturn time.Duration(float64(delay) * jitter)\n}\n\n// Level 2 (medium): Do повторяет op до n раз, применяя Backoff и учитывая ctx.Done().\n// Hint: выходите при успехе операции или при отмене контекста/исчерпании попыток.\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif op == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n < 0 {\n\t\tn = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif i == n {\n\t\t\tbreak\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 3 (medium+): RetryUntil повторяет op, пока shouldRetry(err) == true и не превышен лимит.\n// Hint: переиспользуйте Do, но проводите проверку перед паузой.\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif base == 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif shouldRetry == nil {\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif !shouldRetry(err) {\n\t\t\treturn err\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 4 (medium+): BackoffSequence возвращает слайс задержек для первых n попыток.\n// Hint: используйте Backoff внутри и собирайте длительности.\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tout := make([]time.Duration, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = Backoff(i, base)\n\t}\n\n\treturn out\n}\n\n// Level 5 (medium+): SleepContext ждёт указанную длительность или завершение ctx.\n// Hint: примените time.NewTimer и корректно освобождайте ресурсы.\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d)\n\tselect {\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\t<-timer.C\n\t\t}\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 { // negative attempt numbers treated as zero retries\n\t\tattempt = 0\n\t}\n\tif base <= 0 { // guard against invalid base durations\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt                      // exponential growth by shifting base duration\n\tjitter := 0.5 + rand.Float64()                // randomize delay within [0.5,1.5] factor\n\treturn time.Duration(float64(delay) * jitter) // apply jitter to computed delay\n}\n\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif n <= 0 { // nothing to do when no attempts requested\n\t\treturn nil\n\t}\n\tvar lastErr error                          // remember last error to return when retries exhausted\n\tfor attempt := 0; attempt < n; attempt++ { // iterate through allowed attempts\n\t\tif ctx.Err() != nil { // abort when context already canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err == nil { // succeed immediately when op returns nil\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err // capture error for possible retry or final return\n\t\t}\n\t\tif attempt == n-1 { // stop retrying after last allowed attempt\n\t\t\tbreak\n\t\t}\n\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait respecting context cancellation\n\t\t\treturn err\n\t\t}\n\t}\n\treturn lastErr // return final error after exhausting retries\n}\n\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif shouldRetry == nil { // default to always retrying when predicate missing\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar lastErr error                          // track last error encountered\n\tfor attempt := 0; attempt < n; attempt++ { // up to n attempts conditioned by predicate\n\t\tif ctx.Err() != nil { // break out when context canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err != nil { // invoke operation and inspect error\n\t\t\tlastErr = err          // remember error for potential return\n\t\t\tif !shouldRetry(err) { // stop retrying when predicate rejects error\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait before next retry\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn nil // success terminates loop immediately\n\t}\n\treturn lastErr // return last recorded error when retries depleted\n}\n\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 { // return empty slice for non-positive length\n\t\treturn nil\n\t}\n\tseq := make([]time.Duration, n) // preallocate slice of requested size\n\tfor i := 0; i < n; i++ {        // compute delay for each attempt index\n\t\tseq[i] = Backoff(i, base) // reuse Backoff to calculate duration\n\t}\n\treturn seq // provide caller with generated sequence\n}\n\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 { // skip sleeping for non-positive durations\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d) // allocate timer for requested duration\n\tdefer func() {\n\t\tif !timer.Stop() { // stop timer and drain channel when required\n\t\t\t<-timer.C\n\t\t}\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err() // propagate context cancellation error\n\tcase <-timer.C:\n\t\treturn nil // timer fired successfully without cancellation\n\t}\n}\n",
        "testCode": "package retryx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestBackoff(t *testing.T) {\n\tt.Parallel()\n\td := Backoff(2, 10*time.Millisecond)\n\tif d < 10*time.Millisecond || d > 60*time.Millisecond {\n\t\tt.Fatalf(\"unexpected backoff range: %v\", d)\n\t}\n}\n\nfunc TestDo(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 3 {\n\t\t\treturn errors.New(\"x\")\n\t\t}\n\t\treturn nil\n\t}\n\tif err := Do(context.Background(), 5, time.Millisecond, op); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 3 {\n\t\tt.Fatalf(\"expected 3 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestRetryUntil(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 2 {\n\t\t\treturn errors.New(\"temporary\")\n\t\t}\n\t\treturn errors.New(\"permanent\")\n\t}\n\tshouldRetry := func(err error) bool { return err.Error() == \"temporary\" }\n\tif err := RetryUntil(context.Background(), 5, time.Millisecond, op, shouldRetry); err == nil || err.Error() != \"permanent\" {\n\t\tt.Fatalf(\"expected permanent error, got %v\", err)\n\t}\n\tif calls != 2 {\n\t\tt.Fatalf(\"expected 2 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestBackoffSequence(t *testing.T) {\n\tt.Parallel()\n\tseq := BackoffSequence(3, time.Millisecond)\n\tif len(seq) != 3 {\n\t\tt.Fatalf(\"expected length 3, got %d\", len(seq))\n\t}\n\tif seq[0] <= 0 {\n\t\tt.Fatalf(\"expected positive durations: %v\", seq)\n\t}\n}\n\nfunc TestSleepContext(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)\n\tdefer cancel()\n\tif err := SleepContext(ctx, 20*time.Millisecond); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tctx2, cancel2 := context.WithCancel(context.Background())\n\tdefer cancel2()\n\tstart := time.Now()\n\tif err := SleepContext(ctx2, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif time.Since(start) < 5*time.Millisecond {\n\t\tt.Fatalf(\"sleep returned too early: %v\", time.Since(start))\n\t}\n}\n",
        "tags": [
          "go",
          "retryx"
        ],
        "order": 0
      },
      {
        "package": "retryx",
        "slug": "go-retryx-do",
        "title": "Do повторяет op до n раз, применяя Backoff и учитывая ctx.Done().",
        "description": "Level 2 (medium): Do повторяет op до n раз, применяя Backoff и учитывая ctx.Done().\nHint: выходите при успехе операции или при отмене контекста/исчерпании попыток.",
        "difficulty": "medium",
        "hint1": "выходите при успехе операции или при отмене контекста/исчерпании попыток.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\n// Level 1 (easy): Backoff рассчитывает экспоненциальную задержку base * 2^attempt с джиттером.\n// Hint: добавьте случайный множитель в диапазоне [0.5, 1.5].\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 {\n\t\tattempt = 0\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt\n\tjitter := 0.5 + rand.Float64()\n\treturn time.Duration(float64(delay) * jitter)\n}\n\n// Level 2 (medium): Do повторяет op до n раз, применяя Backoff и учитывая ctx.Done().\n// Hint: выходите при успехе операции или при отмене контекста/исчерпании попыток.\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif op == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n < 0 {\n\t\tn = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif i == n {\n\t\t\tbreak\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 3 (medium+): RetryUntil повторяет op, пока shouldRetry(err) == true и не превышен лимит.\n// Hint: переиспользуйте Do, но проводите проверку перед паузой.\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif base == 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif shouldRetry == nil {\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif !shouldRetry(err) {\n\t\t\treturn err\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 4 (medium+): BackoffSequence возвращает слайс задержек для первых n попыток.\n// Hint: используйте Backoff внутри и собирайте длительности.\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tout := make([]time.Duration, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = Backoff(i, base)\n\t}\n\n\treturn out\n}\n\n// Level 5 (medium+): SleepContext ждёт указанную длительность или завершение ctx.\n// Hint: примените time.NewTimer и корректно освобождайте ресурсы.\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d)\n\tselect {\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\t<-timer.C\n\t\t}\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 { // negative attempt numbers treated as zero retries\n\t\tattempt = 0\n\t}\n\tif base <= 0 { // guard against invalid base durations\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt                      // exponential growth by shifting base duration\n\tjitter := 0.5 + rand.Float64()                // randomize delay within [0.5,1.5] factor\n\treturn time.Duration(float64(delay) * jitter) // apply jitter to computed delay\n}\n\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif n <= 0 { // nothing to do when no attempts requested\n\t\treturn nil\n\t}\n\tvar lastErr error                          // remember last error to return when retries exhausted\n\tfor attempt := 0; attempt < n; attempt++ { // iterate through allowed attempts\n\t\tif ctx.Err() != nil { // abort when context already canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err == nil { // succeed immediately when op returns nil\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err // capture error for possible retry or final return\n\t\t}\n\t\tif attempt == n-1 { // stop retrying after last allowed attempt\n\t\t\tbreak\n\t\t}\n\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait respecting context cancellation\n\t\t\treturn err\n\t\t}\n\t}\n\treturn lastErr // return final error after exhausting retries\n}\n\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif shouldRetry == nil { // default to always retrying when predicate missing\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar lastErr error                          // track last error encountered\n\tfor attempt := 0; attempt < n; attempt++ { // up to n attempts conditioned by predicate\n\t\tif ctx.Err() != nil { // break out when context canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err != nil { // invoke operation and inspect error\n\t\t\tlastErr = err          // remember error for potential return\n\t\t\tif !shouldRetry(err) { // stop retrying when predicate rejects error\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait before next retry\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn nil // success terminates loop immediately\n\t}\n\treturn lastErr // return last recorded error when retries depleted\n}\n\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 { // return empty slice for non-positive length\n\t\treturn nil\n\t}\n\tseq := make([]time.Duration, n) // preallocate slice of requested size\n\tfor i := 0; i < n; i++ {        // compute delay for each attempt index\n\t\tseq[i] = Backoff(i, base) // reuse Backoff to calculate duration\n\t}\n\treturn seq // provide caller with generated sequence\n}\n\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 { // skip sleeping for non-positive durations\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d) // allocate timer for requested duration\n\tdefer func() {\n\t\tif !timer.Stop() { // stop timer and drain channel when required\n\t\t\t<-timer.C\n\t\t}\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err() // propagate context cancellation error\n\tcase <-timer.C:\n\t\treturn nil // timer fired successfully without cancellation\n\t}\n}\n",
        "testCode": "package retryx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestBackoff(t *testing.T) {\n\tt.Parallel()\n\td := Backoff(2, 10*time.Millisecond)\n\tif d < 10*time.Millisecond || d > 60*time.Millisecond {\n\t\tt.Fatalf(\"unexpected backoff range: %v\", d)\n\t}\n}\n\nfunc TestDo(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 3 {\n\t\t\treturn errors.New(\"x\")\n\t\t}\n\t\treturn nil\n\t}\n\tif err := Do(context.Background(), 5, time.Millisecond, op); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 3 {\n\t\tt.Fatalf(\"expected 3 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestRetryUntil(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 2 {\n\t\t\treturn errors.New(\"temporary\")\n\t\t}\n\t\treturn errors.New(\"permanent\")\n\t}\n\tshouldRetry := func(err error) bool { return err.Error() == \"temporary\" }\n\tif err := RetryUntil(context.Background(), 5, time.Millisecond, op, shouldRetry); err == nil || err.Error() != \"permanent\" {\n\t\tt.Fatalf(\"expected permanent error, got %v\", err)\n\t}\n\tif calls != 2 {\n\t\tt.Fatalf(\"expected 2 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestBackoffSequence(t *testing.T) {\n\tt.Parallel()\n\tseq := BackoffSequence(3, time.Millisecond)\n\tif len(seq) != 3 {\n\t\tt.Fatalf(\"expected length 3, got %d\", len(seq))\n\t}\n\tif seq[0] <= 0 {\n\t\tt.Fatalf(\"expected positive durations: %v\", seq)\n\t}\n}\n\nfunc TestSleepContext(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)\n\tdefer cancel()\n\tif err := SleepContext(ctx, 20*time.Millisecond); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tctx2, cancel2 := context.WithCancel(context.Background())\n\tdefer cancel2()\n\tstart := time.Now()\n\tif err := SleepContext(ctx2, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif time.Since(start) < 5*time.Millisecond {\n\t\tt.Fatalf(\"sleep returned too early: %v\", time.Since(start))\n\t}\n}\n",
        "tags": [
          "go",
          "retryx"
        ],
        "order": 1
      },
      {
        "package": "retryx",
        "slug": "go-retryx-retryuntil",
        "title": "RetryUntil повторяет op, пока shouldRetry(err) == true и не превышен лимит.",
        "description": "Level 3 (medium+): RetryUntil повторяет op, пока shouldRetry(err) == true и не превышен лимит.\nHint: переиспользуйте Do, но проводите проверку перед паузой.",
        "difficulty": "medium",
        "hint1": "переиспользуйте Do, но проводите проверку перед паузой.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\n// Level 1 (easy): Backoff рассчитывает экспоненциальную задержку base * 2^attempt с джиттером.\n// Hint: добавьте случайный множитель в диапазоне [0.5, 1.5].\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 {\n\t\tattempt = 0\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt\n\tjitter := 0.5 + rand.Float64()\n\treturn time.Duration(float64(delay) * jitter)\n}\n\n// Level 2 (medium): Do повторяет op до n раз, применяя Backoff и учитывая ctx.Done().\n// Hint: выходите при успехе операции или при отмене контекста/исчерпании попыток.\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif op == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n < 0 {\n\t\tn = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif i == n {\n\t\t\tbreak\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 3 (medium+): RetryUntil повторяет op, пока shouldRetry(err) == true и не превышен лимит.\n// Hint: переиспользуйте Do, но проводите проверку перед паузой.\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif base == 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif shouldRetry == nil {\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif !shouldRetry(err) {\n\t\t\treturn err\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 4 (medium+): BackoffSequence возвращает слайс задержек для первых n попыток.\n// Hint: используйте Backoff внутри и собирайте длительности.\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tout := make([]time.Duration, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = Backoff(i, base)\n\t}\n\n\treturn out\n}\n\n// Level 5 (medium+): SleepContext ждёт указанную длительность или завершение ctx.\n// Hint: примените time.NewTimer и корректно освобождайте ресурсы.\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d)\n\tselect {\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\t<-timer.C\n\t\t}\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 { // negative attempt numbers treated as zero retries\n\t\tattempt = 0\n\t}\n\tif base <= 0 { // guard against invalid base durations\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt                      // exponential growth by shifting base duration\n\tjitter := 0.5 + rand.Float64()                // randomize delay within [0.5,1.5] factor\n\treturn time.Duration(float64(delay) * jitter) // apply jitter to computed delay\n}\n\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif n <= 0 { // nothing to do when no attempts requested\n\t\treturn nil\n\t}\n\tvar lastErr error                          // remember last error to return when retries exhausted\n\tfor attempt := 0; attempt < n; attempt++ { // iterate through allowed attempts\n\t\tif ctx.Err() != nil { // abort when context already canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err == nil { // succeed immediately when op returns nil\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err // capture error for possible retry or final return\n\t\t}\n\t\tif attempt == n-1 { // stop retrying after last allowed attempt\n\t\t\tbreak\n\t\t}\n\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait respecting context cancellation\n\t\t\treturn err\n\t\t}\n\t}\n\treturn lastErr // return final error after exhausting retries\n}\n\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif shouldRetry == nil { // default to always retrying when predicate missing\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar lastErr error                          // track last error encountered\n\tfor attempt := 0; attempt < n; attempt++ { // up to n attempts conditioned by predicate\n\t\tif ctx.Err() != nil { // break out when context canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err != nil { // invoke operation and inspect error\n\t\t\tlastErr = err          // remember error for potential return\n\t\t\tif !shouldRetry(err) { // stop retrying when predicate rejects error\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait before next retry\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn nil // success terminates loop immediately\n\t}\n\treturn lastErr // return last recorded error when retries depleted\n}\n\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 { // return empty slice for non-positive length\n\t\treturn nil\n\t}\n\tseq := make([]time.Duration, n) // preallocate slice of requested size\n\tfor i := 0; i < n; i++ {        // compute delay for each attempt index\n\t\tseq[i] = Backoff(i, base) // reuse Backoff to calculate duration\n\t}\n\treturn seq // provide caller with generated sequence\n}\n\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 { // skip sleeping for non-positive durations\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d) // allocate timer for requested duration\n\tdefer func() {\n\t\tif !timer.Stop() { // stop timer and drain channel when required\n\t\t\t<-timer.C\n\t\t}\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err() // propagate context cancellation error\n\tcase <-timer.C:\n\t\treturn nil // timer fired successfully without cancellation\n\t}\n}\n",
        "testCode": "package retryx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestBackoff(t *testing.T) {\n\tt.Parallel()\n\td := Backoff(2, 10*time.Millisecond)\n\tif d < 10*time.Millisecond || d > 60*time.Millisecond {\n\t\tt.Fatalf(\"unexpected backoff range: %v\", d)\n\t}\n}\n\nfunc TestDo(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 3 {\n\t\t\treturn errors.New(\"x\")\n\t\t}\n\t\treturn nil\n\t}\n\tif err := Do(context.Background(), 5, time.Millisecond, op); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 3 {\n\t\tt.Fatalf(\"expected 3 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestRetryUntil(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 2 {\n\t\t\treturn errors.New(\"temporary\")\n\t\t}\n\t\treturn errors.New(\"permanent\")\n\t}\n\tshouldRetry := func(err error) bool { return err.Error() == \"temporary\" }\n\tif err := RetryUntil(context.Background(), 5, time.Millisecond, op, shouldRetry); err == nil || err.Error() != \"permanent\" {\n\t\tt.Fatalf(\"expected permanent error, got %v\", err)\n\t}\n\tif calls != 2 {\n\t\tt.Fatalf(\"expected 2 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestBackoffSequence(t *testing.T) {\n\tt.Parallel()\n\tseq := BackoffSequence(3, time.Millisecond)\n\tif len(seq) != 3 {\n\t\tt.Fatalf(\"expected length 3, got %d\", len(seq))\n\t}\n\tif seq[0] <= 0 {\n\t\tt.Fatalf(\"expected positive durations: %v\", seq)\n\t}\n}\n\nfunc TestSleepContext(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)\n\tdefer cancel()\n\tif err := SleepContext(ctx, 20*time.Millisecond); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tctx2, cancel2 := context.WithCancel(context.Background())\n\tdefer cancel2()\n\tstart := time.Now()\n\tif err := SleepContext(ctx2, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif time.Since(start) < 5*time.Millisecond {\n\t\tt.Fatalf(\"sleep returned too early: %v\", time.Since(start))\n\t}\n}\n",
        "tags": [
          "go",
          "retryx"
        ],
        "order": 2
      },
      {
        "package": "retryx",
        "slug": "go-retryx-backoffsequence",
        "title": "BackoffSequence возвращает слайс задержек для первых n попыток.",
        "description": "Level 4 (medium+): BackoffSequence возвращает слайс задержек для первых n попыток.\nHint: используйте Backoff внутри и собирайте длительности.",
        "difficulty": "medium",
        "hint1": "используйте Backoff внутри и собирайте длительности.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\n// Level 1 (easy): Backoff рассчитывает экспоненциальную задержку base * 2^attempt с джиттером.\n// Hint: добавьте случайный множитель в диапазоне [0.5, 1.5].\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 {\n\t\tattempt = 0\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt\n\tjitter := 0.5 + rand.Float64()\n\treturn time.Duration(float64(delay) * jitter)\n}\n\n// Level 2 (medium): Do повторяет op до n раз, применяя Backoff и учитывая ctx.Done().\n// Hint: выходите при успехе операции или при отмене контекста/исчерпании попыток.\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif op == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n < 0 {\n\t\tn = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif i == n {\n\t\t\tbreak\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 3 (medium+): RetryUntil повторяет op, пока shouldRetry(err) == true и не превышен лимит.\n// Hint: переиспользуйте Do, но проводите проверку перед паузой.\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif base == 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif shouldRetry == nil {\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif !shouldRetry(err) {\n\t\t\treturn err\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 4 (medium+): BackoffSequence возвращает слайс задержек для первых n попыток.\n// Hint: используйте Backoff внутри и собирайте длительности.\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tout := make([]time.Duration, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = Backoff(i, base)\n\t}\n\n\treturn out\n}\n\n// Level 5 (medium+): SleepContext ждёт указанную длительность или завершение ctx.\n// Hint: примените time.NewTimer и корректно освобождайте ресурсы.\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d)\n\tselect {\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\t<-timer.C\n\t\t}\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 { // negative attempt numbers treated as zero retries\n\t\tattempt = 0\n\t}\n\tif base <= 0 { // guard against invalid base durations\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt                      // exponential growth by shifting base duration\n\tjitter := 0.5 + rand.Float64()                // randomize delay within [0.5,1.5] factor\n\treturn time.Duration(float64(delay) * jitter) // apply jitter to computed delay\n}\n\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif n <= 0 { // nothing to do when no attempts requested\n\t\treturn nil\n\t}\n\tvar lastErr error                          // remember last error to return when retries exhausted\n\tfor attempt := 0; attempt < n; attempt++ { // iterate through allowed attempts\n\t\tif ctx.Err() != nil { // abort when context already canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err == nil { // succeed immediately when op returns nil\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err // capture error for possible retry or final return\n\t\t}\n\t\tif attempt == n-1 { // stop retrying after last allowed attempt\n\t\t\tbreak\n\t\t}\n\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait respecting context cancellation\n\t\t\treturn err\n\t\t}\n\t}\n\treturn lastErr // return final error after exhausting retries\n}\n\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif shouldRetry == nil { // default to always retrying when predicate missing\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar lastErr error                          // track last error encountered\n\tfor attempt := 0; attempt < n; attempt++ { // up to n attempts conditioned by predicate\n\t\tif ctx.Err() != nil { // break out when context canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err != nil { // invoke operation and inspect error\n\t\t\tlastErr = err          // remember error for potential return\n\t\t\tif !shouldRetry(err) { // stop retrying when predicate rejects error\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait before next retry\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn nil // success terminates loop immediately\n\t}\n\treturn lastErr // return last recorded error when retries depleted\n}\n\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 { // return empty slice for non-positive length\n\t\treturn nil\n\t}\n\tseq := make([]time.Duration, n) // preallocate slice of requested size\n\tfor i := 0; i < n; i++ {        // compute delay for each attempt index\n\t\tseq[i] = Backoff(i, base) // reuse Backoff to calculate duration\n\t}\n\treturn seq // provide caller with generated sequence\n}\n\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 { // skip sleeping for non-positive durations\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d) // allocate timer for requested duration\n\tdefer func() {\n\t\tif !timer.Stop() { // stop timer and drain channel when required\n\t\t\t<-timer.C\n\t\t}\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err() // propagate context cancellation error\n\tcase <-timer.C:\n\t\treturn nil // timer fired successfully without cancellation\n\t}\n}\n",
        "testCode": "package retryx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestBackoff(t *testing.T) {\n\tt.Parallel()\n\td := Backoff(2, 10*time.Millisecond)\n\tif d < 10*time.Millisecond || d > 60*time.Millisecond {\n\t\tt.Fatalf(\"unexpected backoff range: %v\", d)\n\t}\n}\n\nfunc TestDo(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 3 {\n\t\t\treturn errors.New(\"x\")\n\t\t}\n\t\treturn nil\n\t}\n\tif err := Do(context.Background(), 5, time.Millisecond, op); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 3 {\n\t\tt.Fatalf(\"expected 3 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestRetryUntil(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 2 {\n\t\t\treturn errors.New(\"temporary\")\n\t\t}\n\t\treturn errors.New(\"permanent\")\n\t}\n\tshouldRetry := func(err error) bool { return err.Error() == \"temporary\" }\n\tif err := RetryUntil(context.Background(), 5, time.Millisecond, op, shouldRetry); err == nil || err.Error() != \"permanent\" {\n\t\tt.Fatalf(\"expected permanent error, got %v\", err)\n\t}\n\tif calls != 2 {\n\t\tt.Fatalf(\"expected 2 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestBackoffSequence(t *testing.T) {\n\tt.Parallel()\n\tseq := BackoffSequence(3, time.Millisecond)\n\tif len(seq) != 3 {\n\t\tt.Fatalf(\"expected length 3, got %d\", len(seq))\n\t}\n\tif seq[0] <= 0 {\n\t\tt.Fatalf(\"expected positive durations: %v\", seq)\n\t}\n}\n\nfunc TestSleepContext(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)\n\tdefer cancel()\n\tif err := SleepContext(ctx, 20*time.Millisecond); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tctx2, cancel2 := context.WithCancel(context.Background())\n\tdefer cancel2()\n\tstart := time.Now()\n\tif err := SleepContext(ctx2, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif time.Since(start) < 5*time.Millisecond {\n\t\tt.Fatalf(\"sleep returned too early: %v\", time.Since(start))\n\t}\n}\n",
        "tags": [
          "go",
          "retryx"
        ],
        "order": 3
      },
      {
        "package": "retryx",
        "slug": "go-retryx-sleepcontext",
        "title": "SleepContext ждёт указанную длительность или завершение ctx.",
        "description": "Level 5 (medium+): SleepContext ждёт указанную длительность или завершение ctx.\nHint: примените time.NewTimer и корректно освобождайте ресурсы.",
        "difficulty": "medium",
        "hint1": "примените time.NewTimer и корректно освобождайте ресурсы.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\n// Level 1 (easy): Backoff рассчитывает экспоненциальную задержку base * 2^attempt с джиттером.\n// Hint: добавьте случайный множитель в диапазоне [0.5, 1.5].\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 {\n\t\tattempt = 0\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt\n\tjitter := 0.5 + rand.Float64()\n\treturn time.Duration(float64(delay) * jitter)\n}\n\n// Level 2 (medium): Do повторяет op до n раз, применяя Backoff и учитывая ctx.Done().\n// Hint: выходите при успехе операции или при отмене контекста/исчерпании попыток.\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif op == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif n < 0 {\n\t\tn = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif i == n {\n\t\t\tbreak\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 3 (medium+): RetryUntil повторяет op, пока shouldRetry(err) == true и не превышен лимит.\n// Hint: переиспользуйте Do, но проводите проверку перед паузой.\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif base == 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif shouldRetry == nil {\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar err error\n\tfor i := 0; i < n; i++ {\n\t\tif ctx.Err() != nil {\n\t\t\treturn ctx.Err()\n\t\t}\n\t\terr = op(ctx)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif !shouldRetry(err) {\n\t\t\treturn err\n\t\t}\n\t\tdelay := Backoff(i, base)\n\t\tif delay > 0 {\n\t\t\ttimer := time.NewTimer(delay)\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t<-timer.C\n\t\t\t\t}\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-timer.C:\n\t\t\t}\n\t\t}\n\t}\n\treturn err\n}\n\n// Level 4 (medium+): BackoffSequence возвращает слайс задержек для первых n попыток.\n// Hint: используйте Backoff внутри и собирайте длительности.\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tout := make([]time.Duration, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = Backoff(i, base)\n\t}\n\n\treturn out\n}\n\n// Level 5 (medium+): SleepContext ждёт указанную длительность или завершение ctx.\n// Hint: примените time.NewTimer и корректно освобождайте ресурсы.\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 {\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d)\n\tselect {\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\t<-timer.C\n\t\t}\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage retryx\n\nimport (\n\t\"context\"\n\t\"math/rand\"\n\t\"time\"\n)\n\ntype Op func(context.Context) error\n\nfunc Backoff(attempt int, base time.Duration) time.Duration {\n\tif attempt < 0 { // negative attempt numbers treated as zero retries\n\t\tattempt = 0\n\t}\n\tif base <= 0 { // guard against invalid base durations\n\t\tbase = time.Millisecond\n\t}\n\tdelay := base << attempt                      // exponential growth by shifting base duration\n\tjitter := 0.5 + rand.Float64()                // randomize delay within [0.5,1.5] factor\n\treturn time.Duration(float64(delay) * jitter) // apply jitter to computed delay\n}\n\nfunc Do(ctx context.Context, n int, base time.Duration, op Op) error {\n\tif n <= 0 { // nothing to do when no attempts requested\n\t\treturn nil\n\t}\n\tvar lastErr error                          // remember last error to return when retries exhausted\n\tfor attempt := 0; attempt < n; attempt++ { // iterate through allowed attempts\n\t\tif ctx.Err() != nil { // abort when context already canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err == nil { // succeed immediately when op returns nil\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err // capture error for possible retry or final return\n\t\t}\n\t\tif attempt == n-1 { // stop retrying after last allowed attempt\n\t\t\tbreak\n\t\t}\n\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait respecting context cancellation\n\t\t\treturn err\n\t\t}\n\t}\n\treturn lastErr // return final error after exhausting retries\n}\n\nfunc RetryUntil(ctx context.Context, n int, base time.Duration, op Op, shouldRetry func(error) bool) error {\n\tif shouldRetry == nil { // default to always retrying when predicate missing\n\t\tshouldRetry = func(error) bool { return true }\n\t}\n\tvar lastErr error                          // track last error encountered\n\tfor attempt := 0; attempt < n; attempt++ { // up to n attempts conditioned by predicate\n\t\tif ctx.Err() != nil { // break out when context canceled\n\t\t\treturn ctx.Err()\n\t\t}\n\t\tif err := op(ctx); err != nil { // invoke operation and inspect error\n\t\t\tlastErr = err          // remember error for potential return\n\t\t\tif !shouldRetry(err) { // stop retrying when predicate rejects error\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := SleepContext(ctx, Backoff(attempt, base)); err != nil { // wait before next retry\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn nil // success terminates loop immediately\n\t}\n\treturn lastErr // return last recorded error when retries depleted\n}\n\nfunc BackoffSequence(n int, base time.Duration) []time.Duration {\n\tif n <= 0 { // return empty slice for non-positive length\n\t\treturn nil\n\t}\n\tseq := make([]time.Duration, n) // preallocate slice of requested size\n\tfor i := 0; i < n; i++ {        // compute delay for each attempt index\n\t\tseq[i] = Backoff(i, base) // reuse Backoff to calculate duration\n\t}\n\treturn seq // provide caller with generated sequence\n}\n\nfunc SleepContext(ctx context.Context, d time.Duration) error {\n\tif d <= 0 { // skip sleeping for non-positive durations\n\t\treturn nil\n\t}\n\ttimer := time.NewTimer(d) // allocate timer for requested duration\n\tdefer func() {\n\t\tif !timer.Stop() { // stop timer and drain channel when required\n\t\t\t<-timer.C\n\t\t}\n\t}()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err() // propagate context cancellation error\n\tcase <-timer.C:\n\t\treturn nil // timer fired successfully without cancellation\n\t}\n}\n",
        "testCode": "package retryx\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestBackoff(t *testing.T) {\n\tt.Parallel()\n\td := Backoff(2, 10*time.Millisecond)\n\tif d < 10*time.Millisecond || d > 60*time.Millisecond {\n\t\tt.Fatalf(\"unexpected backoff range: %v\", d)\n\t}\n}\n\nfunc TestDo(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 3 {\n\t\t\treturn errors.New(\"x\")\n\t\t}\n\t\treturn nil\n\t}\n\tif err := Do(context.Background(), 5, time.Millisecond, op); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif calls != 3 {\n\t\tt.Fatalf(\"expected 3 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestRetryUntil(t *testing.T) {\n\tt.Parallel()\n\tcalls := 0\n\top := func(context.Context) error {\n\t\tcalls++\n\t\tif calls < 2 {\n\t\t\treturn errors.New(\"temporary\")\n\t\t}\n\t\treturn errors.New(\"permanent\")\n\t}\n\tshouldRetry := func(err error) bool { return err.Error() == \"temporary\" }\n\tif err := RetryUntil(context.Background(), 5, time.Millisecond, op, shouldRetry); err == nil || err.Error() != \"permanent\" {\n\t\tt.Fatalf(\"expected permanent error, got %v\", err)\n\t}\n\tif calls != 2 {\n\t\tt.Fatalf(\"expected 2 attempts, got %d\", calls)\n\t}\n}\n\nfunc TestBackoffSequence(t *testing.T) {\n\tt.Parallel()\n\tseq := BackoffSequence(3, time.Millisecond)\n\tif len(seq) != 3 {\n\t\tt.Fatalf(\"expected length 3, got %d\", len(seq))\n\t}\n\tif seq[0] <= 0 {\n\t\tt.Fatalf(\"expected positive durations: %v\", seq)\n\t}\n}\n\nfunc TestSleepContext(t *testing.T) {\n\tt.Parallel()\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)\n\tdefer cancel()\n\tif err := SleepContext(ctx, 20*time.Millisecond); !errors.Is(err, context.DeadlineExceeded) {\n\t\tt.Fatalf(\"expected deadline exceeded, got %v\", err)\n\t}\n\tctx2, cancel2 := context.WithCancel(context.Background())\n\tdefer cancel2()\n\tstart := time.Now()\n\tif err := SleepContext(ctx2, 5*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif time.Since(start) < 5*time.Millisecond {\n\t\tt.Fatalf(\"sleep returned too early: %v\", time.Since(start))\n\t}\n}\n",
        "tags": [
          "go",
          "retryx"
        ],
        "order": 4
      }
    ],
    "category": "production"
  },
  {
    "name": "structinit",
    "tasks": [
      {
        "package": "structinit",
        "slug": "go-structinit-withemail",
        "title": "реализуйте опцию WithEmail с базовой валидацией email.",
        "description": "Level 3 (medium): реализуйте опцию WithEmail с базовой валидацией email.\nHint: проверяйте непустую строку и наличие символа '@'.",
        "difficulty": "medium",
        "hint1": "проверяйте непустую строку и наличие символа '@'.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// Level 1 (easy): объявите структуру User со скрытым полем id и экспортируемыми Name, Email, Age.\n// Hint: поля должны соответствовать существующим тестам.\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\n// Level 2 (easy+): определите тип Option как функцию, принимающую указатель на User и возвращающую ошибку.\n// Hint: опции будут использоваться для конфигурирования конструктора.\ntype Option func(*User) error\n\n// Level 3 (medium): реализуйте опцию WithEmail с базовой валидацией email.\n// Hint: проверяйте непустую строку и наличие символа '@'.\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif strings.TrimSpace(email) == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\n// Level 4 (medium): реализуйте опцию WithAge, допускающую возраст 0..130.\n// Hint: при некорректном значении возвращайте ошибку.\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\n// Level 5 (medium+): реализуйте конструктор NewUser с обязательными полями id>0 и непустым name.\n// Hint: применяйте опции последовательно, останавливаясь на первой ошибке.\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id < 0 {\n\t\treturn nil, fmt.Errorf(\"invalid id\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"invalid name format\")\n\t}\n\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn u, nil\n}\n\n// Level 6 (medium+): добавьте метод ID() для чтения закрытого поля id.\n// Hint: метод должен быть экспортированным и возвращать int.\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\ntype Option func(*User) error\n\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif email == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id <= 0 {\n\t\treturn nil, fmt.Errorf(\"id must be positive\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"name is required\")\n\t}\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn u, nil\n}\n\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "testCode": "package structinit\n\nimport \"testing\"\n\nfunc TestNewUser(t *testing.T) {\n\tu, err := NewUser(1, \"Bob\", WithEmail(\"a@b.c\"), WithAge(30))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif u.ID() != 1 || u.Name != \"Bob\" || u.Email != \"a@b.c\" || u.Age != 30 {\n\t\tt.Fatalf(\"bad user: %+v\", u)\n\t}\n}\n\nfunc TestNewUser_Validation(t *testing.T) {\n\tif _, err := NewUser(0, \"\"); err == nil {\n\t\tt.Fatal(\"must fail on invalid id/name\")\n\t}\n\tif _, err := NewUser(1, \"Bob\", WithAge(-1)); err == nil {\n\t\tt.Fatal(\"must fail on age\")\n\t}\n}\n",
        "tags": [
          "go",
          "structinit"
        ],
        "order": 2
      },
      {
        "package": "structinit",
        "slug": "go-structinit-withage",
        "title": "реализуйте опцию WithAge, допускающую возраст 0..130.",
        "description": "Level 4 (medium): реализуйте опцию WithAge, допускающую возраст 0..130.\nHint: при некорректном значении возвращайте ошибку.",
        "difficulty": "medium",
        "hint1": "при некорректном значении возвращайте ошибку.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// Level 1 (easy): объявите структуру User со скрытым полем id и экспортируемыми Name, Email, Age.\n// Hint: поля должны соответствовать существующим тестам.\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\n// Level 2 (easy+): определите тип Option как функцию, принимающую указатель на User и возвращающую ошибку.\n// Hint: опции будут использоваться для конфигурирования конструктора.\ntype Option func(*User) error\n\n// Level 3 (medium): реализуйте опцию WithEmail с базовой валидацией email.\n// Hint: проверяйте непустую строку и наличие символа '@'.\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif strings.TrimSpace(email) == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\n// Level 4 (medium): реализуйте опцию WithAge, допускающую возраст 0..130.\n// Hint: при некорректном значении возвращайте ошибку.\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\n// Level 5 (medium+): реализуйте конструктор NewUser с обязательными полями id>0 и непустым name.\n// Hint: применяйте опции последовательно, останавливаясь на первой ошибке.\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id < 0 {\n\t\treturn nil, fmt.Errorf(\"invalid id\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"invalid name format\")\n\t}\n\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn u, nil\n}\n\n// Level 6 (medium+): добавьте метод ID() для чтения закрытого поля id.\n// Hint: метод должен быть экспортированным и возвращать int.\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\ntype Option func(*User) error\n\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif email == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id <= 0 {\n\t\treturn nil, fmt.Errorf(\"id must be positive\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"name is required\")\n\t}\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn u, nil\n}\n\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "testCode": "package structinit\n\nimport \"testing\"\n\nfunc TestNewUser(t *testing.T) {\n\tu, err := NewUser(1, \"Bob\", WithEmail(\"a@b.c\"), WithAge(30))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif u.ID() != 1 || u.Name != \"Bob\" || u.Email != \"a@b.c\" || u.Age != 30 {\n\t\tt.Fatalf(\"bad user: %+v\", u)\n\t}\n}\n\nfunc TestNewUser_Validation(t *testing.T) {\n\tif _, err := NewUser(0, \"\"); err == nil {\n\t\tt.Fatal(\"must fail on invalid id/name\")\n\t}\n\tif _, err := NewUser(1, \"Bob\", WithAge(-1)); err == nil {\n\t\tt.Fatal(\"must fail on age\")\n\t}\n}\n",
        "tags": [
          "go",
          "structinit"
        ],
        "order": 3
      },
      {
        "package": "structinit",
        "slug": "go-structinit-newuser",
        "title": "реализуйте конструктор NewUser с обязательными полями id>0 и непустым name.",
        "description": "Level 5 (medium+): реализуйте конструктор NewUser с обязательными полями id>0 и непустым name.\nHint: применяйте опции последовательно, останавливаясь на первой ошибке.",
        "difficulty": "medium",
        "hint1": "применяйте опции последовательно, останавливаясь на первой ошибке.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// Level 1 (easy): объявите структуру User со скрытым полем id и экспортируемыми Name, Email, Age.\n// Hint: поля должны соответствовать существующим тестам.\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\n// Level 2 (easy+): определите тип Option как функцию, принимающую указатель на User и возвращающую ошибку.\n// Hint: опции будут использоваться для конфигурирования конструктора.\ntype Option func(*User) error\n\n// Level 3 (medium): реализуйте опцию WithEmail с базовой валидацией email.\n// Hint: проверяйте непустую строку и наличие символа '@'.\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif strings.TrimSpace(email) == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\n// Level 4 (medium): реализуйте опцию WithAge, допускающую возраст 0..130.\n// Hint: при некорректном значении возвращайте ошибку.\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\n// Level 5 (medium+): реализуйте конструктор NewUser с обязательными полями id>0 и непустым name.\n// Hint: применяйте опции последовательно, останавливаясь на первой ошибке.\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id < 0 {\n\t\treturn nil, fmt.Errorf(\"invalid id\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"invalid name format\")\n\t}\n\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn u, nil\n}\n\n// Level 6 (medium+): добавьте метод ID() для чтения закрытого поля id.\n// Hint: метод должен быть экспортированным и возвращать int.\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\ntype Option func(*User) error\n\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif email == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id <= 0 {\n\t\treturn nil, fmt.Errorf(\"id must be positive\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"name is required\")\n\t}\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn u, nil\n}\n\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "testCode": "package structinit\n\nimport \"testing\"\n\nfunc TestNewUser(t *testing.T) {\n\tu, err := NewUser(1, \"Bob\", WithEmail(\"a@b.c\"), WithAge(30))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif u.ID() != 1 || u.Name != \"Bob\" || u.Email != \"a@b.c\" || u.Age != 30 {\n\t\tt.Fatalf(\"bad user: %+v\", u)\n\t}\n}\n\nfunc TestNewUser_Validation(t *testing.T) {\n\tif _, err := NewUser(0, \"\"); err == nil {\n\t\tt.Fatal(\"must fail on invalid id/name\")\n\t}\n\tif _, err := NewUser(1, \"Bob\", WithAge(-1)); err == nil {\n\t\tt.Fatal(\"must fail on age\")\n\t}\n}\n",
        "tags": [
          "go",
          "structinit"
        ],
        "order": 4
      },
      {
        "package": "structinit",
        "slug": "go-structinit-id",
        "title": "добавьте метод ID() для чтения закрытого поля id.",
        "description": "Level 6 (medium+): добавьте метод ID() для чтения закрытого поля id.\nHint: метод должен быть экспортированным и возвращать int.",
        "difficulty": "medium",
        "hint1": "метод должен быть экспортированным и возвращать int.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// Level 1 (easy): объявите структуру User со скрытым полем id и экспортируемыми Name, Email, Age.\n// Hint: поля должны соответствовать существующим тестам.\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\n// Level 2 (easy+): определите тип Option как функцию, принимающую указатель на User и возвращающую ошибку.\n// Hint: опции будут использоваться для конфигурирования конструктора.\ntype Option func(*User) error\n\n// Level 3 (medium): реализуйте опцию WithEmail с базовой валидацией email.\n// Hint: проверяйте непустую строку и наличие символа '@'.\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif strings.TrimSpace(email) == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\n// Level 4 (medium): реализуйте опцию WithAge, допускающую возраст 0..130.\n// Hint: при некорректном значении возвращайте ошибку.\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\n// Level 5 (medium+): реализуйте конструктор NewUser с обязательными полями id>0 и непустым name.\n// Hint: применяйте опции последовательно, останавливаясь на первой ошибке.\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id < 0 {\n\t\treturn nil, fmt.Errorf(\"invalid id\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"invalid name format\")\n\t}\n\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn u, nil\n}\n\n// Level 6 (medium+): добавьте метод ID() для чтения закрытого поля id.\n// Hint: метод должен быть экспортированным и возвращать int.\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage structinit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\ntype User struct {\n\tid    int\n\tName  string\n\tEmail string\n\tAge   int\n}\n\ntype Option func(*User) error\n\nfunc WithEmail(email string) Option {\n\treturn func(u *User) error {\n\t\tif email == \"\" || !strings.Contains(email, \"@\") {\n\t\t\treturn fmt.Errorf(\"invalid format\")\n\t\t}\n\t\tu.Email = email\n\t\treturn nil\n\t}\n}\n\nfunc WithAge(age int) Option {\n\treturn func(u *User) error {\n\t\tif age < 0 || age > 130 {\n\t\t\treturn fmt.Errorf(\"invalid age\")\n\t\t}\n\t\tu.Age = age\n\t\treturn nil\n\t}\n}\n\nfunc NewUser(id int, name string, opts ...Option) (*User, error) {\n\tif id <= 0 {\n\t\treturn nil, fmt.Errorf(\"id must be positive\")\n\t}\n\tif strings.TrimSpace(name) == \"\" {\n\t\treturn nil, fmt.Errorf(\"name is required\")\n\t}\n\tu := &User{id: id, Name: name}\n\tfor _, opt := range opts {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(u); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn u, nil\n}\n\nfunc (u *User) ID() int {\n\tif u == nil {\n\t\treturn 0\n\t}\n\treturn u.id\n}\n",
        "testCode": "package structinit\n\nimport \"testing\"\n\nfunc TestNewUser(t *testing.T) {\n\tu, err := NewUser(1, \"Bob\", WithEmail(\"a@b.c\"), WithAge(30))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif u.ID() != 1 || u.Name != \"Bob\" || u.Email != \"a@b.c\" || u.Age != 30 {\n\t\tt.Fatalf(\"bad user: %+v\", u)\n\t}\n}\n\nfunc TestNewUser_Validation(t *testing.T) {\n\tif _, err := NewUser(0, \"\"); err == nil {\n\t\tt.Fatal(\"must fail on invalid id/name\")\n\t}\n\tif _, err := NewUser(1, \"Bob\", WithAge(-1)); err == nil {\n\t\tt.Fatal(\"must fail on age\")\n\t}\n}\n",
        "tags": [
          "go",
          "structinit"
        ],
        "order": 5
      }
    ],
    "category": "core"
  },
  {
    "name": "test",
    "tasks": [
      {
        "package": "test",
        "slug": "go-test-flattenunknown",
        "title": "FlattenUnknown принимает произвольный набор элементов input.",
        "description": "Level 1 (medium): FlattenUnknown принимает произвольный набор элементов input.\nКаждый элемент может быть:\n  - целым числом типа int;\n  - вложенным слайсом значений неизвестной глубины, состоящим из int и таких же слайсов.\n\nВерните плоский срез int, сохранив порядок появления чисел во входной структуре.\nHint: вспомогательная рекурсивная функция с type switch по элементу поможет корректно\nразворачивать вложенные уровни и накапливать результат.",
        "difficulty": "medium",
        "hint1": "вспомогательная рекурсивная функция с type switch по элементу поможет корректно",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "package main\n\n// Level 1 (medium): FlattenUnknown принимает произвольный набор элементов input.\n// Каждый элемент может быть:\n//   - целым числом типа int;\n//   - вложенным слайсом значений неизвестной глубины, состоящим из int и таких же слайсов.\n//\n// Верните плоский срез int, сохранив порядок появления чисел во входной структуре.\n// Hint: вспомогательная рекурсивная функция с type switch по элементу поможет корректно\n// разворачивать вложенные уровни и накапливать результат.\nfunc FlattenUnknown(input []any) []int {\n\tif len(input) == 0 {\n\t\treturn nil\n\t}\n\tout := make([]int, 0, len(input))\n\tin := make([]any, 0, len(input))\n\tin = append(in, input...)\n\tidx := 0\n\tfor {\n\t\tif idx >= len(in) {\n\t\t\tbreak\n\t\t}\n\t\tswitch val := in[idx].(type) {\n\t\tcase int:\n\t\t\tout = append(out, val)\n\t\tcase []any:\n\t\t\tin = append(in, val...)\n\t\tdefault:\n\t\t}\n\t\tidx++\n\t}\n\treturn out\n}\n\n// func FlattenUnknown(input []any) []int {\n// \tif len(input) == 0 {\n// \t\treturn nil\n// \t}\n// \tout := make([]int, 0, len(input))\n// \tfor _, v := range input {\n// \t\tswitch val := v.(type) {\n// \t\tcase int:\n// \t\t\tout = append(out, val)\n// \t\tcase []any:\n// \t\t\tout = append(out, FlattenUnknown(val)...)\n// \t\t}\n// \t}\n// \treturn out\n// }\n",
        "solutionCode": "",
        "testCode": "package main\n\nimport (\n\t\"reflect\"\n\t\"testing\"\n)\n\nfunc TestFlattenUnknown(t *testing.T) {\n\tt.Parallel()\n\n\ttests := []struct {\n\t\tname  string\n\t\tinput []any\n\t\twant  []int\n\t}{\n\t\t{\n\t\t\tname:  \"empty input\",\n\t\t\tinput: nil,\n\t\t\twant:  nil,\n\t\t},\n\t\t{\n\t\t\tname:  \"flat integers\",\n\t\t\tinput: []any{1, 2, 3, 4},\n\t\t\twant:  []int{1, 2, 3, 4},\n\t\t},\n\t\t{\n\t\t\tname:  \"single level nesting\",\n\t\t\tinput: []any{1, []any{2, 3}, 4},\n\t\t\twant:  []int{1, 2, 3, 4},\n\t\t},\n\t\t{\n\t\t\tname:  \"mixed empty nests\",\n\t\t\tinput: []any{[]any{}, 5, []any{6, []any{}, 7}, []any{[]any{}}},\n\t\t\twant:  []int{5, 6, 7},\n\t\t},\n\t\t{\n\t\t\tname:  \"deep nesting\",\n\t\t\tinput: []any{[]any{[]any{1}, 2}, 3, []any{[]any{4, []any{5}}}},\n\t\t\twant:  []int{1, 2, 3, 4, 5},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\ttc := tc\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tgot := FlattenUnknown(tc.input)\n\t\t\tif !reflect.DeepEqual(got, tc.want) {\n\t\t\t\tt.Fatalf(\"FlattenUnknown(%v) = %v, want %v\", tc.input, got, tc.want)\n\t\t\t}\n\t\t})\n\t}\n}\n",
        "tags": [
          "go",
          "test"
        ],
        "order": 0
      }
    ],
    "category": "core"
  },
  {
    "name": "timeutils",
    "tasks": [
      {
        "package": "timeutils",
        "slug": "go-timeutils-runafter",
        "title": "вызвать f спустя задержку d и только после этого вернуться.",
        "description": "Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\nHint: используйте time.NewTimer и <-timer.C.",
        "difficulty": "easy",
        "hint1": "используйте time.NewTimer и <-timer.C.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 0
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-waitforsignalortimeout",
        "title": "ждать закрытия signal или истечения timeout, возвращать true если",
        "description": "Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\nсигнал пришёл раньше таймаута.\nHint: объедините select по сигналу и <-timer.C.",
        "difficulty": "easy",
        "hint1": "объедините select по сигналу и <-timer.C.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 1
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-tickn",
        "title": "вызывать f на каждом тикере с периодом interval ровно n раз,",
        "description": "Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\nпередавая номер итерации.\nHint: используйте time.NewTicker и не забудьте остановить его.",
        "difficulty": "easy",
        "hint1": "используйте time.NewTicker и не забудьте остановить его.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 2
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-measureexecutionduration",
        "title": "измерить длительность выполнения f и вернуть значение.",
        "description": "Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\nHint: time.Now и time.Since помогут получить time.Duration.",
        "difficulty": "easy",
        "hint1": "time.Now и time.Since помогут получить time.Duration.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 3
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-sleepuntil",
        "title": "остановиться до наступления момента target, игнорируя прошлое время.",
        "description": "Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\nПояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\nПосле каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\nиз-за планировщика, и требуется повторно подождать остаток.\nHint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.",
        "difficulty": "medium",
        "hint1": "time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 4
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-waitwithcontext",
        "title": "дождаться истечения d, если только ctx не отменён раньше.",
        "description": "Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\nПояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\nЕсли ctx равен nil, используйте context.Background() как значение по умолчанию.\nHint: объедините <-timer.C и ctx.Done().",
        "difficulty": "medium",
        "hint1": "объедините <-timer.C и ctx.Done().",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 5
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-sumdurations",
        "title": "распарсить durations и вернуть их сумму.",
        "description": "Level 7 (medium): распарсить durations и вернуть их сумму.\nПояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\nПри ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\nHint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.",
        "difficulty": "medium",
        "hint1": "time.ParseDuration и аккуратная обработка ошибок с индексом элемента.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 6
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-exponentialbackoff",
        "title": "построить попытки экспоненциального бэкоффа.",
        "description": "Level 8 (medium+): построить попытки экспоненциального бэкоффа.\nПояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\nзначение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\nСледите, чтобы итоговые значения не становились отрицательными из-за переполнения.\nHint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.",
        "difficulty": "medium",
        "hint1": "умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 7
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-retrywithbackoff",
        "title": "повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,",
        "description": "Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\nили пока fn не вернёт nil.\nПояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\nвозвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\nошибку контекста, не теряя последнюю ошибку fn.\nHint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.",
        "difficulty": "hard",
        "hint1": "храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 8
      },
      {
        "package": "timeutils",
        "slug": "go-timeutils-dispatchwithinterval",
        "title": "раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.",
        "description": "Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\nВерните первую ошибку job или ошибку контекста, если тот отменён раньше.\nПояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\nТаймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\ninterval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\nкорректно закрыть канал и горутины.\nHint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.",
        "difficulty": "hard",
        "hint1": "комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n// +build !solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Level 1 (easy): вызвать f спустя задержку d и только после этого вернуться.\n// Hint: используйте time.NewTimer и <-timer.C.\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\n// Level 2 (easy): ждать закрытия signal или истечения timeout, возвращать true если\n// сигнал пришёл раньше таймаута.\n// Hint: объедините select по сигналу и <-timer.C.\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif signal == nil {\n\t\treturn false\n\t}\n\tif timeout <= 0 {\n\t\ttimeout = time.Second\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\n// Level 3 (easy+): вызывать f на каждом тикере с периодом interval ровно n раз,\n// передавая номер итерации.\n// Hint: используйте time.NewTicker и не забудьте остановить его.\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif f == nil || n <= 0 {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Second\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\n\tfor i := 1; i <= n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\n// Level 4 (easy+): измерить длительность выполнения f и вернуть значение.\n// Hint: time.Now и time.Since помогут получить time.Duration.\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\n// Level 5 (medium-): остановиться до наступления момента target, игнорируя прошлое время.\n// Пояснение: если target уже наступил (или находится в прошлом), функция должна вернуться сразу.\n// После каждой паузы пересчитывайте оставшееся время — таймер может \"проснуться\" чуть раньше\n// из-за планировщика, и требуется повторно подождать остаток.\n// Hint: time.Until(target) + таймер, который можно пересоздать при отрицательной длительности.\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\n// Level 6 (medium): дождаться истечения d, если только ctx не отменён раньше.\n// Пояснение: при d <= 0 достаточно проверить состояние контекста и вернуться немедленно.\n// Если ctx равен nil, используйте context.Background() как значение по умолчанию.\n// Hint: объедините <-timer.C и ctx.Done().\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\n// Level 7 (medium): распарсить durations и вернуть их сумму.\n// Пояснение: элементы могут содержать пробелы, поэтому обрежьте строку прежде чем парсить.\n// При ошибке верните fmt.Errorf(\"duration %d: %w\", idx, err), где idx — позиция в исходном слайсе.\n// Hint: time.ParseDuration и аккуратная обработка ошибок с индексом элемента.\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor i, in := range inputs {\n\t\td, err := time.ParseDuration(strings.TrimSpace(in))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", i, err)\n\t\t}\n\t\ttotal += d\n\t}\n\n\treturn total, nil\n}\n\n// Level 8 (medium+): построить попытки экспоненциального бэкоффа.\n// Пояснение: верните пустой слайс, если attempts <= 0. Подменяйте base на минимально положительное\n// значение при base <= 0, а factor < 1 считайте единицей, чтобы бэкофф не убывал.\n// Следите, чтобы итоговые значения не становились отрицательными из-за переполнения.\n// Hint: умножайте базовый интервал на factor^i и позаботьтесь о неотрицательных значениях.\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tif base <= 0 {\n\t\tbase = time.Nanosecond\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tval := float64(base) * math.Pow(factor, float64(i))\n\t\tif val < 0 {\n\t\t\tval = 0\n\t\t}\n\t\tseries = append(series, time.Duration(val))\n\t}\n\treturn series\n}\n\n// Level 9 (senior-): повторять fn с бэкоффом, пока не исчерпаны попытки, не отменён контекст,\n// или пока fn не вернёт nil.\n// Пояснение: если fn вернул nil — завершайте немедленно. При attempts <= 0 или nil-функциях\n// возвращайте nil без ожиданий. Между попытками учитывайте ctx.Done(): при отмене нужно вернуть\n// ошибку контекста, не теряя последнюю ошибку fn.\n// Hint: храните последнюю ошибку, используйте backoff для пауз и чисто останавливайте таймеры.\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tvar lastErr error\n\tfor i := 1; i <= attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts {\n\t\t\tbreak\n\t\t}\n\t\tif backoff == nil {\n\t\t\tcontinue\n\t\t}\n\t\tdelay := backoff(i)\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\n// Level 10 (senior-): раздать jobs не быстрее, чем раз в interval, обрабатывая их worker-ами.\n// Верните первую ошибку job или ошибку контекста, если тот отменён раньше.\n// Пояснение: создайте пул из workers горутин, каждая читает job из канала и уважает ctx.\n// Таймер ограничивает частоту выдачи задач: первая job уходит сразу, последующие — после ожидания\n// interval. Как только встречается ошибка job или контекст завершён, нужно остановить выдачу и\n// корректно закрыть канал и горутины.\n// Hint: комбинируйте time.NewTicker, буфер ошибок и отмену дочернего контекста для остановки пула.\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWg sync.WaitGroup\n\tdispatchWg.Add(1)\n\tgo func() {\n\t\tdefer dispatchWg.Done()\n\t\tdefer close(jobCh)\n\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWg.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "solutionCode": "//go:build solution\n// +build solution\n\npackage timeutils\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc RunAfter(d time.Duration, f func()) {\n\tif f == nil {\n\t\treturn\n\t}\n\tif d <= 0 {\n\t\tf()\n\t\treturn\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\t<-timer.C\n\tf()\n}\n\nfunc WaitForSignalOrTimeout(signal <-chan struct{}, timeout time.Duration) bool {\n\tif timeout <= 0 {\n\t\tselect {\n\t\tcase <-signal:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t}\n\ttimer := time.NewTimer(timeout)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-signal:\n\t\tif !timer.Stop() {\n\t\t\tselect {\n\t\t\tcase <-timer.C:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase <-timer.C:\n\t\treturn false\n\t}\n}\n\nfunc TickN(interval time.Duration, n int, f func(int)) {\n\tif n <= 0 || f == nil {\n\t\treturn\n\t}\n\tif interval <= 0 {\n\t\tinterval = time.Millisecond\n\t}\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tfor i := 0; i < n; i++ {\n\t\t<-ticker.C\n\t\tf(i)\n\t}\n}\n\nfunc MeasureExecutionDuration(f func()) time.Duration {\n\tif f == nil {\n\t\treturn 0\n\t}\n\tstart := time.Now()\n\tf()\n\treturn time.Since(start)\n}\n\nfunc SleepUntil(target time.Time) {\n\tfor {\n\t\td := time.Until(target)\n\t\tif d <= 0 {\n\t\t\treturn\n\t\t}\n\t\ttimer := time.NewTimer(d)\n\t\t<-timer.C\n\t\ttimer.Stop()\n\t}\n}\n\nfunc WaitWithContext(ctx context.Context, d time.Duration) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif d <= 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\ttimer := time.NewTimer(d)\n\tdefer timer.Stop()\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tcase <-timer.C:\n\t\treturn nil\n\t}\n}\n\nfunc SumDurations(inputs []string) (time.Duration, error) {\n\tvar total time.Duration\n\tfor idx, raw := range inputs {\n\t\tdur, err := time.ParseDuration(strings.TrimSpace(raw))\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"duration %d: %w\", idx, err)\n\t\t}\n\t\ttotal += dur\n\t}\n\treturn total, nil\n}\n\nfunc ExponentialBackoff(base time.Duration, factor float64, attempts int) []time.Duration {\n\tif attempts <= 0 {\n\t\treturn nil\n\t}\n\tif base <= 0 {\n\t\tbase = time.Millisecond\n\t}\n\tif factor < 1 {\n\t\tfactor = 1\n\t}\n\tseries := make([]time.Duration, 0, attempts)\n\tfor i := 0; i < attempts; i++ {\n\t\tvalue := float64(base) * math.Pow(factor, float64(i))\n\t\tif value < 0 {\n\t\t\tvalue = 0\n\t\t}\n\t\tseries = append(series, time.Duration(value))\n\t}\n\treturn series\n}\n\nfunc RetryWithBackoff(ctx context.Context, attempts int, backoff func(int) time.Duration, fn func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif attempts <= 0 || fn == nil {\n\t\treturn nil\n\t}\n\tvar lastErr error\n\tfor i := 0; i < attempts; i++ {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fn(ctx); err == nil {\n\t\t\treturn nil\n\t\t} else {\n\t\t\tlastErr = err\n\t\t}\n\t\tif i == attempts-1 {\n\t\t\tbreak\n\t\t}\n\t\tvar delay time.Duration\n\t\tif backoff != nil {\n\t\t\tdelay = backoff(i + 1)\n\t\t}\n\t\tif delay <= 0 {\n\t\t\tcontinue\n\t\t}\n\t\ttimer := time.NewTimer(delay)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t}\n\t}\n\treturn lastErr\n}\n\nfunc DispatchWithInterval(ctx context.Context, workers int, interval time.Duration, jobs []func(context.Context) error) error {\n\tif ctx == nil {\n\t\tctx = context.Background()\n\t}\n\tif workers <= 0 {\n\t\treturn fmt.Errorf(\"workers must be positive\")\n\t}\n\tif len(jobs) == 0 {\n\t\treturn nil\n\t}\n\n\tparent := ctx\n\tctx, cancel := context.WithCancel(parent)\n\tdefer cancel()\n\n\tjobCh := make(chan func(context.Context) error)\n\terrCh := make(chan error, 1)\n\n\tvar wg sync.WaitGroup\n\twg.Add(workers)\n\tfor i := 0; i < workers; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase job, ok := <-jobCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif job == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif err := job(ctx); err != nil {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase errCh <- err:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcancel()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar dispatchWG sync.WaitGroup\n\tdispatchWG.Add(1)\n\tgo func() {\n\t\tdefer dispatchWG.Done()\n\t\tdefer close(jobCh)\n\t\tif interval <= 0 {\n\t\t\tfor _, job := range jobs {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase jobCh <- job:\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tticker := time.NewTicker(interval)\n\t\tdefer ticker.Stop()\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase jobCh <- jobs[0]:\n\t\t}\n\t\tfor _, job := range jobs[1:] {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase jobCh <- job:\n\t\t\t}\n\t\t}\n\t}()\n\n\tdispatchWG.Wait()\n\twg.Wait()\n\n\tvar jobErr error\n\tselect {\n\tcase jobErr = <-errCh:\n\tdefault:\n\t}\n\tif jobErr != nil {\n\t\treturn jobErr\n\t}\n\tif err := parent.Err(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n",
        "testCode": "package timeutils\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestRunAfter(t *testing.T) {\n\tt.Run(\"delayed\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(20*time.Millisecond, func() {\n\t\t\tcalled = true\n\t\t})\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed < 20*time.Millisecond {\n\t\t\tt.Fatalf(\"want at least 20ms wait, got %v\", elapsed)\n\t\t}\n\t})\n\n\tt.Run(\"immediate\", func(t *testing.T) {\n\t\tstart := time.Now()\n\t\tcalled := false\n\t\tRunAfter(0, func() { called = true })\n\t\tif !called {\n\t\t\tt.Fatal(\"callback not invoked\")\n\t\t}\n\t\tif elapsed := time.Since(start); elapsed > 5*time.Millisecond {\n\t\t\tt.Fatalf(\"expected near-immediate execution, got %v\", elapsed)\n\t\t}\n\t})\n}\n\nfunc TestWaitForSignalOrTimeout(t *testing.T) {\n\tt.Run(\"signal first\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tgo func() {\n\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\tclose(signal)\n\t\t}()\n\t\tif ok := WaitForSignalOrTimeout(signal, 50*time.Millisecond); !ok {\n\t\t\tt.Fatal(\"expected signal before timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tif ok := WaitForSignalOrTimeout(signal, 10*time.Millisecond); ok {\n\t\t\tt.Fatal(\"expected timeout\")\n\t\t}\n\t})\n\n\tt.Run(\"no timeout\", func(t *testing.T) {\n\t\tsignal := make(chan struct{})\n\t\tclose(signal)\n\t\tif ok := WaitForSignalOrTimeout(signal, 0); !ok {\n\t\t\tt.Fatal(\"signal should win when timeout <= 0\")\n\t\t}\n\t})\n}\n\nfunc TestTickN(t *testing.T) {\n\tinterval := 15 * time.Millisecond\n\tvar mu sync.Mutex\n\tvar stamps []time.Time\n\tstart := time.Now()\n\tTickN(interval, 3, func(int) {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\t\tstamps = append(stamps, time.Now())\n\t})\n\tif len(stamps) != 3 {\n\t\tt.Fatalf(\"want 3 ticks, got %d\", len(stamps))\n\t}\n\tif firstDelay := stamps[0].Sub(start); firstDelay+3*time.Millisecond < interval {\n\t\tt.Fatalf(\"first tick fired too early: %v\", firstDelay)\n\t}\n\tif span := stamps[2].Sub(stamps[0]); span+3*time.Millisecond < 2*interval {\n\t\tt.Fatalf(\"ticks are too close together: %v\", span)\n\t}\n\n\tcalled := false\n\tTickN(interval, 0, func(int) { called = true })\n\tif called {\n\t\tt.Fatal(\"unexpected invocation when n <= 0\")\n\t}\n}\n\nfunc TestMeasureExecutionDuration(t *testing.T) {\n\td := MeasureExecutionDuration(func() { time.Sleep(20 * time.Millisecond) })\n\tif d < 20*time.Millisecond {\n\t\tt.Fatalf(\"duration too small: %v\", d)\n\t}\n}\n\nfunc TestSleepUntil(t *testing.T) {\n\tstart := time.Now()\n\ttarget := start.Add(30 * time.Millisecond)\n\tSleepUntil(target)\n\tif elapsed := time.Since(start); elapsed+3*time.Millisecond < 30*time.Millisecond {\n\t\tt.Fatalf(\"returned too early: %v\", elapsed)\n\t}\n\n\t// past target should return immediately\n\tbefore := time.Now()\n\tSleepUntil(time.Now().Add(-time.Second))\n\tif elapsed := time.Since(before); elapsed > 5*time.Millisecond {\n\t\tt.Fatalf(\"expected immediate return for past target, got %v\", elapsed)\n\t}\n}\n\nfunc TestWaitWithContext(t *testing.T) {\n\tstart := time.Now()\n\tif err := WaitWithContext(context.Background(), 20*time.Millisecond); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"wait completed too early: %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), 25*time.Millisecond)\n\tdefer cancel()\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- WaitWithContext(ctx, 100*time.Millisecond)\n\t}()\n\tselect {\n\tcase err := <-done:\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatal(\"WaitWithContext did not return\")\n\t}\n}\n\nfunc TestSumDurations(t *testing.T) {\n\ttotal, err := SumDurations([]string{\"1s\", \" 500ms\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif want := 1500 * time.Millisecond; total != want {\n\t\tt.Fatalf(\"want %v, got %v\", want, total)\n\t}\n\n\tif _, err := SumDurations([]string{\"garbage\"}); err == nil {\n\t\tt.Fatal(\"expected parse error\")\n\t}\n}\n\nfunc TestExponentialBackoff(t *testing.T) {\n\tbackoff := ExponentialBackoff(100*time.Millisecond, 2, 4)\n\twant := []time.Duration{100 * time.Millisecond, 200 * time.Millisecond, 400 * time.Millisecond, 800 * time.Millisecond}\n\tif len(backoff) != len(want) {\n\t\tt.Fatalf(\"unexpected length: %d\", len(backoff))\n\t}\n\tfor i := range want {\n\t\tif backoff[i] != want[i] {\n\t\t\tt.Fatalf(\"index %d: want %v, got %v\", i, want[i], backoff[i])\n\t\t}\n\t}\n\n\tstable := ExponentialBackoff(50*time.Millisecond, 0.5, 2)\n\tif stable[0] != stable[1] {\n\t\tt.Fatalf(\"factor < 1 should clamp to 1: %v\", stable)\n\t}\n}\n\nfunc TestRetryWithBackoff(t *testing.T) {\n\tvar attempts int\n\tstart := time.Now()\n\terr := RetryWithBackoff(context.Background(), 5, func(int) time.Duration { return 10 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tif attempts == 3 {\n\t\t\treturn nil\n\t\t}\n\t\treturn errors.New(\"fail\")\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif attempts != 3 {\n\t\tt.Fatalf(\"want 3 attempts, got %d\", attempts)\n\t}\n\tif elapsed := time.Since(start); elapsed+2*time.Millisecond < 20*time.Millisecond {\n\t\tt.Fatalf(\"expected at least two delays, got %v\", elapsed)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tattempts = 0\n\terr = RetryWithBackoff(ctx, 5, func(int) time.Duration { return 50 * time.Millisecond }, func(context.Context) error {\n\t\tattempts++\n\t\tcancel()\n\t\treturn errors.New(\"fail\")\n\t})\n\tif !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"want context canceled, got %v\", err)\n\t}\n\tif attempts != 1 {\n\t\tt.Fatalf(\"unexpected attempts after cancel: %d\", attempts)\n\t}\n}\n\nfunc TestDispatchWithInterval(t *testing.T) {\n\tt.Run(\"success\", func(t *testing.T) {\n\t\tinterval := 15 * time.Millisecond\n\t\tjobs := make([]func(context.Context) error, 4)\n\t\tvar mu sync.Mutex\n\t\tvar starts []time.Time\n\t\tfor i := range jobs {\n\t\t\tjobs[i] = func(context.Context) error {\n\t\t\t\tmu.Lock()\n\t\t\t\tstarts = append(starts, time.Now())\n\t\t\t\tmu.Unlock()\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tstart := time.Now()\n\t\tif err := DispatchWithInterval(context.Background(), 2, interval, jobs); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t}\n\t\tif len(starts) != len(jobs) {\n\t\t\tt.Fatalf(\"want %d runs, got %d\", len(jobs), len(starts))\n\t\t}\n\t\telapsed := time.Since(start)\n\t\tmin := interval * time.Duration(len(jobs)-1)\n\t\tif elapsed+5*time.Millisecond < min {\n\t\t\tt.Fatalf(\"dispatching faster than interval: got %v, want >= %v\", elapsed, min)\n\t\t}\n\t})\n\n\tt.Run(\"job error\", func(t *testing.T) {\n\t\tboom := errors.New(\"boom\")\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error { return boom },\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(context.Background(), 1, 0, jobs)\n\t\tif !errors.Is(err, boom) {\n\t\t\tt.Fatalf(\"want boom, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"context deadline\", func(t *testing.T) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Millisecond)\n\t\tdefer cancel()\n\t\tjobs := []func(context.Context) error{\n\t\t\tfunc(context.Context) error {\n\t\t\t\ttime.Sleep(40 * time.Millisecond)\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tfunc(context.Context) error { return nil },\n\t\t}\n\t\terr := DispatchWithInterval(ctx, 1, 10*time.Millisecond, jobs)\n\t\tif !errors.Is(err, context.DeadlineExceeded) {\n\t\t\tt.Fatalf(\"want deadline exceeded, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "timeutils"
        ],
        "order": 9
      }
    ],
    "category": "production"
  },
  {
    "name": "pattern-abstract_factory",
    "tasks": [
      {
        "package": "abstract_factory",
        "slug": "go-abstract_factory-newfactoryregistry",
        "title": "NewFactoryRegistry",
        "description": "Task 1 (easy): NewFactoryRegistry\nСоздайте пустой реестр фабрик с готовыми мапами и mutex'ом.\nПодсказка: инициализируйте builders/factories, чтобы избежать nil map.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of NewFactoryRegistry.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// Button описывает элемент интерфейса, который можно отрендерить.\ntype Button interface {\n\tRender() string\n\tTheme() string\n}\n\n// Card описывает карточку интерфейса.\ntype Card interface {\n\tRender() string\n\tTheme() string\n}\n\n// UIFactory создаёт согласованные компоненты одного семейства.\ntype UIFactory interface {\n\tTheme() string\n\tCreateButton(label string) Button\n\tCreateCard(title string) Card\n}\n\n// FactoryBuilder создаёт конкретную фабрику по требованию.\ntype FactoryBuilder func() (UIFactory, error)\n\n// FactoryRegistry хранит зарегистрированные фабрики и их экземпляры.\ntype FactoryRegistry struct {\n\tmu        sync.Mutex\n\tbuilders  map[string]FactoryBuilder\n\tfactories map[string]UIFactory\n}\n\n// Task 1 (easy): NewFactoryRegistry\n// Создайте пустой реестр фабрик с готовыми мапами и mutex'ом.\n// Подсказка: инициализируйте builders/factories, чтобы избежать nil map.\nfunc NewFactoryRegistry() *FactoryRegistry {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): RegisterFactory\n// Добавьте или обновите builder по имени, очищая закешированный экземпляр.\n// Подсказка: защищайте доступ к map mutex'ом и игнорируйте nil builder.\nfunc (r *FactoryRegistry) RegisterFactory(name string, builder FactoryBuilder) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Compose\n// Верните пару Button/Card из указанной фабрики, создавая её лениво.\n// Подсказка: используйте builder для отсутствующих фабрик и проверяйте Theme у обоих компонентов.\nfunc (r *FactoryRegistry) Compose(name, content string) (Button, Card, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Button interface { // Button описывает UI кнопку.\n\tRender() string // Render возвращает строковое представление.\n\tTheme() string  // Theme сообщает активную тему.\n}\n\ntype Card interface { // Card описывает карточку интерфейса.\n\tRender() string // Render возвращает текст для отображения.\n\tTheme() string  // Theme сообщает тему компонента.\n}\n\ntype UIFactory interface { // UIFactory создаёт согласованные компоненты.\n\tTheme() string                    // Theme возвращает тему семейства.\n\tCreateButton(label string) Button // CreateButton создаёт кнопку.\n\tCreateCard(title string) Card     // CreateCard создаёт карточку.\n}\n\ntype FactoryBuilder func() (UIFactory, error) // FactoryBuilder создаёт фабрику по требованию.\n\ntype FactoryRegistry struct { // FactoryRegistry хранит builder'ы и фабрики.\n\tmu        sync.Mutex                // mu защищает доступ к структурам.\n\tbuilders  map[string]FactoryBuilder // builders хранит фабрики по имени.\n\tfactories map[string]UIFactory      // factories кэширует созданные фабрики.\n}\n\nfunc NewFactoryRegistry() *FactoryRegistry { // NewFactoryRegistry создаёт пустой реестр фабрик.\n\treturn &FactoryRegistry{ // Возвращаем структуру с готовыми map.\n\t\tbuilders:  make(map[string]FactoryBuilder), // Хранилище билдров по имени.\n\t\tfactories: make(map[string]UIFactory),      // Кэш уже сконструированных фабрик.\n\t}\n}\n\nfunc (r *FactoryRegistry) RegisterFactory(name string, builder FactoryBuilder) { // RegisterFactory добавляет или обновляет builder.\n\tif r == nil || builder == nil || name == \"\" { // Проверяем входные данные.\n\t\treturn // Нечего регистрировать в некорректных случаях.\n\t}\n\tr.mu.Lock()            // Защищаем работу со внутренними структурами.\n\tdefer r.mu.Unlock()    // Освобождаем mutex по завершении.\n\tif r.builders == nil { // Лениво инициализируем map при необходимости.\n\t\tr.builders = make(map[string]FactoryBuilder) // Создаём map builder'ов.\n\t}\n\tif r.factories == nil { // Кэш фабрик тоже может быть nil.\n\t\tr.factories = make(map[string]UIFactory) // Создаём map фабрик.\n\t}\n\tr.builders[name] = builder // Сохраняем builder по имени.\n\tdelete(r.factories, name)  // Сброс кэша, чтобы новая фабрика создалась заново.\n}\n\nfunc (r *FactoryRegistry) Compose(name, content string) (Button, Card, error) { // Compose возвращает согласованные компоненты UI.\n\tif r == nil { // Nil-реестр не обслуживается.\n\t\treturn nil, nil, fmt.Errorf(\"registry is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif name == \"\" { // Имя фабрики обязательно.\n\t\treturn nil, nil, fmt.Errorf(\"factory name is empty\") // Возвращаем ошибку валидации.\n\t}\n\tfactory, err := r.resolveFactory(name) // Пытаемся получить/создать фабрику по имени.\n\tif err != nil {                        // Обрабатываем ошибку резолва.\n\t\treturn nil, nil, err // Прокидываем ошибку вызывающему коду.\n\t}\n\tbutton := factory.CreateButton(content) // Создаём кнопку через фабрику.\n\tcard := factory.CreateCard(content)     // Создаём карточку через фабрику.\n\tif button == nil || card == nil {       // Проверяем, что компоненты присутствуют.\n\t\treturn nil, nil, fmt.Errorf(\"factory %s returned nil components\", name) // Сообщаем об ошибке фабрики.\n\t}\n\ttheme := factory.Theme()                              // Считываем тему семейства.\n\tif button.Theme() != theme || card.Theme() != theme { // Компоненты должны быть в одной теме.\n\t\treturn nil, nil, fmt.Errorf(\"factory %s produced inconsistent components\", name) // Сообщаем о несогласованности.\n\t}\n\treturn button, card, nil // Возвращаем пару согласованных компонентов.\n}\n\nfunc (r *FactoryRegistry) resolveFactory(name string) (UIFactory, error) { // resolveFactory создаёт фабрику лениво и кэширует её.\n\tr.mu.Lock()            // Защищаем доступ к внутренним map.\n\tdefer r.mu.Unlock()    // Освобождаем mutex после работы.\n\tif r.builders == nil { // Инициализируем map билдров, если нужно.\n\t\tr.builders = make(map[string]FactoryBuilder) // Создаём пустое хранилище билдров.\n\t}\n\tif r.factories == nil { // Аналогично поступаем с кэшем фабрик.\n\t\tr.factories = make(map[string]UIFactory) // Создаём пустой кэш.\n\t}\n\tif factory, ok := r.factories[name]; ok { // Проверяем, есть ли фабрика в кэше.\n\t\treturn factory, nil // Возвращаем уже созданную фабрику.\n\t}\n\tbuilder, ok := r.builders[name] // Ищем builder по имени.\n\tif !ok || builder == nil {      // Builder отсутствует или nil.\n\t\treturn nil, fmt.Errorf(\"factory %s is not registered\", name) // Сообщаем об ошибке.\n\t}\n\tfactory, err := builder() // Создаём фабрику через builder.\n\tif err != nil {           // Обрабатываем ошибку создания.\n\t\treturn nil, err // Прокидываем ошибку дальше.\n\t}\n\tr.factories[name] = factory // Сохраняем фабрику в кэше для последующих вызовов.\n\treturn factory, nil         // Возвращаем созданную фабрику.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\ntype stubButton struct {\n\ttheme string\n\tlabel string\n}\n\nfunc (b stubButton) Render() string { return b.label + \":\" + b.theme }\nfunc (b stubButton) Theme() string  { return b.theme }\n\ntype stubCard struct {\n\ttheme string\n\ttitle string\n}\n\nfunc (c stubCard) Render() string { return c.title + \":\" + c.theme }\nfunc (c stubCard) Theme() string  { return c.theme }\n\ntype stubFactory struct {\n\ttheme  string\n\tbutton int64\n\tcard   int64\n}\n\nfunc (f *stubFactory) Theme() string { return f.theme }\n\nfunc (f *stubFactory) CreateButton(label string) Button {\n\tatomic.AddInt64(&f.button, 1)\n\treturn stubButton{theme: f.theme, label: label}\n}\n\nfunc (f *stubFactory) CreateCard(title string) Card {\n\tatomic.AddInt64(&f.card, 1)\n\treturn stubCard{theme: f.theme, title: title}\n}\n\n// ---- NewFactoryRegistry ----\n\nfunc TestNewFactoryRegistryInitializesMaps(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif reg == nil || reg.builders == nil || reg.factories == nil {\n\t\tt.Fatalf(\"registry not initialized: %#v\", reg)\n\t}\n}\n\nfunc TestNewFactoryRegistryIndependentInstances(t *testing.T) {\n\tr1 := NewFactoryRegistry()\n\tr2 := NewFactoryRegistry()\n\tif &r1.builders == &r2.builders {\n\t\tt.Fatalf(\"builders map should be distinct\")\n\t}\n}\n\nfunc TestNewFactoryRegistryStartsEmpty(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif len(reg.builders) != 0 || len(reg.factories) != 0 {\n\t\tt.Fatalf(\"new registry must be empty\")\n\t}\n}\n\n// ---- RegisterFactory ----\n\nfunc TestRegisterFactoryStoresBuilder(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"mobile\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"mobile\"}, nil\n\t})\n\tif _, ok := reg.builders[\"mobile\"]; !ok {\n\t\tt.Fatalf(\"builder not registered\")\n\t}\n}\n\nfunc TestRegisterFactoryOverridesAndClearsCache(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"ui\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"old\"}, nil\n\t})\n\t_, _, _ = reg.Compose(\"ui\", \"play\")\n\treg.factories[\"ui\"] = &stubFactory{theme: \"manual\"}\n\treg.RegisterFactory(\"ui\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"new\"}, nil\n\t})\n\tif _, ok := reg.factories[\"ui\"]; ok {\n\t\tt.Fatalf(\"cache should be cleared on re-register\")\n\t}\n}\n\nfunc TestRegisterFactoryIgnoresNilBuilder(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"noop\", nil)\n\tif len(reg.builders) != 0 {\n\t\tt.Fatalf(\"nil builder should not be stored\")\n\t}\n}\n\n// ---- Compose ----\n\nfunc TestComposeUsesFactoryOutputs(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"mobile\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"mobile\"}, nil\n\t})\n\tbtn, card, err := reg.Compose(\"mobile\", \"deploy\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif btn.Theme() != card.Theme() || btn.Theme() != \"mobile\" {\n\t\tt.Fatalf(\"themes mismatch: btn=%s card=%s\", btn.Theme(), card.Theme())\n\t}\n}\n\nfunc TestComposeCachesFactoryInstance(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tvar builds atomic.Int64\n\treg.RegisterFactory(\"desktop\", func() (UIFactory, error) {\n\t\tbuilds.Add(1)\n\t\treturn &stubFactory{theme: \"desktop\"}, nil\n\t})\n\tfor i := 0; i < 3; i++ {\n\t\tif _, _, err := reg.Compose(\"desktop\", \"x\"); err != nil {\n\t\t\tt.Fatalf(\"compose failed: %v\", err)\n\t\t}\n\t}\n\tif builds.Load() != 1 {\n\t\tt.Fatalf(\"factory should be built once, got %d\", builds.Load())\n\t}\n}\n\nfunc TestComposeErrorsOnMissingFactory(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif _, _, err := reg.Compose(\"unknown\", \"x\"); err == nil {\n\t\tt.Fatalf(\"expected error for unknown factory\")\n\t}\n}\n",
        "tags": [
          "go",
          "abstract_factory",
          "patterns",
          "creational"
        ],
        "order": 0
      },
      {
        "package": "abstract_factory",
        "slug": "go-abstract_factory-registerfactory",
        "title": "RegisterFactory",
        "description": "Task 2 (easy+): RegisterFactory\nДобавьте или обновите builder по имени, очищая закешированный экземпляр.\nПодсказка: защищайте доступ к map mutex'ом и игнорируйте nil builder.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of RegisterFactory.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// Button описывает элемент интерфейса, который можно отрендерить.\ntype Button interface {\n\tRender() string\n\tTheme() string\n}\n\n// Card описывает карточку интерфейса.\ntype Card interface {\n\tRender() string\n\tTheme() string\n}\n\n// UIFactory создаёт согласованные компоненты одного семейства.\ntype UIFactory interface {\n\tTheme() string\n\tCreateButton(label string) Button\n\tCreateCard(title string) Card\n}\n\n// FactoryBuilder создаёт конкретную фабрику по требованию.\ntype FactoryBuilder func() (UIFactory, error)\n\n// FactoryRegistry хранит зарегистрированные фабрики и их экземпляры.\ntype FactoryRegistry struct {\n\tmu        sync.Mutex\n\tbuilders  map[string]FactoryBuilder\n\tfactories map[string]UIFactory\n}\n\n// Task 1 (easy): NewFactoryRegistry\n// Создайте пустой реестр фабрик с готовыми мапами и mutex'ом.\n// Подсказка: инициализируйте builders/factories, чтобы избежать nil map.\nfunc NewFactoryRegistry() *FactoryRegistry {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): RegisterFactory\n// Добавьте или обновите builder по имени, очищая закешированный экземпляр.\n// Подсказка: защищайте доступ к map mutex'ом и игнорируйте nil builder.\nfunc (r *FactoryRegistry) RegisterFactory(name string, builder FactoryBuilder) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Compose\n// Верните пару Button/Card из указанной фабрики, создавая её лениво.\n// Подсказка: используйте builder для отсутствующих фабрик и проверяйте Theme у обоих компонентов.\nfunc (r *FactoryRegistry) Compose(name, content string) (Button, Card, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Button interface { // Button описывает UI кнопку.\n\tRender() string // Render возвращает строковое представление.\n\tTheme() string  // Theme сообщает активную тему.\n}\n\ntype Card interface { // Card описывает карточку интерфейса.\n\tRender() string // Render возвращает текст для отображения.\n\tTheme() string  // Theme сообщает тему компонента.\n}\n\ntype UIFactory interface { // UIFactory создаёт согласованные компоненты.\n\tTheme() string                    // Theme возвращает тему семейства.\n\tCreateButton(label string) Button // CreateButton создаёт кнопку.\n\tCreateCard(title string) Card     // CreateCard создаёт карточку.\n}\n\ntype FactoryBuilder func() (UIFactory, error) // FactoryBuilder создаёт фабрику по требованию.\n\ntype FactoryRegistry struct { // FactoryRegistry хранит builder'ы и фабрики.\n\tmu        sync.Mutex                // mu защищает доступ к структурам.\n\tbuilders  map[string]FactoryBuilder // builders хранит фабрики по имени.\n\tfactories map[string]UIFactory      // factories кэширует созданные фабрики.\n}\n\nfunc NewFactoryRegistry() *FactoryRegistry { // NewFactoryRegistry создаёт пустой реестр фабрик.\n\treturn &FactoryRegistry{ // Возвращаем структуру с готовыми map.\n\t\tbuilders:  make(map[string]FactoryBuilder), // Хранилище билдров по имени.\n\t\tfactories: make(map[string]UIFactory),      // Кэш уже сконструированных фабрик.\n\t}\n}\n\nfunc (r *FactoryRegistry) RegisterFactory(name string, builder FactoryBuilder) { // RegisterFactory добавляет или обновляет builder.\n\tif r == nil || builder == nil || name == \"\" { // Проверяем входные данные.\n\t\treturn // Нечего регистрировать в некорректных случаях.\n\t}\n\tr.mu.Lock()            // Защищаем работу со внутренними структурами.\n\tdefer r.mu.Unlock()    // Освобождаем mutex по завершении.\n\tif r.builders == nil { // Лениво инициализируем map при необходимости.\n\t\tr.builders = make(map[string]FactoryBuilder) // Создаём map builder'ов.\n\t}\n\tif r.factories == nil { // Кэш фабрик тоже может быть nil.\n\t\tr.factories = make(map[string]UIFactory) // Создаём map фабрик.\n\t}\n\tr.builders[name] = builder // Сохраняем builder по имени.\n\tdelete(r.factories, name)  // Сброс кэша, чтобы новая фабрика создалась заново.\n}\n\nfunc (r *FactoryRegistry) Compose(name, content string) (Button, Card, error) { // Compose возвращает согласованные компоненты UI.\n\tif r == nil { // Nil-реестр не обслуживается.\n\t\treturn nil, nil, fmt.Errorf(\"registry is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif name == \"\" { // Имя фабрики обязательно.\n\t\treturn nil, nil, fmt.Errorf(\"factory name is empty\") // Возвращаем ошибку валидации.\n\t}\n\tfactory, err := r.resolveFactory(name) // Пытаемся получить/создать фабрику по имени.\n\tif err != nil {                        // Обрабатываем ошибку резолва.\n\t\treturn nil, nil, err // Прокидываем ошибку вызывающему коду.\n\t}\n\tbutton := factory.CreateButton(content) // Создаём кнопку через фабрику.\n\tcard := factory.CreateCard(content)     // Создаём карточку через фабрику.\n\tif button == nil || card == nil {       // Проверяем, что компоненты присутствуют.\n\t\treturn nil, nil, fmt.Errorf(\"factory %s returned nil components\", name) // Сообщаем об ошибке фабрики.\n\t}\n\ttheme := factory.Theme()                              // Считываем тему семейства.\n\tif button.Theme() != theme || card.Theme() != theme { // Компоненты должны быть в одной теме.\n\t\treturn nil, nil, fmt.Errorf(\"factory %s produced inconsistent components\", name) // Сообщаем о несогласованности.\n\t}\n\treturn button, card, nil // Возвращаем пару согласованных компонентов.\n}\n\nfunc (r *FactoryRegistry) resolveFactory(name string) (UIFactory, error) { // resolveFactory создаёт фабрику лениво и кэширует её.\n\tr.mu.Lock()            // Защищаем доступ к внутренним map.\n\tdefer r.mu.Unlock()    // Освобождаем mutex после работы.\n\tif r.builders == nil { // Инициализируем map билдров, если нужно.\n\t\tr.builders = make(map[string]FactoryBuilder) // Создаём пустое хранилище билдров.\n\t}\n\tif r.factories == nil { // Аналогично поступаем с кэшем фабрик.\n\t\tr.factories = make(map[string]UIFactory) // Создаём пустой кэш.\n\t}\n\tif factory, ok := r.factories[name]; ok { // Проверяем, есть ли фабрика в кэше.\n\t\treturn factory, nil // Возвращаем уже созданную фабрику.\n\t}\n\tbuilder, ok := r.builders[name] // Ищем builder по имени.\n\tif !ok || builder == nil {      // Builder отсутствует или nil.\n\t\treturn nil, fmt.Errorf(\"factory %s is not registered\", name) // Сообщаем об ошибке.\n\t}\n\tfactory, err := builder() // Создаём фабрику через builder.\n\tif err != nil {           // Обрабатываем ошибку создания.\n\t\treturn nil, err // Прокидываем ошибку дальше.\n\t}\n\tr.factories[name] = factory // Сохраняем фабрику в кэше для последующих вызовов.\n\treturn factory, nil         // Возвращаем созданную фабрику.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\ntype stubButton struct {\n\ttheme string\n\tlabel string\n}\n\nfunc (b stubButton) Render() string { return b.label + \":\" + b.theme }\nfunc (b stubButton) Theme() string  { return b.theme }\n\ntype stubCard struct {\n\ttheme string\n\ttitle string\n}\n\nfunc (c stubCard) Render() string { return c.title + \":\" + c.theme }\nfunc (c stubCard) Theme() string  { return c.theme }\n\ntype stubFactory struct {\n\ttheme  string\n\tbutton int64\n\tcard   int64\n}\n\nfunc (f *stubFactory) Theme() string { return f.theme }\n\nfunc (f *stubFactory) CreateButton(label string) Button {\n\tatomic.AddInt64(&f.button, 1)\n\treturn stubButton{theme: f.theme, label: label}\n}\n\nfunc (f *stubFactory) CreateCard(title string) Card {\n\tatomic.AddInt64(&f.card, 1)\n\treturn stubCard{theme: f.theme, title: title}\n}\n\n// ---- NewFactoryRegistry ----\n\nfunc TestNewFactoryRegistryInitializesMaps(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif reg == nil || reg.builders == nil || reg.factories == nil {\n\t\tt.Fatalf(\"registry not initialized: %#v\", reg)\n\t}\n}\n\nfunc TestNewFactoryRegistryIndependentInstances(t *testing.T) {\n\tr1 := NewFactoryRegistry()\n\tr2 := NewFactoryRegistry()\n\tif &r1.builders == &r2.builders {\n\t\tt.Fatalf(\"builders map should be distinct\")\n\t}\n}\n\nfunc TestNewFactoryRegistryStartsEmpty(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif len(reg.builders) != 0 || len(reg.factories) != 0 {\n\t\tt.Fatalf(\"new registry must be empty\")\n\t}\n}\n\n// ---- RegisterFactory ----\n\nfunc TestRegisterFactoryStoresBuilder(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"mobile\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"mobile\"}, nil\n\t})\n\tif _, ok := reg.builders[\"mobile\"]; !ok {\n\t\tt.Fatalf(\"builder not registered\")\n\t}\n}\n\nfunc TestRegisterFactoryOverridesAndClearsCache(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"ui\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"old\"}, nil\n\t})\n\t_, _, _ = reg.Compose(\"ui\", \"play\")\n\treg.factories[\"ui\"] = &stubFactory{theme: \"manual\"}\n\treg.RegisterFactory(\"ui\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"new\"}, nil\n\t})\n\tif _, ok := reg.factories[\"ui\"]; ok {\n\t\tt.Fatalf(\"cache should be cleared on re-register\")\n\t}\n}\n\nfunc TestRegisterFactoryIgnoresNilBuilder(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"noop\", nil)\n\tif len(reg.builders) != 0 {\n\t\tt.Fatalf(\"nil builder should not be stored\")\n\t}\n}\n\n// ---- Compose ----\n\nfunc TestComposeUsesFactoryOutputs(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"mobile\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"mobile\"}, nil\n\t})\n\tbtn, card, err := reg.Compose(\"mobile\", \"deploy\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif btn.Theme() != card.Theme() || btn.Theme() != \"mobile\" {\n\t\tt.Fatalf(\"themes mismatch: btn=%s card=%s\", btn.Theme(), card.Theme())\n\t}\n}\n\nfunc TestComposeCachesFactoryInstance(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tvar builds atomic.Int64\n\treg.RegisterFactory(\"desktop\", func() (UIFactory, error) {\n\t\tbuilds.Add(1)\n\t\treturn &stubFactory{theme: \"desktop\"}, nil\n\t})\n\tfor i := 0; i < 3; i++ {\n\t\tif _, _, err := reg.Compose(\"desktop\", \"x\"); err != nil {\n\t\t\tt.Fatalf(\"compose failed: %v\", err)\n\t\t}\n\t}\n\tif builds.Load() != 1 {\n\t\tt.Fatalf(\"factory should be built once, got %d\", builds.Load())\n\t}\n}\n\nfunc TestComposeErrorsOnMissingFactory(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif _, _, err := reg.Compose(\"unknown\", \"x\"); err == nil {\n\t\tt.Fatalf(\"expected error for unknown factory\")\n\t}\n}\n",
        "tags": [
          "go",
          "abstract_factory",
          "patterns",
          "creational"
        ],
        "order": 1
      },
      {
        "package": "abstract_factory",
        "slug": "go-abstract_factory-compose",
        "title": "Compose",
        "description": "Task 3 (medium): Compose\nВерните пару Button/Card из указанной фабрики, создавая её лениво.\nПодсказка: используйте builder для отсутствующих фабрик и проверяйте Theme у обоих компонентов.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Compose.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// Button описывает элемент интерфейса, который можно отрендерить.\ntype Button interface {\n\tRender() string\n\tTheme() string\n}\n\n// Card описывает карточку интерфейса.\ntype Card interface {\n\tRender() string\n\tTheme() string\n}\n\n// UIFactory создаёт согласованные компоненты одного семейства.\ntype UIFactory interface {\n\tTheme() string\n\tCreateButton(label string) Button\n\tCreateCard(title string) Card\n}\n\n// FactoryBuilder создаёт конкретную фабрику по требованию.\ntype FactoryBuilder func() (UIFactory, error)\n\n// FactoryRegistry хранит зарегистрированные фабрики и их экземпляры.\ntype FactoryRegistry struct {\n\tmu        sync.Mutex\n\tbuilders  map[string]FactoryBuilder\n\tfactories map[string]UIFactory\n}\n\n// Task 1 (easy): NewFactoryRegistry\n// Создайте пустой реестр фабрик с готовыми мапами и mutex'ом.\n// Подсказка: инициализируйте builders/factories, чтобы избежать nil map.\nfunc NewFactoryRegistry() *FactoryRegistry {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): RegisterFactory\n// Добавьте или обновите builder по имени, очищая закешированный экземпляр.\n// Подсказка: защищайте доступ к map mutex'ом и игнорируйте nil builder.\nfunc (r *FactoryRegistry) RegisterFactory(name string, builder FactoryBuilder) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Compose\n// Верните пару Button/Card из указанной фабрики, создавая её лениво.\n// Подсказка: используйте builder для отсутствующих фабрик и проверяйте Theme у обоих компонентов.\nfunc (r *FactoryRegistry) Compose(name, content string) (Button, Card, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Button interface { // Button описывает UI кнопку.\n\tRender() string // Render возвращает строковое представление.\n\tTheme() string  // Theme сообщает активную тему.\n}\n\ntype Card interface { // Card описывает карточку интерфейса.\n\tRender() string // Render возвращает текст для отображения.\n\tTheme() string  // Theme сообщает тему компонента.\n}\n\ntype UIFactory interface { // UIFactory создаёт согласованные компоненты.\n\tTheme() string                    // Theme возвращает тему семейства.\n\tCreateButton(label string) Button // CreateButton создаёт кнопку.\n\tCreateCard(title string) Card     // CreateCard создаёт карточку.\n}\n\ntype FactoryBuilder func() (UIFactory, error) // FactoryBuilder создаёт фабрику по требованию.\n\ntype FactoryRegistry struct { // FactoryRegistry хранит builder'ы и фабрики.\n\tmu        sync.Mutex                // mu защищает доступ к структурам.\n\tbuilders  map[string]FactoryBuilder // builders хранит фабрики по имени.\n\tfactories map[string]UIFactory      // factories кэширует созданные фабрики.\n}\n\nfunc NewFactoryRegistry() *FactoryRegistry { // NewFactoryRegistry создаёт пустой реестр фабрик.\n\treturn &FactoryRegistry{ // Возвращаем структуру с готовыми map.\n\t\tbuilders:  make(map[string]FactoryBuilder), // Хранилище билдров по имени.\n\t\tfactories: make(map[string]UIFactory),      // Кэш уже сконструированных фабрик.\n\t}\n}\n\nfunc (r *FactoryRegistry) RegisterFactory(name string, builder FactoryBuilder) { // RegisterFactory добавляет или обновляет builder.\n\tif r == nil || builder == nil || name == \"\" { // Проверяем входные данные.\n\t\treturn // Нечего регистрировать в некорректных случаях.\n\t}\n\tr.mu.Lock()            // Защищаем работу со внутренними структурами.\n\tdefer r.mu.Unlock()    // Освобождаем mutex по завершении.\n\tif r.builders == nil { // Лениво инициализируем map при необходимости.\n\t\tr.builders = make(map[string]FactoryBuilder) // Создаём map builder'ов.\n\t}\n\tif r.factories == nil { // Кэш фабрик тоже может быть nil.\n\t\tr.factories = make(map[string]UIFactory) // Создаём map фабрик.\n\t}\n\tr.builders[name] = builder // Сохраняем builder по имени.\n\tdelete(r.factories, name)  // Сброс кэша, чтобы новая фабрика создалась заново.\n}\n\nfunc (r *FactoryRegistry) Compose(name, content string) (Button, Card, error) { // Compose возвращает согласованные компоненты UI.\n\tif r == nil { // Nil-реестр не обслуживается.\n\t\treturn nil, nil, fmt.Errorf(\"registry is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif name == \"\" { // Имя фабрики обязательно.\n\t\treturn nil, nil, fmt.Errorf(\"factory name is empty\") // Возвращаем ошибку валидации.\n\t}\n\tfactory, err := r.resolveFactory(name) // Пытаемся получить/создать фабрику по имени.\n\tif err != nil {                        // Обрабатываем ошибку резолва.\n\t\treturn nil, nil, err // Прокидываем ошибку вызывающему коду.\n\t}\n\tbutton := factory.CreateButton(content) // Создаём кнопку через фабрику.\n\tcard := factory.CreateCard(content)     // Создаём карточку через фабрику.\n\tif button == nil || card == nil {       // Проверяем, что компоненты присутствуют.\n\t\treturn nil, nil, fmt.Errorf(\"factory %s returned nil components\", name) // Сообщаем об ошибке фабрики.\n\t}\n\ttheme := factory.Theme()                              // Считываем тему семейства.\n\tif button.Theme() != theme || card.Theme() != theme { // Компоненты должны быть в одной теме.\n\t\treturn nil, nil, fmt.Errorf(\"factory %s produced inconsistent components\", name) // Сообщаем о несогласованности.\n\t}\n\treturn button, card, nil // Возвращаем пару согласованных компонентов.\n}\n\nfunc (r *FactoryRegistry) resolveFactory(name string) (UIFactory, error) { // resolveFactory создаёт фабрику лениво и кэширует её.\n\tr.mu.Lock()            // Защищаем доступ к внутренним map.\n\tdefer r.mu.Unlock()    // Освобождаем mutex после работы.\n\tif r.builders == nil { // Инициализируем map билдров, если нужно.\n\t\tr.builders = make(map[string]FactoryBuilder) // Создаём пустое хранилище билдров.\n\t}\n\tif r.factories == nil { // Аналогично поступаем с кэшем фабрик.\n\t\tr.factories = make(map[string]UIFactory) // Создаём пустой кэш.\n\t}\n\tif factory, ok := r.factories[name]; ok { // Проверяем, есть ли фабрика в кэше.\n\t\treturn factory, nil // Возвращаем уже созданную фабрику.\n\t}\n\tbuilder, ok := r.builders[name] // Ищем builder по имени.\n\tif !ok || builder == nil {      // Builder отсутствует или nil.\n\t\treturn nil, fmt.Errorf(\"factory %s is not registered\", name) // Сообщаем об ошибке.\n\t}\n\tfactory, err := builder() // Создаём фабрику через builder.\n\tif err != nil {           // Обрабатываем ошибку создания.\n\t\treturn nil, err // Прокидываем ошибку дальше.\n\t}\n\tr.factories[name] = factory // Сохраняем фабрику в кэше для последующих вызовов.\n\treturn factory, nil         // Возвращаем созданную фабрику.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\ntype stubButton struct {\n\ttheme string\n\tlabel string\n}\n\nfunc (b stubButton) Render() string { return b.label + \":\" + b.theme }\nfunc (b stubButton) Theme() string  { return b.theme }\n\ntype stubCard struct {\n\ttheme string\n\ttitle string\n}\n\nfunc (c stubCard) Render() string { return c.title + \":\" + c.theme }\nfunc (c stubCard) Theme() string  { return c.theme }\n\ntype stubFactory struct {\n\ttheme  string\n\tbutton int64\n\tcard   int64\n}\n\nfunc (f *stubFactory) Theme() string { return f.theme }\n\nfunc (f *stubFactory) CreateButton(label string) Button {\n\tatomic.AddInt64(&f.button, 1)\n\treturn stubButton{theme: f.theme, label: label}\n}\n\nfunc (f *stubFactory) CreateCard(title string) Card {\n\tatomic.AddInt64(&f.card, 1)\n\treturn stubCard{theme: f.theme, title: title}\n}\n\n// ---- NewFactoryRegistry ----\n\nfunc TestNewFactoryRegistryInitializesMaps(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif reg == nil || reg.builders == nil || reg.factories == nil {\n\t\tt.Fatalf(\"registry not initialized: %#v\", reg)\n\t}\n}\n\nfunc TestNewFactoryRegistryIndependentInstances(t *testing.T) {\n\tr1 := NewFactoryRegistry()\n\tr2 := NewFactoryRegistry()\n\tif &r1.builders == &r2.builders {\n\t\tt.Fatalf(\"builders map should be distinct\")\n\t}\n}\n\nfunc TestNewFactoryRegistryStartsEmpty(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif len(reg.builders) != 0 || len(reg.factories) != 0 {\n\t\tt.Fatalf(\"new registry must be empty\")\n\t}\n}\n\n// ---- RegisterFactory ----\n\nfunc TestRegisterFactoryStoresBuilder(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"mobile\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"mobile\"}, nil\n\t})\n\tif _, ok := reg.builders[\"mobile\"]; !ok {\n\t\tt.Fatalf(\"builder not registered\")\n\t}\n}\n\nfunc TestRegisterFactoryOverridesAndClearsCache(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"ui\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"old\"}, nil\n\t})\n\t_, _, _ = reg.Compose(\"ui\", \"play\")\n\treg.factories[\"ui\"] = &stubFactory{theme: \"manual\"}\n\treg.RegisterFactory(\"ui\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"new\"}, nil\n\t})\n\tif _, ok := reg.factories[\"ui\"]; ok {\n\t\tt.Fatalf(\"cache should be cleared on re-register\")\n\t}\n}\n\nfunc TestRegisterFactoryIgnoresNilBuilder(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"noop\", nil)\n\tif len(reg.builders) != 0 {\n\t\tt.Fatalf(\"nil builder should not be stored\")\n\t}\n}\n\n// ---- Compose ----\n\nfunc TestComposeUsesFactoryOutputs(t *testing.T) {\n\treg := NewFactoryRegistry()\n\treg.RegisterFactory(\"mobile\", func() (UIFactory, error) {\n\t\treturn &stubFactory{theme: \"mobile\"}, nil\n\t})\n\tbtn, card, err := reg.Compose(\"mobile\", \"deploy\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif btn.Theme() != card.Theme() || btn.Theme() != \"mobile\" {\n\t\tt.Fatalf(\"themes mismatch: btn=%s card=%s\", btn.Theme(), card.Theme())\n\t}\n}\n\nfunc TestComposeCachesFactoryInstance(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tvar builds atomic.Int64\n\treg.RegisterFactory(\"desktop\", func() (UIFactory, error) {\n\t\tbuilds.Add(1)\n\t\treturn &stubFactory{theme: \"desktop\"}, nil\n\t})\n\tfor i := 0; i < 3; i++ {\n\t\tif _, _, err := reg.Compose(\"desktop\", \"x\"); err != nil {\n\t\t\tt.Fatalf(\"compose failed: %v\", err)\n\t\t}\n\t}\n\tif builds.Load() != 1 {\n\t\tt.Fatalf(\"factory should be built once, got %d\", builds.Load())\n\t}\n}\n\nfunc TestComposeErrorsOnMissingFactory(t *testing.T) {\n\treg := NewFactoryRegistry()\n\tif _, _, err := reg.Compose(\"unknown\", \"x\"); err == nil {\n\t\tt.Fatalf(\"expected error for unknown factory\")\n\t}\n}\n",
        "tags": [
          "go",
          "abstract_factory",
          "patterns",
          "creational"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-builder",
    "tasks": [
      {
        "package": "builder",
        "slug": "go-builder-newformbuilder",
        "title": "NewFormBuilder",
        "description": "Task 1 (easy): NewFormBuilder\nСоздайте builder с указанным именем формы и пустым списком полей.\nПодсказка: храните имя внутри структуры и инициализируйте срез.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of NewFormBuilder.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"errors\"\n\n// FormField описывает отдельное поле формы.\ntype FormField struct {\n\tName     string\n\tRequired bool\n\tDefault  string\n}\n\n// Form представляет итоговый результат сборки.\ntype Form struct {\n\tName   string\n\tFields []FormField\n\tValues map[string]string\n}\n\n// FormBuilder конструирует форму пошагово.\ntype FormBuilder struct {\n\tname   string\n\tfields []FormField\n}\n\n// ErrMissingField сигнализирует об отсутствии обязательного поля.\nvar ErrMissingField = errors.New(\"missing required field\")\n\n// Task 1 (easy): NewFormBuilder\n// Создайте builder с указанным именем формы и пустым списком полей.\n// Подсказка: храните имя внутри структуры и инициализируйте срез.\nfunc NewFormBuilder(name string) *FormBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): AddField\n// Добавьте поле в builder, игнорируя дубликаты имён и возвращая builder для чейнинга.\n// Подсказка: заменяйте existing поле с тем же именем, чтобы последнее определение побеждало.\nfunc (b *FormBuilder) AddField(field FormField) *FormBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Build\n// Постройте форму, объединив входные данные и default значения, проверив обязательные поля.\n// Подсказка: копируйте карту значений, чтобы дальнейшие изменения не влияли на результат.\nfunc (b *FormBuilder) Build(data map[string]string) (Form, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport \"errors\"\n\ntype FormField struct { // FormField описывает поле формы.\n\tName     string // Name — уникальный идентификатор поля.\n\tRequired bool   // Required отмечает необходимость заполнения.\n\tDefault  string // Default хранит значение по умолчанию.\n}\n\ntype Form struct { // Form представляет готовую форму.\n\tName   string            // Name указывает название формы.\n\tFields []FormField       // Fields содержит описание полей.\n\tValues map[string]string // Values хранит пользовательские значения.\n}\n\ntype FormBuilder struct { // FormBuilder собирает форму по шагам.\n\tname   string      // name — название формы.\n\tfields []FormField // fields — список текущих полей.\n}\n\nvar ErrMissingField = errors.New(\"missing required field\") // ErrMissingField сигнализирует о нехватке данных.\n\nfunc NewFormBuilder(name string) *FormBuilder { // NewFormBuilder создаёт builder с указанным именем.\n\treturn &FormBuilder{ // Возвращаем готовую структуру.\n\t\tname:   name,                 // Сохраняем имя формы.\n\t\tfields: make([]FormField, 0), // Инициализируем срез полей.\n\t}\n}\n\nfunc (b *FormBuilder) AddField(field FormField) *FormBuilder { // AddField добавляет или заменяет поле.\n\tif b == nil { // Nil-builder не поддерживает операции.\n\t\treturn nil // Возвращаем nil для безопасного чейнинга.\n\t}\n\tfor idx, existing := range b.fields { // Ищем поле с таким же именем.\n\t\tif existing.Name == field.Name { // Найден дубликат.\n\t\t\tb.fields[idx] = field // Заменяем существующее поле.\n\t\t\treturn b              // Возвращаем builder для флюентного интерфейса.\n\t\t}\n\t}\n\tb.fields = append(b.fields, field) // Добавляем новое поле в конец.\n\treturn b                           // Возвращаем builder для дальнейших вызовов.\n}\n\nfunc (b *FormBuilder) Build(data map[string]string) (Form, error) { // Build собирает форму из полей и входных данных.\n\tif b == nil { // Nil-builder не может построить форму.\n\t\treturn Form{}, ErrMissingField // Возвращаем ошибку отсутствия обязательных полей.\n\t}\n\tvalues := make(map[string]string, len(b.fields)) // Готовим карту значений результата.\n\tfor _, field := range b.fields {                 // Проходим по каждому полю.\n\t\tval, ok := data[field.Name] // Проверяем, передано ли значение пользователем.\n\t\tif !ok || val == \"\" {       // Значение отсутствует или пустое.\n\t\t\tval = field.Default // Используем значение по умолчанию.\n\t\t}\n\t\tif field.Required && val == \"\" { // Обязательное поле не заполнено.\n\t\t\treturn Form{}, ErrMissingField // Возвращаем ошибку валидации.\n\t\t}\n\t\tvalues[field.Name] = val // Сохраняем вычисленное значение.\n\t}\n\tfieldsCopy := make([]FormField, len(b.fields)) // Создаём копию метаданных полей.\n\tcopy(fieldsCopy, b.fields)                     // Копируем поля, чтобы защитить builder от внешних изменений.\n\treturn Form{                                   // Формируем результат.\n\t\tName:   b.name,     // Имя формы берём из builder.\n\t\tFields: fieldsCopy, // Прикладываем копию списка полей.\n\t\tValues: values,     // Передаём вычисленные значения.\n\t}, nil\n}\n",
        "testCode": "package creational\n\nimport \"testing\"\n\n// ---- NewFormBuilder ----\n\nfunc TestNewFormBuilderInitializesFields(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tif b == nil || b.name != \"signup\" {\n\t\tt.Fatalf(\"builder not initialized: %#v\", b)\n\t}\n\tif len(b.fields) != 0 {\n\t\tt.Fatalf(\"expected empty fields, got %#v\", b.fields)\n\t}\n}\n\nfunc TestNewFormBuilderIndependentInstances(t *testing.T) {\n\tb1 := NewFormBuilder(\"a\")\n\tb2 := NewFormBuilder(\"b\")\n\tb1.fields = append(b1.fields, FormField{Name: \"email\"})\n\tif len(b2.fields) != 0 {\n\t\tt.Fatalf(\"builders should not share slices\")\n\t}\n}\n\nfunc TestNewFormBuilderAllowsEmptyName(t *testing.T) {\n\tif b := NewFormBuilder(\"\"); b == nil {\n\t\tt.Fatalf(\"builder should be created even with empty name\")\n\t}\n}\n\n// ---- AddField ----\n\nfunc TestAddFieldAppendsField(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tb.AddField(FormField{Name: \"email\", Required: true})\n\tif len(b.fields) != 1 || b.fields[0].Name != \"email\" {\n\t\tt.Fatalf(\"field not added: %#v\", b.fields)\n\t}\n}\n\nfunc TestAddFieldOverridesDuplicates(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tb.AddField(FormField{Name: \"email\", Required: true})\n\tb.AddField(FormField{Name: \"email\", Required: false, Default: \"anon\"})\n\tif len(b.fields) != 1 || b.fields[0].Default != \"anon\" {\n\t\tt.Fatalf(\"duplicate should override previous field: %#v\", b.fields)\n\t}\n}\n\nfunc TestAddFieldOnNilBuilderReturnsNil(t *testing.T) {\n\tif res := (*FormBuilder)(nil).AddField(FormField{Name: \"x\"}); res != nil {\n\t\tt.Fatalf(\"expected nil when builder is nil\")\n\t}\n}\n\n// ---- Build ----\n\nfunc TestBuildMergesDefaultsAndInput(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").\n\t\tAddField(FormField{Name: \"email\", Required: true}).\n\t\tAddField(FormField{Name: \"country\", Default: \"US\"})\n\tform, err := b.Build(map[string]string{\"email\": \"dev@company\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif form.Values[\"country\"] != \"US\" || form.Values[\"email\"] != \"dev@company\" {\n\t\tt.Fatalf(\"unexpected values: %#v\", form.Values)\n\t}\n}\n\nfunc TestBuildValidatesRequiredFields(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").AddField(FormField{Name: \"email\", Required: true})\n\tif _, err := b.Build(map[string]string{}); err != ErrMissingField {\n\t\tt.Fatalf(\"expected ErrMissingField, got %v\", err)\n\t}\n}\n\nfunc TestBuildReturnsCopyOfValues(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").AddField(FormField{Name: \"city\"})\n\tinput := map[string]string{\"city\": \"Paris\"}\n\tform, err := b.Build(input)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tinput[\"city\"] = \"London\"\n\tif form.Values[\"city\"] != \"Paris\" {\n\t\tt.Fatalf(\"form values should not be affected by caller mutations\")\n\t}\n}\n",
        "tags": [
          "go",
          "builder",
          "patterns",
          "creational"
        ],
        "order": 0
      },
      {
        "package": "builder",
        "slug": "go-builder-addfield",
        "title": "AddField",
        "description": "Task 2 (easy+): AddField\nДобавьте поле в builder, игнорируя дубликаты имён и возвращая builder для чейнинга.\nПодсказка: заменяйте existing поле с тем же именем, чтобы последнее определение побеждало.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of AddField.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"errors\"\n\n// FormField описывает отдельное поле формы.\ntype FormField struct {\n\tName     string\n\tRequired bool\n\tDefault  string\n}\n\n// Form представляет итоговый результат сборки.\ntype Form struct {\n\tName   string\n\tFields []FormField\n\tValues map[string]string\n}\n\n// FormBuilder конструирует форму пошагово.\ntype FormBuilder struct {\n\tname   string\n\tfields []FormField\n}\n\n// ErrMissingField сигнализирует об отсутствии обязательного поля.\nvar ErrMissingField = errors.New(\"missing required field\")\n\n// Task 1 (easy): NewFormBuilder\n// Создайте builder с указанным именем формы и пустым списком полей.\n// Подсказка: храните имя внутри структуры и инициализируйте срез.\nfunc NewFormBuilder(name string) *FormBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): AddField\n// Добавьте поле в builder, игнорируя дубликаты имён и возвращая builder для чейнинга.\n// Подсказка: заменяйте existing поле с тем же именем, чтобы последнее определение побеждало.\nfunc (b *FormBuilder) AddField(field FormField) *FormBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Build\n// Постройте форму, объединив входные данные и default значения, проверив обязательные поля.\n// Подсказка: копируйте карту значений, чтобы дальнейшие изменения не влияли на результат.\nfunc (b *FormBuilder) Build(data map[string]string) (Form, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport \"errors\"\n\ntype FormField struct { // FormField описывает поле формы.\n\tName     string // Name — уникальный идентификатор поля.\n\tRequired bool   // Required отмечает необходимость заполнения.\n\tDefault  string // Default хранит значение по умолчанию.\n}\n\ntype Form struct { // Form представляет готовую форму.\n\tName   string            // Name указывает название формы.\n\tFields []FormField       // Fields содержит описание полей.\n\tValues map[string]string // Values хранит пользовательские значения.\n}\n\ntype FormBuilder struct { // FormBuilder собирает форму по шагам.\n\tname   string      // name — название формы.\n\tfields []FormField // fields — список текущих полей.\n}\n\nvar ErrMissingField = errors.New(\"missing required field\") // ErrMissingField сигнализирует о нехватке данных.\n\nfunc NewFormBuilder(name string) *FormBuilder { // NewFormBuilder создаёт builder с указанным именем.\n\treturn &FormBuilder{ // Возвращаем готовую структуру.\n\t\tname:   name,                 // Сохраняем имя формы.\n\t\tfields: make([]FormField, 0), // Инициализируем срез полей.\n\t}\n}\n\nfunc (b *FormBuilder) AddField(field FormField) *FormBuilder { // AddField добавляет или заменяет поле.\n\tif b == nil { // Nil-builder не поддерживает операции.\n\t\treturn nil // Возвращаем nil для безопасного чейнинга.\n\t}\n\tfor idx, existing := range b.fields { // Ищем поле с таким же именем.\n\t\tif existing.Name == field.Name { // Найден дубликат.\n\t\t\tb.fields[idx] = field // Заменяем существующее поле.\n\t\t\treturn b              // Возвращаем builder для флюентного интерфейса.\n\t\t}\n\t}\n\tb.fields = append(b.fields, field) // Добавляем новое поле в конец.\n\treturn b                           // Возвращаем builder для дальнейших вызовов.\n}\n\nfunc (b *FormBuilder) Build(data map[string]string) (Form, error) { // Build собирает форму из полей и входных данных.\n\tif b == nil { // Nil-builder не может построить форму.\n\t\treturn Form{}, ErrMissingField // Возвращаем ошибку отсутствия обязательных полей.\n\t}\n\tvalues := make(map[string]string, len(b.fields)) // Готовим карту значений результата.\n\tfor _, field := range b.fields {                 // Проходим по каждому полю.\n\t\tval, ok := data[field.Name] // Проверяем, передано ли значение пользователем.\n\t\tif !ok || val == \"\" {       // Значение отсутствует или пустое.\n\t\t\tval = field.Default // Используем значение по умолчанию.\n\t\t}\n\t\tif field.Required && val == \"\" { // Обязательное поле не заполнено.\n\t\t\treturn Form{}, ErrMissingField // Возвращаем ошибку валидации.\n\t\t}\n\t\tvalues[field.Name] = val // Сохраняем вычисленное значение.\n\t}\n\tfieldsCopy := make([]FormField, len(b.fields)) // Создаём копию метаданных полей.\n\tcopy(fieldsCopy, b.fields)                     // Копируем поля, чтобы защитить builder от внешних изменений.\n\treturn Form{                                   // Формируем результат.\n\t\tName:   b.name,     // Имя формы берём из builder.\n\t\tFields: fieldsCopy, // Прикладываем копию списка полей.\n\t\tValues: values,     // Передаём вычисленные значения.\n\t}, nil\n}\n",
        "testCode": "package creational\n\nimport \"testing\"\n\n// ---- NewFormBuilder ----\n\nfunc TestNewFormBuilderInitializesFields(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tif b == nil || b.name != \"signup\" {\n\t\tt.Fatalf(\"builder not initialized: %#v\", b)\n\t}\n\tif len(b.fields) != 0 {\n\t\tt.Fatalf(\"expected empty fields, got %#v\", b.fields)\n\t}\n}\n\nfunc TestNewFormBuilderIndependentInstances(t *testing.T) {\n\tb1 := NewFormBuilder(\"a\")\n\tb2 := NewFormBuilder(\"b\")\n\tb1.fields = append(b1.fields, FormField{Name: \"email\"})\n\tif len(b2.fields) != 0 {\n\t\tt.Fatalf(\"builders should not share slices\")\n\t}\n}\n\nfunc TestNewFormBuilderAllowsEmptyName(t *testing.T) {\n\tif b := NewFormBuilder(\"\"); b == nil {\n\t\tt.Fatalf(\"builder should be created even with empty name\")\n\t}\n}\n\n// ---- AddField ----\n\nfunc TestAddFieldAppendsField(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tb.AddField(FormField{Name: \"email\", Required: true})\n\tif len(b.fields) != 1 || b.fields[0].Name != \"email\" {\n\t\tt.Fatalf(\"field not added: %#v\", b.fields)\n\t}\n}\n\nfunc TestAddFieldOverridesDuplicates(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tb.AddField(FormField{Name: \"email\", Required: true})\n\tb.AddField(FormField{Name: \"email\", Required: false, Default: \"anon\"})\n\tif len(b.fields) != 1 || b.fields[0].Default != \"anon\" {\n\t\tt.Fatalf(\"duplicate should override previous field: %#v\", b.fields)\n\t}\n}\n\nfunc TestAddFieldOnNilBuilderReturnsNil(t *testing.T) {\n\tif res := (*FormBuilder)(nil).AddField(FormField{Name: \"x\"}); res != nil {\n\t\tt.Fatalf(\"expected nil when builder is nil\")\n\t}\n}\n\n// ---- Build ----\n\nfunc TestBuildMergesDefaultsAndInput(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").\n\t\tAddField(FormField{Name: \"email\", Required: true}).\n\t\tAddField(FormField{Name: \"country\", Default: \"US\"})\n\tform, err := b.Build(map[string]string{\"email\": \"dev@company\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif form.Values[\"country\"] != \"US\" || form.Values[\"email\"] != \"dev@company\" {\n\t\tt.Fatalf(\"unexpected values: %#v\", form.Values)\n\t}\n}\n\nfunc TestBuildValidatesRequiredFields(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").AddField(FormField{Name: \"email\", Required: true})\n\tif _, err := b.Build(map[string]string{}); err != ErrMissingField {\n\t\tt.Fatalf(\"expected ErrMissingField, got %v\", err)\n\t}\n}\n\nfunc TestBuildReturnsCopyOfValues(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").AddField(FormField{Name: \"city\"})\n\tinput := map[string]string{\"city\": \"Paris\"}\n\tform, err := b.Build(input)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tinput[\"city\"] = \"London\"\n\tif form.Values[\"city\"] != \"Paris\" {\n\t\tt.Fatalf(\"form values should not be affected by caller mutations\")\n\t}\n}\n",
        "tags": [
          "go",
          "builder",
          "patterns",
          "creational"
        ],
        "order": 1
      },
      {
        "package": "builder",
        "slug": "go-builder-build",
        "title": "Build",
        "description": "Task 3 (medium): Build\nПостройте форму, объединив входные данные и default значения, проверив обязательные поля.\nПодсказка: копируйте карту значений, чтобы дальнейшие изменения не влияли на результат.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Build.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"errors\"\n\n// FormField описывает отдельное поле формы.\ntype FormField struct {\n\tName     string\n\tRequired bool\n\tDefault  string\n}\n\n// Form представляет итоговый результат сборки.\ntype Form struct {\n\tName   string\n\tFields []FormField\n\tValues map[string]string\n}\n\n// FormBuilder конструирует форму пошагово.\ntype FormBuilder struct {\n\tname   string\n\tfields []FormField\n}\n\n// ErrMissingField сигнализирует об отсутствии обязательного поля.\nvar ErrMissingField = errors.New(\"missing required field\")\n\n// Task 1 (easy): NewFormBuilder\n// Создайте builder с указанным именем формы и пустым списком полей.\n// Подсказка: храните имя внутри структуры и инициализируйте срез.\nfunc NewFormBuilder(name string) *FormBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): AddField\n// Добавьте поле в builder, игнорируя дубликаты имён и возвращая builder для чейнинга.\n// Подсказка: заменяйте existing поле с тем же именем, чтобы последнее определение побеждало.\nfunc (b *FormBuilder) AddField(field FormField) *FormBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Build\n// Постройте форму, объединив входные данные и default значения, проверив обязательные поля.\n// Подсказка: копируйте карту значений, чтобы дальнейшие изменения не влияли на результат.\nfunc (b *FormBuilder) Build(data map[string]string) (Form, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport \"errors\"\n\ntype FormField struct { // FormField описывает поле формы.\n\tName     string // Name — уникальный идентификатор поля.\n\tRequired bool   // Required отмечает необходимость заполнения.\n\tDefault  string // Default хранит значение по умолчанию.\n}\n\ntype Form struct { // Form представляет готовую форму.\n\tName   string            // Name указывает название формы.\n\tFields []FormField       // Fields содержит описание полей.\n\tValues map[string]string // Values хранит пользовательские значения.\n}\n\ntype FormBuilder struct { // FormBuilder собирает форму по шагам.\n\tname   string      // name — название формы.\n\tfields []FormField // fields — список текущих полей.\n}\n\nvar ErrMissingField = errors.New(\"missing required field\") // ErrMissingField сигнализирует о нехватке данных.\n\nfunc NewFormBuilder(name string) *FormBuilder { // NewFormBuilder создаёт builder с указанным именем.\n\treturn &FormBuilder{ // Возвращаем готовую структуру.\n\t\tname:   name,                 // Сохраняем имя формы.\n\t\tfields: make([]FormField, 0), // Инициализируем срез полей.\n\t}\n}\n\nfunc (b *FormBuilder) AddField(field FormField) *FormBuilder { // AddField добавляет или заменяет поле.\n\tif b == nil { // Nil-builder не поддерживает операции.\n\t\treturn nil // Возвращаем nil для безопасного чейнинга.\n\t}\n\tfor idx, existing := range b.fields { // Ищем поле с таким же именем.\n\t\tif existing.Name == field.Name { // Найден дубликат.\n\t\t\tb.fields[idx] = field // Заменяем существующее поле.\n\t\t\treturn b              // Возвращаем builder для флюентного интерфейса.\n\t\t}\n\t}\n\tb.fields = append(b.fields, field) // Добавляем новое поле в конец.\n\treturn b                           // Возвращаем builder для дальнейших вызовов.\n}\n\nfunc (b *FormBuilder) Build(data map[string]string) (Form, error) { // Build собирает форму из полей и входных данных.\n\tif b == nil { // Nil-builder не может построить форму.\n\t\treturn Form{}, ErrMissingField // Возвращаем ошибку отсутствия обязательных полей.\n\t}\n\tvalues := make(map[string]string, len(b.fields)) // Готовим карту значений результата.\n\tfor _, field := range b.fields {                 // Проходим по каждому полю.\n\t\tval, ok := data[field.Name] // Проверяем, передано ли значение пользователем.\n\t\tif !ok || val == \"\" {       // Значение отсутствует или пустое.\n\t\t\tval = field.Default // Используем значение по умолчанию.\n\t\t}\n\t\tif field.Required && val == \"\" { // Обязательное поле не заполнено.\n\t\t\treturn Form{}, ErrMissingField // Возвращаем ошибку валидации.\n\t\t}\n\t\tvalues[field.Name] = val // Сохраняем вычисленное значение.\n\t}\n\tfieldsCopy := make([]FormField, len(b.fields)) // Создаём копию метаданных полей.\n\tcopy(fieldsCopy, b.fields)                     // Копируем поля, чтобы защитить builder от внешних изменений.\n\treturn Form{                                   // Формируем результат.\n\t\tName:   b.name,     // Имя формы берём из builder.\n\t\tFields: fieldsCopy, // Прикладываем копию списка полей.\n\t\tValues: values,     // Передаём вычисленные значения.\n\t}, nil\n}\n",
        "testCode": "package creational\n\nimport \"testing\"\n\n// ---- NewFormBuilder ----\n\nfunc TestNewFormBuilderInitializesFields(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tif b == nil || b.name != \"signup\" {\n\t\tt.Fatalf(\"builder not initialized: %#v\", b)\n\t}\n\tif len(b.fields) != 0 {\n\t\tt.Fatalf(\"expected empty fields, got %#v\", b.fields)\n\t}\n}\n\nfunc TestNewFormBuilderIndependentInstances(t *testing.T) {\n\tb1 := NewFormBuilder(\"a\")\n\tb2 := NewFormBuilder(\"b\")\n\tb1.fields = append(b1.fields, FormField{Name: \"email\"})\n\tif len(b2.fields) != 0 {\n\t\tt.Fatalf(\"builders should not share slices\")\n\t}\n}\n\nfunc TestNewFormBuilderAllowsEmptyName(t *testing.T) {\n\tif b := NewFormBuilder(\"\"); b == nil {\n\t\tt.Fatalf(\"builder should be created even with empty name\")\n\t}\n}\n\n// ---- AddField ----\n\nfunc TestAddFieldAppendsField(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tb.AddField(FormField{Name: \"email\", Required: true})\n\tif len(b.fields) != 1 || b.fields[0].Name != \"email\" {\n\t\tt.Fatalf(\"field not added: %#v\", b.fields)\n\t}\n}\n\nfunc TestAddFieldOverridesDuplicates(t *testing.T) {\n\tb := NewFormBuilder(\"signup\")\n\tb.AddField(FormField{Name: \"email\", Required: true})\n\tb.AddField(FormField{Name: \"email\", Required: false, Default: \"anon\"})\n\tif len(b.fields) != 1 || b.fields[0].Default != \"anon\" {\n\t\tt.Fatalf(\"duplicate should override previous field: %#v\", b.fields)\n\t}\n}\n\nfunc TestAddFieldOnNilBuilderReturnsNil(t *testing.T) {\n\tif res := (*FormBuilder)(nil).AddField(FormField{Name: \"x\"}); res != nil {\n\t\tt.Fatalf(\"expected nil when builder is nil\")\n\t}\n}\n\n// ---- Build ----\n\nfunc TestBuildMergesDefaultsAndInput(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").\n\t\tAddField(FormField{Name: \"email\", Required: true}).\n\t\tAddField(FormField{Name: \"country\", Default: \"US\"})\n\tform, err := b.Build(map[string]string{\"email\": \"dev@company\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif form.Values[\"country\"] != \"US\" || form.Values[\"email\"] != \"dev@company\" {\n\t\tt.Fatalf(\"unexpected values: %#v\", form.Values)\n\t}\n}\n\nfunc TestBuildValidatesRequiredFields(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").AddField(FormField{Name: \"email\", Required: true})\n\tif _, err := b.Build(map[string]string{}); err != ErrMissingField {\n\t\tt.Fatalf(\"expected ErrMissingField, got %v\", err)\n\t}\n}\n\nfunc TestBuildReturnsCopyOfValues(t *testing.T) {\n\tb := NewFormBuilder(\"signup\").AddField(FormField{Name: \"city\"})\n\tinput := map[string]string{\"city\": \"Paris\"}\n\tform, err := b.Build(input)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tinput[\"city\"] = \"London\"\n\tif form.Values[\"city\"] != \"Paris\" {\n\t\tt.Fatalf(\"form values should not be affected by caller mutations\")\n\t}\n}\n",
        "tags": [
          "go",
          "builder",
          "patterns",
          "creational"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-factory_method",
    "tasks": [
      {
        "package": "factory_method",
        "slug": "go-factory_method-newdeliverycreator",
        "title": "NewDeliveryCreator",
        "description": "Task 1 (easy): NewDeliveryCreator\nСоздайте пустой реестр transport фабрик.\nПодсказка: инициализируйте map и подготовьте RWMutex для конкурентного доступа.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of NewDeliveryCreator.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// Transport определяет способ доставки.\ntype Transport interface {\n\tDeliver(packageID string) string\n\tKind() string\n}\n\n// TransportFactory создаёт конкретный транспорт.\ntype TransportFactory func() Transport\n\n// DeliveryCreator управляет регистрацией фабричных методов.\ntype DeliveryCreator struct {\n\tmu        sync.RWMutex\n\tfactories map[string]TransportFactory\n}\n\n// Task 1 (easy): NewDeliveryCreator\n// Создайте пустой реестр transport фабрик.\n// Подсказка: инициализируйте map и подготовьте RWMutex для конкурентного доступа.\nfunc NewDeliveryCreator() *DeliveryCreator {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Зарегистрируйте factory по ключу, разрешая перезапись.\n// Подсказка: используйте Lock/Unlock и игнорируйте nil factory.\nfunc (c *DeliveryCreator) Register(kind string, factory TransportFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Deliver\n// Создайте транспорт по ключу и выполните доставку.\n// Подсказка: верните ошибку, если factory не найден, и включите название транспорта в ответ.\nfunc (c *DeliveryCreator) Deliver(kind, packageID string) (string, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Transport interface { // Transport описывает доставку.\n\tDeliver(packageID string) string // Deliver возвращает результат доставки.\n\tKind() string                    // Kind сообщает тип транспорта.\n}\n\ntype TransportFactory func() Transport // TransportFactory создаёт транспорт.\n\ntype DeliveryCreator struct { // DeliveryCreator управляет фабриками.\n\tmu        sync.RWMutex                // mu защищает карту.\n\tfactories map[string]TransportFactory // factories хранит зарегистрированные фабрики.\n}\n\nfunc NewDeliveryCreator() *DeliveryCreator { // NewDeliveryCreator подготавливает реестр фабрик.\n\treturn &DeliveryCreator{ // Возвращаем структуру с инициализированной map.\n\t\tfactories: make(map[string]TransportFactory), // Готовое хранилище фабричных методов.\n\t}\n}\n\nfunc (c *DeliveryCreator) Register(kind string, factory TransportFactory) { // Register добавляет фабричный метод в реестр.\n\tif c == nil || factory == nil || kind == \"\" { // Проверяем корректность входных данных.\n\t\treturn // Не храним некорректные значения.\n\t}\n\tc.mu.Lock()             // Защищаем доступ к map на запись.\n\tdefer c.mu.Unlock()     // Освобождаем mutex по завершении.\n\tif c.factories == nil { // Лениво инициализируем map.\n\t\tc.factories = make(map[string]TransportFactory) // Создаём новое хранилище.\n\t}\n\tc.factories[kind] = factory // Сохраняем/перезаписываем фабрику по ключу.\n}\n\nfunc (c *DeliveryCreator) Deliver(kind, packageID string) (string, error) { // Deliver создаёт транспорт и выполняет доставку.\n\tif c == nil { // Nil-creator не поддерживается.\n\t\treturn \"\", fmt.Errorf(\"creator is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tc.mu.RLock()                 // Берём read-lock для поиска фабрики.\n\tfactory := c.factories[kind] // Ищем фабрику по типу транспорта.\n\tc.mu.RUnlock()               // Освобождаем read-lock.\n\tif factory == nil {          // Фабрика не найдена.\n\t\treturn \"\", fmt.Errorf(\"transport %s is not registered\", kind) // Возвращаем ошибку.\n\t}\n\ttransport := factory() // Создаём транспорт через фабричный метод.\n\tif transport == nil {  // Фабрика вернула nil.\n\t\treturn \"\", fmt.Errorf(\"transport %s factory returned nil\", kind) // Сообщаем об ошибке реализации.\n\t}\n\tresult := transport.Deliver(packageID) // Выполняем доставку.\n\treturn result, nil                     // Возвращаем строку результата.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\ntype stubTransport struct {\n\tkind   string\n\tcalled *atomic.Int64\n}\n\nfunc (t *stubTransport) Deliver(packageID string) string {\n\tif t.called != nil {\n\t\tt.called.Add(1)\n\t}\n\treturn t.kind + \":\" + packageID\n}\n\nfunc (t *stubTransport) Kind() string {\n\treturn t.kind\n}\n\n// ---- NewDeliveryCreator ----\n\nfunc TestNewDeliveryCreatorInitializesMap(t *testing.T) {\n\tcreator := NewDeliveryCreator()\n\tif creator == nil || creator.factories == nil {\n\t\tt.Fatalf(\"creator not initialized: %#v\", creator)\n\t}\n}\n\nfunc TestNewDeliveryCreatorIndependentInstances(t *testing.T) {\n\tc1 := NewDeliveryCreator()\n\tc2 := NewDeliveryCreator()\n\tc1.factories[\"x\"] = func() Transport { return &stubTransport{kind: \"x\"} }\n\tif len(c2.factories) != 0 {\n\t\tt.Fatalf(\"instances should not share map\")\n\t}\n}\n\nfunc TestNewDeliveryCreatorStartsEmpty(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tif len(c.factories) != 0 {\n\t\tt.Fatalf(\"expected empty registry\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestRegisterStoresFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"air\", func() Transport { return &stubTransport{kind: \"air\"} })\n\tif _, ok := c.factories[\"air\"]; !ok {\n\t\tt.Fatalf(\"factory not stored\")\n\t}\n}\n\nfunc TestRegisterOverridesExisting(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"road\"} })\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"new\"} })\n\tif transport, _ := c.Deliver(\"road\", \"pkg\"); !strings.HasPrefix(transport, \"new\") {\n\t\tt.Fatalf(\"factory should be overridden, got %s\", transport)\n\t}\n}\n\nfunc TestRegisterIgnoresNilFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"sea\", nil)\n\tif len(c.factories) != 0 {\n\t\tt.Fatalf(\"nil factory should not be registered\")\n\t}\n}\n\n// ---- Deliver ----\n\nfunc TestDeliverCreatesTransport(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"air\", func() Transport { return &stubTransport{kind: \"air\"} })\n\tmsg, err := c.Deliver(\"air\", \"123\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif msg != \"air:123\" {\n\t\tt.Fatalf(\"unexpected delivery string: %s\", msg)\n\t}\n}\n\nfunc TestDeliverUnknownFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tif _, err := c.Deliver(\"missing\", \"1\"); err == nil {\n\t\tt.Fatalf(\"expected error for missing factory\")\n\t}\n}\n\nfunc TestDeliverUsesFreshTransportEachTime(t *testing.T) {\n\tcalls := atomic.Int64{}\n\tc := NewDeliveryCreator()\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"road\", called: &calls} })\n\tfor i := 0; i < 3; i++ {\n\t\tif _, err := c.Deliver(\"road\", \"pkg\"); err != nil {\n\t\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t\t}\n\t}\n\tif calls.Load() != 3 {\n\t\tt.Fatalf(\"transport should be created each time, got %d\", calls.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "factory_method",
          "patterns",
          "creational"
        ],
        "order": 0
      },
      {
        "package": "factory_method",
        "slug": "go-factory_method-register",
        "title": "Register",
        "description": "Task 2 (easy+): Register\nЗарегистрируйте factory по ключу, разрешая перезапись.\nПодсказка: используйте Lock/Unlock и игнорируйте nil factory.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Register.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// Transport определяет способ доставки.\ntype Transport interface {\n\tDeliver(packageID string) string\n\tKind() string\n}\n\n// TransportFactory создаёт конкретный транспорт.\ntype TransportFactory func() Transport\n\n// DeliveryCreator управляет регистрацией фабричных методов.\ntype DeliveryCreator struct {\n\tmu        sync.RWMutex\n\tfactories map[string]TransportFactory\n}\n\n// Task 1 (easy): NewDeliveryCreator\n// Создайте пустой реестр transport фабрик.\n// Подсказка: инициализируйте map и подготовьте RWMutex для конкурентного доступа.\nfunc NewDeliveryCreator() *DeliveryCreator {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Зарегистрируйте factory по ключу, разрешая перезапись.\n// Подсказка: используйте Lock/Unlock и игнорируйте nil factory.\nfunc (c *DeliveryCreator) Register(kind string, factory TransportFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Deliver\n// Создайте транспорт по ключу и выполните доставку.\n// Подсказка: верните ошибку, если factory не найден, и включите название транспорта в ответ.\nfunc (c *DeliveryCreator) Deliver(kind, packageID string) (string, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Transport interface { // Transport описывает доставку.\n\tDeliver(packageID string) string // Deliver возвращает результат доставки.\n\tKind() string                    // Kind сообщает тип транспорта.\n}\n\ntype TransportFactory func() Transport // TransportFactory создаёт транспорт.\n\ntype DeliveryCreator struct { // DeliveryCreator управляет фабриками.\n\tmu        sync.RWMutex                // mu защищает карту.\n\tfactories map[string]TransportFactory // factories хранит зарегистрированные фабрики.\n}\n\nfunc NewDeliveryCreator() *DeliveryCreator { // NewDeliveryCreator подготавливает реестр фабрик.\n\treturn &DeliveryCreator{ // Возвращаем структуру с инициализированной map.\n\t\tfactories: make(map[string]TransportFactory), // Готовое хранилище фабричных методов.\n\t}\n}\n\nfunc (c *DeliveryCreator) Register(kind string, factory TransportFactory) { // Register добавляет фабричный метод в реестр.\n\tif c == nil || factory == nil || kind == \"\" { // Проверяем корректность входных данных.\n\t\treturn // Не храним некорректные значения.\n\t}\n\tc.mu.Lock()             // Защищаем доступ к map на запись.\n\tdefer c.mu.Unlock()     // Освобождаем mutex по завершении.\n\tif c.factories == nil { // Лениво инициализируем map.\n\t\tc.factories = make(map[string]TransportFactory) // Создаём новое хранилище.\n\t}\n\tc.factories[kind] = factory // Сохраняем/перезаписываем фабрику по ключу.\n}\n\nfunc (c *DeliveryCreator) Deliver(kind, packageID string) (string, error) { // Deliver создаёт транспорт и выполняет доставку.\n\tif c == nil { // Nil-creator не поддерживается.\n\t\treturn \"\", fmt.Errorf(\"creator is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tc.mu.RLock()                 // Берём read-lock для поиска фабрики.\n\tfactory := c.factories[kind] // Ищем фабрику по типу транспорта.\n\tc.mu.RUnlock()               // Освобождаем read-lock.\n\tif factory == nil {          // Фабрика не найдена.\n\t\treturn \"\", fmt.Errorf(\"transport %s is not registered\", kind) // Возвращаем ошибку.\n\t}\n\ttransport := factory() // Создаём транспорт через фабричный метод.\n\tif transport == nil {  // Фабрика вернула nil.\n\t\treturn \"\", fmt.Errorf(\"transport %s factory returned nil\", kind) // Сообщаем об ошибке реализации.\n\t}\n\tresult := transport.Deliver(packageID) // Выполняем доставку.\n\treturn result, nil                     // Возвращаем строку результата.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\ntype stubTransport struct {\n\tkind   string\n\tcalled *atomic.Int64\n}\n\nfunc (t *stubTransport) Deliver(packageID string) string {\n\tif t.called != nil {\n\t\tt.called.Add(1)\n\t}\n\treturn t.kind + \":\" + packageID\n}\n\nfunc (t *stubTransport) Kind() string {\n\treturn t.kind\n}\n\n// ---- NewDeliveryCreator ----\n\nfunc TestNewDeliveryCreatorInitializesMap(t *testing.T) {\n\tcreator := NewDeliveryCreator()\n\tif creator == nil || creator.factories == nil {\n\t\tt.Fatalf(\"creator not initialized: %#v\", creator)\n\t}\n}\n\nfunc TestNewDeliveryCreatorIndependentInstances(t *testing.T) {\n\tc1 := NewDeliveryCreator()\n\tc2 := NewDeliveryCreator()\n\tc1.factories[\"x\"] = func() Transport { return &stubTransport{kind: \"x\"} }\n\tif len(c2.factories) != 0 {\n\t\tt.Fatalf(\"instances should not share map\")\n\t}\n}\n\nfunc TestNewDeliveryCreatorStartsEmpty(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tif len(c.factories) != 0 {\n\t\tt.Fatalf(\"expected empty registry\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestRegisterStoresFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"air\", func() Transport { return &stubTransport{kind: \"air\"} })\n\tif _, ok := c.factories[\"air\"]; !ok {\n\t\tt.Fatalf(\"factory not stored\")\n\t}\n}\n\nfunc TestRegisterOverridesExisting(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"road\"} })\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"new\"} })\n\tif transport, _ := c.Deliver(\"road\", \"pkg\"); !strings.HasPrefix(transport, \"new\") {\n\t\tt.Fatalf(\"factory should be overridden, got %s\", transport)\n\t}\n}\n\nfunc TestRegisterIgnoresNilFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"sea\", nil)\n\tif len(c.factories) != 0 {\n\t\tt.Fatalf(\"nil factory should not be registered\")\n\t}\n}\n\n// ---- Deliver ----\n\nfunc TestDeliverCreatesTransport(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"air\", func() Transport { return &stubTransport{kind: \"air\"} })\n\tmsg, err := c.Deliver(\"air\", \"123\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif msg != \"air:123\" {\n\t\tt.Fatalf(\"unexpected delivery string: %s\", msg)\n\t}\n}\n\nfunc TestDeliverUnknownFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tif _, err := c.Deliver(\"missing\", \"1\"); err == nil {\n\t\tt.Fatalf(\"expected error for missing factory\")\n\t}\n}\n\nfunc TestDeliverUsesFreshTransportEachTime(t *testing.T) {\n\tcalls := atomic.Int64{}\n\tc := NewDeliveryCreator()\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"road\", called: &calls} })\n\tfor i := 0; i < 3; i++ {\n\t\tif _, err := c.Deliver(\"road\", \"pkg\"); err != nil {\n\t\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t\t}\n\t}\n\tif calls.Load() != 3 {\n\t\tt.Fatalf(\"transport should be created each time, got %d\", calls.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "factory_method",
          "patterns",
          "creational"
        ],
        "order": 1
      },
      {
        "package": "factory_method",
        "slug": "go-factory_method-deliver",
        "title": "Deliver",
        "description": "Task 3 (medium): Deliver\nСоздайте транспорт по ключу и выполните доставку.\nПодсказка: верните ошибку, если factory не найден, и включите название транспорта в ответ.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Deliver.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// Transport определяет способ доставки.\ntype Transport interface {\n\tDeliver(packageID string) string\n\tKind() string\n}\n\n// TransportFactory создаёт конкретный транспорт.\ntype TransportFactory func() Transport\n\n// DeliveryCreator управляет регистрацией фабричных методов.\ntype DeliveryCreator struct {\n\tmu        sync.RWMutex\n\tfactories map[string]TransportFactory\n}\n\n// Task 1 (easy): NewDeliveryCreator\n// Создайте пустой реестр transport фабрик.\n// Подсказка: инициализируйте map и подготовьте RWMutex для конкурентного доступа.\nfunc NewDeliveryCreator() *DeliveryCreator {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Зарегистрируйте factory по ключу, разрешая перезапись.\n// Подсказка: используйте Lock/Unlock и игнорируйте nil factory.\nfunc (c *DeliveryCreator) Register(kind string, factory TransportFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Deliver\n// Создайте транспорт по ключу и выполните доставку.\n// Подсказка: верните ошибку, если factory не найден, и включите название транспорта в ответ.\nfunc (c *DeliveryCreator) Deliver(kind, packageID string) (string, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Transport interface { // Transport описывает доставку.\n\tDeliver(packageID string) string // Deliver возвращает результат доставки.\n\tKind() string                    // Kind сообщает тип транспорта.\n}\n\ntype TransportFactory func() Transport // TransportFactory создаёт транспорт.\n\ntype DeliveryCreator struct { // DeliveryCreator управляет фабриками.\n\tmu        sync.RWMutex                // mu защищает карту.\n\tfactories map[string]TransportFactory // factories хранит зарегистрированные фабрики.\n}\n\nfunc NewDeliveryCreator() *DeliveryCreator { // NewDeliveryCreator подготавливает реестр фабрик.\n\treturn &DeliveryCreator{ // Возвращаем структуру с инициализированной map.\n\t\tfactories: make(map[string]TransportFactory), // Готовое хранилище фабричных методов.\n\t}\n}\n\nfunc (c *DeliveryCreator) Register(kind string, factory TransportFactory) { // Register добавляет фабричный метод в реестр.\n\tif c == nil || factory == nil || kind == \"\" { // Проверяем корректность входных данных.\n\t\treturn // Не храним некорректные значения.\n\t}\n\tc.mu.Lock()             // Защищаем доступ к map на запись.\n\tdefer c.mu.Unlock()     // Освобождаем mutex по завершении.\n\tif c.factories == nil { // Лениво инициализируем map.\n\t\tc.factories = make(map[string]TransportFactory) // Создаём новое хранилище.\n\t}\n\tc.factories[kind] = factory // Сохраняем/перезаписываем фабрику по ключу.\n}\n\nfunc (c *DeliveryCreator) Deliver(kind, packageID string) (string, error) { // Deliver создаёт транспорт и выполняет доставку.\n\tif c == nil { // Nil-creator не поддерживается.\n\t\treturn \"\", fmt.Errorf(\"creator is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tc.mu.RLock()                 // Берём read-lock для поиска фабрики.\n\tfactory := c.factories[kind] // Ищем фабрику по типу транспорта.\n\tc.mu.RUnlock()               // Освобождаем read-lock.\n\tif factory == nil {          // Фабрика не найдена.\n\t\treturn \"\", fmt.Errorf(\"transport %s is not registered\", kind) // Возвращаем ошибку.\n\t}\n\ttransport := factory() // Создаём транспорт через фабричный метод.\n\tif transport == nil {  // Фабрика вернула nil.\n\t\treturn \"\", fmt.Errorf(\"transport %s factory returned nil\", kind) // Сообщаем об ошибке реализации.\n\t}\n\tresult := transport.Deliver(packageID) // Выполняем доставку.\n\treturn result, nil                     // Возвращаем строку результата.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\ntype stubTransport struct {\n\tkind   string\n\tcalled *atomic.Int64\n}\n\nfunc (t *stubTransport) Deliver(packageID string) string {\n\tif t.called != nil {\n\t\tt.called.Add(1)\n\t}\n\treturn t.kind + \":\" + packageID\n}\n\nfunc (t *stubTransport) Kind() string {\n\treturn t.kind\n}\n\n// ---- NewDeliveryCreator ----\n\nfunc TestNewDeliveryCreatorInitializesMap(t *testing.T) {\n\tcreator := NewDeliveryCreator()\n\tif creator == nil || creator.factories == nil {\n\t\tt.Fatalf(\"creator not initialized: %#v\", creator)\n\t}\n}\n\nfunc TestNewDeliveryCreatorIndependentInstances(t *testing.T) {\n\tc1 := NewDeliveryCreator()\n\tc2 := NewDeliveryCreator()\n\tc1.factories[\"x\"] = func() Transport { return &stubTransport{kind: \"x\"} }\n\tif len(c2.factories) != 0 {\n\t\tt.Fatalf(\"instances should not share map\")\n\t}\n}\n\nfunc TestNewDeliveryCreatorStartsEmpty(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tif len(c.factories) != 0 {\n\t\tt.Fatalf(\"expected empty registry\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestRegisterStoresFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"air\", func() Transport { return &stubTransport{kind: \"air\"} })\n\tif _, ok := c.factories[\"air\"]; !ok {\n\t\tt.Fatalf(\"factory not stored\")\n\t}\n}\n\nfunc TestRegisterOverridesExisting(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"road\"} })\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"new\"} })\n\tif transport, _ := c.Deliver(\"road\", \"pkg\"); !strings.HasPrefix(transport, \"new\") {\n\t\tt.Fatalf(\"factory should be overridden, got %s\", transport)\n\t}\n}\n\nfunc TestRegisterIgnoresNilFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"sea\", nil)\n\tif len(c.factories) != 0 {\n\t\tt.Fatalf(\"nil factory should not be registered\")\n\t}\n}\n\n// ---- Deliver ----\n\nfunc TestDeliverCreatesTransport(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tc.Register(\"air\", func() Transport { return &stubTransport{kind: \"air\"} })\n\tmsg, err := c.Deliver(\"air\", \"123\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif msg != \"air:123\" {\n\t\tt.Fatalf(\"unexpected delivery string: %s\", msg)\n\t}\n}\n\nfunc TestDeliverUnknownFactory(t *testing.T) {\n\tc := NewDeliveryCreator()\n\tif _, err := c.Deliver(\"missing\", \"1\"); err == nil {\n\t\tt.Fatalf(\"expected error for missing factory\")\n\t}\n}\n\nfunc TestDeliverUsesFreshTransportEachTime(t *testing.T) {\n\tcalls := atomic.Int64{}\n\tc := NewDeliveryCreator()\n\tc.Register(\"road\", func() Transport { return &stubTransport{kind: \"road\", called: &calls} })\n\tfor i := 0; i < 3; i++ {\n\t\tif _, err := c.Deliver(\"road\", \"pkg\"); err != nil {\n\t\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t\t}\n\t}\n\tif calls.Load() != 3 {\n\t\tt.Fatalf(\"transport should be created each time, got %d\", calls.Load())\n\t}\n}\n",
        "tags": [
          "go",
          "factory_method",
          "patterns",
          "creational"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-prototype",
    "tasks": [
      {
        "package": "prototype",
        "slug": "go-prototype-clone",
        "title": "Clone",
        "description": "Task 1 (easy): Clone\nРеализуйте глубокое копирование DataPrototype.\nПодсказка: создайте новую map и скопируйте все пары ключ-значение.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Clone.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// Prototype описывает объект, который можно клонировать.\ntype Prototype interface {\n\tClone() Prototype\n\tLabel() string\n\tSet(key, value string)\n\tValue(key string) string\n}\n\n// DataPrototype реализует Prototype для хранения map значений.\ntype DataPrototype struct {\n\tname string\n\tdata map[string]string\n}\n\n// PrototypeRegistry хранит доступные прототипы.\ntype PrototypeRegistry struct {\n\tmu         sync.RWMutex\n\tprototypes map[string]Prototype\n}\n\n// ErrPrototypeNotFound сигнализирует об отсутствии записи.\nvar ErrPrototypeNotFound = errors.New(\"prototype not found\")\n\n// Task 1 (easy): Clone\n// Реализуйте глубокое копирование DataPrototype.\n// Подсказка: создайте новую map и скопируйте все пары ключ-значение.\nfunc (p *DataPrototype) Clone() Prototype {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Добавьте прототип в реестр по ключу.\n// Подсказка: используйте Lock/Unlock и инициализируйте map при первом вызове.\nfunc (r *PrototypeRegistry) Register(name string, proto Prototype) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CloneFromRegistry\n// Найдите прототип и верните его клон.\n// Подсказка: используйте RLock для чтения и возвращайте ErrPrototypeNotFound, если ключ отсутствует.\nfunc (r *PrototypeRegistry) CloneFromRegistry(name string) (Prototype, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Prototype interface { // Prototype описывает объект, который можно клонировать.\n\tClone() Prototype        // Clone возвращает копию объекта.\n\tLabel() string           // Label сообщает имя прототипа.\n\tSet(key, value string)   // Set меняет значение.\n\tValue(key string) string // Value возвращает значение.\n}\n\ntype DataPrototype struct { // DataPrototype хранит данные в map.\n\tname string            // name — человекочитаемое имя.\n\tdata map[string]string // data — хранилище значений.\n}\n\ntype PrototypeRegistry struct { // PrototypeRegistry управляет прототипами.\n\tmu         sync.RWMutex         // mu защищает доступ к map.\n\tprototypes map[string]Prototype // prototypes хранит зарегистрированные объекты.\n}\n\nvar ErrPrototypeNotFound = errors.New(\"prototype not found\") // ErrPrototypeNotFound сигнализирует об отсутствии записи.\n\nfunc (p *DataPrototype) Clone() Prototype { // Clone создаёт глубокую копию DataPrototype.\n\tif p == nil { // Nil-прототип возвращает nil-значение.\n\t\treturn &DataPrototype{} // Возвращаем пустую структуру, чтобы избежать паники.\n\t}\n\tcopyData := make(map[string]string, len(p.data)) // Готовим новую map для значений.\n\tfor k, v := range p.data {                       // Копируем все пары ключ-значение.\n\t\tcopyData[k] = v // Переносим значение.\n\t}\n\treturn &DataPrototype{ // Формируем новый экземпляр.\n\t\tname: p.name,   // Имя клонируется побайтно.\n\t\tdata: copyData, // Используем глубокую копию данных.\n\t}\n}\n\nfunc (p *DataPrototype) Label() string { // Label возвращает название прототипа.\n\tif p == nil { // Nil-прототип не имеет имени.\n\t\treturn \"\" // Возвращаем пустую строку.\n\t}\n\treturn p.name // Возвращаем сохранённое имя.\n}\n\nfunc (p *DataPrototype) Set(key, value string) { // Set изменяет значение в прототипе.\n\tif p == nil { // Nil-прототип игнорируем.\n\t\treturn // Нечего менять.\n\t}\n\tif p.data == nil { // Инициализируем map при необходимости.\n\t\tp.data = make(map[string]string) // Создаём хранилище значений.\n\t}\n\tp.data[key] = value // Сохраняем пару ключ/значение.\n}\n\nfunc (p *DataPrototype) Value(key string) string { // Value возвращает значение по ключу.\n\tif p == nil || p.data == nil { // Нет данных для чтения.\n\t\treturn \"\" // Возвращаем пустую строку.\n\t}\n\treturn p.data[key] // Возвращаем значение (пустая строка, если нет ключа).\n}\n\nfunc (r *PrototypeRegistry) Register(name string, proto Prototype) { // Register добавляет прототип в реестр.\n\tif r == nil || proto == nil || name == \"\" { // Проверяем входные параметры.\n\t\treturn // Нечего регистрировать.\n\t}\n\tr.mu.Lock()              // Захватываем mutex для записи.\n\tdefer r.mu.Unlock()      // Освобождаем его после завершения.\n\tif r.prototypes == nil { // Инициализируем map, если нужно.\n\t\tr.prototypes = make(map[string]Prototype) // Создаём хранилище прототипов.\n\t}\n\tr.prototypes[name] = proto // Сохраняем прототип по имени.\n}\n\nfunc (r *PrototypeRegistry) CloneFromRegistry(name string) (Prototype, error) { // CloneFromRegistry возвращает клон по ключу.\n\tif r == nil { // Nil-реестр не поддерживается.\n\t\treturn nil, fmt.Errorf(\"registry is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tr.mu.RLock()                    // Берём read-lock для доступа к map.\n\tproto, ok := r.prototypes[name] // Ищем прототип по имени.\n\tr.mu.RUnlock()                  // Освобождаем read-lock.\n\tif !ok || proto == nil {        // Прототип не найден.\n\t\treturn nil, ErrPrototypeNotFound // Возвращаем заранее определённую ошибку.\n\t}\n\treturn proto.Clone(), nil // Возвращаем клон найденного прототипа.\n}\n",
        "testCode": "package creational\n\nimport \"testing\"\n\n// ---- DataPrototype.Clone ----\n\nfunc TestDataPrototypeCloneCopiesData(t *testing.T) {\n\tp := &DataPrototype{\n\t\tname: \"invoice\",\n\t\tdata: map[string]string{\"currency\": \"USD\", \"customer\": \"ACME\"},\n\t}\n\tclone := p.Clone()\n\tcp := clone.(*DataPrototype)\n\tcp.data[\"currency\"] = \"EUR\"\n\tif p.data[\"currency\"] != \"USD\" {\n\t\tt.Fatalf(\"original prototype should remain unchanged\")\n\t}\n}\n\nfunc TestDataPrototypeCloneReturnsNewInstance(t *testing.T) {\n\tp := &DataPrototype{name: \"invoice\", data: map[string]string{}}\n\tif p.Clone() == p {\n\t\tt.Fatalf(\"clone should return new instance\")\n\t}\n}\n\nfunc TestDataPrototypeCloneNilSafe(t *testing.T) {\n\tvar p *DataPrototype\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"Clone must be nil-safe: %v\", r)\n\t\t}\n\t}()\n\t_ = p.Clone()\n}\n\n// ---- PrototypeRegistry.Register ----\n\nfunc TestPrototypeRegistryRegisterStoresPrototype(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tproto := &DataPrototype{name: \"invoice\"}\n\treg.Register(\"invoice\", proto)\n\treg.mu.RLock()\n\tdefer reg.mu.RUnlock()\n\tif reg.prototypes[\"invoice\"] != proto {\n\t\tt.Fatalf(\"prototype not stored\")\n\t}\n}\n\nfunc TestPrototypeRegistryRegisterOverrides(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tfirst := &DataPrototype{name: \"v1\"}\n\tsecond := &DataPrototype{name: \"v2\"}\n\treg.Register(\"doc\", first)\n\treg.Register(\"doc\", second)\n\treg.mu.RLock()\n\tgot := reg.prototypes[\"doc\"]\n\treg.mu.RUnlock()\n\tif got != second {\n\t\tt.Fatalf(\"expected second prototype, got %#v\", got)\n\t}\n}\n\nfunc TestPrototypeRegistryRegisterNilPrototype(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\treg.Register(\"doc\", nil)\n\treg.mu.RLock()\n\t_, ok := reg.prototypes[\"doc\"]\n\treg.mu.RUnlock()\n\tif ok {\n\t\tt.Fatalf(\"nil prototype should not be registered\")\n\t}\n}\n\n// ---- CloneFromRegistry ----\n\nfunc TestCloneFromRegistryReturnsClone(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tproto := &DataPrototype{name: \"invoice\", data: map[string]string{\"k\": \"v\"}}\n\treg.Register(\"invoice\", proto)\n\tclone, err := reg.CloneFromRegistry(\"invoice\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif clone == proto {\n\t\tt.Fatalf(\"registry should return clone, not reference\")\n\t}\n}\n\nfunc TestCloneFromRegistryUnknown(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tif _, err := reg.CloneFromRegistry(\"missing\"); err != ErrPrototypeNotFound {\n\t\tt.Fatalf(\"expected ErrPrototypeNotFound, got %v\", err)\n\t}\n}\n\nfunc TestCloneFromRegistryNilRegistry(t *testing.T) {\n\tvar reg *PrototypeRegistry\n\tif _, err := reg.CloneFromRegistry(\"doc\"); err == nil {\n\t\tt.Fatalf(\"expected error for nil registry\")\n\t}\n}\n",
        "tags": [
          "go",
          "prototype",
          "patterns",
          "creational"
        ],
        "order": 0
      },
      {
        "package": "prototype",
        "slug": "go-prototype-register",
        "title": "Register",
        "description": "Task 2 (easy+): Register\nДобавьте прототип в реестр по ключу.\nПодсказка: используйте Lock/Unlock и инициализируйте map при первом вызове.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Register.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// Prototype описывает объект, который можно клонировать.\ntype Prototype interface {\n\tClone() Prototype\n\tLabel() string\n\tSet(key, value string)\n\tValue(key string) string\n}\n\n// DataPrototype реализует Prototype для хранения map значений.\ntype DataPrototype struct {\n\tname string\n\tdata map[string]string\n}\n\n// PrototypeRegistry хранит доступные прототипы.\ntype PrototypeRegistry struct {\n\tmu         sync.RWMutex\n\tprototypes map[string]Prototype\n}\n\n// ErrPrototypeNotFound сигнализирует об отсутствии записи.\nvar ErrPrototypeNotFound = errors.New(\"prototype not found\")\n\n// Task 1 (easy): Clone\n// Реализуйте глубокое копирование DataPrototype.\n// Подсказка: создайте новую map и скопируйте все пары ключ-значение.\nfunc (p *DataPrototype) Clone() Prototype {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Добавьте прототип в реестр по ключу.\n// Подсказка: используйте Lock/Unlock и инициализируйте map при первом вызове.\nfunc (r *PrototypeRegistry) Register(name string, proto Prototype) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CloneFromRegistry\n// Найдите прототип и верните его клон.\n// Подсказка: используйте RLock для чтения и возвращайте ErrPrototypeNotFound, если ключ отсутствует.\nfunc (r *PrototypeRegistry) CloneFromRegistry(name string) (Prototype, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Prototype interface { // Prototype описывает объект, который можно клонировать.\n\tClone() Prototype        // Clone возвращает копию объекта.\n\tLabel() string           // Label сообщает имя прототипа.\n\tSet(key, value string)   // Set меняет значение.\n\tValue(key string) string // Value возвращает значение.\n}\n\ntype DataPrototype struct { // DataPrototype хранит данные в map.\n\tname string            // name — человекочитаемое имя.\n\tdata map[string]string // data — хранилище значений.\n}\n\ntype PrototypeRegistry struct { // PrototypeRegistry управляет прототипами.\n\tmu         sync.RWMutex         // mu защищает доступ к map.\n\tprototypes map[string]Prototype // prototypes хранит зарегистрированные объекты.\n}\n\nvar ErrPrototypeNotFound = errors.New(\"prototype not found\") // ErrPrototypeNotFound сигнализирует об отсутствии записи.\n\nfunc (p *DataPrototype) Clone() Prototype { // Clone создаёт глубокую копию DataPrototype.\n\tif p == nil { // Nil-прототип возвращает nil-значение.\n\t\treturn &DataPrototype{} // Возвращаем пустую структуру, чтобы избежать паники.\n\t}\n\tcopyData := make(map[string]string, len(p.data)) // Готовим новую map для значений.\n\tfor k, v := range p.data {                       // Копируем все пары ключ-значение.\n\t\tcopyData[k] = v // Переносим значение.\n\t}\n\treturn &DataPrototype{ // Формируем новый экземпляр.\n\t\tname: p.name,   // Имя клонируется побайтно.\n\t\tdata: copyData, // Используем глубокую копию данных.\n\t}\n}\n\nfunc (p *DataPrototype) Label() string { // Label возвращает название прототипа.\n\tif p == nil { // Nil-прототип не имеет имени.\n\t\treturn \"\" // Возвращаем пустую строку.\n\t}\n\treturn p.name // Возвращаем сохранённое имя.\n}\n\nfunc (p *DataPrototype) Set(key, value string) { // Set изменяет значение в прототипе.\n\tif p == nil { // Nil-прототип игнорируем.\n\t\treturn // Нечего менять.\n\t}\n\tif p.data == nil { // Инициализируем map при необходимости.\n\t\tp.data = make(map[string]string) // Создаём хранилище значений.\n\t}\n\tp.data[key] = value // Сохраняем пару ключ/значение.\n}\n\nfunc (p *DataPrototype) Value(key string) string { // Value возвращает значение по ключу.\n\tif p == nil || p.data == nil { // Нет данных для чтения.\n\t\treturn \"\" // Возвращаем пустую строку.\n\t}\n\treturn p.data[key] // Возвращаем значение (пустая строка, если нет ключа).\n}\n\nfunc (r *PrototypeRegistry) Register(name string, proto Prototype) { // Register добавляет прототип в реестр.\n\tif r == nil || proto == nil || name == \"\" { // Проверяем входные параметры.\n\t\treturn // Нечего регистрировать.\n\t}\n\tr.mu.Lock()              // Захватываем mutex для записи.\n\tdefer r.mu.Unlock()      // Освобождаем его после завершения.\n\tif r.prototypes == nil { // Инициализируем map, если нужно.\n\t\tr.prototypes = make(map[string]Prototype) // Создаём хранилище прототипов.\n\t}\n\tr.prototypes[name] = proto // Сохраняем прототип по имени.\n}\n\nfunc (r *PrototypeRegistry) CloneFromRegistry(name string) (Prototype, error) { // CloneFromRegistry возвращает клон по ключу.\n\tif r == nil { // Nil-реестр не поддерживается.\n\t\treturn nil, fmt.Errorf(\"registry is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tr.mu.RLock()                    // Берём read-lock для доступа к map.\n\tproto, ok := r.prototypes[name] // Ищем прототип по имени.\n\tr.mu.RUnlock()                  // Освобождаем read-lock.\n\tif !ok || proto == nil {        // Прототип не найден.\n\t\treturn nil, ErrPrototypeNotFound // Возвращаем заранее определённую ошибку.\n\t}\n\treturn proto.Clone(), nil // Возвращаем клон найденного прототипа.\n}\n",
        "testCode": "package creational\n\nimport \"testing\"\n\n// ---- DataPrototype.Clone ----\n\nfunc TestDataPrototypeCloneCopiesData(t *testing.T) {\n\tp := &DataPrototype{\n\t\tname: \"invoice\",\n\t\tdata: map[string]string{\"currency\": \"USD\", \"customer\": \"ACME\"},\n\t}\n\tclone := p.Clone()\n\tcp := clone.(*DataPrototype)\n\tcp.data[\"currency\"] = \"EUR\"\n\tif p.data[\"currency\"] != \"USD\" {\n\t\tt.Fatalf(\"original prototype should remain unchanged\")\n\t}\n}\n\nfunc TestDataPrototypeCloneReturnsNewInstance(t *testing.T) {\n\tp := &DataPrototype{name: \"invoice\", data: map[string]string{}}\n\tif p.Clone() == p {\n\t\tt.Fatalf(\"clone should return new instance\")\n\t}\n}\n\nfunc TestDataPrototypeCloneNilSafe(t *testing.T) {\n\tvar p *DataPrototype\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"Clone must be nil-safe: %v\", r)\n\t\t}\n\t}()\n\t_ = p.Clone()\n}\n\n// ---- PrototypeRegistry.Register ----\n\nfunc TestPrototypeRegistryRegisterStoresPrototype(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tproto := &DataPrototype{name: \"invoice\"}\n\treg.Register(\"invoice\", proto)\n\treg.mu.RLock()\n\tdefer reg.mu.RUnlock()\n\tif reg.prototypes[\"invoice\"] != proto {\n\t\tt.Fatalf(\"prototype not stored\")\n\t}\n}\n\nfunc TestPrototypeRegistryRegisterOverrides(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tfirst := &DataPrototype{name: \"v1\"}\n\tsecond := &DataPrototype{name: \"v2\"}\n\treg.Register(\"doc\", first)\n\treg.Register(\"doc\", second)\n\treg.mu.RLock()\n\tgot := reg.prototypes[\"doc\"]\n\treg.mu.RUnlock()\n\tif got != second {\n\t\tt.Fatalf(\"expected second prototype, got %#v\", got)\n\t}\n}\n\nfunc TestPrototypeRegistryRegisterNilPrototype(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\treg.Register(\"doc\", nil)\n\treg.mu.RLock()\n\t_, ok := reg.prototypes[\"doc\"]\n\treg.mu.RUnlock()\n\tif ok {\n\t\tt.Fatalf(\"nil prototype should not be registered\")\n\t}\n}\n\n// ---- CloneFromRegistry ----\n\nfunc TestCloneFromRegistryReturnsClone(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tproto := &DataPrototype{name: \"invoice\", data: map[string]string{\"k\": \"v\"}}\n\treg.Register(\"invoice\", proto)\n\tclone, err := reg.CloneFromRegistry(\"invoice\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif clone == proto {\n\t\tt.Fatalf(\"registry should return clone, not reference\")\n\t}\n}\n\nfunc TestCloneFromRegistryUnknown(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tif _, err := reg.CloneFromRegistry(\"missing\"); err != ErrPrototypeNotFound {\n\t\tt.Fatalf(\"expected ErrPrototypeNotFound, got %v\", err)\n\t}\n}\n\nfunc TestCloneFromRegistryNilRegistry(t *testing.T) {\n\tvar reg *PrototypeRegistry\n\tif _, err := reg.CloneFromRegistry(\"doc\"); err == nil {\n\t\tt.Fatalf(\"expected error for nil registry\")\n\t}\n}\n",
        "tags": [
          "go",
          "prototype",
          "patterns",
          "creational"
        ],
        "order": 1
      },
      {
        "package": "prototype",
        "slug": "go-prototype-clonefromregistry",
        "title": "CloneFromRegistry",
        "description": "Task 3 (medium): CloneFromRegistry\nНайдите прототип и верните его клон.\nПодсказка: используйте RLock для чтения и возвращайте ErrPrototypeNotFound, если ключ отсутствует.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of CloneFromRegistry.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// Prototype описывает объект, который можно клонировать.\ntype Prototype interface {\n\tClone() Prototype\n\tLabel() string\n\tSet(key, value string)\n\tValue(key string) string\n}\n\n// DataPrototype реализует Prototype для хранения map значений.\ntype DataPrototype struct {\n\tname string\n\tdata map[string]string\n}\n\n// PrototypeRegistry хранит доступные прототипы.\ntype PrototypeRegistry struct {\n\tmu         sync.RWMutex\n\tprototypes map[string]Prototype\n}\n\n// ErrPrototypeNotFound сигнализирует об отсутствии записи.\nvar ErrPrototypeNotFound = errors.New(\"prototype not found\")\n\n// Task 1 (easy): Clone\n// Реализуйте глубокое копирование DataPrototype.\n// Подсказка: создайте новую map и скопируйте все пары ключ-значение.\nfunc (p *DataPrototype) Clone() Prototype {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Добавьте прототип в реестр по ключу.\n// Подсказка: используйте Lock/Unlock и инициализируйте map при первом вызове.\nfunc (r *PrototypeRegistry) Register(name string, proto Prototype) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CloneFromRegistry\n// Найдите прототип и верните его клон.\n// Подсказка: используйте RLock для чтения и возвращайте ErrPrototypeNotFound, если ключ отсутствует.\nfunc (r *PrototypeRegistry) CloneFromRegistry(name string) (Prototype, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Prototype interface { // Prototype описывает объект, который можно клонировать.\n\tClone() Prototype        // Clone возвращает копию объекта.\n\tLabel() string           // Label сообщает имя прототипа.\n\tSet(key, value string)   // Set меняет значение.\n\tValue(key string) string // Value возвращает значение.\n}\n\ntype DataPrototype struct { // DataPrototype хранит данные в map.\n\tname string            // name — человекочитаемое имя.\n\tdata map[string]string // data — хранилище значений.\n}\n\ntype PrototypeRegistry struct { // PrototypeRegistry управляет прототипами.\n\tmu         sync.RWMutex         // mu защищает доступ к map.\n\tprototypes map[string]Prototype // prototypes хранит зарегистрированные объекты.\n}\n\nvar ErrPrototypeNotFound = errors.New(\"prototype not found\") // ErrPrototypeNotFound сигнализирует об отсутствии записи.\n\nfunc (p *DataPrototype) Clone() Prototype { // Clone создаёт глубокую копию DataPrototype.\n\tif p == nil { // Nil-прототип возвращает nil-значение.\n\t\treturn &DataPrototype{} // Возвращаем пустую структуру, чтобы избежать паники.\n\t}\n\tcopyData := make(map[string]string, len(p.data)) // Готовим новую map для значений.\n\tfor k, v := range p.data {                       // Копируем все пары ключ-значение.\n\t\tcopyData[k] = v // Переносим значение.\n\t}\n\treturn &DataPrototype{ // Формируем новый экземпляр.\n\t\tname: p.name,   // Имя клонируется побайтно.\n\t\tdata: copyData, // Используем глубокую копию данных.\n\t}\n}\n\nfunc (p *DataPrototype) Label() string { // Label возвращает название прототипа.\n\tif p == nil { // Nil-прототип не имеет имени.\n\t\treturn \"\" // Возвращаем пустую строку.\n\t}\n\treturn p.name // Возвращаем сохранённое имя.\n}\n\nfunc (p *DataPrototype) Set(key, value string) { // Set изменяет значение в прототипе.\n\tif p == nil { // Nil-прототип игнорируем.\n\t\treturn // Нечего менять.\n\t}\n\tif p.data == nil { // Инициализируем map при необходимости.\n\t\tp.data = make(map[string]string) // Создаём хранилище значений.\n\t}\n\tp.data[key] = value // Сохраняем пару ключ/значение.\n}\n\nfunc (p *DataPrototype) Value(key string) string { // Value возвращает значение по ключу.\n\tif p == nil || p.data == nil { // Нет данных для чтения.\n\t\treturn \"\" // Возвращаем пустую строку.\n\t}\n\treturn p.data[key] // Возвращаем значение (пустая строка, если нет ключа).\n}\n\nfunc (r *PrototypeRegistry) Register(name string, proto Prototype) { // Register добавляет прототип в реестр.\n\tif r == nil || proto == nil || name == \"\" { // Проверяем входные параметры.\n\t\treturn // Нечего регистрировать.\n\t}\n\tr.mu.Lock()              // Захватываем mutex для записи.\n\tdefer r.mu.Unlock()      // Освобождаем его после завершения.\n\tif r.prototypes == nil { // Инициализируем map, если нужно.\n\t\tr.prototypes = make(map[string]Prototype) // Создаём хранилище прототипов.\n\t}\n\tr.prototypes[name] = proto // Сохраняем прототип по имени.\n}\n\nfunc (r *PrototypeRegistry) CloneFromRegistry(name string) (Prototype, error) { // CloneFromRegistry возвращает клон по ключу.\n\tif r == nil { // Nil-реестр не поддерживается.\n\t\treturn nil, fmt.Errorf(\"registry is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tr.mu.RLock()                    // Берём read-lock для доступа к map.\n\tproto, ok := r.prototypes[name] // Ищем прототип по имени.\n\tr.mu.RUnlock()                  // Освобождаем read-lock.\n\tif !ok || proto == nil {        // Прототип не найден.\n\t\treturn nil, ErrPrototypeNotFound // Возвращаем заранее определённую ошибку.\n\t}\n\treturn proto.Clone(), nil // Возвращаем клон найденного прототипа.\n}\n",
        "testCode": "package creational\n\nimport \"testing\"\n\n// ---- DataPrototype.Clone ----\n\nfunc TestDataPrototypeCloneCopiesData(t *testing.T) {\n\tp := &DataPrototype{\n\t\tname: \"invoice\",\n\t\tdata: map[string]string{\"currency\": \"USD\", \"customer\": \"ACME\"},\n\t}\n\tclone := p.Clone()\n\tcp := clone.(*DataPrototype)\n\tcp.data[\"currency\"] = \"EUR\"\n\tif p.data[\"currency\"] != \"USD\" {\n\t\tt.Fatalf(\"original prototype should remain unchanged\")\n\t}\n}\n\nfunc TestDataPrototypeCloneReturnsNewInstance(t *testing.T) {\n\tp := &DataPrototype{name: \"invoice\", data: map[string]string{}}\n\tif p.Clone() == p {\n\t\tt.Fatalf(\"clone should return new instance\")\n\t}\n}\n\nfunc TestDataPrototypeCloneNilSafe(t *testing.T) {\n\tvar p *DataPrototype\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"Clone must be nil-safe: %v\", r)\n\t\t}\n\t}()\n\t_ = p.Clone()\n}\n\n// ---- PrototypeRegistry.Register ----\n\nfunc TestPrototypeRegistryRegisterStoresPrototype(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tproto := &DataPrototype{name: \"invoice\"}\n\treg.Register(\"invoice\", proto)\n\treg.mu.RLock()\n\tdefer reg.mu.RUnlock()\n\tif reg.prototypes[\"invoice\"] != proto {\n\t\tt.Fatalf(\"prototype not stored\")\n\t}\n}\n\nfunc TestPrototypeRegistryRegisterOverrides(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tfirst := &DataPrototype{name: \"v1\"}\n\tsecond := &DataPrototype{name: \"v2\"}\n\treg.Register(\"doc\", first)\n\treg.Register(\"doc\", second)\n\treg.mu.RLock()\n\tgot := reg.prototypes[\"doc\"]\n\treg.mu.RUnlock()\n\tif got != second {\n\t\tt.Fatalf(\"expected second prototype, got %#v\", got)\n\t}\n}\n\nfunc TestPrototypeRegistryRegisterNilPrototype(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\treg.Register(\"doc\", nil)\n\treg.mu.RLock()\n\t_, ok := reg.prototypes[\"doc\"]\n\treg.mu.RUnlock()\n\tif ok {\n\t\tt.Fatalf(\"nil prototype should not be registered\")\n\t}\n}\n\n// ---- CloneFromRegistry ----\n\nfunc TestCloneFromRegistryReturnsClone(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tproto := &DataPrototype{name: \"invoice\", data: map[string]string{\"k\": \"v\"}}\n\treg.Register(\"invoice\", proto)\n\tclone, err := reg.CloneFromRegistry(\"invoice\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif clone == proto {\n\t\tt.Fatalf(\"registry should return clone, not reference\")\n\t}\n}\n\nfunc TestCloneFromRegistryUnknown(t *testing.T) {\n\treg := &PrototypeRegistry{}\n\tif _, err := reg.CloneFromRegistry(\"missing\"); err != ErrPrototypeNotFound {\n\t\tt.Fatalf(\"expected ErrPrototypeNotFound, got %v\", err)\n\t}\n}\n\nfunc TestCloneFromRegistryNilRegistry(t *testing.T) {\n\tvar reg *PrototypeRegistry\n\tif _, err := reg.CloneFromRegistry(\"doc\"); err == nil {\n\t\tt.Fatalf(\"expected error for nil registry\")\n\t}\n}\n",
        "tags": [
          "go",
          "prototype",
          "patterns",
          "creational"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-singleton",
    "tasks": [
      {
        "package": "singleton",
        "slug": "go-singleton-globalconfig",
        "title": "GlobalConfig",
        "description": "Task 1 (easy): GlobalConfig\nВерните singleton ConfigSingleton с ленивой инициализацией.\nПодсказка: используйте sync.Once и инициализируйте карту значений.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of GlobalConfig.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// ConfigSingleton предоставляет потокобезопасный доступ к настройкам.\ntype ConfigSingleton struct {\n\tmu     sync.RWMutex\n\tvalues map[string]string\n}\n\nvar (\n\tconfigOnce     sync.Once\n\tconfigInstance *ConfigSingleton\n)\n\n// Task 1 (easy): GlobalConfig\n// Верните singleton ConfigSingleton с ленивой инициализацией.\n// Подсказка: используйте sync.Once и инициализируйте карту значений.\nfunc GlobalConfig() *ConfigSingleton {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Set\n// Сохраните пару ключ/значение в singleton.\n// Подсказка: защитите запись mutex'ом и инициализируйте карту при необходимости.\nfunc (c *ConfigSingleton) Set(key, value string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Get\n// Прочитайте значение по ключу.\n// Подсказка: используйте RLock и возвращайте второй bool как признак наличия.\nfunc (c *ConfigSingleton) Get(key string) (string, bool) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport \"sync\"\n\ntype ConfigSingleton struct { // ConfigSingleton хранит настройки.\n\tmu     sync.RWMutex      // mu защищает карту значений.\n\tvalues map[string]string // values содержит пары ключ/значение.\n}\n\nvar (\n\tconfigOnce     sync.Once        // configOnce гарантирует единичную инициализацию.\n\tconfigInstance *ConfigSingleton // configInstance хранит singleton.\n)\n\nfunc GlobalConfig() *ConfigSingleton { // GlobalConfig возвращает singleton конфигурации.\n\tconfigOnce.Do(func() { // Гарантируем однократную инициализацию.\n\t\tconfigInstance = &ConfigSingleton{ // Создаём экземпляр конфигурации.\n\t\t\tvalues: make(map[string]string), // Инициализируем карту значений.\n\t\t}\n\t})\n\treturn configInstance // Возвращаем готовый singleton.\n}\n\nfunc (c *ConfigSingleton) Set(key, value string) { // Set записывает значение в конфигурацию.\n\tif c == nil { // Nil-получатель игнорируем.\n\t\treturn // Нечего записывать.\n\t}\n\tc.mu.Lock()          // Защищаем запись mutex'ом.\n\tdefer c.mu.Unlock()  // Освобождаем mutex по завершении.\n\tif c.values == nil { // Лениво инициализируем карту при необходимости.\n\t\tc.values = make(map[string]string) // Создаём map для значений.\n\t}\n\tc.values[key] = value // Записываем пару ключ/значение.\n}\n\nfunc (c *ConfigSingleton) Get(key string) (string, bool) { // Get возвращает значение по ключу.\n\tif c == nil { // Nil-получатель не содержит значений.\n\t\treturn \"\", false // Сообщаем об отсутствии данных.\n\t}\n\tc.mu.RLock()         // Используем read-lock для безопасного чтения.\n\tdefer c.mu.RUnlock() // Освобождаем его после чтения.\n\tif c.values == nil { // Карта ещё не инициализирована.\n\t\treturn \"\", false // Значения отсутствуют.\n\t}\n\tval, ok := c.values[key] // Читаем значение из карты.\n\treturn val, ok           // Возвращаем найденное значение и флаг наличия.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc resetConfigSingletonUnsafe() {\n\tconfigInstance = nil\n\tconfigOnce = sync.Once{}\n}\n\n// ---- GlobalConfig ----\n\nfunc TestGlobalConfigReturnsSameInstance(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg1 := GlobalConfig()\n\tcfg2 := GlobalConfig()\n\tif cfg1 == nil || cfg2 == nil {\n\t\tt.Fatalf(\"GlobalConfig must not return nil\")\n\t}\n\tif cfg1 != cfg2 {\n\t\tt.Fatalf(\"GlobalConfig should return singleton instances\")\n\t}\n}\n\nfunc TestGlobalConfigInitializesMap(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tif cfg.values == nil {\n\t\tt.Fatalf(\"values map must be initialized\")\n\t}\n}\n\nfunc TestGlobalConfigConcurrentAccess(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tconst goroutines = 16\n\twg := sync.WaitGroup{}\n\twg.Add(goroutines)\n\tinstances := make(chan *ConfigSingleton, goroutines)\n\tfor i := 0; i < goroutines; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tinstances <- GlobalConfig()\n\t\t}()\n\t}\n\twg.Wait()\n\tclose(instances)\n\tvar ref *ConfigSingleton\n\tfor inst := range instances {\n\t\tif ref == nil {\n\t\t\tref = inst\n\t\t\tcontinue\n\t\t}\n\t\tif inst != ref {\n\t\t\tt.Fatalf(\"expected identical singleton instances\")\n\t\t}\n\t}\n}\n\n// ---- Set ----\n\nfunc TestConfigSetStoresValue(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tcfg.Set(\"env\", \"prod\")\n\tif val, ok := cfg.values[\"env\"]; !ok || val != \"prod\" {\n\t\tt.Fatalf(\"Set should store key/value\")\n\t}\n}\n\nfunc TestConfigSetInitializesMap(t *testing.T) {\n\tcfg := &ConfigSingleton{}\n\tcfg.Set(\"key\", \"value\")\n\tif cfg.values[\"key\"] != \"value\" {\n\t\tt.Fatalf(\"Set should create map lazily\")\n\t}\n}\n\nfunc TestConfigSetNilReceiver(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"Set on nil receiver must not panic: %v\", r)\n\t\t}\n\t}()\n\t(*ConfigSingleton)(nil).Set(\"k\", \"v\")\n}\n\n// ---- Get ----\n\nfunc TestConfigGetReturnsValue(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tcfg.Set(\"mode\", \"debug\")\n\tif val, ok := cfg.Get(\"mode\"); !ok || val != \"debug\" {\n\t\tt.Fatalf(\"Get returned wrong value: %s %v\", val, ok)\n\t}\n}\n\nfunc TestConfigGetMissingValue(t *testing.T) {\n\tcfg := &ConfigSingleton{}\n\tif _, ok := cfg.Get(\"missing\"); ok {\n\t\tt.Fatalf(\"Get should return false for missing keys\")\n\t}\n}\n\nfunc TestConfigGetNilReceiver(t *testing.T) {\n\tif _, ok := (*ConfigSingleton)(nil).Get(\"k\"); ok {\n\t\tt.Fatalf(\"nil receiver should report missing value\")\n\t}\n}\n",
        "tags": [
          "go",
          "singleton",
          "patterns",
          "creational"
        ],
        "order": 0
      },
      {
        "package": "singleton",
        "slug": "go-singleton-set",
        "title": "Set",
        "description": "Task 2 (easy+): Set\nСохраните пару ключ/значение в singleton.\nПодсказка: защитите запись mutex'ом и инициализируйте карту при необходимости.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Set.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// ConfigSingleton предоставляет потокобезопасный доступ к настройкам.\ntype ConfigSingleton struct {\n\tmu     sync.RWMutex\n\tvalues map[string]string\n}\n\nvar (\n\tconfigOnce     sync.Once\n\tconfigInstance *ConfigSingleton\n)\n\n// Task 1 (easy): GlobalConfig\n// Верните singleton ConfigSingleton с ленивой инициализацией.\n// Подсказка: используйте sync.Once и инициализируйте карту значений.\nfunc GlobalConfig() *ConfigSingleton {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Set\n// Сохраните пару ключ/значение в singleton.\n// Подсказка: защитите запись mutex'ом и инициализируйте карту при необходимости.\nfunc (c *ConfigSingleton) Set(key, value string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Get\n// Прочитайте значение по ключу.\n// Подсказка: используйте RLock и возвращайте второй bool как признак наличия.\nfunc (c *ConfigSingleton) Get(key string) (string, bool) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport \"sync\"\n\ntype ConfigSingleton struct { // ConfigSingleton хранит настройки.\n\tmu     sync.RWMutex      // mu защищает карту значений.\n\tvalues map[string]string // values содержит пары ключ/значение.\n}\n\nvar (\n\tconfigOnce     sync.Once        // configOnce гарантирует единичную инициализацию.\n\tconfigInstance *ConfigSingleton // configInstance хранит singleton.\n)\n\nfunc GlobalConfig() *ConfigSingleton { // GlobalConfig возвращает singleton конфигурации.\n\tconfigOnce.Do(func() { // Гарантируем однократную инициализацию.\n\t\tconfigInstance = &ConfigSingleton{ // Создаём экземпляр конфигурации.\n\t\t\tvalues: make(map[string]string), // Инициализируем карту значений.\n\t\t}\n\t})\n\treturn configInstance // Возвращаем готовый singleton.\n}\n\nfunc (c *ConfigSingleton) Set(key, value string) { // Set записывает значение в конфигурацию.\n\tif c == nil { // Nil-получатель игнорируем.\n\t\treturn // Нечего записывать.\n\t}\n\tc.mu.Lock()          // Защищаем запись mutex'ом.\n\tdefer c.mu.Unlock()  // Освобождаем mutex по завершении.\n\tif c.values == nil { // Лениво инициализируем карту при необходимости.\n\t\tc.values = make(map[string]string) // Создаём map для значений.\n\t}\n\tc.values[key] = value // Записываем пару ключ/значение.\n}\n\nfunc (c *ConfigSingleton) Get(key string) (string, bool) { // Get возвращает значение по ключу.\n\tif c == nil { // Nil-получатель не содержит значений.\n\t\treturn \"\", false // Сообщаем об отсутствии данных.\n\t}\n\tc.mu.RLock()         // Используем read-lock для безопасного чтения.\n\tdefer c.mu.RUnlock() // Освобождаем его после чтения.\n\tif c.values == nil { // Карта ещё не инициализирована.\n\t\treturn \"\", false // Значения отсутствуют.\n\t}\n\tval, ok := c.values[key] // Читаем значение из карты.\n\treturn val, ok           // Возвращаем найденное значение и флаг наличия.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc resetConfigSingletonUnsafe() {\n\tconfigInstance = nil\n\tconfigOnce = sync.Once{}\n}\n\n// ---- GlobalConfig ----\n\nfunc TestGlobalConfigReturnsSameInstance(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg1 := GlobalConfig()\n\tcfg2 := GlobalConfig()\n\tif cfg1 == nil || cfg2 == nil {\n\t\tt.Fatalf(\"GlobalConfig must not return nil\")\n\t}\n\tif cfg1 != cfg2 {\n\t\tt.Fatalf(\"GlobalConfig should return singleton instances\")\n\t}\n}\n\nfunc TestGlobalConfigInitializesMap(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tif cfg.values == nil {\n\t\tt.Fatalf(\"values map must be initialized\")\n\t}\n}\n\nfunc TestGlobalConfigConcurrentAccess(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tconst goroutines = 16\n\twg := sync.WaitGroup{}\n\twg.Add(goroutines)\n\tinstances := make(chan *ConfigSingleton, goroutines)\n\tfor i := 0; i < goroutines; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tinstances <- GlobalConfig()\n\t\t}()\n\t}\n\twg.Wait()\n\tclose(instances)\n\tvar ref *ConfigSingleton\n\tfor inst := range instances {\n\t\tif ref == nil {\n\t\t\tref = inst\n\t\t\tcontinue\n\t\t}\n\t\tif inst != ref {\n\t\t\tt.Fatalf(\"expected identical singleton instances\")\n\t\t}\n\t}\n}\n\n// ---- Set ----\n\nfunc TestConfigSetStoresValue(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tcfg.Set(\"env\", \"prod\")\n\tif val, ok := cfg.values[\"env\"]; !ok || val != \"prod\" {\n\t\tt.Fatalf(\"Set should store key/value\")\n\t}\n}\n\nfunc TestConfigSetInitializesMap(t *testing.T) {\n\tcfg := &ConfigSingleton{}\n\tcfg.Set(\"key\", \"value\")\n\tif cfg.values[\"key\"] != \"value\" {\n\t\tt.Fatalf(\"Set should create map lazily\")\n\t}\n}\n\nfunc TestConfigSetNilReceiver(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"Set on nil receiver must not panic: %v\", r)\n\t\t}\n\t}()\n\t(*ConfigSingleton)(nil).Set(\"k\", \"v\")\n}\n\n// ---- Get ----\n\nfunc TestConfigGetReturnsValue(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tcfg.Set(\"mode\", \"debug\")\n\tif val, ok := cfg.Get(\"mode\"); !ok || val != \"debug\" {\n\t\tt.Fatalf(\"Get returned wrong value: %s %v\", val, ok)\n\t}\n}\n\nfunc TestConfigGetMissingValue(t *testing.T) {\n\tcfg := &ConfigSingleton{}\n\tif _, ok := cfg.Get(\"missing\"); ok {\n\t\tt.Fatalf(\"Get should return false for missing keys\")\n\t}\n}\n\nfunc TestConfigGetNilReceiver(t *testing.T) {\n\tif _, ok := (*ConfigSingleton)(nil).Get(\"k\"); ok {\n\t\tt.Fatalf(\"nil receiver should report missing value\")\n\t}\n}\n",
        "tags": [
          "go",
          "singleton",
          "patterns",
          "creational"
        ],
        "order": 1
      },
      {
        "package": "singleton",
        "slug": "go-singleton-get",
        "title": "Get",
        "description": "Task 3 (medium): Get\nПрочитайте значение по ключу.\nПодсказка: используйте RLock и возвращайте второй bool как признак наличия.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Get.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage creational\n\nimport \"sync\"\n\n// ConfigSingleton предоставляет потокобезопасный доступ к настройкам.\ntype ConfigSingleton struct {\n\tmu     sync.RWMutex\n\tvalues map[string]string\n}\n\nvar (\n\tconfigOnce     sync.Once\n\tconfigInstance *ConfigSingleton\n)\n\n// Task 1 (easy): GlobalConfig\n// Верните singleton ConfigSingleton с ленивой инициализацией.\n// Подсказка: используйте sync.Once и инициализируйте карту значений.\nfunc GlobalConfig() *ConfigSingleton {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Set\n// Сохраните пару ключ/значение в singleton.\n// Подсказка: защитите запись mutex'ом и инициализируйте карту при необходимости.\nfunc (c *ConfigSingleton) Set(key, value string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Get\n// Прочитайте значение по ключу.\n// Подсказка: используйте RLock и возвращайте второй bool как признак наличия.\nfunc (c *ConfigSingleton) Get(key string) (string, bool) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage creational\n\nimport \"sync\"\n\ntype ConfigSingleton struct { // ConfigSingleton хранит настройки.\n\tmu     sync.RWMutex      // mu защищает карту значений.\n\tvalues map[string]string // values содержит пары ключ/значение.\n}\n\nvar (\n\tconfigOnce     sync.Once        // configOnce гарантирует единичную инициализацию.\n\tconfigInstance *ConfigSingleton // configInstance хранит singleton.\n)\n\nfunc GlobalConfig() *ConfigSingleton { // GlobalConfig возвращает singleton конфигурации.\n\tconfigOnce.Do(func() { // Гарантируем однократную инициализацию.\n\t\tconfigInstance = &ConfigSingleton{ // Создаём экземпляр конфигурации.\n\t\t\tvalues: make(map[string]string), // Инициализируем карту значений.\n\t\t}\n\t})\n\treturn configInstance // Возвращаем готовый singleton.\n}\n\nfunc (c *ConfigSingleton) Set(key, value string) { // Set записывает значение в конфигурацию.\n\tif c == nil { // Nil-получатель игнорируем.\n\t\treturn // Нечего записывать.\n\t}\n\tc.mu.Lock()          // Защищаем запись mutex'ом.\n\tdefer c.mu.Unlock()  // Освобождаем mutex по завершении.\n\tif c.values == nil { // Лениво инициализируем карту при необходимости.\n\t\tc.values = make(map[string]string) // Создаём map для значений.\n\t}\n\tc.values[key] = value // Записываем пару ключ/значение.\n}\n\nfunc (c *ConfigSingleton) Get(key string) (string, bool) { // Get возвращает значение по ключу.\n\tif c == nil { // Nil-получатель не содержит значений.\n\t\treturn \"\", false // Сообщаем об отсутствии данных.\n\t}\n\tc.mu.RLock()         // Используем read-lock для безопасного чтения.\n\tdefer c.mu.RUnlock() // Освобождаем его после чтения.\n\tif c.values == nil { // Карта ещё не инициализирована.\n\t\treturn \"\", false // Значения отсутствуют.\n\t}\n\tval, ok := c.values[key] // Читаем значение из карты.\n\treturn val, ok           // Возвращаем найденное значение и флаг наличия.\n}\n",
        "testCode": "package creational\n\nimport (\n\t\"sync\"\n\t\"testing\"\n)\n\nfunc resetConfigSingletonUnsafe() {\n\tconfigInstance = nil\n\tconfigOnce = sync.Once{}\n}\n\n// ---- GlobalConfig ----\n\nfunc TestGlobalConfigReturnsSameInstance(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg1 := GlobalConfig()\n\tcfg2 := GlobalConfig()\n\tif cfg1 == nil || cfg2 == nil {\n\t\tt.Fatalf(\"GlobalConfig must not return nil\")\n\t}\n\tif cfg1 != cfg2 {\n\t\tt.Fatalf(\"GlobalConfig should return singleton instances\")\n\t}\n}\n\nfunc TestGlobalConfigInitializesMap(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tif cfg.values == nil {\n\t\tt.Fatalf(\"values map must be initialized\")\n\t}\n}\n\nfunc TestGlobalConfigConcurrentAccess(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tconst goroutines = 16\n\twg := sync.WaitGroup{}\n\twg.Add(goroutines)\n\tinstances := make(chan *ConfigSingleton, goroutines)\n\tfor i := 0; i < goroutines; i++ {\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tinstances <- GlobalConfig()\n\t\t}()\n\t}\n\twg.Wait()\n\tclose(instances)\n\tvar ref *ConfigSingleton\n\tfor inst := range instances {\n\t\tif ref == nil {\n\t\t\tref = inst\n\t\t\tcontinue\n\t\t}\n\t\tif inst != ref {\n\t\t\tt.Fatalf(\"expected identical singleton instances\")\n\t\t}\n\t}\n}\n\n// ---- Set ----\n\nfunc TestConfigSetStoresValue(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tcfg.Set(\"env\", \"prod\")\n\tif val, ok := cfg.values[\"env\"]; !ok || val != \"prod\" {\n\t\tt.Fatalf(\"Set should store key/value\")\n\t}\n}\n\nfunc TestConfigSetInitializesMap(t *testing.T) {\n\tcfg := &ConfigSingleton{}\n\tcfg.Set(\"key\", \"value\")\n\tif cfg.values[\"key\"] != \"value\" {\n\t\tt.Fatalf(\"Set should create map lazily\")\n\t}\n}\n\nfunc TestConfigSetNilReceiver(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"Set on nil receiver must not panic: %v\", r)\n\t\t}\n\t}()\n\t(*ConfigSingleton)(nil).Set(\"k\", \"v\")\n}\n\n// ---- Get ----\n\nfunc TestConfigGetReturnsValue(t *testing.T) {\n\tresetConfigSingletonUnsafe()\n\tcfg := GlobalConfig()\n\tcfg.Set(\"mode\", \"debug\")\n\tif val, ok := cfg.Get(\"mode\"); !ok || val != \"debug\" {\n\t\tt.Fatalf(\"Get returned wrong value: %s %v\", val, ok)\n\t}\n}\n\nfunc TestConfigGetMissingValue(t *testing.T) {\n\tcfg := &ConfigSingleton{}\n\tif _, ok := cfg.Get(\"missing\"); ok {\n\t\tt.Fatalf(\"Get should return false for missing keys\")\n\t}\n}\n\nfunc TestConfigGetNilReceiver(t *testing.T) {\n\tif _, ok := (*ConfigSingleton)(nil).Get(\"k\"); ok {\n\t\tt.Fatalf(\"nil receiver should report missing value\")\n\t}\n}\n",
        "tags": [
          "go",
          "singleton",
          "patterns",
          "creational"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-adapter",
    "tasks": [
      {
        "package": "adapter",
        "slug": "go-adapter-newlegacypaymentadapter",
        "title": "создайте конструктор, который нормализует валюту, копирует метаданные и подставляет clock по умолчанию.",
        "description": "Task 1 (easy): создайте конструктор, который нормализует валюту, копирует метаданные и подставляет clock по умолчанию.\nПодсказка: возвращайте nil, если легаси сервис отсутствует, а пустую валюту заменяйте на USD в upper-case.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of создайте конструктор, который нормализует валюту, копирует метаданные и подставляет clock по умолчанию..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"strings\"\n\t\"time\"\n)\n\nvar (\n\t// ErrMissingLegacyService возвращается, когда адаптер создан без легаси сервиса.\n\tErrMissingLegacyService = errors.New(\"legacy payment service is nil\")\n)\n\n// Money описывает сумму и валюту современного API.\ntype Money struct {\n\tAmount   int64\n\tCurrency string\n}\n\n// LegacyInvoice — контракт старого сервиса оплат.\ntype LegacyInvoice struct {\n\tCustomerID string\n\tCurrency   string\n\tTotalCents int64\n\tCreatedAt  time.Time\n\tMetadata   map[string]string\n}\n\n// LegacyPaymentService предоставляет устаревший метод Pay.\ntype LegacyPaymentService interface {\n\tPay(ctx context.Context, invoice LegacyInvoice) error\n}\n\n// PaymentGateway — современный интерфейс, который нужно адаптировать.\ntype PaymentGateway interface {\n\tCharge(ctx context.Context, amount Money, customerID string) error\n}\n\n// Clock позволяет подменять источник времени в тестах.\ntype Clock interface {\n\tNow() time.Time\n}\n\n// LegacyPaymentAdapter связывает современные вызовы с легаси сервисом.\ntype LegacyPaymentAdapter struct {\n\tLegacy          LegacyPaymentService\n\tDefaultCurrency string\n\tMetadata        map[string]string\n\tClock           Clock\n}\n\n// Task 1 (easy): создайте конструктор, который нормализует валюту, копирует метаданные и подставляет clock по умолчанию.\n// Подсказка: возвращайте nil, если легаси сервис отсутствует, а пустую валюту заменяйте на USD в upper-case.\nfunc NewLegacyPaymentAdapter(service LegacyPaymentService, defaultCurrency string, metadata map[string]string, clock Clock) PaymentGateway {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): реализуйте метод Charge, собирающий LegacyInvoice и делегирующий Pay.\n// Подсказка: проверяйте context, объединяйте метаданные и приводите выбранную валюту к верхнему регистру.\nfunc (a *LegacyPaymentAdapter) Charge(ctx context.Context, amount Money, customerID string) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype defaultClock struct{} // defaultClock реализует Clock через системное время.\n\nfunc (defaultClock) Now() time.Time { // Now возвращает текущее UTC время.\n\treturn time.Now().UTC() // Берём текущее время и нормализуем к UTC.\n}\n\nfunc cloneMetadata(src map[string]string) map[string]string { // cloneMetadata копирует карту метаданных.\n\tif src == nil { // Если исходная карта nil...\n\t\treturn make(map[string]string) // ...возвращаем новый пустой map.\n\t}\n\tdst := make(map[string]string, len(src)) // Выделяем карту нужного размера.\n\tfor k, v := range src {                  // Итерируемся по исходным парам ключ-значение.\n\t\tdst[k] = v // Копируем каждую запись.\n\t}\n\treturn dst // Возвращаем независимую копию.\n}\n\nfunc normalizeCurrency(code string) string { // normalizeCurrency приводит код валюты к upper-case.\n\tcode = strings.ToUpper(strings.TrimSpace(code)) // Тримим пробелы и делаем upper-case.\n\tif code == \"\" {                                 // Если код по-прежнему пустой...\n\t\treturn \"USD\" // ...используем USD по умолчанию.\n\t}\n\treturn code // Возвращаем валидный код.\n}\n\nfunc NewLegacyPaymentAdapter(service LegacyPaymentService, defaultCurrency string, metadata map[string]string, clock Clock) PaymentGateway { // Конструктор адаптера.\n\tif service == nil { // Без легаси сервиса работать нечему.\n\t\treturn nil // Сообщаем вызывающему о невозможности построения.\n\t}\n\tnormCurrency := normalizeCurrency(defaultCurrency) // Нормализуем валюту по умолчанию.\n\tclonedMetadata := cloneMetadata(metadata)          // Готовим копию метаданных, чтобы не делить map.\n\tif clock == nil {                                  // Если clock не передан...\n\t\tclock = defaultClock{} // ...используем системные часы.\n\t}\n\treturn &LegacyPaymentAdapter{ // Возвращаем готовый адаптер.\n\t\tLegacy:          service,        // Устанавливаем легаси сервис.\n\t\tDefaultCurrency: normCurrency,   // Сохраняем валюту по умолчанию.\n\t\tMetadata:        clonedMetadata, // Кладём копию метаданных.\n\t\tClock:           clock,          // Настраиваем источник времени.\n\t} // Завершили создание.\n}\n\nfunc (a *LegacyPaymentAdapter) Charge(ctx context.Context, amount Money, customerID string) error { // Charge преобразует вызов к легаси API.\n\tif ctx == nil { // Если контекст не указан...\n\t\tctx = context.Background() // ...используем фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем, не отменён ли контекст.\n\t\treturn err // Возвращаем ошибку отмены.\n\t}\n\tif a == nil || a.Legacy == nil { // Без адаптера или легаси сервиса вызвать нечего.\n\t\treturn ErrMissingLegacyService // Сообщаем об ошибке конфигурации.\n\t}\n\tcurrency := normalizeCurrency(amount.Currency)                     // Нормализуем валюту из суммы.\n\tif currency == \"USD\" && strings.TrimSpace(amount.Currency) == \"\" { // Если сумма не задала валюту явно...\n\t\tcurrency = normalizeCurrency(a.DefaultCurrency) // ...переиспользуем валюту адаптера.\n\t}\n\tissuedAt := time.Now().UTC() // По умолчанию берём текущее время.\n\tif a.Clock != nil {          // Если у адаптера есть clock...\n\t\tissuedAt = a.Clock.Now() // ...используем его для детерминизма.\n\t}\n\tinvoice := LegacyInvoice{ // Собираем LegacyInvoice.\n\t\tCustomerID: customerID,                // Записываем идентификатор клиента.\n\t\tCurrency:   currency,                  // Устанавливаем валюту.\n\t\tTotalCents: amount.Amount,             // Передаём сумму в центах.\n\t\tCreatedAt:  issuedAt,                  // Фиксируем время создания.\n\t\tMetadata:   cloneMetadata(a.Metadata), // Копируем метаданные адаптера.\n\t} // Завершили построение invoice.\n\treturn a.Legacy.Pay(ctx, invoice) // Делегируем выполнение легаси сервису.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype legacyPaymentStub struct {\n\tinvoices []LegacyInvoice\n\terr      error\n\tcalls    int\n}\n\nfunc (s *legacyPaymentStub) Pay(_ context.Context, invoice LegacyInvoice) error {\n\ts.calls++\n\ts.invoices = append(s.invoices, invoice)\n\treturn s.err\n}\n\ntype fixedClock struct {\n\tcurrent time.Time\n}\n\nfunc (c fixedClock) Now() time.Time {\n\treturn c.current\n}\n\nfunc TestNewLegacyPaymentAdapter(t *testing.T) {\n\tt.Run(\"normalizes currency and copies metadata\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tmeta := map[string]string{\"env\": \"prod\"}\n\t\tnow := fixedClock{current: time.Unix(44, 0)}\n\n\t\tgateway := NewLegacyPaymentAdapter(service, \"rub\", meta, now)\n\t\tif gateway == nil {\n\t\t\tt.Fatalf(\"expected adapter, got nil\")\n\t\t}\n\t\tadapter, ok := gateway.(*LegacyPaymentAdapter)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected *LegacyPaymentAdapter, got %T\", gateway)\n\t\t}\n\t\tif adapter.DefaultCurrency != \"RUB\" {\n\t\t\tt.Fatalf(\"currency was not upper-cased: %q\", adapter.DefaultCurrency)\n\t\t}\n\t\tif adapter.Clock != now {\n\t\t\tt.Fatalf(\"clock was not stored\")\n\t\t}\n\t\tmeta[\"env\"] = \"dev\"\n\t\tif adapter.Metadata[\"env\"] != \"prod\" {\n\t\t\tt.Fatalf(\"metadata must be copied, got %v\", adapter.Metadata)\n\t\t}\n\t})\n\n\tt.Run(\"returns nil when service missing\", func(t *testing.T) {\n\t\tif adapter := NewLegacyPaymentAdapter(nil, \"usd\", nil, nil); adapter != nil {\n\t\t\tt.Fatalf(\"expected nil adapter when service missing\")\n\t\t}\n\t})\n\n\tt.Run(\"defaults empty currency to USD\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tgateway := NewLegacyPaymentAdapter(service, \"\", nil, fixedClock{})\n\t\tif gateway == nil {\n\t\t\tt.Fatalf(\"expected adapter instance\")\n\t\t}\n\t\tadapter := gateway.(*LegacyPaymentAdapter)\n\t\tif adapter.DefaultCurrency != \"USD\" {\n\t\t\tt.Fatalf(\"expected USD default, got %q\", adapter.DefaultCurrency)\n\t\t}\n\t\tif adapter.Metadata == nil {\n\t\t\tt.Fatalf(\"metadata map must be allocated even when nil provided\")\n\t\t}\n\t})\n}\n\nfunc TestLegacyPaymentAdapterCharge(t *testing.T) {\n\tt.Run(\"delegates to legacy service with invoice data\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tnow := time.Unix(100, 0)\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tLegacy:          service,\n\t\t\tDefaultCurrency: \"USD\",\n\t\t\tMetadata:        map[string]string{\"source\": \"gateway\"},\n\t\t\tClock:           fixedClock{current: now},\n\t\t}\n\n\t\terr := gateway.Charge(context.Background(), Money{Amount: 4200, Currency: \"eur\"}, \"customer-1\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected no error, got %v\", err)\n\t\t}\n\t\tif service.calls != 1 {\n\t\t\tt.Fatalf(\"expected Pay to be called once, got %d\", service.calls)\n\t\t}\n\t\tinvoice := service.invoices[0]\n\t\tif invoice.Currency != \"EUR\" {\n\t\t\tt.Fatalf(\"expected uppercase currency, got %q\", invoice.Currency)\n\t\t}\n\t\tif invoice.TotalCents != 4200 || invoice.CustomerID != \"customer-1\" {\n\t\t\tt.Fatalf(\"unexpected invoice payload: %+v\", invoice)\n\t\t}\n\t\tif invoice.CreatedAt != now {\n\t\t\tt.Fatalf(\"expected CreatedAt from clock\")\n\t\t}\n\t\tif invoice.Metadata[\"source\"] != \"gateway\" {\n\t\t\tt.Fatalf(\"metadata must include adapter data: %+v\", invoice.Metadata)\n\t\t}\n\t\tinvoice.Metadata[\"source\"] = \"changed\"\n\t\tif gateway.Metadata[\"source\"] != \"gateway\" {\n\t\t\tt.Fatalf(\"invoice metadata must not mutate adapter metadata\")\n\t\t}\n\t})\n\n\tt.Run(\"uses default currency when amount is empty\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tLegacy:          service,\n\t\t\tDefaultCurrency: \"GBP\",\n\t\t\tMetadata:        map[string]string{},\n\t\t\tClock:           fixedClock{current: time.Unix(1, 0)},\n\t\t}\n\t\tif err := gateway.Charge(context.Background(), Money{Amount: 99}, \"cust\"); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif service.invoices[0].Currency != \"GBP\" {\n\t\t\tt.Fatalf(\"expected default currency fallback, got %q\", service.invoices[0].Currency)\n\t\t}\n\t})\n\n\tt.Run(\"returns context error before calling legacy service\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tLegacy:          service,\n\t\t\tDefaultCurrency: \"USD\",\n\t\t\tMetadata:        map[string]string{},\n\t\t\tClock:           fixedClock{current: time.Unix(1, 0)},\n\t\t}\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := gateway.Charge(ctx, Money{Amount: 1}, \"cust\")\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif service.calls != 0 {\n\t\t\tt.Fatalf(\"legacy service must not be called on canceled context\")\n\t\t}\n\t})\n\n\tt.Run(\"returns error when legacy service missing\", func(t *testing.T) {\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tDefaultCurrency: \"USD\",\n\t\t\tMetadata:        map[string]string{},\n\t\t}\n\t\terr := gateway.Charge(context.Background(), Money{Amount: 10}, \"cust\")\n\t\tif !errors.Is(err, ErrMissingLegacyService) {\n\t\t\tt.Fatalf(\"expected ErrMissingLegacyService, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "adapter",
          "patterns",
          "structural"
        ],
        "order": 0
      },
      {
        "package": "adapter",
        "slug": "go-adapter-charge",
        "title": "реализуйте метод Charge, собирающий LegacyInvoice и делегирующий Pay.",
        "description": "Task 2 (easy+): реализуйте метод Charge, собирающий LegacyInvoice и делегирующий Pay.\nПодсказка: проверяйте context, объединяйте метаданные и приводите выбранную валюту к верхнему регистру.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of реализуйте метод Charge, собирающий LegacyInvoice и делегирующий Pay..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"strings\"\n\t\"time\"\n)\n\nvar (\n\t// ErrMissingLegacyService возвращается, когда адаптер создан без легаси сервиса.\n\tErrMissingLegacyService = errors.New(\"legacy payment service is nil\")\n)\n\n// Money описывает сумму и валюту современного API.\ntype Money struct {\n\tAmount   int64\n\tCurrency string\n}\n\n// LegacyInvoice — контракт старого сервиса оплат.\ntype LegacyInvoice struct {\n\tCustomerID string\n\tCurrency   string\n\tTotalCents int64\n\tCreatedAt  time.Time\n\tMetadata   map[string]string\n}\n\n// LegacyPaymentService предоставляет устаревший метод Pay.\ntype LegacyPaymentService interface {\n\tPay(ctx context.Context, invoice LegacyInvoice) error\n}\n\n// PaymentGateway — современный интерфейс, который нужно адаптировать.\ntype PaymentGateway interface {\n\tCharge(ctx context.Context, amount Money, customerID string) error\n}\n\n// Clock позволяет подменять источник времени в тестах.\ntype Clock interface {\n\tNow() time.Time\n}\n\n// LegacyPaymentAdapter связывает современные вызовы с легаси сервисом.\ntype LegacyPaymentAdapter struct {\n\tLegacy          LegacyPaymentService\n\tDefaultCurrency string\n\tMetadata        map[string]string\n\tClock           Clock\n}\n\n// Task 1 (easy): создайте конструктор, который нормализует валюту, копирует метаданные и подставляет clock по умолчанию.\n// Подсказка: возвращайте nil, если легаси сервис отсутствует, а пустую валюту заменяйте на USD в upper-case.\nfunc NewLegacyPaymentAdapter(service LegacyPaymentService, defaultCurrency string, metadata map[string]string, clock Clock) PaymentGateway {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): реализуйте метод Charge, собирающий LegacyInvoice и делегирующий Pay.\n// Подсказка: проверяйте context, объединяйте метаданные и приводите выбранную валюту к верхнему регистру.\nfunc (a *LegacyPaymentAdapter) Charge(ctx context.Context, amount Money, customerID string) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype defaultClock struct{} // defaultClock реализует Clock через системное время.\n\nfunc (defaultClock) Now() time.Time { // Now возвращает текущее UTC время.\n\treturn time.Now().UTC() // Берём текущее время и нормализуем к UTC.\n}\n\nfunc cloneMetadata(src map[string]string) map[string]string { // cloneMetadata копирует карту метаданных.\n\tif src == nil { // Если исходная карта nil...\n\t\treturn make(map[string]string) // ...возвращаем новый пустой map.\n\t}\n\tdst := make(map[string]string, len(src)) // Выделяем карту нужного размера.\n\tfor k, v := range src {                  // Итерируемся по исходным парам ключ-значение.\n\t\tdst[k] = v // Копируем каждую запись.\n\t}\n\treturn dst // Возвращаем независимую копию.\n}\n\nfunc normalizeCurrency(code string) string { // normalizeCurrency приводит код валюты к upper-case.\n\tcode = strings.ToUpper(strings.TrimSpace(code)) // Тримим пробелы и делаем upper-case.\n\tif code == \"\" {                                 // Если код по-прежнему пустой...\n\t\treturn \"USD\" // ...используем USD по умолчанию.\n\t}\n\treturn code // Возвращаем валидный код.\n}\n\nfunc NewLegacyPaymentAdapter(service LegacyPaymentService, defaultCurrency string, metadata map[string]string, clock Clock) PaymentGateway { // Конструктор адаптера.\n\tif service == nil { // Без легаси сервиса работать нечему.\n\t\treturn nil // Сообщаем вызывающему о невозможности построения.\n\t}\n\tnormCurrency := normalizeCurrency(defaultCurrency) // Нормализуем валюту по умолчанию.\n\tclonedMetadata := cloneMetadata(metadata)          // Готовим копию метаданных, чтобы не делить map.\n\tif clock == nil {                                  // Если clock не передан...\n\t\tclock = defaultClock{} // ...используем системные часы.\n\t}\n\treturn &LegacyPaymentAdapter{ // Возвращаем готовый адаптер.\n\t\tLegacy:          service,        // Устанавливаем легаси сервис.\n\t\tDefaultCurrency: normCurrency,   // Сохраняем валюту по умолчанию.\n\t\tMetadata:        clonedMetadata, // Кладём копию метаданных.\n\t\tClock:           clock,          // Настраиваем источник времени.\n\t} // Завершили создание.\n}\n\nfunc (a *LegacyPaymentAdapter) Charge(ctx context.Context, amount Money, customerID string) error { // Charge преобразует вызов к легаси API.\n\tif ctx == nil { // Если контекст не указан...\n\t\tctx = context.Background() // ...используем фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем, не отменён ли контекст.\n\t\treturn err // Возвращаем ошибку отмены.\n\t}\n\tif a == nil || a.Legacy == nil { // Без адаптера или легаси сервиса вызвать нечего.\n\t\treturn ErrMissingLegacyService // Сообщаем об ошибке конфигурации.\n\t}\n\tcurrency := normalizeCurrency(amount.Currency)                     // Нормализуем валюту из суммы.\n\tif currency == \"USD\" && strings.TrimSpace(amount.Currency) == \"\" { // Если сумма не задала валюту явно...\n\t\tcurrency = normalizeCurrency(a.DefaultCurrency) // ...переиспользуем валюту адаптера.\n\t}\n\tissuedAt := time.Now().UTC() // По умолчанию берём текущее время.\n\tif a.Clock != nil {          // Если у адаптера есть clock...\n\t\tissuedAt = a.Clock.Now() // ...используем его для детерминизма.\n\t}\n\tinvoice := LegacyInvoice{ // Собираем LegacyInvoice.\n\t\tCustomerID: customerID,                // Записываем идентификатор клиента.\n\t\tCurrency:   currency,                  // Устанавливаем валюту.\n\t\tTotalCents: amount.Amount,             // Передаём сумму в центах.\n\t\tCreatedAt:  issuedAt,                  // Фиксируем время создания.\n\t\tMetadata:   cloneMetadata(a.Metadata), // Копируем метаданные адаптера.\n\t} // Завершили построение invoice.\n\treturn a.Legacy.Pay(ctx, invoice) // Делегируем выполнение легаси сервису.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype legacyPaymentStub struct {\n\tinvoices []LegacyInvoice\n\terr      error\n\tcalls    int\n}\n\nfunc (s *legacyPaymentStub) Pay(_ context.Context, invoice LegacyInvoice) error {\n\ts.calls++\n\ts.invoices = append(s.invoices, invoice)\n\treturn s.err\n}\n\ntype fixedClock struct {\n\tcurrent time.Time\n}\n\nfunc (c fixedClock) Now() time.Time {\n\treturn c.current\n}\n\nfunc TestNewLegacyPaymentAdapter(t *testing.T) {\n\tt.Run(\"normalizes currency and copies metadata\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tmeta := map[string]string{\"env\": \"prod\"}\n\t\tnow := fixedClock{current: time.Unix(44, 0)}\n\n\t\tgateway := NewLegacyPaymentAdapter(service, \"rub\", meta, now)\n\t\tif gateway == nil {\n\t\t\tt.Fatalf(\"expected adapter, got nil\")\n\t\t}\n\t\tadapter, ok := gateway.(*LegacyPaymentAdapter)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected *LegacyPaymentAdapter, got %T\", gateway)\n\t\t}\n\t\tif adapter.DefaultCurrency != \"RUB\" {\n\t\t\tt.Fatalf(\"currency was not upper-cased: %q\", adapter.DefaultCurrency)\n\t\t}\n\t\tif adapter.Clock != now {\n\t\t\tt.Fatalf(\"clock was not stored\")\n\t\t}\n\t\tmeta[\"env\"] = \"dev\"\n\t\tif adapter.Metadata[\"env\"] != \"prod\" {\n\t\t\tt.Fatalf(\"metadata must be copied, got %v\", adapter.Metadata)\n\t\t}\n\t})\n\n\tt.Run(\"returns nil when service missing\", func(t *testing.T) {\n\t\tif adapter := NewLegacyPaymentAdapter(nil, \"usd\", nil, nil); adapter != nil {\n\t\t\tt.Fatalf(\"expected nil adapter when service missing\")\n\t\t}\n\t})\n\n\tt.Run(\"defaults empty currency to USD\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tgateway := NewLegacyPaymentAdapter(service, \"\", nil, fixedClock{})\n\t\tif gateway == nil {\n\t\t\tt.Fatalf(\"expected adapter instance\")\n\t\t}\n\t\tadapter := gateway.(*LegacyPaymentAdapter)\n\t\tif adapter.DefaultCurrency != \"USD\" {\n\t\t\tt.Fatalf(\"expected USD default, got %q\", adapter.DefaultCurrency)\n\t\t}\n\t\tif adapter.Metadata == nil {\n\t\t\tt.Fatalf(\"metadata map must be allocated even when nil provided\")\n\t\t}\n\t})\n}\n\nfunc TestLegacyPaymentAdapterCharge(t *testing.T) {\n\tt.Run(\"delegates to legacy service with invoice data\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tnow := time.Unix(100, 0)\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tLegacy:          service,\n\t\t\tDefaultCurrency: \"USD\",\n\t\t\tMetadata:        map[string]string{\"source\": \"gateway\"},\n\t\t\tClock:           fixedClock{current: now},\n\t\t}\n\n\t\terr := gateway.Charge(context.Background(), Money{Amount: 4200, Currency: \"eur\"}, \"customer-1\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected no error, got %v\", err)\n\t\t}\n\t\tif service.calls != 1 {\n\t\t\tt.Fatalf(\"expected Pay to be called once, got %d\", service.calls)\n\t\t}\n\t\tinvoice := service.invoices[0]\n\t\tif invoice.Currency != \"EUR\" {\n\t\t\tt.Fatalf(\"expected uppercase currency, got %q\", invoice.Currency)\n\t\t}\n\t\tif invoice.TotalCents != 4200 || invoice.CustomerID != \"customer-1\" {\n\t\t\tt.Fatalf(\"unexpected invoice payload: %+v\", invoice)\n\t\t}\n\t\tif invoice.CreatedAt != now {\n\t\t\tt.Fatalf(\"expected CreatedAt from clock\")\n\t\t}\n\t\tif invoice.Metadata[\"source\"] != \"gateway\" {\n\t\t\tt.Fatalf(\"metadata must include adapter data: %+v\", invoice.Metadata)\n\t\t}\n\t\tinvoice.Metadata[\"source\"] = \"changed\"\n\t\tif gateway.Metadata[\"source\"] != \"gateway\" {\n\t\t\tt.Fatalf(\"invoice metadata must not mutate adapter metadata\")\n\t\t}\n\t})\n\n\tt.Run(\"uses default currency when amount is empty\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tLegacy:          service,\n\t\t\tDefaultCurrency: \"GBP\",\n\t\t\tMetadata:        map[string]string{},\n\t\t\tClock:           fixedClock{current: time.Unix(1, 0)},\n\t\t}\n\t\tif err := gateway.Charge(context.Background(), Money{Amount: 99}, \"cust\"); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif service.invoices[0].Currency != \"GBP\" {\n\t\t\tt.Fatalf(\"expected default currency fallback, got %q\", service.invoices[0].Currency)\n\t\t}\n\t})\n\n\tt.Run(\"returns context error before calling legacy service\", func(t *testing.T) {\n\t\tservice := &legacyPaymentStub{}\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tLegacy:          service,\n\t\t\tDefaultCurrency: \"USD\",\n\t\t\tMetadata:        map[string]string{},\n\t\t\tClock:           fixedClock{current: time.Unix(1, 0)},\n\t\t}\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := gateway.Charge(ctx, Money{Amount: 1}, \"cust\")\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif service.calls != 0 {\n\t\t\tt.Fatalf(\"legacy service must not be called on canceled context\")\n\t\t}\n\t})\n\n\tt.Run(\"returns error when legacy service missing\", func(t *testing.T) {\n\t\tgateway := &LegacyPaymentAdapter{\n\t\t\tDefaultCurrency: \"USD\",\n\t\t\tMetadata:        map[string]string{},\n\t\t}\n\t\terr := gateway.Charge(context.Background(), Money{Amount: 10}, \"cust\")\n\t\tif !errors.Is(err, ErrMissingLegacyService) {\n\t\t\tt.Fatalf(\"expected ErrMissingLegacyService, got %v\", err)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "adapter",
          "patterns",
          "structural"
        ],
        "order": 1
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-bridge",
    "tasks": [
      {
        "package": "bridge",
        "slug": "go-bridge-newalertnotifier",
        "title": "создайте AlertNotifier, валидирующий зависимости и нормализующий префикс.",
        "description": "Task 1 (easy): создайте AlertNotifier, валидирующий зависимости и нормализующий префикс.\nПодсказка: обрезайте пробелы, добавляйте пробел после непустого префикса и возвращайте осмысленные ошибки.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of создайте AlertNotifier, валидирующий зависимости и нормализующий префикс..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n)\n\nvar (\n\t// ErrMissingNotificationChannel сигнализирует об отсутствии Implementation.\n\tErrMissingNotificationChannel = errors.New(\"notification channel is nil\")\n\t// ErrMissingNotificationFormatter сигнализирует об отсутствии Formatter.\n\tErrMissingNotificationFormatter = errors.New(\"notification formatter is nil\")\n)\n\n// AlertLevel определяет уровень уведомления.\ntype AlertLevel string\n\n// Alert описывает сообщение, которое нужно отправить.\ntype Alert struct {\n\tLevel    AlertLevel\n\tMessage  string\n\tMetadata map[string]string\n}\n\n// NotificationChannel — Implementation слоя Bridge, отвечающий за отправку.\ntype NotificationChannel interface {\n\tSend(ctx context.Context, payload string) error\n}\n\n// NotificationFormatter — вторая иерархия, отвечающая за форматирование.\ntype NotificationFormatter interface {\n\tFormat(alert Alert) string\n}\n\n// AlertNotifier — Abstraction уровня Bridge, объединяющая каналы и форматтеры.\ntype AlertNotifier struct {\n\tChannel   NotificationChannel\n\tFormatter NotificationFormatter\n\tPrefix    string\n}\n\n// Task 1 (easy): создайте AlertNotifier, валидирующий зависимости и нормализующий префикс.\n// Подсказка: обрезайте пробелы, добавляйте пробел после непустого префикса и возвращайте осмысленные ошибки.\nfunc NewAlertNotifier(channel NotificationChannel, formatter NotificationFormatter, prefix string) (*AlertNotifier, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): реализуйте Notify, связывающий абстракцию (Alert) с каналом доставки.\n// Подсказка: проверяйте context, используйте Formatter.Format и добавляйте префикс + upper-case уровень перед отправкой.\nfunc (n *AlertNotifier) Notify(ctx context.Context, alert Alert) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strings\"\n)\n\nfunc normalizePrefix(prefix string) string { // normalizePrefix подготавливает текст префикса.\n\tprefix = strings.TrimSpace(prefix) // Сначала обрезаем пробелы по краям.\n\tif prefix == \"\" {                  // Если строка пустая...\n\t\treturn \"\" // ...префикс отсутствует.\n\t}\n\treturn prefix + \" \" // Для непустого префикса добавляем завершающий пробел.\n}\n\nfunc NewAlertNotifier(channel NotificationChannel, formatter NotificationFormatter, prefix string) (*AlertNotifier, error) { // Конструктор AlertNotifier.\n\tif channel == nil { // Проверяем наличие Implementation.\n\t\treturn nil, ErrMissingNotificationChannel // Возвращаем ошибку отсутствующего канала.\n\t}\n\tif formatter == nil { // Проверяем Formatter.\n\t\treturn nil, ErrMissingNotificationFormatter // Сообщаем об ошибке конфигурации.\n\t}\n\treturn &AlertNotifier{ // Возвращаем настроенный Bridge.\n\t\tChannel:   channel,                 // Сохраняем канал доставки.\n\t\tFormatter: formatter,               // Сохраняем форматтер.\n\t\tPrefix:    normalizePrefix(prefix), // Нормализуем префикс заранее.\n\t}, nil // Успешно завершили создание.\n}\n\nfunc (n *AlertNotifier) Notify(ctx context.Context, alert Alert) error { // Notify связывает абстракцию с реализацией.\n\tif ctx == nil { // Обрабатываем nil-context.\n\t\tctx = context.Background() // Используем контекст по умолчанию.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену контекста до работы.\n\t\treturn err // Немедленно возвращаем ошибку отмены.\n\t}\n\tif n == nil || n.Channel == nil { // Без канала нельзя отправлять сообщения.\n\t\treturn ErrMissingNotificationChannel // Сообщаем об отсутствии Implementation.\n\t}\n\tif n.Formatter == nil { // Без форматтера нельзя подготовить сообщение.\n\t\treturn ErrMissingNotificationFormatter // Возвращаем ошибку конфигурации.\n\t}\n\tlevel := strings.ToUpper(string(alert.Level))                   // Приводим уровень к upper-case.\n\tformatted := n.Formatter.Format(alert)                          // Получаем текст из форматтера.\n\tpayload := fmt.Sprintf(\"%s[%s] %s\", n.Prefix, level, formatted) // Собираем итоговую строку.\n\treturn n.Channel.Send(ctx, payload)                             // Делегируем доставку каналу.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"strings\"\n\t\"testing\"\n)\n\ntype channelStub struct {\n\tpayloads []string\n\terr      error\n}\n\nfunc (c *channelStub) Send(_ context.Context, payload string) error {\n\tc.payloads = append(c.payloads, payload)\n\treturn c.err\n}\n\ntype formatterStub struct {\n\tcalls []Alert\n\tres   string\n}\n\nfunc (f *formatterStub) Format(alert Alert) string {\n\tf.calls = append(f.calls, alert)\n\tif f.res != \"\" {\n\t\treturn f.res\n\t}\n\treturn alert.Message\n}\n\nfunc TestNewAlertNotifier(t *testing.T) {\n\tt.Run(\"validates dependencies\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\tformatter := &formatterStub{}\n\n\t\tnotifier, err := NewAlertNotifier(channel, formatter, \" ops \")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected no error, got %v\", err)\n\t\t}\n\t\tif notifier == nil {\n\t\t\tt.Fatalf(\"expected notifier instance\")\n\t\t}\n\t\tif notifier.Channel != channel || notifier.Formatter != formatter {\n\t\t\tt.Fatalf(\"dependencies were not stored\")\n\t\t}\n\t\tif notifier.Prefix != \"ops \" {\n\t\t\tt.Fatalf(\"prefix must be trimmed with trailing space, got %q\", notifier.Prefix)\n\t\t}\n\t})\n\n\tt.Run(\"fails when channel missing\", func(t *testing.T) {\n\t\tformatter := &formatterStub{}\n\t\t_, err := NewAlertNotifier(nil, formatter, \"\")\n\t\tif !errors.Is(err, ErrMissingNotificationChannel) {\n\t\t\tt.Fatalf(\"expected ErrMissingNotificationChannel, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"fails when formatter missing\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\t_, err := NewAlertNotifier(channel, nil, \"\")\n\t\tif !errors.Is(err, ErrMissingNotificationFormatter) {\n\t\t\tt.Fatalf(\"expected ErrMissingNotificationFormatter, got %v\", err)\n\t\t}\n\t})\n}\n\nfunc TestAlertNotifierNotify(t *testing.T) {\n\tt.Run(\"formats alert and sends payload\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\tformatter := &formatterStub{res: \"disk full\"}\n\t\tnotifier := &AlertNotifier{\n\t\t\tChannel:   channel,\n\t\t\tFormatter: formatter,\n\t\t\tPrefix:    \"ops \",\n\t\t}\n\n\t\terr := notifier.Notify(context.Background(), Alert{Level: \"warn\", Message: \"ignored\"})\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif len(channel.payloads) != 1 {\n\t\t\tt.Fatalf(\"expected payload to be sent once, got %d\", len(channel.payloads))\n\t\t}\n\t\tpayload := channel.payloads[0]\n\t\tif !strings.HasPrefix(payload, \"ops [WARN] \") {\n\t\t\tt.Fatalf(\"payload must include prefix and upper level, got %q\", payload)\n\t\t}\n\t\tif !strings.HasSuffix(payload, \"disk full\") {\n\t\t\tt.Fatalf(\"payload must include formatter result, got %q\", payload)\n\t\t}\n\t\tif len(formatter.calls) != 1 || formatter.calls[0].Level != \"warn\" {\n\t\t\tt.Fatalf(\"formatter must be called with original alert\")\n\t\t}\n\t})\n\n\tt.Run(\"respects channel errors\", func(t *testing.T) {\n\t\tchannel := &channelStub{err: errors.New(\"boom\")}\n\t\tformatter := &formatterStub{}\n\t\tnotifier := &AlertNotifier{\n\t\t\tChannel:   channel,\n\t\t\tFormatter: formatter,\n\t\t}\n\t\terr := notifier.Notify(context.Background(), Alert{Level: \"info\"})\n\t\tif !errors.Is(err, channel.err) {\n\t\t\tt.Fatalf(\"expected channel error, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"stops on canceled context\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\tformatter := &formatterStub{}\n\t\tnotifier := &AlertNotifier{\n\t\t\tChannel:   channel,\n\t\t\tFormatter: formatter,\n\t\t}\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := notifier.Notify(ctx, Alert{Level: \"info\"})\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(channel.payloads) != 0 {\n\t\t\tt.Fatalf(\"channel must not be used when context canceled\")\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "bridge",
          "patterns",
          "structural"
        ],
        "order": 0
      },
      {
        "package": "bridge",
        "slug": "go-bridge-notify",
        "title": "реализуйте Notify, связывающий абстракцию (Alert) с каналом доставки.",
        "description": "Task 2 (easy+): реализуйте Notify, связывающий абстракцию (Alert) с каналом доставки.\nПодсказка: проверяйте context, используйте Formatter.Format и добавляйте префикс + upper-case уровень перед отправкой.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of реализуйте Notify, связывающий абстракцию (Alert) с каналом доставки..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n)\n\nvar (\n\t// ErrMissingNotificationChannel сигнализирует об отсутствии Implementation.\n\tErrMissingNotificationChannel = errors.New(\"notification channel is nil\")\n\t// ErrMissingNotificationFormatter сигнализирует об отсутствии Formatter.\n\tErrMissingNotificationFormatter = errors.New(\"notification formatter is nil\")\n)\n\n// AlertLevel определяет уровень уведомления.\ntype AlertLevel string\n\n// Alert описывает сообщение, которое нужно отправить.\ntype Alert struct {\n\tLevel    AlertLevel\n\tMessage  string\n\tMetadata map[string]string\n}\n\n// NotificationChannel — Implementation слоя Bridge, отвечающий за отправку.\ntype NotificationChannel interface {\n\tSend(ctx context.Context, payload string) error\n}\n\n// NotificationFormatter — вторая иерархия, отвечающая за форматирование.\ntype NotificationFormatter interface {\n\tFormat(alert Alert) string\n}\n\n// AlertNotifier — Abstraction уровня Bridge, объединяющая каналы и форматтеры.\ntype AlertNotifier struct {\n\tChannel   NotificationChannel\n\tFormatter NotificationFormatter\n\tPrefix    string\n}\n\n// Task 1 (easy): создайте AlertNotifier, валидирующий зависимости и нормализующий префикс.\n// Подсказка: обрезайте пробелы, добавляйте пробел после непустого префикса и возвращайте осмысленные ошибки.\nfunc NewAlertNotifier(channel NotificationChannel, formatter NotificationFormatter, prefix string) (*AlertNotifier, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): реализуйте Notify, связывающий абстракцию (Alert) с каналом доставки.\n// Подсказка: проверяйте context, используйте Formatter.Format и добавляйте префикс + upper-case уровень перед отправкой.\nfunc (n *AlertNotifier) Notify(ctx context.Context, alert Alert) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strings\"\n)\n\nfunc normalizePrefix(prefix string) string { // normalizePrefix подготавливает текст префикса.\n\tprefix = strings.TrimSpace(prefix) // Сначала обрезаем пробелы по краям.\n\tif prefix == \"\" {                  // Если строка пустая...\n\t\treturn \"\" // ...префикс отсутствует.\n\t}\n\treturn prefix + \" \" // Для непустого префикса добавляем завершающий пробел.\n}\n\nfunc NewAlertNotifier(channel NotificationChannel, formatter NotificationFormatter, prefix string) (*AlertNotifier, error) { // Конструктор AlertNotifier.\n\tif channel == nil { // Проверяем наличие Implementation.\n\t\treturn nil, ErrMissingNotificationChannel // Возвращаем ошибку отсутствующего канала.\n\t}\n\tif formatter == nil { // Проверяем Formatter.\n\t\treturn nil, ErrMissingNotificationFormatter // Сообщаем об ошибке конфигурации.\n\t}\n\treturn &AlertNotifier{ // Возвращаем настроенный Bridge.\n\t\tChannel:   channel,                 // Сохраняем канал доставки.\n\t\tFormatter: formatter,               // Сохраняем форматтер.\n\t\tPrefix:    normalizePrefix(prefix), // Нормализуем префикс заранее.\n\t}, nil // Успешно завершили создание.\n}\n\nfunc (n *AlertNotifier) Notify(ctx context.Context, alert Alert) error { // Notify связывает абстракцию с реализацией.\n\tif ctx == nil { // Обрабатываем nil-context.\n\t\tctx = context.Background() // Используем контекст по умолчанию.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену контекста до работы.\n\t\treturn err // Немедленно возвращаем ошибку отмены.\n\t}\n\tif n == nil || n.Channel == nil { // Без канала нельзя отправлять сообщения.\n\t\treturn ErrMissingNotificationChannel // Сообщаем об отсутствии Implementation.\n\t}\n\tif n.Formatter == nil { // Без форматтера нельзя подготовить сообщение.\n\t\treturn ErrMissingNotificationFormatter // Возвращаем ошибку конфигурации.\n\t}\n\tlevel := strings.ToUpper(string(alert.Level))                   // Приводим уровень к upper-case.\n\tformatted := n.Formatter.Format(alert)                          // Получаем текст из форматтера.\n\tpayload := fmt.Sprintf(\"%s[%s] %s\", n.Prefix, level, formatted) // Собираем итоговую строку.\n\treturn n.Channel.Send(ctx, payload)                             // Делегируем доставку каналу.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"strings\"\n\t\"testing\"\n)\n\ntype channelStub struct {\n\tpayloads []string\n\terr      error\n}\n\nfunc (c *channelStub) Send(_ context.Context, payload string) error {\n\tc.payloads = append(c.payloads, payload)\n\treturn c.err\n}\n\ntype formatterStub struct {\n\tcalls []Alert\n\tres   string\n}\n\nfunc (f *formatterStub) Format(alert Alert) string {\n\tf.calls = append(f.calls, alert)\n\tif f.res != \"\" {\n\t\treturn f.res\n\t}\n\treturn alert.Message\n}\n\nfunc TestNewAlertNotifier(t *testing.T) {\n\tt.Run(\"validates dependencies\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\tformatter := &formatterStub{}\n\n\t\tnotifier, err := NewAlertNotifier(channel, formatter, \" ops \")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected no error, got %v\", err)\n\t\t}\n\t\tif notifier == nil {\n\t\t\tt.Fatalf(\"expected notifier instance\")\n\t\t}\n\t\tif notifier.Channel != channel || notifier.Formatter != formatter {\n\t\t\tt.Fatalf(\"dependencies were not stored\")\n\t\t}\n\t\tif notifier.Prefix != \"ops \" {\n\t\t\tt.Fatalf(\"prefix must be trimmed with trailing space, got %q\", notifier.Prefix)\n\t\t}\n\t})\n\n\tt.Run(\"fails when channel missing\", func(t *testing.T) {\n\t\tformatter := &formatterStub{}\n\t\t_, err := NewAlertNotifier(nil, formatter, \"\")\n\t\tif !errors.Is(err, ErrMissingNotificationChannel) {\n\t\t\tt.Fatalf(\"expected ErrMissingNotificationChannel, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"fails when formatter missing\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\t_, err := NewAlertNotifier(channel, nil, \"\")\n\t\tif !errors.Is(err, ErrMissingNotificationFormatter) {\n\t\t\tt.Fatalf(\"expected ErrMissingNotificationFormatter, got %v\", err)\n\t\t}\n\t})\n}\n\nfunc TestAlertNotifierNotify(t *testing.T) {\n\tt.Run(\"formats alert and sends payload\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\tformatter := &formatterStub{res: \"disk full\"}\n\t\tnotifier := &AlertNotifier{\n\t\t\tChannel:   channel,\n\t\t\tFormatter: formatter,\n\t\t\tPrefix:    \"ops \",\n\t\t}\n\n\t\terr := notifier.Notify(context.Background(), Alert{Level: \"warn\", Message: \"ignored\"})\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif len(channel.payloads) != 1 {\n\t\t\tt.Fatalf(\"expected payload to be sent once, got %d\", len(channel.payloads))\n\t\t}\n\t\tpayload := channel.payloads[0]\n\t\tif !strings.HasPrefix(payload, \"ops [WARN] \") {\n\t\t\tt.Fatalf(\"payload must include prefix and upper level, got %q\", payload)\n\t\t}\n\t\tif !strings.HasSuffix(payload, \"disk full\") {\n\t\t\tt.Fatalf(\"payload must include formatter result, got %q\", payload)\n\t\t}\n\t\tif len(formatter.calls) != 1 || formatter.calls[0].Level != \"warn\" {\n\t\t\tt.Fatalf(\"formatter must be called with original alert\")\n\t\t}\n\t})\n\n\tt.Run(\"respects channel errors\", func(t *testing.T) {\n\t\tchannel := &channelStub{err: errors.New(\"boom\")}\n\t\tformatter := &formatterStub{}\n\t\tnotifier := &AlertNotifier{\n\t\t\tChannel:   channel,\n\t\t\tFormatter: formatter,\n\t\t}\n\t\terr := notifier.Notify(context.Background(), Alert{Level: \"info\"})\n\t\tif !errors.Is(err, channel.err) {\n\t\t\tt.Fatalf(\"expected channel error, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"stops on canceled context\", func(t *testing.T) {\n\t\tchannel := &channelStub{}\n\t\tformatter := &formatterStub{}\n\t\tnotifier := &AlertNotifier{\n\t\t\tChannel:   channel,\n\t\t\tFormatter: formatter,\n\t\t}\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := notifier.Notify(ctx, Alert{Level: \"info\"})\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(channel.payloads) != 0 {\n\t\t\tt.Fatalf(\"channel must not be used when context canceled\")\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "bridge",
          "patterns",
          "structural"
        ],
        "order": 1
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-composite",
    "tasks": [
      {
        "package": "composite",
        "slug": "go-composite-newbudgetcomposite",
        "title": "реализуйте конструктор композита, который копирует входной срез и фильтрует nil-детей.",
        "description": "Task 1 (easy): реализуйте конструктор композита, который копирует входной срез и фильтрует nil-детей.\nПодсказка: нормализуйте имя (TrimSpace) и всегда выделяйте новый срез Children.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of реализуйте конструктор композита, который копирует входной срез и фильтрует nil-детей..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport \"strings\"\n\n// BudgetComponent описывает лист или составной элемент дерева бюджета.\ntype BudgetComponent interface {\n\tCost() int\n}\n\n// BudgetComposite реализует компонент, агрегирующий дочерние элементы.\ntype BudgetComposite struct {\n\tName     string\n\tChildren []BudgetComponent\n}\n\n// Task 1 (easy): реализуйте конструктор композита, который копирует входной срез и фильтрует nil-детей.\n// Подсказка: нормализуйте имя (TrimSpace) и всегда выделяйте новый срез Children.\nfunc NewBudgetComposite(name string, children ...BudgetComponent) *BudgetComposite {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): реализуйте метод Cost, рекурсивно суммирующий стоимость всех детей.\n// Подсказка: пропускайте nil-детей, вызывайте Cost() у каждого компонента и обрабатывайте пустой список.\nfunc (c *BudgetComposite) Cost() int {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport \"strings\"\n\nfunc NewBudgetComposite(name string, children ...BudgetComponent) *BudgetComposite { // Конструктор BudgetComposite.\n\ttrimmed := strings.TrimSpace(name)                    // Нормализуем имя компонента.\n\tfiltered := make([]BudgetComponent, 0, len(children)) // Готовим срез для детей.\n\tfor _, child := range children {                      // Проходим по всем входным детям.\n\t\tif child == nil { // Пропускаем отсутствующих детей.\n\t\t\tcontinue // Переходим к следующему.\n\t\t}\n\t\tfiltered = append(filtered, child) // Сохраняем валидного ребёнка.\n\t}\n\treturn &BudgetComposite{ // Собираем структуру.\n\t\tName:     trimmed,  // Сохраняем имя.\n\t\tChildren: filtered, // Кладём копию среза детей.\n\t} // Возвращаем готовый композит.\n}\n\nfunc (c *BudgetComposite) Cost() int { // Cost суммирует стоимость детей.\n\tif c == nil { // Nil-композит стоит 0.\n\t\treturn 0 // Возвращаем ноль.\n\t}\n\ttotal := 0                         // Инициализируем аккумулятор.\n\tfor _, child := range c.Children { // Обходим дочерние компоненты.\n\t\tif child == nil { // Пропускаем nil-ссылки.\n\t\t\tcontinue // Идём дальше.\n\t\t}\n\t\ttotal += child.Cost() // Добавляем стоимость ребёнка (лист или подкомпозит).\n\t}\n\treturn total // Возвращаем суммарную стоимость.\n}\n",
        "testCode": "package structural\n\nimport \"testing\"\n\ntype componentStub struct {\n\tvalue int\n}\n\nfunc (s componentStub) Cost() int {\n\treturn s.value\n}\n\nfunc TestNewBudgetComposite(t *testing.T) {\n\tt.Run(\"copies children slice and trims name\", func(t *testing.T) {\n\t\tchild := componentStub{value: 30}\n\t\tcomposite := NewBudgetComposite(\"  ops  \", child)\n\t\tif composite == nil {\n\t\t\tt.Fatalf(\"expected composite instance\")\n\t\t}\n\t\tif composite.Name != \"ops\" {\n\t\t\tt.Fatalf(\"expected trimmed name, got %q\", composite.Name)\n\t\t}\n\t\tif len(composite.Children) != 1 {\n\t\t\tt.Fatalf(\"expected child copy, got %d\", len(composite.Children))\n\t\t}\n\t\tif &composite.Children[0] == nil {\n\t\t\tt.Fatalf(\"child pointer should not be nil\")\n\t\t}\n\t})\n\n\tt.Run(\"filters nil children\", func(t *testing.T) {\n\t\tcomposite := NewBudgetComposite(\"team\", nil, componentStub{value: 10})\n\t\tif len(composite.Children) != 1 {\n\t\t\tt.Fatalf(\"expected only non-nil children to be stored, got %d\", len(composite.Children))\n\t\t}\n\t})\n\n\tt.Run(\"always allocates child slice\", func(t *testing.T) {\n\t\tcomposite := NewBudgetComposite(\"empty\")\n\t\tif composite.Children == nil {\n\t\t\tt.Fatalf(\"children slice must not be nil\")\n\t\t}\n\t\tif len(composite.Children) != 0 {\n\t\t\tt.Fatalf(\"expected no children by default, got %d\", len(composite.Children))\n\t\t}\n\t})\n}\n\nfunc TestBudgetCompositeCost(t *testing.T) {\n\tt.Run(\"sums children cost\", func(t *testing.T) {\n\t\troot := &BudgetComposite{\n\t\t\tName: \"root\",\n\t\t\tChildren: []BudgetComponent{\n\t\t\t\tcomponentStub{value: 10},\n\t\t\t\tcomponentStub{value: 20},\n\t\t\t},\n\t\t}\n\t\tif got := root.Cost(); got != 30 {\n\t\t\tt.Fatalf(\"expected 30, got %d\", got)\n\t\t}\n\t})\n\n\tt.Run(\"handles nested composites\", func(t *testing.T) {\n\t\tleaf := componentStub{value: 7}\n\t\tchild := &BudgetComposite{\n\t\t\tName:     \"child\",\n\t\t\tChildren: []BudgetComponent{leaf},\n\t\t}\n\t\troot := &BudgetComposite{\n\t\t\tName:     \"root\",\n\t\t\tChildren: []BudgetComponent{componentStub{value: 3}, child},\n\t\t}\n\t\tif got := root.Cost(); got != 10 {\n\t\t\tt.Fatalf(\"expected 10, got %d\", got)\n\t\t}\n\t})\n\n\tt.Run(\"supports nil receiver\", func(t *testing.T) {\n\t\tvar root *BudgetComposite\n\t\tif got := root.Cost(); got != 0 {\n\t\t\tt.Fatalf(\"nil composite must cost 0, got %d\", got)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "composite",
          "patterns",
          "structural"
        ],
        "order": 0
      },
      {
        "package": "composite",
        "slug": "go-composite-cost",
        "title": "реализуйте метод Cost, рекурсивно суммирующий стоимость всех детей.",
        "description": "Task 2 (easy+): реализуйте метод Cost, рекурсивно суммирующий стоимость всех детей.\nПодсказка: пропускайте nil-детей, вызывайте Cost() у каждого компонента и обрабатывайте пустой список.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of реализуйте метод Cost, рекурсивно суммирующий стоимость всех детей..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport \"strings\"\n\n// BudgetComponent описывает лист или составной элемент дерева бюджета.\ntype BudgetComponent interface {\n\tCost() int\n}\n\n// BudgetComposite реализует компонент, агрегирующий дочерние элементы.\ntype BudgetComposite struct {\n\tName     string\n\tChildren []BudgetComponent\n}\n\n// Task 1 (easy): реализуйте конструктор композита, который копирует входной срез и фильтрует nil-детей.\n// Подсказка: нормализуйте имя (TrimSpace) и всегда выделяйте новый срез Children.\nfunc NewBudgetComposite(name string, children ...BudgetComponent) *BudgetComposite {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): реализуйте метод Cost, рекурсивно суммирующий стоимость всех детей.\n// Подсказка: пропускайте nil-детей, вызывайте Cost() у каждого компонента и обрабатывайте пустой список.\nfunc (c *BudgetComposite) Cost() int {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport \"strings\"\n\nfunc NewBudgetComposite(name string, children ...BudgetComponent) *BudgetComposite { // Конструктор BudgetComposite.\n\ttrimmed := strings.TrimSpace(name)                    // Нормализуем имя компонента.\n\tfiltered := make([]BudgetComponent, 0, len(children)) // Готовим срез для детей.\n\tfor _, child := range children {                      // Проходим по всем входным детям.\n\t\tif child == nil { // Пропускаем отсутствующих детей.\n\t\t\tcontinue // Переходим к следующему.\n\t\t}\n\t\tfiltered = append(filtered, child) // Сохраняем валидного ребёнка.\n\t}\n\treturn &BudgetComposite{ // Собираем структуру.\n\t\tName:     trimmed,  // Сохраняем имя.\n\t\tChildren: filtered, // Кладём копию среза детей.\n\t} // Возвращаем готовый композит.\n}\n\nfunc (c *BudgetComposite) Cost() int { // Cost суммирует стоимость детей.\n\tif c == nil { // Nil-композит стоит 0.\n\t\treturn 0 // Возвращаем ноль.\n\t}\n\ttotal := 0                         // Инициализируем аккумулятор.\n\tfor _, child := range c.Children { // Обходим дочерние компоненты.\n\t\tif child == nil { // Пропускаем nil-ссылки.\n\t\t\tcontinue // Идём дальше.\n\t\t}\n\t\ttotal += child.Cost() // Добавляем стоимость ребёнка (лист или подкомпозит).\n\t}\n\treturn total // Возвращаем суммарную стоимость.\n}\n",
        "testCode": "package structural\n\nimport \"testing\"\n\ntype componentStub struct {\n\tvalue int\n}\n\nfunc (s componentStub) Cost() int {\n\treturn s.value\n}\n\nfunc TestNewBudgetComposite(t *testing.T) {\n\tt.Run(\"copies children slice and trims name\", func(t *testing.T) {\n\t\tchild := componentStub{value: 30}\n\t\tcomposite := NewBudgetComposite(\"  ops  \", child)\n\t\tif composite == nil {\n\t\t\tt.Fatalf(\"expected composite instance\")\n\t\t}\n\t\tif composite.Name != \"ops\" {\n\t\t\tt.Fatalf(\"expected trimmed name, got %q\", composite.Name)\n\t\t}\n\t\tif len(composite.Children) != 1 {\n\t\t\tt.Fatalf(\"expected child copy, got %d\", len(composite.Children))\n\t\t}\n\t\tif &composite.Children[0] == nil {\n\t\t\tt.Fatalf(\"child pointer should not be nil\")\n\t\t}\n\t})\n\n\tt.Run(\"filters nil children\", func(t *testing.T) {\n\t\tcomposite := NewBudgetComposite(\"team\", nil, componentStub{value: 10})\n\t\tif len(composite.Children) != 1 {\n\t\t\tt.Fatalf(\"expected only non-nil children to be stored, got %d\", len(composite.Children))\n\t\t}\n\t})\n\n\tt.Run(\"always allocates child slice\", func(t *testing.T) {\n\t\tcomposite := NewBudgetComposite(\"empty\")\n\t\tif composite.Children == nil {\n\t\t\tt.Fatalf(\"children slice must not be nil\")\n\t\t}\n\t\tif len(composite.Children) != 0 {\n\t\t\tt.Fatalf(\"expected no children by default, got %d\", len(composite.Children))\n\t\t}\n\t})\n}\n\nfunc TestBudgetCompositeCost(t *testing.T) {\n\tt.Run(\"sums children cost\", func(t *testing.T) {\n\t\troot := &BudgetComposite{\n\t\t\tName: \"root\",\n\t\t\tChildren: []BudgetComponent{\n\t\t\t\tcomponentStub{value: 10},\n\t\t\t\tcomponentStub{value: 20},\n\t\t\t},\n\t\t}\n\t\tif got := root.Cost(); got != 30 {\n\t\t\tt.Fatalf(\"expected 30, got %d\", got)\n\t\t}\n\t})\n\n\tt.Run(\"handles nested composites\", func(t *testing.T) {\n\t\tleaf := componentStub{value: 7}\n\t\tchild := &BudgetComposite{\n\t\t\tName:     \"child\",\n\t\t\tChildren: []BudgetComponent{leaf},\n\t\t}\n\t\troot := &BudgetComposite{\n\t\t\tName:     \"root\",\n\t\t\tChildren: []BudgetComponent{componentStub{value: 3}, child},\n\t\t}\n\t\tif got := root.Cost(); got != 10 {\n\t\t\tt.Fatalf(\"expected 10, got %d\", got)\n\t\t}\n\t})\n\n\tt.Run(\"supports nil receiver\", func(t *testing.T) {\n\t\tvar root *BudgetComposite\n\t\tif got := root.Cost(); got != 0 {\n\t\t\tt.Fatalf(\"nil composite must cost 0, got %d\", got)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "composite",
          "patterns",
          "structural"
        ],
        "order": 1
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-decorator",
    "tasks": [
      {
        "package": "decorator",
        "slug": "go-decorator-newinstrumentedstorage",
        "title": "создайте декоратор, который валидирует базовое хранилище и подставляет no-op зависимости.",
        "description": "Task 1 (easy): создайте декоратор, который валидирует базовое хранилище и подставляет no-op зависимости.\nПодсказка: верните nil, если базы нет, и заверните logger/metrics в no-op реализации, чтобы не проверять их в Save.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of создайте декоратор, который валидирует базовое хранилище и подставляет no-op зависимости..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\t// ErrMissingBaseStorage сигнализирует об отсутствии базового компонента.\n\tErrMissingBaseStorage = errors.New(\"base storage is nil\")\n)\n\n// Storage — базовый интерфейс, который нужно оборачивать декораторами.\ntype Storage interface {\n\tSave(ctx context.Context, key string, payload []byte) error\n}\n\n// AuditLogger пишет операции сохранения.\ntype AuditLogger interface {\n\tRecord(entry string)\n}\n\n// MetricsCollector снимает метрики по вызовам.\ntype MetricsCollector interface {\n\tObserveWrite(key string, size int)\n}\n\n// InstrumentedStorage — декоратор, добавляющий аудит и метрики поверх Storage.\ntype InstrumentedStorage struct {\n\tBase    Storage\n\tLogger  AuditLogger\n\tMetrics MetricsCollector\n}\n\n// Task 1 (easy): создайте декоратор, который валидирует базовое хранилище и подставляет no-op зависимости.\n// Подсказка: верните nil, если базы нет, и заверните logger/metrics в no-op реализации, чтобы не проверять их в Save.\nfunc NewInstrumentedStorage(base Storage, logger AuditLogger, metrics MetricsCollector) Storage {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте Save, который логирует попытку, вызывает Base.Save и снимает метрики с учётом ошибок.\n// Подсказка: проверяйте context, логируйте start/finish (fmt.Sprintf) и в случае ошибки добавляйте суффикс \":error\".\nfunc (s *InstrumentedStorage) Save(ctx context.Context, key string, payload []byte) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\ntype noopLogger struct{} // noopLogger — AuditLogger по умолчанию.\n\nfunc (noopLogger) Record(string) {} // Record ничего не делает.\n\ntype noopMetrics struct{} // noopMetrics — MetricsCollector по умолчанию.\n\nfunc (noopMetrics) ObserveWrite(string, int) {} // ObserveWrite игнорирует вызов.\n\nfunc NewInstrumentedStorage(base Storage, logger AuditLogger, metrics MetricsCollector) Storage { // Конструктор декоратора.\n\tif base == nil { // Без базового хранилища декоратор не нужен.\n\t\treturn nil // Возвращаем nil.\n\t}\n\tif logger == nil { // Если логгер не передан...\n\t\tlogger = noopLogger{} // ...используем no-op реализацию.\n\t}\n\tif metrics == nil { // Аналогично для метрик.\n\t\tmetrics = noopMetrics{} // Подставляем no-op.\n\t}\n\treturn &InstrumentedStorage{ // Собираем декоратор.\n\t\tBase:    base,    // Сохраняем базовый storage.\n\t\tLogger:  logger,  // Сохраняем логгер.\n\t\tMetrics: metrics, // Сохраняем метрики.\n\t} // Возвращаем готовую обёртку.\n}\n\nfunc (s *InstrumentedStorage) Save(ctx context.Context, key string, payload []byte) error { // Save добавляет логи и метрики.\n\tif ctx == nil { // Обрабатываем nil-context.\n\t\tctx = context.Background() // Заменяем на фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену контекста.\n\t\treturn err // Немедленно возвращаем ошибку.\n\t}\n\tif s == nil || s.Base == nil { // Без базового storage работать нельзя.\n\t\treturn ErrMissingBaseStorage // Сообщаем об ошибке конфигурации.\n\t}\n\tlogger := s.Logger // Берём логгер из структуры.\n\tif logger == nil { // Если он не задан...\n\t\tlogger = noopLogger{} // ...обеспечиваем no-op.\n\t}\n\tmetrics := s.Metrics // Аналогично обрабатываем метрики.\n\tif metrics == nil {\n\t\tmetrics = noopMetrics{}\n\t}\n\tlogger.Record(fmt.Sprintf(\"start:%s\", key)) // Логируем старт операции.\n\terr := s.Base.Save(ctx, key, payload)       // Делегируем вызов базовому storage.\n\tsuffix := \"\"                                // Готовим суффикс статуса.\n\tif err != nil {                             // Если произошла ошибка...\n\t\tsuffix = \":error\" // ...добавим её в лог.\n\t}\n\tlogger.Record(fmt.Sprintf(\"finish:%s%s\", key, suffix)) // Пишем завершение операции.\n\tmetrics.ObserveWrite(key, len(payload))                // Снимаем метрику по размеру payload.\n\tif err != nil {                                        // Если база вернула ошибку...\n\t\treturn fmt.Errorf(\"storage save: %w\", err) // ...оборачиваем и возвращаем её.\n\t}\n\treturn nil // Операция прошла успешно.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\ntype storageStub struct {\n\terr   error\n\tcalls []string\n}\n\nfunc (s *storageStub) Save(_ context.Context, key string, payload []byte) error {\n\ts.calls = append(s.calls, fmt.Sprintf(\"%s:%d\", key, len(payload)))\n\treturn s.err\n}\n\ntype auditLoggerStub struct {\n\tentries []string\n}\n\nfunc (l *auditLoggerStub) Record(entry string) {\n\tl.entries = append(l.entries, entry)\n}\n\ntype metricsStub struct {\n\tsamples []struct {\n\t\tkey  string\n\t\tsize int\n\t}\n}\n\nfunc (m *metricsStub) ObserveWrite(key string, size int) {\n\tm.samples = append(m.samples, struct {\n\t\tkey  string\n\t\tsize int\n\t}{key: key, size: size})\n}\n\nfunc TestNewInstrumentedStorage(t *testing.T) {\n\tt.Run(\"wraps base storage and keeps dependencies\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\n\t\tstorage := NewInstrumentedStorage(base, logger, metrics)\n\t\tif storage == nil {\n\t\t\tt.Fatalf(\"expected decorator instance\")\n\t\t}\n\t\tinst, ok := storage.(*InstrumentedStorage)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected *InstrumentedStorage, got %T\", storage)\n\t\t}\n\t\tif inst.Base != base || inst.Logger != logger || inst.Metrics != metrics {\n\t\t\tt.Fatalf(\"dependencies should be stored intact\")\n\t\t}\n\t})\n\n\tt.Run(\"returns nil when base missing\", func(t *testing.T) {\n\t\tif storage := NewInstrumentedStorage(nil, nil, nil); storage != nil {\n\t\t\tt.Fatalf(\"expected nil storage for missing base\")\n\t\t}\n\t})\n\n\tt.Run(\"installs no-op dependencies when logger or metrics missing\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tstorage := NewInstrumentedStorage(base, nil, nil)\n\t\tinst := storage.(*InstrumentedStorage)\n\t\tif inst.Logger == nil || inst.Metrics == nil {\n\t\t\tt.Fatalf(\"decorator must set fallback logger/metrics\")\n\t\t}\n\t})\n}\n\nfunc TestInstrumentedStorageSave(t *testing.T) {\n\tt.Run(\"logs lifecycle and records metrics\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\t\tstorage := &InstrumentedStorage{Base: base, Logger: logger, Metrics: metrics}\n\n\t\tpayload := []byte(\"hello\")\n\t\tif err := storage.Save(context.Background(), \"file.txt\", payload); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif got := logger.entries; len(got) != 2 || got[0] != \"start:file.txt\" || got[1] != \"finish:file.txt\" {\n\t\t\tt.Fatalf(\"unexpected log entries: %v\", got)\n\t\t}\n\t\tif len(metrics.samples) != 1 || metrics.samples[0].size != len(payload) {\n\t\t\tt.Fatalf(\"metrics should observe payload size, got %v\", metrics.samples)\n\t\t}\n\t})\n\n\tt.Run(\"returns context error before invoking base\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\t\tstorage := &InstrumentedStorage{Base: base, Logger: logger, Metrics: metrics}\n\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := storage.Save(ctx, \"file.txt\", []byte(\"x\"))\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(base.calls) != 0 {\n\t\t\tt.Fatalf(\"base storage must not be invoked on canceled context\")\n\t\t}\n\t})\n\n\tt.Run(\"logs error suffix and propagates failure\", func(t *testing.T) {\n\t\tbase := &storageStub{err: errors.New(\"disk full\")}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\t\tstorage := &InstrumentedStorage{Base: base, Logger: logger, Metrics: metrics}\n\n\t\terr := storage.Save(context.Background(), \"file.txt\", []byte(\"x\"))\n\t\tif !errors.Is(err, base.err) {\n\t\t\tt.Fatalf(\"expected wrapped base error, got %v\", err)\n\t\t}\n\t\tif len(logger.entries) != 2 || logger.entries[1] != \"finish:file.txt:error\" {\n\t\t\tt.Fatalf(\"finish log must contain :error suffix, got %v\", logger.entries)\n\t\t}\n\t\tif len(metrics.samples) != 1 {\n\t\t\tt.Fatalf(\"metrics must still observe attempt, got %v\", metrics.samples)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "decorator",
          "patterns",
          "structural"
        ],
        "order": 0
      },
      {
        "package": "decorator",
        "slug": "go-decorator-save",
        "title": "реализуйте Save, который логирует попытку, вызывает Base.Save и снимает метрики с учётом ошибок.",
        "description": "Task 2 (medium): реализуйте Save, который логирует попытку, вызывает Base.Save и снимает метрики с учётом ошибок.\nПодсказка: проверяйте context, логируйте start/finish (fmt.Sprintf) и в случае ошибки добавляйте суффикс \":error\".",
        "difficulty": "medium",
        "hint1": "Think about the core concept of реализуйте Save, который логирует попытку, вызывает Base.Save и снимает метрики с учётом ошибок..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\t// ErrMissingBaseStorage сигнализирует об отсутствии базового компонента.\n\tErrMissingBaseStorage = errors.New(\"base storage is nil\")\n)\n\n// Storage — базовый интерфейс, который нужно оборачивать декораторами.\ntype Storage interface {\n\tSave(ctx context.Context, key string, payload []byte) error\n}\n\n// AuditLogger пишет операции сохранения.\ntype AuditLogger interface {\n\tRecord(entry string)\n}\n\n// MetricsCollector снимает метрики по вызовам.\ntype MetricsCollector interface {\n\tObserveWrite(key string, size int)\n}\n\n// InstrumentedStorage — декоратор, добавляющий аудит и метрики поверх Storage.\ntype InstrumentedStorage struct {\n\tBase    Storage\n\tLogger  AuditLogger\n\tMetrics MetricsCollector\n}\n\n// Task 1 (easy): создайте декоратор, который валидирует базовое хранилище и подставляет no-op зависимости.\n// Подсказка: верните nil, если базы нет, и заверните logger/metrics в no-op реализации, чтобы не проверять их в Save.\nfunc NewInstrumentedStorage(base Storage, logger AuditLogger, metrics MetricsCollector) Storage {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте Save, который логирует попытку, вызывает Base.Save и снимает метрики с учётом ошибок.\n// Подсказка: проверяйте context, логируйте start/finish (fmt.Sprintf) и в случае ошибки добавляйте суффикс \":error\".\nfunc (s *InstrumentedStorage) Save(ctx context.Context, key string, payload []byte) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\ntype noopLogger struct{} // noopLogger — AuditLogger по умолчанию.\n\nfunc (noopLogger) Record(string) {} // Record ничего не делает.\n\ntype noopMetrics struct{} // noopMetrics — MetricsCollector по умолчанию.\n\nfunc (noopMetrics) ObserveWrite(string, int) {} // ObserveWrite игнорирует вызов.\n\nfunc NewInstrumentedStorage(base Storage, logger AuditLogger, metrics MetricsCollector) Storage { // Конструктор декоратора.\n\tif base == nil { // Без базового хранилища декоратор не нужен.\n\t\treturn nil // Возвращаем nil.\n\t}\n\tif logger == nil { // Если логгер не передан...\n\t\tlogger = noopLogger{} // ...используем no-op реализацию.\n\t}\n\tif metrics == nil { // Аналогично для метрик.\n\t\tmetrics = noopMetrics{} // Подставляем no-op.\n\t}\n\treturn &InstrumentedStorage{ // Собираем декоратор.\n\t\tBase:    base,    // Сохраняем базовый storage.\n\t\tLogger:  logger,  // Сохраняем логгер.\n\t\tMetrics: metrics, // Сохраняем метрики.\n\t} // Возвращаем готовую обёртку.\n}\n\nfunc (s *InstrumentedStorage) Save(ctx context.Context, key string, payload []byte) error { // Save добавляет логи и метрики.\n\tif ctx == nil { // Обрабатываем nil-context.\n\t\tctx = context.Background() // Заменяем на фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену контекста.\n\t\treturn err // Немедленно возвращаем ошибку.\n\t}\n\tif s == nil || s.Base == nil { // Без базового storage работать нельзя.\n\t\treturn ErrMissingBaseStorage // Сообщаем об ошибке конфигурации.\n\t}\n\tlogger := s.Logger // Берём логгер из структуры.\n\tif logger == nil { // Если он не задан...\n\t\tlogger = noopLogger{} // ...обеспечиваем no-op.\n\t}\n\tmetrics := s.Metrics // Аналогично обрабатываем метрики.\n\tif metrics == nil {\n\t\tmetrics = noopMetrics{}\n\t}\n\tlogger.Record(fmt.Sprintf(\"start:%s\", key)) // Логируем старт операции.\n\terr := s.Base.Save(ctx, key, payload)       // Делегируем вызов базовому storage.\n\tsuffix := \"\"                                // Готовим суффикс статуса.\n\tif err != nil {                             // Если произошла ошибка...\n\t\tsuffix = \":error\" // ...добавим её в лог.\n\t}\n\tlogger.Record(fmt.Sprintf(\"finish:%s%s\", key, suffix)) // Пишем завершение операции.\n\tmetrics.ObserveWrite(key, len(payload))                // Снимаем метрику по размеру payload.\n\tif err != nil {                                        // Если база вернула ошибку...\n\t\treturn fmt.Errorf(\"storage save: %w\", err) // ...оборачиваем и возвращаем её.\n\t}\n\treturn nil // Операция прошла успешно.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n)\n\ntype storageStub struct {\n\terr   error\n\tcalls []string\n}\n\nfunc (s *storageStub) Save(_ context.Context, key string, payload []byte) error {\n\ts.calls = append(s.calls, fmt.Sprintf(\"%s:%d\", key, len(payload)))\n\treturn s.err\n}\n\ntype auditLoggerStub struct {\n\tentries []string\n}\n\nfunc (l *auditLoggerStub) Record(entry string) {\n\tl.entries = append(l.entries, entry)\n}\n\ntype metricsStub struct {\n\tsamples []struct {\n\t\tkey  string\n\t\tsize int\n\t}\n}\n\nfunc (m *metricsStub) ObserveWrite(key string, size int) {\n\tm.samples = append(m.samples, struct {\n\t\tkey  string\n\t\tsize int\n\t}{key: key, size: size})\n}\n\nfunc TestNewInstrumentedStorage(t *testing.T) {\n\tt.Run(\"wraps base storage and keeps dependencies\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\n\t\tstorage := NewInstrumentedStorage(base, logger, metrics)\n\t\tif storage == nil {\n\t\t\tt.Fatalf(\"expected decorator instance\")\n\t\t}\n\t\tinst, ok := storage.(*InstrumentedStorage)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"expected *InstrumentedStorage, got %T\", storage)\n\t\t}\n\t\tif inst.Base != base || inst.Logger != logger || inst.Metrics != metrics {\n\t\t\tt.Fatalf(\"dependencies should be stored intact\")\n\t\t}\n\t})\n\n\tt.Run(\"returns nil when base missing\", func(t *testing.T) {\n\t\tif storage := NewInstrumentedStorage(nil, nil, nil); storage != nil {\n\t\t\tt.Fatalf(\"expected nil storage for missing base\")\n\t\t}\n\t})\n\n\tt.Run(\"installs no-op dependencies when logger or metrics missing\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tstorage := NewInstrumentedStorage(base, nil, nil)\n\t\tinst := storage.(*InstrumentedStorage)\n\t\tif inst.Logger == nil || inst.Metrics == nil {\n\t\t\tt.Fatalf(\"decorator must set fallback logger/metrics\")\n\t\t}\n\t})\n}\n\nfunc TestInstrumentedStorageSave(t *testing.T) {\n\tt.Run(\"logs lifecycle and records metrics\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\t\tstorage := &InstrumentedStorage{Base: base, Logger: logger, Metrics: metrics}\n\n\t\tpayload := []byte(\"hello\")\n\t\tif err := storage.Save(context.Background(), \"file.txt\", payload); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif got := logger.entries; len(got) != 2 || got[0] != \"start:file.txt\" || got[1] != \"finish:file.txt\" {\n\t\t\tt.Fatalf(\"unexpected log entries: %v\", got)\n\t\t}\n\t\tif len(metrics.samples) != 1 || metrics.samples[0].size != len(payload) {\n\t\t\tt.Fatalf(\"metrics should observe payload size, got %v\", metrics.samples)\n\t\t}\n\t})\n\n\tt.Run(\"returns context error before invoking base\", func(t *testing.T) {\n\t\tbase := &storageStub{}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\t\tstorage := &InstrumentedStorage{Base: base, Logger: logger, Metrics: metrics}\n\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := storage.Save(ctx, \"file.txt\", []byte(\"x\"))\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(base.calls) != 0 {\n\t\t\tt.Fatalf(\"base storage must not be invoked on canceled context\")\n\t\t}\n\t})\n\n\tt.Run(\"logs error suffix and propagates failure\", func(t *testing.T) {\n\t\tbase := &storageStub{err: errors.New(\"disk full\")}\n\t\tlogger := &auditLoggerStub{}\n\t\tmetrics := &metricsStub{}\n\t\tstorage := &InstrumentedStorage{Base: base, Logger: logger, Metrics: metrics}\n\n\t\terr := storage.Save(context.Background(), \"file.txt\", []byte(\"x\"))\n\t\tif !errors.Is(err, base.err) {\n\t\t\tt.Fatalf(\"expected wrapped base error, got %v\", err)\n\t\t}\n\t\tif len(logger.entries) != 2 || logger.entries[1] != \"finish:file.txt:error\" {\n\t\t\tt.Fatalf(\"finish log must contain :error suffix, got %v\", logger.entries)\n\t\t}\n\t\tif len(metrics.samples) != 1 {\n\t\t\tt.Fatalf(\"metrics must still observe attempt, got %v\", metrics.samples)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "decorator",
          "patterns",
          "structural"
        ],
        "order": 1
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-facade",
    "tasks": [
      {
        "package": "facade",
        "slug": "go-facade-neworderfacade",
        "title": "соберите OrderFacade и провалидируйте обязательные зависимости.",
        "description": "Task 1 (easy): соберите OrderFacade и провалидируйте обязательные зависимости.\nПодсказка: возвращайте осмысленные ошибки и позволяйте отсутствовать NotificationService (по желанию).",
        "difficulty": "easy",
        "hint1": "Think about the core concept of соберите OrderFacade и провалидируйте обязательные зависимости..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\t// ErrMissingPaymentService сообщает о незаполненной зависимости оплаты.\n\tErrMissingPaymentService = errors.New(\"payment service is nil\")\n\t// ErrMissingInventoryService сообщает об отсутствии склада.\n\tErrMissingInventoryService = errors.New(\"inventory service is nil\")\n\t// ErrMissingNotificationService сообщает об отсутствии уведомлений.\n\tErrMissingNotificationService = errors.New(\"notification service is nil\")\n)\n\n// PaymentService отвечает за списание средств по заказу.\ntype PaymentService interface {\n\tCharge(ctx context.Context, orderID string, amount Money) error\n}\n\n// InventoryService резервирует и освобождает товары.\ntype InventoryService interface {\n\tReserve(ctx context.Context, sku string, qty int) error\n\tRelease(ctx context.Context, sku string, qty int)\n}\n\n// NotificationService отправляет письма клиенту.\ntype NotificationService interface {\n\tSendOrderConfirmation(ctx context.Context, orderID string, email string) error\n}\n\n// OrderRequest описывает входные данные фасада.\ntype OrderRequest struct {\n\tOrderID       string\n\tSKU           string\n\tQuantity      int\n\tAmount        Money\n\tCustomerEmail string\n}\n\n// OrderFacade объединяет подсистемы в единый сценарий.\ntype OrderFacade struct {\n\tPayment       PaymentService\n\tInventory     InventoryService\n\tNotifications NotificationService\n}\n\n// Task 1 (easy): соберите OrderFacade и провалидируйте обязательные зависимости.\n// Подсказка: возвращайте осмысленные ошибки и позволяйте отсутствовать NotificationService (по желанию).\nfunc NewOrderFacade(payment PaymentService, inventory InventoryService, notifications NotificationService) (*OrderFacade, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте ProcessOrder, который резервирует товар, списывает оплату и отправляет уведомление.\n// Подсказка: при ошибке оплаты освободите резерв, оборачивайте ошибки через fmt.Errorf и проверяйте context перед каждой подсистемой.\nfunc (f *OrderFacade) ProcessOrder(ctx context.Context, req OrderRequest) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\nfunc NewOrderFacade(payment PaymentService, inventory InventoryService, notifications NotificationService) (*OrderFacade, error) { // Конструктор фасада.\n\tif payment == nil { // Проверяем обязательный сервис оплаты.\n\t\treturn nil, ErrMissingPaymentService // Возвращаем соответствующую ошибку.\n\t}\n\tif inventory == nil { // Без склада фасад не сможет резервировать товары.\n\t\treturn nil, ErrMissingInventoryService // Сообщаем об ошибке зависимости.\n\t}\n\treturn &OrderFacade{ // Собираем фасад.\n\t\tPayment:       payment,       // Сохраняем сервис оплаты.\n\t\tInventory:     inventory,     // Сохраняем сервис склада.\n\t\tNotifications: notifications, // Уведомления опциональны.\n\t}, nil // Возвращаем готовый объект.\n}\n\nfunc (f *OrderFacade) ProcessOrder(ctx context.Context, req OrderRequest) error { // ProcessOrder координирует подсистемы.\n\tif ctx == nil { // Обрабатываем nil-context.\n\t\tctx = context.Background() // Используем фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену заранее.\n\t\treturn err // Возвращаем ошибку контекста.\n\t}\n\tif f == nil || f.Payment == nil { // Без сервисов нет смысла продолжать.\n\t\treturn ErrMissingPaymentService // Сообщаем об ошибке конфигурации.\n\t}\n\tif f.Inventory == nil { // Аналогичная проверка склада.\n\t\treturn ErrMissingInventoryService // Возвращаем ошибку.\n\t}\n\tif err := f.Inventory.Reserve(ctx, req.SKU, req.Quantity); err != nil { // Пытаемся зарезервировать товар.\n\t\treturn fmt.Errorf(\"inventory reserve: %w\", err) // Оборачиваем ошибку склада.\n\t}\n\treleaseNeeded := true // Помечаем, что нужно освобождение при ошибке.\n\tdefer func() {        // Обеспечиваем освобождение резерва на выходе.\n\t\tif releaseNeeded { // Только если операция не дошла до успешного конца.\n\t\t\tf.Inventory.Release(ctx, req.SKU, req.Quantity) // Снимаем резерв.\n\t\t}\n\t}() // Немедленно регистрируем defer.\n\tif err := f.Payment.Charge(ctx, req.OrderID, req.Amount); err != nil { // Списываем оплату.\n\t\treturn fmt.Errorf(\"payment charge: %w\", err) // Сообщаем об ошибке оплаты.\n\t}\n\tif f.Notifications != nil { // Отправляем письмо только при наличии сервиса.\n\t\tif err := f.Notifications.SendOrderConfirmation(ctx, req.OrderID, req.CustomerEmail); err != nil { // Пытаемся уведомить клиента.\n\t\t\treturn fmt.Errorf(\"notification send: %w\", err) // Пробрасываем ошибку уведомлений.\n\t\t}\n\t}\n\treleaseNeeded = false // Все шаги выполнены успешно — не надо освобождать резерв.\n\treturn nil            // Операция завершилась успешно.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"strings\"\n\t\"testing\"\n)\n\ntype paymentStub struct {\n\torderIDs []string\n\tamounts  []Money\n\terr      error\n}\n\nfunc (p *paymentStub) Charge(_ context.Context, orderID string, amount Money) error {\n\tp.orderIDs = append(p.orderIDs, orderID)\n\tp.amounts = append(p.amounts, amount)\n\treturn p.err\n}\n\ntype inventoryStub struct {\n\treserveCalls []struct {\n\t\tsku string\n\t\tqty int\n\t}\n\treleaseCalls []struct {\n\t\tsku string\n\t\tqty int\n\t}\n\treserveErr error\n}\n\nfunc (i *inventoryStub) Reserve(_ context.Context, sku string, qty int) error {\n\ti.reserveCalls = append(i.reserveCalls, struct {\n\t\tsku string\n\t\tqty int\n\t}{sku: sku, qty: qty})\n\treturn i.reserveErr\n}\n\nfunc (i *inventoryStub) Release(_ context.Context, sku string, qty int) {\n\ti.releaseCalls = append(i.releaseCalls, struct {\n\t\tsku string\n\t\tqty int\n\t}{sku: sku, qty: qty})\n}\n\ntype notificationStub struct {\n\torderIDs []string\n\temails   []string\n\terr      error\n}\n\nfunc (n *notificationStub) SendOrderConfirmation(_ context.Context, orderID string, email string) error {\n\tn.orderIDs = append(n.orderIDs, orderID)\n\tn.emails = append(n.emails, email)\n\treturn n.err\n}\n\nfunc TestNewOrderFacade(t *testing.T) {\n\tt.Run(\"returns facade when required dependencies present\", func(t *testing.T) {\n\t\tpayment := &paymentStub{}\n\t\tinventory := &inventoryStub{}\n\t\tfacade, err := NewOrderFacade(payment, inventory, nil)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected no error, got %v\", err)\n\t\t}\n\t\tif facade.Payment != payment || facade.Inventory != inventory {\n\t\t\tt.Fatalf(\"facade must store dependencies\")\n\t\t}\n\t\tif facade.Notifications != nil {\n\t\t\tt.Fatalf(\"notifications should remain nil when omitted\")\n\t\t}\n\t})\n\n\tt.Run(\"fails when payment missing\", func(t *testing.T) {\n\t\t_, err := NewOrderFacade(nil, &inventoryStub{}, nil)\n\t\tif !errors.Is(err, ErrMissingPaymentService) {\n\t\t\tt.Fatalf(\"expected ErrMissingPaymentService, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"fails when inventory missing\", func(t *testing.T) {\n\t\t_, err := NewOrderFacade(&paymentStub{}, nil, nil)\n\t\tif !errors.Is(err, ErrMissingInventoryService) {\n\t\t\tt.Fatalf(\"expected ErrMissingInventoryService, got %v\", err)\n\t\t}\n\t})\n}\n\nfunc TestOrderFacadeProcessOrder(t *testing.T) {\n\tt.Run(\"executes happy path with notification\", func(t *testing.T) {\n\t\tpayment := &paymentStub{}\n\t\tinventory := &inventoryStub{}\n\t\tnotifications := &notificationStub{}\n\t\tfacade := &OrderFacade{\n\t\t\tPayment:       payment,\n\t\t\tInventory:     inventory,\n\t\t\tNotifications: notifications,\n\t\t}\n\t\treq := OrderRequest{\n\t\t\tOrderID:       \"order-1\",\n\t\t\tSKU:           \"sku-1\",\n\t\t\tQuantity:      2,\n\t\t\tAmount:        Money{Amount: 5000, Currency: \"usd\"},\n\t\t\tCustomerEmail: \"user@example.com\",\n\t\t}\n\t\tif err := facade.ProcessOrder(context.Background(), req); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif len(inventory.reserveCalls) != 1 || inventory.reserveCalls[0].sku != \"sku-1\" {\n\t\t\tt.Fatalf(\"inventory reserve not called correctly: %+v\", inventory.reserveCalls)\n\t\t}\n\t\tif len(payment.orderIDs) != 1 || payment.orderIDs[0] != \"order-1\" {\n\t\t\tt.Fatalf(\"payment not charged: %+v\", payment.orderIDs)\n\t\t}\n\t\tif len(notifications.orderIDs) != 1 || notifications.emails[0] != \"user@example.com\" {\n\t\t\tt.Fatalf(\"notification not sent: %+v\", notifications.orderIDs)\n\t\t}\n\t})\n\n\tt.Run(\"releases inventory when payment fails\", func(t *testing.T) {\n\t\tpayment := &paymentStub{err: errors.New(\"card declined\")}\n\t\tinventory := &inventoryStub{}\n\t\tfacade := &OrderFacade{Payment: payment, Inventory: inventory}\n\t\treq := OrderRequest{OrderID: \"order-2\", SKU: \"sku-2\", Quantity: 1, Amount: Money{Amount: 100}}\n\t\terr := facade.ProcessOrder(context.Background(), req)\n\t\tif err == nil || !strings.Contains(err.Error(), \"payment\") {\n\t\t\tt.Fatalf(\"expected payment error, got %v\", err)\n\t\t}\n\t\tif len(inventory.releaseCalls) != 1 || inventory.releaseCalls[0].sku != \"sku-2\" {\n\t\t\tt.Fatalf(\"release must be called on payment failure\")\n\t\t}\n\t})\n\n\tt.Run(\"stops immediately on canceled context\", func(t *testing.T) {\n\t\tpayment := &paymentStub{}\n\t\tinventory := &inventoryStub{}\n\t\tfacade := &OrderFacade{Payment: payment, Inventory: inventory}\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := facade.ProcessOrder(ctx, OrderRequest{OrderID: \"order-3\"})\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(inventory.reserveCalls) != 0 {\n\t\t\tt.Fatalf(\"inventory must not be called when context canceled\")\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "facade",
          "patterns",
          "structural"
        ],
        "order": 0
      },
      {
        "package": "facade",
        "slug": "go-facade-processorder",
        "title": "реализуйте ProcessOrder, который резервирует товар, списывает оплату и отправляет уведомление.",
        "description": "Task 2 (medium): реализуйте ProcessOrder, который резервирует товар, списывает оплату и отправляет уведомление.\nПодсказка: при ошибке оплаты освободите резерв, оборачивайте ошибки через fmt.Errorf и проверяйте context перед каждой подсистемой.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of реализуйте ProcessOrder, который резервирует товар, списывает оплату и отправляет уведомление..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\t// ErrMissingPaymentService сообщает о незаполненной зависимости оплаты.\n\tErrMissingPaymentService = errors.New(\"payment service is nil\")\n\t// ErrMissingInventoryService сообщает об отсутствии склада.\n\tErrMissingInventoryService = errors.New(\"inventory service is nil\")\n\t// ErrMissingNotificationService сообщает об отсутствии уведомлений.\n\tErrMissingNotificationService = errors.New(\"notification service is nil\")\n)\n\n// PaymentService отвечает за списание средств по заказу.\ntype PaymentService interface {\n\tCharge(ctx context.Context, orderID string, amount Money) error\n}\n\n// InventoryService резервирует и освобождает товары.\ntype InventoryService interface {\n\tReserve(ctx context.Context, sku string, qty int) error\n\tRelease(ctx context.Context, sku string, qty int)\n}\n\n// NotificationService отправляет письма клиенту.\ntype NotificationService interface {\n\tSendOrderConfirmation(ctx context.Context, orderID string, email string) error\n}\n\n// OrderRequest описывает входные данные фасада.\ntype OrderRequest struct {\n\tOrderID       string\n\tSKU           string\n\tQuantity      int\n\tAmount        Money\n\tCustomerEmail string\n}\n\n// OrderFacade объединяет подсистемы в единый сценарий.\ntype OrderFacade struct {\n\tPayment       PaymentService\n\tInventory     InventoryService\n\tNotifications NotificationService\n}\n\n// Task 1 (easy): соберите OrderFacade и провалидируйте обязательные зависимости.\n// Подсказка: возвращайте осмысленные ошибки и позволяйте отсутствовать NotificationService (по желанию).\nfunc NewOrderFacade(payment PaymentService, inventory InventoryService, notifications NotificationService) (*OrderFacade, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте ProcessOrder, который резервирует товар, списывает оплату и отправляет уведомление.\n// Подсказка: при ошибке оплаты освободите резерв, оборачивайте ошибки через fmt.Errorf и проверяйте context перед каждой подсистемой.\nfunc (f *OrderFacade) ProcessOrder(ctx context.Context, req OrderRequest) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\nfunc NewOrderFacade(payment PaymentService, inventory InventoryService, notifications NotificationService) (*OrderFacade, error) { // Конструктор фасада.\n\tif payment == nil { // Проверяем обязательный сервис оплаты.\n\t\treturn nil, ErrMissingPaymentService // Возвращаем соответствующую ошибку.\n\t}\n\tif inventory == nil { // Без склада фасад не сможет резервировать товары.\n\t\treturn nil, ErrMissingInventoryService // Сообщаем об ошибке зависимости.\n\t}\n\treturn &OrderFacade{ // Собираем фасад.\n\t\tPayment:       payment,       // Сохраняем сервис оплаты.\n\t\tInventory:     inventory,     // Сохраняем сервис склада.\n\t\tNotifications: notifications, // Уведомления опциональны.\n\t}, nil // Возвращаем готовый объект.\n}\n\nfunc (f *OrderFacade) ProcessOrder(ctx context.Context, req OrderRequest) error { // ProcessOrder координирует подсистемы.\n\tif ctx == nil { // Обрабатываем nil-context.\n\t\tctx = context.Background() // Используем фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену заранее.\n\t\treturn err // Возвращаем ошибку контекста.\n\t}\n\tif f == nil || f.Payment == nil { // Без сервисов нет смысла продолжать.\n\t\treturn ErrMissingPaymentService // Сообщаем об ошибке конфигурации.\n\t}\n\tif f.Inventory == nil { // Аналогичная проверка склада.\n\t\treturn ErrMissingInventoryService // Возвращаем ошибку.\n\t}\n\tif err := f.Inventory.Reserve(ctx, req.SKU, req.Quantity); err != nil { // Пытаемся зарезервировать товар.\n\t\treturn fmt.Errorf(\"inventory reserve: %w\", err) // Оборачиваем ошибку склада.\n\t}\n\treleaseNeeded := true // Помечаем, что нужно освобождение при ошибке.\n\tdefer func() {        // Обеспечиваем освобождение резерва на выходе.\n\t\tif releaseNeeded { // Только если операция не дошла до успешного конца.\n\t\t\tf.Inventory.Release(ctx, req.SKU, req.Quantity) // Снимаем резерв.\n\t\t}\n\t}() // Немедленно регистрируем defer.\n\tif err := f.Payment.Charge(ctx, req.OrderID, req.Amount); err != nil { // Списываем оплату.\n\t\treturn fmt.Errorf(\"payment charge: %w\", err) // Сообщаем об ошибке оплаты.\n\t}\n\tif f.Notifications != nil { // Отправляем письмо только при наличии сервиса.\n\t\tif err := f.Notifications.SendOrderConfirmation(ctx, req.OrderID, req.CustomerEmail); err != nil { // Пытаемся уведомить клиента.\n\t\t\treturn fmt.Errorf(\"notification send: %w\", err) // Пробрасываем ошибку уведомлений.\n\t\t}\n\t}\n\treleaseNeeded = false // Все шаги выполнены успешно — не надо освобождать резерв.\n\treturn nil            // Операция завершилась успешно.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"strings\"\n\t\"testing\"\n)\n\ntype paymentStub struct {\n\torderIDs []string\n\tamounts  []Money\n\terr      error\n}\n\nfunc (p *paymentStub) Charge(_ context.Context, orderID string, amount Money) error {\n\tp.orderIDs = append(p.orderIDs, orderID)\n\tp.amounts = append(p.amounts, amount)\n\treturn p.err\n}\n\ntype inventoryStub struct {\n\treserveCalls []struct {\n\t\tsku string\n\t\tqty int\n\t}\n\treleaseCalls []struct {\n\t\tsku string\n\t\tqty int\n\t}\n\treserveErr error\n}\n\nfunc (i *inventoryStub) Reserve(_ context.Context, sku string, qty int) error {\n\ti.reserveCalls = append(i.reserveCalls, struct {\n\t\tsku string\n\t\tqty int\n\t}{sku: sku, qty: qty})\n\treturn i.reserveErr\n}\n\nfunc (i *inventoryStub) Release(_ context.Context, sku string, qty int) {\n\ti.releaseCalls = append(i.releaseCalls, struct {\n\t\tsku string\n\t\tqty int\n\t}{sku: sku, qty: qty})\n}\n\ntype notificationStub struct {\n\torderIDs []string\n\temails   []string\n\terr      error\n}\n\nfunc (n *notificationStub) SendOrderConfirmation(_ context.Context, orderID string, email string) error {\n\tn.orderIDs = append(n.orderIDs, orderID)\n\tn.emails = append(n.emails, email)\n\treturn n.err\n}\n\nfunc TestNewOrderFacade(t *testing.T) {\n\tt.Run(\"returns facade when required dependencies present\", func(t *testing.T) {\n\t\tpayment := &paymentStub{}\n\t\tinventory := &inventoryStub{}\n\t\tfacade, err := NewOrderFacade(payment, inventory, nil)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected no error, got %v\", err)\n\t\t}\n\t\tif facade.Payment != payment || facade.Inventory != inventory {\n\t\t\tt.Fatalf(\"facade must store dependencies\")\n\t\t}\n\t\tif facade.Notifications != nil {\n\t\t\tt.Fatalf(\"notifications should remain nil when omitted\")\n\t\t}\n\t})\n\n\tt.Run(\"fails when payment missing\", func(t *testing.T) {\n\t\t_, err := NewOrderFacade(nil, &inventoryStub{}, nil)\n\t\tif !errors.Is(err, ErrMissingPaymentService) {\n\t\t\tt.Fatalf(\"expected ErrMissingPaymentService, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"fails when inventory missing\", func(t *testing.T) {\n\t\t_, err := NewOrderFacade(&paymentStub{}, nil, nil)\n\t\tif !errors.Is(err, ErrMissingInventoryService) {\n\t\t\tt.Fatalf(\"expected ErrMissingInventoryService, got %v\", err)\n\t\t}\n\t})\n}\n\nfunc TestOrderFacadeProcessOrder(t *testing.T) {\n\tt.Run(\"executes happy path with notification\", func(t *testing.T) {\n\t\tpayment := &paymentStub{}\n\t\tinventory := &inventoryStub{}\n\t\tnotifications := &notificationStub{}\n\t\tfacade := &OrderFacade{\n\t\t\tPayment:       payment,\n\t\t\tInventory:     inventory,\n\t\t\tNotifications: notifications,\n\t\t}\n\t\treq := OrderRequest{\n\t\t\tOrderID:       \"order-1\",\n\t\t\tSKU:           \"sku-1\",\n\t\t\tQuantity:      2,\n\t\t\tAmount:        Money{Amount: 5000, Currency: \"usd\"},\n\t\t\tCustomerEmail: \"user@example.com\",\n\t\t}\n\t\tif err := facade.ProcessOrder(context.Background(), req); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif len(inventory.reserveCalls) != 1 || inventory.reserveCalls[0].sku != \"sku-1\" {\n\t\t\tt.Fatalf(\"inventory reserve not called correctly: %+v\", inventory.reserveCalls)\n\t\t}\n\t\tif len(payment.orderIDs) != 1 || payment.orderIDs[0] != \"order-1\" {\n\t\t\tt.Fatalf(\"payment not charged: %+v\", payment.orderIDs)\n\t\t}\n\t\tif len(notifications.orderIDs) != 1 || notifications.emails[0] != \"user@example.com\" {\n\t\t\tt.Fatalf(\"notification not sent: %+v\", notifications.orderIDs)\n\t\t}\n\t})\n\n\tt.Run(\"releases inventory when payment fails\", func(t *testing.T) {\n\t\tpayment := &paymentStub{err: errors.New(\"card declined\")}\n\t\tinventory := &inventoryStub{}\n\t\tfacade := &OrderFacade{Payment: payment, Inventory: inventory}\n\t\treq := OrderRequest{OrderID: \"order-2\", SKU: \"sku-2\", Quantity: 1, Amount: Money{Amount: 100}}\n\t\terr := facade.ProcessOrder(context.Background(), req)\n\t\tif err == nil || !strings.Contains(err.Error(), \"payment\") {\n\t\t\tt.Fatalf(\"expected payment error, got %v\", err)\n\t\t}\n\t\tif len(inventory.releaseCalls) != 1 || inventory.releaseCalls[0].sku != \"sku-2\" {\n\t\t\tt.Fatalf(\"release must be called on payment failure\")\n\t\t}\n\t})\n\n\tt.Run(\"stops immediately on canceled context\", func(t *testing.T) {\n\t\tpayment := &paymentStub{}\n\t\tinventory := &inventoryStub{}\n\t\tfacade := &OrderFacade{Payment: payment, Inventory: inventory}\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\terr := facade.ProcessOrder(ctx, OrderRequest{OrderID: \"order-3\"})\n\t\tif !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(inventory.reserveCalls) != 0 {\n\t\t\tt.Fatalf(\"inventory must not be called when context canceled\")\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "facade",
          "patterns",
          "structural"
        ],
        "order": 1
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-flyweight",
    "tasks": [
      {
        "package": "flyweight",
        "slug": "go-flyweight-newiconfactory",
        "title": "реализуйте фабрику, валидирующую loader и создающую кеш.",
        "description": "Task 1 (easy): реализуйте фабрику, валидирующую loader и создающую кеш.\nПодсказка: верните ошибку при nil loader и выделите map для будущих IconModel.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of реализуйте фабрику, валидирующую loader и создающую кеш..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\nvar (\n\t// ErrMissingIconLoader сигнализирует о неинициализированном загрузчике.\n\tErrMissingIconLoader = errors.New(\"icon loader is nil\")\n)\n\n// IconSpec описывает внешнее состояние иконки.\ntype IconSpec struct {\n\tName  string\n\tColor string\n\tSize  int\n}\n\n// IconModel — разделяемая часть состояния (данные иконки).\ntype IconModel struct {\n\tSpec IconSpec\n\tData []byte\n}\n\n// IconLoader загружает IconModel из внешнего источника.\ntype IconLoader interface {\n\tLoad(spec IconSpec) ([]byte, error)\n}\n\n// IconFactory управляет пулом IconModel (flyweight).\ntype IconFactory struct {\n\tloader IconLoader\n\tcache  map[string]*IconModel\n\tmu     sync.RWMutex\n}\n\n// Task 1 (easy): реализуйте фабрику, валидирующую loader и создающую кеш.\n// Подсказка: верните ошибку при nil loader и выделите map для будущих IconModel.\nfunc NewIconFactory(loader IconLoader) (*IconFactory, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте GetIcon, который ищет легковес в кеше или загружает через loader.\n// Подсказка: используйте двойную проверку с RWMutex, формируйте ключ как комбинацию полей IconSpec и кешируйте успешный результат.\nfunc (f *IconFactory) GetIcon(spec IconSpec) (*IconModel, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport \"fmt\"\n\nfunc iconCacheKey(spec IconSpec) string { // iconCacheKey собирает уникальный ключ.\n\treturn fmt.Sprintf(\"%s|%s|%d\", spec.Name, spec.Color, spec.Size) // Конкатенируем поля через разделитель.\n}\n\nfunc NewIconFactory(loader IconLoader) (*IconFactory, error) { // Конструктор IconFactory.\n\tif loader == nil { // Проверяем обязательную зависимость.\n\t\treturn nil, ErrMissingIconLoader // Возвращаем ошибку.\n\t}\n\treturn &IconFactory{ // Создаём фабрику.\n\t\tloader: loader,                      // Сохраняем загрузчик.\n\t\tcache:  make(map[string]*IconModel), // Инициализируем кеш.\n\t}, nil // Возвращаем результат.\n}\n\nfunc (f *IconFactory) GetIcon(spec IconSpec) (*IconModel, error) { // GetIcon возвращает flyweight.\n\tif f == nil || f.loader == nil { // Проверяем состояние фабрики.\n\t\treturn nil, ErrMissingIconLoader // Без loader работать нельзя.\n\t}\n\tkey := iconCacheKey(spec)         // Строим ключ для кеша.\n\tf.mu.RLock()                      // Захватываем read-лок.\n\tif icon, ok := f.cache[key]; ok { // Проверяем наличие в кеше.\n\t\tf.mu.RUnlock()   // Снимаем лок.\n\t\treturn icon, nil // Возвращаем кэшированную модель.\n\t}\n\tf.mu.RUnlock()                   // Снимаем read-лок перед загрузкой.\n\tdata, err := f.loader.Load(spec) // Загружаем данные через loader.\n\tif err != nil {                  // Проверяем ошибку загрузки.\n\t\treturn nil, err // Пробрасываем ошибку.\n\t}\n\ticon := &IconModel{Spec: spec, Data: data} // Создаём новую модель.\n\tf.mu.Lock()                                // Захватываем write-лок для записи.\n\tdefer f.mu.Unlock()                        // Освобождаем лок при выходе.\n\tif existing, ok := f.cache[key]; ok {      // Повторно проверяем кеш (между read и write могли добавить).\n\t\treturn existing, nil // Используем существующую модель.\n\t}\n\tf.cache[key] = icon // Кладём новую модель в кеш.\n\treturn icon, nil    // Возвращаем созданный flyweight.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n)\n\ntype loaderStub struct {\n\tmu    sync.Mutex\n\tcalls []IconSpec\n\tdata  []byte\n\terr   error\n}\n\nfunc (l *loaderStub) Load(spec IconSpec) ([]byte, error) {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.calls = append(l.calls, spec)\n\tif l.err != nil {\n\t\treturn nil, l.err\n\t}\n\treturn append([]byte(nil), l.data...), nil\n}\n\nfunc TestNewIconFactory(t *testing.T) {\n\tt.Run(\"initializes cache and stores loader\", func(t *testing.T) {\n\t\tloader := &loaderStub{}\n\t\tfactory, err := NewIconFactory(loader)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif factory.loader != loader {\n\t\t\tt.Fatalf(\"loader not stored\")\n\t\t}\n\t\tif factory.cache == nil || len(factory.cache) != 0 {\n\t\t\tt.Fatalf(\"cache must be initialized empty\")\n\t\t}\n\t})\n\n\tt.Run(\"fails when loader missing\", func(t *testing.T) {\n\t\tif _, err := NewIconFactory(nil); !errors.Is(err, ErrMissingIconLoader) {\n\t\t\tt.Fatalf(\"expected ErrMissingIconLoader, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"creates independent cache per factory\", func(t *testing.T) {\n\t\tloader := &loaderStub{}\n\t\tleft, _ := NewIconFactory(loader)\n\t\tright, _ := NewIconFactory(loader)\n\t\tif left.cache == right.cache {\n\t\t\tt.Fatalf(\"factories must not share cache map\")\n\t\t}\n\t})\n}\n\nfunc TestIconFactoryGetIcon(t *testing.T) {\n\tt.Run(\"caches icon after first load\", func(t *testing.T) {\n\t\tloader := &loaderStub{data: []byte(\"png\")}\n\t\tfactory, _ := NewIconFactory(loader)\n\t\tspec := IconSpec{Name: \"db\", Color: \"blue\", Size: 32}\n\t\tfirst, err := factory.GetIcon(spec)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tsecond, err := factory.GetIcon(spec)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected cached success, got %v\", err)\n\t\t}\n\t\tif first != second {\n\t\t\tt.Fatalf(\"expected cached pointer, got different values\")\n\t\t}\n\t\tif len(loader.calls) != 1 {\n\t\t\tt.Fatalf(\"loader should be called once, got %d\", len(loader.calls))\n\t\t}\n\t})\n\n\tt.Run(\"propagates loader errors\", func(t *testing.T) {\n\t\tloader := &loaderStub{err: errors.New(\"not found\")}\n\t\tfactory, _ := NewIconFactory(loader)\n\t\t_, err := factory.GetIcon(IconSpec{Name: \"missing\"})\n\t\tif !errors.Is(err, loader.err) {\n\t\t\tt.Fatalf(\"expected loader error, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"stores spec inside cached model\", func(t *testing.T) {\n\t\tloader := &loaderStub{data: []byte(\"svg\")}\n\t\tfactory, _ := NewIconFactory(loader)\n\t\tspec := IconSpec{Name: \"user\", Color: \"green\", Size: 16}\n\t\ticon, err := factory.GetIcon(spec)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif icon.Spec != spec {\n\t\t\tt.Fatalf(\"icon must keep spec for debugging, got %+v\", icon.Spec)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "flyweight",
          "patterns",
          "structural"
        ],
        "order": 0
      },
      {
        "package": "flyweight",
        "slug": "go-flyweight-geticon",
        "title": "реализуйте GetIcon, который ищет легковес в кеше или загружает через loader.",
        "description": "Task 2 (medium): реализуйте GetIcon, который ищет легковес в кеше или загружает через loader.\nПодсказка: используйте двойную проверку с RWMutex, формируйте ключ как комбинацию полей IconSpec и кешируйте успешный результат.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of реализуйте GetIcon, который ищет легковес в кеше или загружает через loader..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\nvar (\n\t// ErrMissingIconLoader сигнализирует о неинициализированном загрузчике.\n\tErrMissingIconLoader = errors.New(\"icon loader is nil\")\n)\n\n// IconSpec описывает внешнее состояние иконки.\ntype IconSpec struct {\n\tName  string\n\tColor string\n\tSize  int\n}\n\n// IconModel — разделяемая часть состояния (данные иконки).\ntype IconModel struct {\n\tSpec IconSpec\n\tData []byte\n}\n\n// IconLoader загружает IconModel из внешнего источника.\ntype IconLoader interface {\n\tLoad(spec IconSpec) ([]byte, error)\n}\n\n// IconFactory управляет пулом IconModel (flyweight).\ntype IconFactory struct {\n\tloader IconLoader\n\tcache  map[string]*IconModel\n\tmu     sync.RWMutex\n}\n\n// Task 1 (easy): реализуйте фабрику, валидирующую loader и создающую кеш.\n// Подсказка: верните ошибку при nil loader и выделите map для будущих IconModel.\nfunc NewIconFactory(loader IconLoader) (*IconFactory, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте GetIcon, который ищет легковес в кеше или загружает через loader.\n// Подсказка: используйте двойную проверку с RWMutex, формируйте ключ как комбинацию полей IconSpec и кешируйте успешный результат.\nfunc (f *IconFactory) GetIcon(spec IconSpec) (*IconModel, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport \"fmt\"\n\nfunc iconCacheKey(spec IconSpec) string { // iconCacheKey собирает уникальный ключ.\n\treturn fmt.Sprintf(\"%s|%s|%d\", spec.Name, spec.Color, spec.Size) // Конкатенируем поля через разделитель.\n}\n\nfunc NewIconFactory(loader IconLoader) (*IconFactory, error) { // Конструктор IconFactory.\n\tif loader == nil { // Проверяем обязательную зависимость.\n\t\treturn nil, ErrMissingIconLoader // Возвращаем ошибку.\n\t}\n\treturn &IconFactory{ // Создаём фабрику.\n\t\tloader: loader,                      // Сохраняем загрузчик.\n\t\tcache:  make(map[string]*IconModel), // Инициализируем кеш.\n\t}, nil // Возвращаем результат.\n}\n\nfunc (f *IconFactory) GetIcon(spec IconSpec) (*IconModel, error) { // GetIcon возвращает flyweight.\n\tif f == nil || f.loader == nil { // Проверяем состояние фабрики.\n\t\treturn nil, ErrMissingIconLoader // Без loader работать нельзя.\n\t}\n\tkey := iconCacheKey(spec)         // Строим ключ для кеша.\n\tf.mu.RLock()                      // Захватываем read-лок.\n\tif icon, ok := f.cache[key]; ok { // Проверяем наличие в кеше.\n\t\tf.mu.RUnlock()   // Снимаем лок.\n\t\treturn icon, nil // Возвращаем кэшированную модель.\n\t}\n\tf.mu.RUnlock()                   // Снимаем read-лок перед загрузкой.\n\tdata, err := f.loader.Load(spec) // Загружаем данные через loader.\n\tif err != nil {                  // Проверяем ошибку загрузки.\n\t\treturn nil, err // Пробрасываем ошибку.\n\t}\n\ticon := &IconModel{Spec: spec, Data: data} // Создаём новую модель.\n\tf.mu.Lock()                                // Захватываем write-лок для записи.\n\tdefer f.mu.Unlock()                        // Освобождаем лок при выходе.\n\tif existing, ok := f.cache[key]; ok {      // Повторно проверяем кеш (между read и write могли добавить).\n\t\treturn existing, nil // Используем существующую модель.\n\t}\n\tf.cache[key] = icon // Кладём новую модель в кеш.\n\treturn icon, nil    // Возвращаем созданный flyweight.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n)\n\ntype loaderStub struct {\n\tmu    sync.Mutex\n\tcalls []IconSpec\n\tdata  []byte\n\terr   error\n}\n\nfunc (l *loaderStub) Load(spec IconSpec) ([]byte, error) {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.calls = append(l.calls, spec)\n\tif l.err != nil {\n\t\treturn nil, l.err\n\t}\n\treturn append([]byte(nil), l.data...), nil\n}\n\nfunc TestNewIconFactory(t *testing.T) {\n\tt.Run(\"initializes cache and stores loader\", func(t *testing.T) {\n\t\tloader := &loaderStub{}\n\t\tfactory, err := NewIconFactory(loader)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif factory.loader != loader {\n\t\t\tt.Fatalf(\"loader not stored\")\n\t\t}\n\t\tif factory.cache == nil || len(factory.cache) != 0 {\n\t\t\tt.Fatalf(\"cache must be initialized empty\")\n\t\t}\n\t})\n\n\tt.Run(\"fails when loader missing\", func(t *testing.T) {\n\t\tif _, err := NewIconFactory(nil); !errors.Is(err, ErrMissingIconLoader) {\n\t\t\tt.Fatalf(\"expected ErrMissingIconLoader, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"creates independent cache per factory\", func(t *testing.T) {\n\t\tloader := &loaderStub{}\n\t\tleft, _ := NewIconFactory(loader)\n\t\tright, _ := NewIconFactory(loader)\n\t\tif left.cache == right.cache {\n\t\t\tt.Fatalf(\"factories must not share cache map\")\n\t\t}\n\t})\n}\n\nfunc TestIconFactoryGetIcon(t *testing.T) {\n\tt.Run(\"caches icon after first load\", func(t *testing.T) {\n\t\tloader := &loaderStub{data: []byte(\"png\")}\n\t\tfactory, _ := NewIconFactory(loader)\n\t\tspec := IconSpec{Name: \"db\", Color: \"blue\", Size: 32}\n\t\tfirst, err := factory.GetIcon(spec)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tsecond, err := factory.GetIcon(spec)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected cached success, got %v\", err)\n\t\t}\n\t\tif first != second {\n\t\t\tt.Fatalf(\"expected cached pointer, got different values\")\n\t\t}\n\t\tif len(loader.calls) != 1 {\n\t\t\tt.Fatalf(\"loader should be called once, got %d\", len(loader.calls))\n\t\t}\n\t})\n\n\tt.Run(\"propagates loader errors\", func(t *testing.T) {\n\t\tloader := &loaderStub{err: errors.New(\"not found\")}\n\t\tfactory, _ := NewIconFactory(loader)\n\t\t_, err := factory.GetIcon(IconSpec{Name: \"missing\"})\n\t\tif !errors.Is(err, loader.err) {\n\t\t\tt.Fatalf(\"expected loader error, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"stores spec inside cached model\", func(t *testing.T) {\n\t\tloader := &loaderStub{data: []byte(\"svg\")}\n\t\tfactory, _ := NewIconFactory(loader)\n\t\tspec := IconSpec{Name: \"user\", Color: \"green\", Size: 16}\n\t\ticon, err := factory.GetIcon(spec)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif icon.Spec != spec {\n\t\t\tt.Fatalf(\"icon must keep spec for debugging, got %+v\", icon.Spec)\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "flyweight",
          "patterns",
          "structural"
        ],
        "order": 1
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-proxy",
    "tasks": [
      {
        "package": "proxy",
        "slug": "go-proxy-newcachingstoreproxy",
        "title": "создайте прокси, который валидирует входные параметры и выделяет кеш.",
        "description": "Task 1 (easy+): создайте прокси, который валидирует входные параметры и выделяет кеш.\nПодсказка: нормализуйте TTL (минимум 1s), требуйте Base != nil и подставляйте Clock по умолчанию.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of создайте прокси, который валидирует входные параметры и выделяет кеш..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar (\n\t// ErrMissingDataStore сигнализирует об отсутствии реального объекта.\n\tErrMissingDataStore = errors.New(\"data store is nil\")\n)\n\n// DataStore описывает дорогой ресурс, который хотим проксировать.\ntype DataStore interface {\n\tFetch(ctx context.Context, key string) (string, error)\n}\n\n// TimeSource абстрагирует время, чтобы детерминировать TTL.\ntype TimeSource interface {\n\tNow() time.Time\n}\n\n// cacheEntry хранит значение и момент истечения.\ntype cacheEntry struct {\n\tvalue   string\n\texpires time.Time\n}\n\n// CachingStoreProxy добавляет кеш с TTL поверх DataStore.\ntype CachingStoreProxy struct {\n\tBase  DataStore\n\tTTL   time.Duration\n\tClock TimeSource\n\n\tmu    sync.RWMutex\n\tcache map[string]cacheEntry\n}\n\n// Task 1 (easy+): создайте прокси, который валидирует входные параметры и выделяет кеш.\n// Подсказка: нормализуйте TTL (минимум 1s), требуйте Base != nil и подставляйте Clock по умолчанию.\nfunc NewCachingStoreProxy(base DataStore, ttl time.Duration, clock TimeSource) (*CachingStoreProxy, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте Fetch, проверяющий кеш и синхронно обновляющий его при промахе.\n// Подсказка: используйте RWMutex для доступа, уважайте context и обновляйте expires через Clock.Now() + TTL.\nfunc (p *CachingStoreProxy) Fetch(ctx context.Context, key string) (string, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\ntype systemTimeSource struct{} // systemTimeSource реализует TimeSource через time.Now.\n\nfunc (systemTimeSource) Now() time.Time { // Now возвращает текущее время.\n\treturn time.Now() // Делегируем стандартной библиотеке.\n}\n\nfunc NewCachingStoreProxy(base DataStore, ttl time.Duration, clock TimeSource) (*CachingStoreProxy, error) { // Конструктор прокси.\n\tif base == nil { // Проверяем наличие реального объекта.\n\t\treturn nil, ErrMissingDataStore // Сообщаем об ошибке зависимости.\n\t}\n\tif ttl <= 0 { // Недопустимый TTL...\n\t\tttl = time.Second // ...приводим к 1 секунде.\n\t}\n\tif clock == nil { // Если источник времени не передан...\n\t\tclock = systemTimeSource{} // ...используем системный.\n\t}\n\treturn &CachingStoreProxy{ // Собираем прокси.\n\t\tBase:  base,                        // Сохраняем реальный объект.\n\t\tTTL:   ttl,                         // Фиксируем TTL.\n\t\tClock: clock,                       // Настраиваем источник времени.\n\t\tcache: make(map[string]cacheEntry), // Выделяем кеш.\n\t}, nil // Возвращаем успешный результат.\n}\n\nfunc (p *CachingStoreProxy) Fetch(ctx context.Context, key string) (string, error) { // Fetch с кешированием.\n\tif ctx == nil { // Обработка nil-context.\n\t\tctx = context.Background() // Подменяем на фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену до работы.\n\t\treturn \"\", err // Возвращаем ошибку контекста.\n\t}\n\tif p == nil || p.Base == nil { // Без реального объекта работать нельзя.\n\t\treturn \"\", ErrMissingDataStore // Сообщаем об ошибке конфигурации.\n\t}\n\tnow := p.Clock.Now()                 // Получаем текущее время.\n\tp.mu.RLock()                         // Захватываем read-лок для проверки кеша.\n\tentry, ok := p.cache[key]            // Пытаемся найти ключ.\n\tif ok && now.Before(entry.expires) { // Если запись существует и ещё валидна...\n\t\tp.mu.RUnlock()          // ...снимаем лок.\n\t\treturn entry.value, nil // ...возвращаем кешированное значение.\n\t}\n\tp.mu.RUnlock()                       // Нет валидного кеша — снимаем лок перед обращением к базе.\n\tvalue, err := p.Base.Fetch(ctx, key) // Запрашиваем значение у реального объекта.\n\tif err != nil {                      // Если база вернула ошибку...\n\t\treturn \"\", err // ...пробрасываем её.\n\t}\n\trefreshTime := p.Clock.Now().Add(p.TTL)                       // Вычисляем момент истечения новой записи.\n\tp.mu.Lock()                                                   // Захватываем write-лок для обновления кеша.\n\tp.cache[key] = cacheEntry{value: value, expires: refreshTime} // Сохраняем новую запись.\n\tp.mu.Unlock()                                                 // Снимаем write-лок.\n\treturn value, nil                                             // Возвращаем свежее значение.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype dataStoreStub struct {\n\tmu     sync.Mutex\n\tcalls  []string\n\tvalues map[string]string\n\terr    error\n}\n\nfunc (s *dataStoreStub) Fetch(_ context.Context, key string) (string, error) {\n\ts.mu.Lock()\n\tdefer s.mu.Unlock()\n\ts.calls = append(s.calls, key)\n\tif s.err != nil {\n\t\treturn \"\", s.err\n\t}\n\treturn s.values[key], nil\n}\n\ntype fakeClock struct {\n\tmu  sync.Mutex\n\tnow time.Time\n}\n\nfunc (c *fakeClock) Now() time.Time {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\treturn c.now\n}\n\nfunc (c *fakeClock) Advance(d time.Duration) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.now = c.now.Add(d)\n}\n\nfunc TestNewCachingStoreProxy(t *testing.T) {\n\tt.Run(\"validates base and normalizes TTL\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{}\n\t\tclock := &fakeClock{now: time.Unix(0, 0)}\n\t\tproxy, err := NewCachingStoreProxy(base, 0, clock)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif proxy.Base != base {\n\t\t\tt.Fatalf(\"base store not stored\")\n\t\t}\n\t\tif proxy.TTL != time.Second {\n\t\t\tt.Fatalf(\"ttl should fallback to 1s, got %v\", proxy.TTL)\n\t\t}\n\t\tif proxy.Clock != clock {\n\t\t\tt.Fatalf(\"clock should be stored as provided\")\n\t\t}\n\t\tif proxy.cache == nil {\n\t\t\tt.Fatalf(\"cache map must be allocated\")\n\t\t}\n\t})\n\n\tt.Run(\"fails when base missing\", func(t *testing.T) {\n\t\tif _, err := NewCachingStoreProxy(nil, time.Second, nil); !errors.Is(err, ErrMissingDataStore) {\n\t\t\tt.Fatalf(\"expected ErrMissingDataStore, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"installs clock when nil provided\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{}\n\t\tproxy, err := NewCachingStoreProxy(base, time.Second, nil)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif proxy.Clock == nil {\n\t\t\tt.Fatalf(\"proxy must assign clock by default\")\n\t\t}\n\t})\n}\n\nfunc TestCachingStoreProxyFetch(t *testing.T) {\n\tt.Run(\"returns cached value before ttl expires\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{values: map[string]string{\"k\": \"v1\"}}\n\t\tclock := &fakeClock{now: time.Unix(100, 0)}\n\t\tproxy, _ := NewCachingStoreProxy(base, 2*time.Second, clock)\n\n\t\tval1, err := proxy.Fetch(context.Background(), \"k\")\n\t\tif err != nil || val1 != \"v1\" {\n\t\t\tt.Fatalf(\"unexpected result: %v %v\", val1, err)\n\t\t}\n\t\tclock.Advance(time.Second)\n\t\tval2, err := proxy.Fetch(context.Background(), \"k\")\n\t\tif err != nil || val2 != \"v1\" {\n\t\t\tt.Fatalf(\"expected cached value, got %v %v\", val2, err)\n\t\t}\n\t\tif len(base.calls) != 1 {\n\t\t\tt.Fatalf(\"base should be called once, got %d\", len(base.calls))\n\t\t}\n\t})\n\n\tt.Run(\"refreshes cache after ttl expiration\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{values: map[string]string{\"k\": \"v1\"}}\n\t\tclock := &fakeClock{now: time.Unix(0, 0)}\n\t\tproxy, _ := NewCachingStoreProxy(base, time.Second, clock)\n\n\t\tif _, err := proxy.Fetch(context.Background(), \"k\"); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tbase.values[\"k\"] = \"v2\"\n\t\tclock.Advance(2 * time.Second)\n\t\tval, err := proxy.Fetch(context.Background(), \"k\")\n\t\tif err != nil || val != \"v2\" {\n\t\t\tt.Fatalf(\"expected refreshed value v2, got %v %v\", val, err)\n\t\t}\n\t\tif len(base.calls) != 2 {\n\t\t\tt.Fatalf(\"base should be called twice after expiration, got %d\", len(base.calls))\n\t\t}\n\t})\n\n\tt.Run(\"respects canceled context and does not call base\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{values: map[string]string{\"k\": \"v\"}}\n\t\tclock := &fakeClock{now: time.Unix(0, 0)}\n\t\tproxy, _ := NewCachingStoreProxy(base, time.Second, clock)\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\tif _, err := proxy.Fetch(ctx, \"k\"); !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(base.calls) != 0 {\n\t\t\tt.Fatalf(\"base must not be called when context canceled\")\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "proxy",
          "patterns",
          "structural"
        ],
        "order": 0
      },
      {
        "package": "proxy",
        "slug": "go-proxy-fetch",
        "title": "реализуйте Fetch, проверяющий кеш и синхронно обновляющий его при промахе.",
        "description": "Task 2 (medium): реализуйте Fetch, проверяющий кеш и синхронно обновляющий его при промахе.\nПодсказка: используйте RWMutex для доступа, уважайте context и обновляйте expires через Clock.Now() + TTL.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of реализуйте Fetch, проверяющий кеш и синхронно обновляющий его при промахе..",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar (\n\t// ErrMissingDataStore сигнализирует об отсутствии реального объекта.\n\tErrMissingDataStore = errors.New(\"data store is nil\")\n)\n\n// DataStore описывает дорогой ресурс, который хотим проксировать.\ntype DataStore interface {\n\tFetch(ctx context.Context, key string) (string, error)\n}\n\n// TimeSource абстрагирует время, чтобы детерминировать TTL.\ntype TimeSource interface {\n\tNow() time.Time\n}\n\n// cacheEntry хранит значение и момент истечения.\ntype cacheEntry struct {\n\tvalue   string\n\texpires time.Time\n}\n\n// CachingStoreProxy добавляет кеш с TTL поверх DataStore.\ntype CachingStoreProxy struct {\n\tBase  DataStore\n\tTTL   time.Duration\n\tClock TimeSource\n\n\tmu    sync.RWMutex\n\tcache map[string]cacheEntry\n}\n\n// Task 1 (easy+): создайте прокси, который валидирует входные параметры и выделяет кеш.\n// Подсказка: нормализуйте TTL (минимум 1s), требуйте Base != nil и подставляйте Clock по умолчанию.\nfunc NewCachingStoreProxy(base DataStore, ttl time.Duration, clock TimeSource) (*CachingStoreProxy, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (medium): реализуйте Fetch, проверяющий кеш и синхронно обновляющий его при промахе.\n// Подсказка: используйте RWMutex для доступа, уважайте context и обновляйте expires через Clock.Now() + TTL.\nfunc (p *CachingStoreProxy) Fetch(ctx context.Context, key string) (string, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage structural\n\nimport (\n\t\"context\"\n\t\"time\"\n)\n\ntype systemTimeSource struct{} // systemTimeSource реализует TimeSource через time.Now.\n\nfunc (systemTimeSource) Now() time.Time { // Now возвращает текущее время.\n\treturn time.Now() // Делегируем стандартной библиотеке.\n}\n\nfunc NewCachingStoreProxy(base DataStore, ttl time.Duration, clock TimeSource) (*CachingStoreProxy, error) { // Конструктор прокси.\n\tif base == nil { // Проверяем наличие реального объекта.\n\t\treturn nil, ErrMissingDataStore // Сообщаем об ошибке зависимости.\n\t}\n\tif ttl <= 0 { // Недопустимый TTL...\n\t\tttl = time.Second // ...приводим к 1 секунде.\n\t}\n\tif clock == nil { // Если источник времени не передан...\n\t\tclock = systemTimeSource{} // ...используем системный.\n\t}\n\treturn &CachingStoreProxy{ // Собираем прокси.\n\t\tBase:  base,                        // Сохраняем реальный объект.\n\t\tTTL:   ttl,                         // Фиксируем TTL.\n\t\tClock: clock,                       // Настраиваем источник времени.\n\t\tcache: make(map[string]cacheEntry), // Выделяем кеш.\n\t}, nil // Возвращаем успешный результат.\n}\n\nfunc (p *CachingStoreProxy) Fetch(ctx context.Context, key string) (string, error) { // Fetch с кешированием.\n\tif ctx == nil { // Обработка nil-context.\n\t\tctx = context.Background() // Подменяем на фон.\n\t}\n\tif err := ctx.Err(); err != nil { // Проверяем отмену до работы.\n\t\treturn \"\", err // Возвращаем ошибку контекста.\n\t}\n\tif p == nil || p.Base == nil { // Без реального объекта работать нельзя.\n\t\treturn \"\", ErrMissingDataStore // Сообщаем об ошибке конфигурации.\n\t}\n\tnow := p.Clock.Now()                 // Получаем текущее время.\n\tp.mu.RLock()                         // Захватываем read-лок для проверки кеша.\n\tentry, ok := p.cache[key]            // Пытаемся найти ключ.\n\tif ok && now.Before(entry.expires) { // Если запись существует и ещё валидна...\n\t\tp.mu.RUnlock()          // ...снимаем лок.\n\t\treturn entry.value, nil // ...возвращаем кешированное значение.\n\t}\n\tp.mu.RUnlock()                       // Нет валидного кеша — снимаем лок перед обращением к базе.\n\tvalue, err := p.Base.Fetch(ctx, key) // Запрашиваем значение у реального объекта.\n\tif err != nil {                      // Если база вернула ошибку...\n\t\treturn \"\", err // ...пробрасываем её.\n\t}\n\trefreshTime := p.Clock.Now().Add(p.TTL)                       // Вычисляем момент истечения новой записи.\n\tp.mu.Lock()                                                   // Захватываем write-лок для обновления кеша.\n\tp.cache[key] = cacheEntry{value: value, expires: refreshTime} // Сохраняем новую запись.\n\tp.mu.Unlock()                                                 // Снимаем write-лок.\n\treturn value, nil                                             // Возвращаем свежее значение.\n}\n",
        "testCode": "package structural\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype dataStoreStub struct {\n\tmu     sync.Mutex\n\tcalls  []string\n\tvalues map[string]string\n\terr    error\n}\n\nfunc (s *dataStoreStub) Fetch(_ context.Context, key string) (string, error) {\n\ts.mu.Lock()\n\tdefer s.mu.Unlock()\n\ts.calls = append(s.calls, key)\n\tif s.err != nil {\n\t\treturn \"\", s.err\n\t}\n\treturn s.values[key], nil\n}\n\ntype fakeClock struct {\n\tmu  sync.Mutex\n\tnow time.Time\n}\n\nfunc (c *fakeClock) Now() time.Time {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\treturn c.now\n}\n\nfunc (c *fakeClock) Advance(d time.Duration) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.now = c.now.Add(d)\n}\n\nfunc TestNewCachingStoreProxy(t *testing.T) {\n\tt.Run(\"validates base and normalizes TTL\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{}\n\t\tclock := &fakeClock{now: time.Unix(0, 0)}\n\t\tproxy, err := NewCachingStoreProxy(base, 0, clock)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif proxy.Base != base {\n\t\t\tt.Fatalf(\"base store not stored\")\n\t\t}\n\t\tif proxy.TTL != time.Second {\n\t\t\tt.Fatalf(\"ttl should fallback to 1s, got %v\", proxy.TTL)\n\t\t}\n\t\tif proxy.Clock != clock {\n\t\t\tt.Fatalf(\"clock should be stored as provided\")\n\t\t}\n\t\tif proxy.cache == nil {\n\t\t\tt.Fatalf(\"cache map must be allocated\")\n\t\t}\n\t})\n\n\tt.Run(\"fails when base missing\", func(t *testing.T) {\n\t\tif _, err := NewCachingStoreProxy(nil, time.Second, nil); !errors.Is(err, ErrMissingDataStore) {\n\t\t\tt.Fatalf(\"expected ErrMissingDataStore, got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"installs clock when nil provided\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{}\n\t\tproxy, err := NewCachingStoreProxy(base, time.Second, nil)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tif proxy.Clock == nil {\n\t\t\tt.Fatalf(\"proxy must assign clock by default\")\n\t\t}\n\t})\n}\n\nfunc TestCachingStoreProxyFetch(t *testing.T) {\n\tt.Run(\"returns cached value before ttl expires\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{values: map[string]string{\"k\": \"v1\"}}\n\t\tclock := &fakeClock{now: time.Unix(100, 0)}\n\t\tproxy, _ := NewCachingStoreProxy(base, 2*time.Second, clock)\n\n\t\tval1, err := proxy.Fetch(context.Background(), \"k\")\n\t\tif err != nil || val1 != \"v1\" {\n\t\t\tt.Fatalf(\"unexpected result: %v %v\", val1, err)\n\t\t}\n\t\tclock.Advance(time.Second)\n\t\tval2, err := proxy.Fetch(context.Background(), \"k\")\n\t\tif err != nil || val2 != \"v1\" {\n\t\t\tt.Fatalf(\"expected cached value, got %v %v\", val2, err)\n\t\t}\n\t\tif len(base.calls) != 1 {\n\t\t\tt.Fatalf(\"base should be called once, got %d\", len(base.calls))\n\t\t}\n\t})\n\n\tt.Run(\"refreshes cache after ttl expiration\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{values: map[string]string{\"k\": \"v1\"}}\n\t\tclock := &fakeClock{now: time.Unix(0, 0)}\n\t\tproxy, _ := NewCachingStoreProxy(base, time.Second, clock)\n\n\t\tif _, err := proxy.Fetch(context.Background(), \"k\"); err != nil {\n\t\t\tt.Fatalf(\"expected success, got %v\", err)\n\t\t}\n\t\tbase.values[\"k\"] = \"v2\"\n\t\tclock.Advance(2 * time.Second)\n\t\tval, err := proxy.Fetch(context.Background(), \"k\")\n\t\tif err != nil || val != \"v2\" {\n\t\t\tt.Fatalf(\"expected refreshed value v2, got %v %v\", val, err)\n\t\t}\n\t\tif len(base.calls) != 2 {\n\t\t\tt.Fatalf(\"base should be called twice after expiration, got %d\", len(base.calls))\n\t\t}\n\t})\n\n\tt.Run(\"respects canceled context and does not call base\", func(t *testing.T) {\n\t\tbase := &dataStoreStub{values: map[string]string{\"k\": \"v\"}}\n\t\tclock := &fakeClock{now: time.Unix(0, 0)}\n\t\tproxy, _ := NewCachingStoreProxy(base, time.Second, clock)\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tcancel()\n\t\tif _, err := proxy.Fetch(ctx, \"k\"); !errors.Is(err, context.Canceled) {\n\t\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t\t}\n\t\tif len(base.calls) != 0 {\n\t\t\tt.Fatalf(\"base must not be called when context canceled\")\n\t\t}\n\t})\n}\n",
        "tags": [
          "go",
          "proxy",
          "patterns",
          "structural"
        ],
        "order": 1
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-chain_of_responsibility",
    "tasks": [
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-compose",
        "title": "Compose",
        "description": "Task 1 (easy): Compose\nРеализуйте функцию Compose, которая на основе final Handler и набора middleware\nсоздаёт единый Handler. Middleware должны вызываться в порядке добавления.\nПодсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Compose.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-newchainbuilder",
        "title": "NewChainBuilder",
        "description": "Task 2 (easy+): NewChainBuilder\nСоздайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\nПодсказка: достаточно выделить map[string]MiddlewareFactory.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of NewChainBuilder.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-register",
        "title": "Register",
        "description": "Task 2 (easy+): Register\nРеализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\nПодсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Register.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-build",
        "title": "Build",
        "description": "Task 2 (easy+): Build\nСоберите Handler на основе последовательности HandlerConfig; верните ошибку,\nесли фабрика не зарегистрирована. Финальный обработчик можно передать через final.\nПодсказка: вызовите Compose с построенным списком middleware.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Build.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-add",
        "title": "Recorder.Add",
        "description": "Task 3 (medium): Recorder.Add\nДобавьте потокобезопасную запись события в журнал.\nПодсказка: защитите доступ к log при помощи mutex.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Recorder.Add.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 2
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-snapshot",
        "title": "Recorder.Snapshot",
        "description": "Task 3 (medium): Recorder.Snapshot\nВерните копию накопленных записей для анализа.\nПодсказка: скопируйте текущий slice под защитой mutex.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Recorder.Snapshot.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 2
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-monitoringmiddleware",
        "title": "MonitoringMiddleware",
        "description": "Task 3 (medium): MonitoringMiddleware\nРеализуйте middleware, которое логирует начало и завершение обработки звена.\nПодсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».",
        "difficulty": "medium",
        "hint1": "Think about the core concept of MonitoringMiddleware.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 2
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-asyncmiddleware",
        "title": "AsyncMiddleware",
        "description": "Task 4 (medium+): AsyncMiddleware\nДобавьте middleware, которое выполняет следующий обработчик асинхронно и\nподдерживает таймаут либо отмену контекста.\nПодсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of AsyncMiddleware.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 3
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-handler",
        "title": "Handler",
        "description": "Task 5 (medium+): Handler\nВерните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\nПодсказка: защищайте срез Calls mutex'ом.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Handler.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 4
      },
      {
        "package": "chain_of_responsibility",
        "slug": "go-chain_of_responsibility-terminalhandler",
        "title": "TerminalHandler",
        "description": "Task 5 (medium+): TerminalHandler\nРеализуйте финальный обработчик, который записывает результат обработки и,\nпри необходимости, логирует событие через Recorder.\nПодсказка: обновите req.Result и добавьте запись «terminal:name».",
        "difficulty": "medium",
        "hint1": "Think about the core concept of TerminalHandler.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"sync\"\n\t\"time\"\n)\n\nvar ChainOfResponsibilityTasks []Task\n\n// Request моделирует входящий запрос для цепочки обработчиков.\ntype Request struct {\n\tID     string\n\tData   map[string]string\n\tTrace  []string\n\tResult string\n}\n\n// AddTrace фиксирует прохождение очередного звена через структуру Request.\n// Подсказка: просто добавьте новую запись в срез Trace, если Request не nil.\nfunc (r *Request) AddTrace(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Handler описывает конечную функцию-обработчик RPC.\ntype Handler func(ctx context.Context, req *Request) error\n\n// Middleware — промежуточное звено цепочки.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error\n\n// Task 1 (easy): Compose\n// Реализуйте функцию Compose, которая на основе final Handler и набора middleware\n// создаёт единый Handler. Middleware должны вызываться в порядке добавления.\n// Подсказка: итерируйтесь по middleware в обратном порядке и оборачивайте текущий next.\nfunc Compose(final Handler, middlewares ...Middleware) Handler {\n\tpanic(\"TODO\")\n}\n\n// HandlerConfig описывает параметры конкретного звена цепочки.\ntype HandlerConfig struct {\n\tName   string\n\tParams map[string]string\n}\n\n// MiddlewareFactory создает middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware\n\n// ChainBuilder хранит зарегистрированные фабрики звеньев.\ntype ChainBuilder struct {\n\tfactories map[string]MiddlewareFactory\n}\n\n// Task 2 (easy+): NewChainBuilder\n// Создайте конструктор, который инициализирует ChainBuilder с пустым реестром фабрик.\n// Подсказка: достаточно выделить map[string]MiddlewareFactory.\nfunc NewChainBuilder() *ChainBuilder {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Register\n// Реализуйте метод регистрации фабрики по имени, чтобы позднее собирать цепочку.\n// Подсказка: храните фабрики в map; повторная регистрация может перезаписывать значение.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Build\n// Соберите Handler на основе последовательности HandlerConfig; верните ошибку,\n// если фабрика не зарегистрирована. Финальный обработчик можно передать через final.\n// Подсказка: вызовите Compose с построенным списком middleware.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) {\n\tpanic(\"TODO\")\n}\n\n// Recorder фиксирует события цепочки для мониторинга.\ntype Recorder struct {\n\tmu  sync.Mutex\n\tlog []string\n}\n\n// Task 3 (medium): Recorder.Add\n// Добавьте потокобезопасную запись события в журнал.\n// Подсказка: защитите доступ к log при помощи mutex.\nfunc (r *Recorder) Add(entry string) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Recorder.Snapshot\n// Верните копию накопленных записей для анализа.\n// Подсказка: скопируйте текущий slice под защитой mutex.\nfunc (r *Recorder) Snapshot() []string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): MonitoringMiddleware\n// Реализуйте middleware, которое логирует начало и завершение обработки звена.\n// Подсказка: записывайте названия событий «name:start:id» и «name:end:id:ok».\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): AsyncMiddleware\n// Добавьте middleware, которое выполняет следующий обработчик асинхронно и\n// поддерживает таймаут либо отмену контекста.\n// Подсказка: запускайте next в отдельной горутине и используйте select по done/ctx/timer.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware {\n\tpanic(\"TODO\")\n}\n\n// FakeHandler помогает писать тесты и фиксировать вызовы финального обработчика.\ntype FakeHandler struct {\n\tmu    sync.Mutex\n\tCalls []string\n}\n\n// Task 5 (medium+): Handler\n// Верните Handler, который просто фиксирует имя обработки и добавляет его в Request.Trace.\n// Подсказка: защищайте срез Calls mutex'ом.\nfunc (f *FakeHandler) Handler(name string) Handler {\n\tpanic(\"TODO\")\n}\n\n// Task 5 (medium+): TerminalHandler\n// Реализуйте финальный обработчик, который записывает результат обработки и,\n// при необходимости, логирует событие через Recorder.\n// Подсказка: обновите req.Result и добавьте запись «terminal:name».\nfunc TerminalHandler(name string, recorder *Recorder) Handler {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Request хранит входные данные и следы прохождения.\ntype Request struct { // Request моделирует запрос RPC.\n\tID     string            // ID — уникальный идентификатор запроса.\n\tData   map[string]string // Data содержит произвольные параметры.\n\tTrace  []string          // Trace фиксирует прохождение middleware.\n\tResult string            // Result хранит итог обработки.\n}\n\n// AddTrace добавляет запись о прохождении.\nfunc (r *Request) AddTrace(entry string) { // AddTrace логирует звено цепочки.\n\tif r == nil { // Проверяем, что указатель не nil.\n\t\treturn // Ничего не делаем, если Request отсутствует.\n\t}\n\tr.Trace = append(r.Trace, entry) // Добавляем новую запись в trace.\n}\n\n// Handler — финальная функция цепочки.\ntype Handler func(ctx context.Context, req *Request) error // Handler выполняет обработку запроса.\n\n// Middleware — промежуточное звено.\ntype Middleware func(ctx context.Context, req *Request, next Handler) error // Middleware оборачивает вызовы.\n\n// Compose собирает цепочку из middleware и финального обработчика.\nfunc Compose(final Handler, middlewares ...Middleware) Handler { // Compose конструирует Handler.\n\tif final == nil { // Если финальный обработчик не передан...\n\t\tfinal = func(ctx context.Context, req *Request) error { // ...используем заглушку.\n\t\t\treq.AddTrace(\"final\")    // Отмечаем окончание цепочки.\n\t\t\treq.Result = \"completed\" // Ставим итоговый результат.\n\t\t\treturn nil               // Возвращаем успех.\n\t\t}\n\t}\n\tchain := final                               // Начинаем собирать цепочку с финального обработчика.\n\tfor i := len(middlewares) - 1; i >= 0; i-- { // Проходим middleware в обратном порядке.\n\t\tmw := middlewares[i]                                    // Текущее middleware.\n\t\tnext := chain                                           // Запоминаем, что будет следующим.\n\t\tchain = func(ctx context.Context, req *Request) error { // Создаём новую функцию-обёртку.\n\t\t\treturn mw(ctx, req, next) // Вызываем текущее middleware, передавая ссылку на следующий.\n\t\t}\n\t}\n\treturn chain // Возвращаем собранный обработчик.\n}\n\n// HandlerConfig описывает конфигурацию звена цепи.\ntype HandlerConfig struct { // HandlerConfig содержит имя и параметры.\n\tName   string            // Name — ключ зарегистрированной фабрики.\n\tParams map[string]string // Params — произвольные настройки.\n}\n\n// MiddlewareFactory создаёт middleware на основе конфигурации.\ntype MiddlewareFactory func(cfg HandlerConfig) Middleware // Фабрика возвращает middleware.\n\n// ChainBuilder управляет реестром фабрик.\ntype ChainBuilder struct { // ChainBuilder собирает цепочки на лету.\n\tfactories map[string]MiddlewareFactory // factories хранит фабрики по имени.\n}\n\n// NewChainBuilder создаёт пустой builder.\nfunc NewChainBuilder() *ChainBuilder { // Конструктор ChainBuilder.\n\treturn &ChainBuilder{factories: make(map[string]MiddlewareFactory)} // Инициализируем map фабрик.\n}\n\n// Register добавляет или переопределяет фабрику.\nfunc (b *ChainBuilder) Register(name string, factory MiddlewareFactory) { // Регистрируем фабрику.\n\tb.factories[name] = factory // Сохраняем фабрику по имени.\n}\n\n// Build собирает handler по списку конфигураций.\nfunc (b *ChainBuilder) Build(configs []HandlerConfig, final Handler) (Handler, error) { // Собираем цепочку.\n\tvar middlewares []Middleware  // Срез для собранных middleware.\n\tfor _, cfg := range configs { // Обрабатываем каждую конфигурацию.\n\t\tfactory, ok := b.factories[cfg.Name] // Ищем фабрику по имени.\n\t\tif !ok {                             // Если не нашли —\n\t\t\treturn nil, fmt.Errorf(\"handler %s not registered\", cfg.Name) // — возвращаем ошибку.\n\t\t}\n\t\tmiddlewares = append(middlewares, factory(cfg)) // Добавляем созданное middleware в список.\n\t}\n\treturn Compose(final, middlewares...), nil // Compose создаёт итоговый Handler.\n}\n\n// Recorder хранит последовательность логов.\ntype Recorder struct { // Recorder нужен для наблюдения за цепочкой.\n\tmu  sync.Mutex // mu защищает доступ к log.\n\tlog []string   // log — накопленный журнал.\n}\n\n// Add записывает новую строку в журнал.\nfunc (r *Recorder) Add(entry string) { // Add потокобезопасно логирует события.\n\tr.mu.Lock()                  // Берём mutex.\n\tdefer r.mu.Unlock()          // Обязательно освобождаем mutex.\n\tr.log = append(r.log, entry) // Добавляем запись в журнал.\n}\n\n// Snapshot возвращает копию журнала.\nfunc (r *Recorder) Snapshot() []string { // Snapshot нужен для тестов.\n\tr.mu.Lock()                       // Защищаем чтение.\n\tdefer r.mu.Unlock()               // Освобождаем mutex.\n\tout := make([]string, len(r.log)) // Выделяем новый срез под копию.\n\tcopy(out, r.log)                  // Копируем содержимое log.\n\treturn out                        // Возвращаем копию журнала.\n}\n\n// MonitoringMiddleware логирует вход и выход звена.\nfunc MonitoringMiddleware(name string, recorder *Recorder) Middleware { // MonitoringMiddleware создаёт middleware.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:start:%s\", name, req.ID))              // Логируем старт звена.\n\t\terr := next(ctx, req)                                               // Вызываем следующий обработчик.\n\t\trecorder.Add(fmt.Sprintf(\"%s:end:%s:%v\", name, req.ID, err == nil)) // Логируем завершение.\n\t\treturn err                                                          // Прокидываем ошибку, если она есть.\n\t}\n}\n\n// AuthorizationMiddleware проверяет роль запроса.\nfunc AuthorizationMiddleware(cfg HandlerConfig) Middleware { // AuthorizationMiddleware зависит от параметров.\n\trequired := cfg.Params[\"role\"]                                       // Получаем требуемую роль.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\trole := req.Data[\"role\"] // Считываем роль из данных запроса.\n\t\tif role != required {    // Если роли не совпадают —\n\t\t\treq.AddTrace(\"auth:denied\")                       // — отмечаем отказ.\n\t\t\treturn fmt.Errorf(\"forbidden: need %s\", required) // — возвращаем ошибку.\n\t\t}\n\t\treq.AddTrace(\"auth:ok\") // Фиксируем успешную авторизацию.\n\t\treturn next(ctx, req)   // Передаём управление дальше.\n\t}\n}\n\n// BusinessMiddleware выполняет доменную логику.\nfunc BusinessMiddleware(cfg HandlerConfig) Middleware { // BusinessMiddleware зависит от уровня.\n\tlevel := cfg.Params[\"level\"]                                         // Получаем уровень обработки.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем middleware.\n\t\treq.AddTrace(\"business:\" + level) // Отмечаем текущий уровень в trace.\n\t\tif level == req.Data[\"level\"] {   // Если уровень совпадает с запросом —\n\t\t\treq.Result = \"handled by \" + level // — считаем запрос обработанным.\n\t\t\treturn nil                         // — останавливаем цепочку.\n\t\t}\n\t\treturn next(ctx, req) // Иначе передаём управление дальше.\n\t}\n}\n\n// AsyncMiddleware выполняет next асинхронно с таймаутом.\nfunc AsyncMiddleware(name string, recorder *Recorder, timeout time.Duration) Middleware { // Создаём middleware с таймаутом.\n\treturn func(ctx context.Context, req *Request, next Handler) error { // Возвращаем функцию-обёртку.\n\t\tdone := make(chan error, 1)   // Канал для результата next.\n\t\trecorder.Add(name + \":spawn\") // Логируем запуск.\n\t\tgo func() {                   // Стартуем горутину.\n\t\t\tdone <- next(ctx, req) // Передаём результат выполнения.\n\t\t}()\n\t\tselect { // Ждём завершения, отмены контекста или таймаута.\n\t\tcase <-ctx.Done(): // Контекст отменён —\n\t\t\trecorder.Add(name + \":cancel\") // — логируем отмену.\n\t\t\treturn ctx.Err()               // — возвращаем ошибку контекста.\n\t\tcase err := <-done: // next завершил работу —\n\t\t\trecorder.Add(name + \":done\") // — пишем лог —\n\t\t\treturn err                   // — и возвращаем его ошибку.\n\t\tcase <-time.After(timeout): // Истёк таймаут —\n\t\t\trecorder.Add(name + \":timeout\")         // — логируем событие —\n\t\t\treturn fmt.Errorf(\"%s timed out\", name) // — возвращаем ошибку.\n\t\t}\n\t}\n}\n\n// FakeHandler фиксирует вызовы финального обработчика.\ntype FakeHandler struct { // Используется в тестах.\n\tmu    sync.Mutex // Защищает Calls.\n\tCalls []string   // Список имён вызванных обработчиков.\n}\n\n// Handler возвращает обработчик, записывающий факт вызова.\nfunc (f *FakeHandler) Handler(name string) Handler { // Создаём финальный Handler для тестов.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tf.mu.Lock()                     // Защищаем доступ к Calls.\n\t\tdefer f.mu.Unlock()             // Освобождаем mutex после записи.\n\t\tf.Calls = append(f.Calls, name) // Фиксируем имя вызванного обработчика.\n\t\tif req != nil {                 // Защита от nil request.\n\t\t\treq.AddTrace(name) // Добавляем имя в trace запроса.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n\n// TerminalHandler завершает цепь, устанавливая результат.\nfunc TerminalHandler(name string, recorder *Recorder) Handler { // Создаём финальный Handler с логированием.\n\treturn func(ctx context.Context, req *Request) error { // Возвращаем функцию.\n\t\tif req != nil { // Проверяем, что запрос существует.\n\t\t\treq.Result = name // Устанавливаем итоговый результат.\n\t\t}\n\t\tif recorder != nil { // Если есть recorder —\n\t\t\trecorder.Add(\"terminal:\" + name) // — логируем завершение.\n\t\t}\n\t\treturn nil // Возвращаем успех.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- AddTrace ----\n\nfunc TestRequestAddTraceAppends(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tif len(r.Trace) != 1 || r.Trace[0] != \"a\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", r.Trace)\n\t}\n}\n\nfunc TestRequestAddTraceMultiple(t *testing.T) {\n\tr := &Request{}\n\tr.AddTrace(\"a\")\n\tr.AddTrace(\"b\")\n\tif got := r.Trace; len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected trace: %#v\", got)\n\t}\n}\n\nfunc TestRequestAddTraceNilSafe(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"AddTrace should not panic, got %v\", r)\n\t\t}\n\t}()\n\t(*Request)(nil).AddTrace(\"noop\")\n}\n\n// ---- Compose ----\n\nfunc TestComposeMiddlewareOrder(t *testing.T) {\n\treq := &Request{}\n\tmw1 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw1\")\n\t\treturn next(ctx, r)\n\t}\n\tmw2 := func(ctx context.Context, r *Request, next Handler) error {\n\t\tr.AddTrace(\"mw2\")\n\t\treturn next(ctx, r)\n\t}\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\tr.AddTrace(\"final\")\n\t\treturn nil\n\t}\n\thandler := Compose(final, mw1, mw2)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\twant := []string{\"mw1\", \"mw2\", \"final\"}\n\tif len(req.Trace) != len(want) {\n\t\tt.Fatalf(\"trace mismatch: %#v\", req.Trace)\n\t}\n\tfor i, v := range want {\n\t\tif req.Trace[i] != v {\n\t\t\tt.Fatalf(\"trace[%d]=%s want %s\", i, req.Trace[i], v)\n\t\t}\n\t}\n}\n\nfunc TestComposeDefaultFinal(t *testing.T) {\n\treq := &Request{Trace: []string{}}\n\thandler := Compose(nil)\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\tif req.Result != \"completed\" {\n\t\tt.Fatalf(\"unexpected result: %s\", req.Result)\n\t}\n}\n\nfunc TestComposePropagatesError(t *testing.T) {\n\tfinal := func(ctx context.Context, r *Request) error {\n\t\treturn errors.New(\"boom\")\n\t}\n\thandler := Compose(final)\n\tif err := handler(context.Background(), &Request{}); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- NewChainBuilder ----\n\nfunc TestNewChainBuilderInitializesMap(t *testing.T) {\n\tb := NewChainBuilder()\n\tif b == nil || b.factories == nil {\n\t\tt.Fatalf(\"builder or map is nil: %#v\", b)\n\t}\n}\n\nfunc TestNewChainBuilderReturnsIndependentInstances(t *testing.T) {\n\tb1 := NewChainBuilder()\n\tb2 := NewChainBuilder()\n\tif &b1.factories == &b2.factories {\n\t\tt.Fatalf(\"maps should be independent\")\n\t}\n}\n\nfunc TestNewChainBuilderStartsEmpty(t *testing.T) {\n\tb := NewChainBuilder()\n\tif len(b.factories) != 0 {\n\t\tt.Fatalf(\"factories should be empty\")\n\t}\n}\n\n// ---- Register ----\n\nfunc TestChainBuilderRegisterAddsFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tcalled := false\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\tcalled = true\n\t\treturn nil\n\t})\n\tif _, ok := b.factories[\"auth\"]; !ok {\n\t\tt.Fatalf(\"factory not registered\")\n\t}\n\tb.factories[\"auth\"](HandlerConfig{})\n\tif !called {\n\t\tt.Fatalf(\"factory not invoked\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOverrides(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"auth\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error { return nil }\n\t})\n\tsecondCalled := false\n\tsecond := func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\tsecondCalled = true\n\t\t\treturn nil\n\t\t}\n\t}\n\tb.Register(\"auth\", second)\n\tmw := b.factories[\"auth\"](HandlerConfig{})\n\t_ = mw(context.Background(), &Request{}, nil)\n\tif !secondCalled {\n\t\tt.Fatalf(\"factory not overridden\")\n\t}\n}\n\nfunc TestChainBuilderRegisterOnNilBuilderPanics(t *testing.T) {\n\tdefer func() {\n\t\tif r := recover(); r == nil {\n\t\t\tt.Fatalf(\"expected panic\")\n\t\t}\n\t}()\n\tvar b *ChainBuilder\n\tb.Register(\"auth\", nil)\n}\n\n// ---- Build ----\n\nfunc TestChainBuilderBuildSuccess(t *testing.T) {\n\tb := NewChainBuilder()\n\tb.Register(\"noop\", func(cfg HandlerConfig) Middleware {\n\t\treturn func(ctx context.Context, req *Request, next Handler) error {\n\t\t\treq.AddTrace(\"noop\")\n\t\t\treturn next(ctx, req)\n\t\t}\n\t})\n\th, err := b.Build([]HandlerConfig{{Name: \"noop\"}}, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"final\")\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif len(req.Trace) != 2 {\n\t\tt.Fatalf(\"trace not propagated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestChainBuilderBuildMissingFactory(t *testing.T) {\n\tb := NewChainBuilder()\n\tif _, err := b.Build([]HandlerConfig{{Name: \"missing\"}}, nil); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestChainBuilderBuildUsesFinalHandler(t *testing.T) {\n\tb := NewChainBuilder()\n\th, err := b.Build(nil, func(ctx context.Context, req *Request) error {\n\t\treq.Result = \"done\"\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\treq := &Request{}\n\tif err := h(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected handler err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"final handler not executed\")\n\t}\n}\n\n// ---- Recorder.Add ----\n\nfunc TestRecorderAddAppendsEntries(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tif len(r.log) != 2 {\n\t\tt.Fatalf(\"log len mismatch: %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddIsThreadSafe(t *testing.T) {\n\tr := &Recorder{}\n\tvar wg sync.WaitGroup\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\t\t\tr.Add(\"entry\")\n\t\t}(i)\n\t}\n\twg.Wait()\n\tif len(r.log) != 10 {\n\t\tt.Fatalf(\"expected 10 entries, got %d\", len(r.log))\n\t}\n}\n\nfunc TestRecorderAddAcceptsEmptyString(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"\")\n\tif len(r.log) != 1 || r.log[0] != \"\" {\n\t\tt.Fatalf(\"unexpected log: %#v\", r.log)\n\t}\n}\n\n// ---- Recorder.Snapshot ----\n\nfunc TestRecorderSnapshotReturnsCopy(t *testing.T) {\n\tr := &Recorder{log: []string{\"a\"}}\n\tsnap := r.Snapshot()\n\tsnap[0] = \"b\"\n\tif r.log[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot must be copy\")\n\t}\n}\n\nfunc TestRecorderSnapshotEmpty(t *testing.T) {\n\tr := &Recorder{}\n\tif snap := r.Snapshot(); len(snap) != 0 {\n\t\tt.Fatalf(\"expected empty snapshot\")\n\t}\n}\n\nfunc TestRecorderSnapshotReflectsCurrentLog(t *testing.T) {\n\tr := &Recorder{}\n\tr.Add(\"a\")\n\tr.Add(\"b\")\n\tsnap := r.Snapshot()\n\tif len(snap) != 2 {\n\t\tt.Fatalf(\"unexpected snapshot len: %d\", len(snap))\n\t}\n}\n\n// ---- MonitoringMiddleware ----\n\nfunc TestMonitoringMiddlewareLogsStartAndEnd(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\thandler := mw\n\terr := handler(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(rec.log) != 2 {\n\t\tt.Fatalf(\"log length mismatch: %#v\", rec.log)\n\t}\n}\n\nfunc TestMonitoringMiddlewarePropagatesError(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\twant := errors.New(\"fail\")\n\terr := mw(context.Background(), &Request{ID: \"1\"}, func(ctx context.Context, req *Request) error { return want })\n\tif !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected error %v got %v\", want, err)\n\t}\n}\n\nfunc TestMonitoringMiddlewareKeepsRequestTrace(t *testing.T) {\n\trec := &Recorder{}\n\tmw := MonitoringMiddleware(\"auth\", rec)\n\treq := &Request{ID: \"1\"}\n\t_ = mw(context.Background(), req, func(ctx context.Context, req *Request) error {\n\t\treq.AddTrace(\"inner\")\n\t\treturn nil\n\t})\n\tif len(req.Trace) != 1 {\n\t\tt.Fatalf(\"trace should be updated by next\")\n\t}\n}\n\n// ---- AsyncMiddleware ----\n\nfunc TestAsyncMiddlewareCompletes(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\treq := &Request{}\n\terr := mw(context.Background(), req, func(ctx context.Context, req *Request) error { return nil })\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n}\n\nfunc TestAsyncMiddlewareContextCancel(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Second)\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\terr := mw(ctx, &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(time.Second)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected context error\")\n\t}\n}\n\nfunc TestAsyncMiddlewareTimeout(t *testing.T) {\n\trec := &Recorder{}\n\tmw := AsyncMiddleware(\"async\", rec, time.Millisecond)\n\terr := mw(context.Background(), &Request{}, func(ctx context.Context, req *Request) error {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t\treturn nil\n\t})\n\tif err == nil {\n\t\tt.Fatalf(\"expected timeout error\")\n\t}\n}\n\n// ---- FakeHandler.Handler ----\n\nfunc TestFakeHandlerRecordsCalls(t *testing.T) {\n\th := &FakeHandler{}\n\thandler := h.Handler(\"final\")\n\tif err := handler(context.Background(), &Request{}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(h.Calls) != 1 {\n\t\tt.Fatalf(\"call not recorded\")\n\t}\n}\n\nfunc TestFakeHandlerAddsTrace(t *testing.T) {\n\th := &FakeHandler{}\n\treq := &Request{}\n\t_ = h.Handler(\"final\")(context.Background(), req)\n\tif len(req.Trace) != 1 || req.Trace[0] != \"final\" {\n\t\tt.Fatalf(\"trace not updated: %#v\", req.Trace)\n\t}\n}\n\nfunc TestFakeHandlerThreadSafe(t *testing.T) {\n\th := &FakeHandler{}\n\tvar wg sync.WaitGroup\n\thandler := h.Handler(\"final\")\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\t_ = handler(context.Background(), &Request{})\n\t\t}()\n\t}\n\twg.Wait()\n\tif len(h.Calls) != 5 {\n\t\tt.Fatalf(\"expected 5 calls, got %d\", len(h.Calls))\n\t}\n}\n\n// ---- TerminalHandler ----\n\nfunc TestTerminalHandlerSetsResult(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\treq := &Request{}\n\tif err := handler(context.Background(), req); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif req.Result != \"done\" {\n\t\tt.Fatalf(\"result not set\")\n\t}\n}\n\nfunc TestTerminalHandlerLogsWhenRecorderProvided(t *testing.T) {\n\trec := &Recorder{}\n\thandler := TerminalHandler(\"done\", rec)\n\t_ = handler(context.Background(), &Request{})\n\tif len(rec.log) != 1 {\n\t\tt.Fatalf(\"terminal event not logged\")\n\t}\n}\n\nfunc TestTerminalHandlerHandlesNilRequest(t *testing.T) {\n\thandler := TerminalHandler(\"done\", nil)\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Fatalf(\"handler should not panic on nil request\")\n\t\t}\n\t}()\n\t_ = handler(context.Background(), nil)\n}\n",
        "tags": [
          "go",
          "chain_of_responsibility",
          "patterns",
          "behavioral"
        ],
        "order": 4
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-command",
    "tasks": [
      {
        "package": "command",
        "slug": "go-command-processparallel",
        "title": "параллельная обработка",
        "description": "Task 4 (medium+): параллельная обработка\nРеализуйте ProcessParallel, который выполняет команды несколькими воркерами.\nПри ошибке хотя бы одной команды функция возвращает первую ошибку.\nПодсказка: используйте каналы и WaitGroup, workers <=0 трактуйте как 1.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of параллельная обработка.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"sync\"\n)\n\n// Task 1 (easy): Command interface и очередь\n// Реализуйте интерфейс Command с методами Execute/Undo/Name и очередь CommandQueue,\n// которая последовательно выполняет команды и хранит стек выполненных для Undo.\n// Подсказка: храните очередь в срезе и переносите выполненные команды в history.\ntype Command interface {\n\tExecute(ctx context.Context) error\n\tUndo(ctx context.Context) error\n\tName() string\n}\n\ntype CommandQueue struct {\n\tcmds    []Command\n\thistory []Command\n}\n\n// NewCommandQueue создаёт пустую очередь команд.\nfunc NewCommandQueue() *CommandQueue {\n\tpanic(\"TODO\")\n}\n\n// Enqueue добавляет команду в конец очереди.\nfunc (q *CommandQueue) Enqueue(cmd Command) {\n\tpanic(\"TODO\")\n}\n\n// Process выполняет команды по порядку до первой ошибки.\nfunc (q *CommandQueue) Process(ctx context.Context) error {\n\tpanic(\"TODO\")\n}\n\n// Undo откатывает последнюю успешно выполненную команду.\nfunc (q *CommandQueue) Undo(ctx context.Context) error {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): LoggingCommand\n// Создайте декоратор LoggingCommand, который логирует запуск и откат команд.\n// Logger.Log получает строки вида \"execute:<name>\" и \"undo:<name>\".\n// Подсказка: если Base nil — возвращайте ошибку.\ntype Logger interface {\n\tLog(entry string)\n}\n\ntype LoggingCommand struct {\n\tBase   Command\n\tLogger Logger\n}\n\nfunc (c LoggingCommand) Execute(ctx context.Context) error {\n\tpanic(\"TODO\")\n}\n\nfunc (c LoggingCommand) Undo(ctx context.Context) error {\n\tpanic(\"TODO\")\n}\n\nfunc (c LoggingCommand) Name() string {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): JSON сериализация\n// Представьте конверт CommandEnvelope для хранения имени и JSON тела команды.\n// SerializeCommand требует, чтобы команда реализовывала json.Marshaler.\n// DeserializeCommand восстанавливает команду по названию через registry.\ntype CommandEnvelope struct {\n\tName string          `json:\"name\"`\n\tBody json.RawMessage `json:\"body\"`\n}\n\ntype CommandFactory func(body json.RawMessage) (Command, error)\n\nfunc SerializeCommand(cmd Command) (CommandEnvelope, error) {\n\tpanic(\"TODO\")\n}\n\nfunc DeserializeCommand(env CommandEnvelope, registry map[string]CommandFactory) (Command, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 4 (medium+): параллельная обработка\n// Реализуйте ProcessParallel, который выполняет команды несколькими воркерами.\n// При ошибке хотя бы одной команды функция возвращает первую ошибку.\n// Подсказка: используйте каналы и WaitGroup, workers <=0 трактуйте как 1.\nfunc ProcessParallel(ctx context.Context, cmds []Command, workers int) error {\n\tpanic(\"TODO\")\n}\n\n// helper для сериализации ошибок\nfunc wrapExecutionError(name string, err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\treturn fmt.Errorf(\"command %s: %w\", name, err)\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc NewCommandQueue() *CommandQueue { // NewCommandQueue создаёт пустую очередь команд.\n\treturn &CommandQueue{} // Выделяем CommandQueue с пустыми срезами.\n}\n\nfunc (q *CommandQueue) Enqueue(cmd Command) { // Enqueue добавляет команду в очередь.\n\tif q == nil || cmd == nil { // Проверяем, что очередь и команда существуют.\n\t\treturn // Ничего не делаем для nil.\n\t}\n\tq.cmds = append(q.cmds, cmd) // Дописываем команду в конец среза.\n}\n\nfunc (q *CommandQueue) Process(ctx context.Context) error { // Process выполняет команды последовательно.\n\tif q == nil { // Пустая очередь — нечего делать.\n\t\treturn nil // Возвращаем успешный результат.\n\t}\n\tfor len(q.cmds) > 0 { // Пока есть команды в очереди.\n\t\tcmd := q.cmds[0]                         // Берём первую команду.\n\t\tq.cmds = q.cmds[1:]                      // Удаляем её из очереди (сдвиг среза).\n\t\tif err := cmd.Execute(ctx); err != nil { // Пытаемся выполнить команду.\n\t\t\treturn wrapExecutionError(cmd.Name(), err) // Оборачиваем ошибку именем команды.\n\t\t}\n\t\tq.history = append(q.history, cmd) // Запоминаем выполненную команду для Undo.\n\t}\n\treturn nil // Все команды выполнены успешно.\n}\n\nfunc (q *CommandQueue) Undo(ctx context.Context) error { // Undo откатывает последнюю команду.\n\tif q == nil || len(q.history) == 0 { // Если история пустая, откатывать нечего.\n\t\treturn nil // Возвращаем успешный результат.\n\t}\n\tidx := len(q.history) - 1             // Индекс последней команды.\n\tcmd := q.history[idx]                 // Берём эту команду.\n\tq.history = q.history[:idx]           // Удаляем её из истории.\n\tif err := cmd.Undo(ctx); err != nil { // Вызываем Undo у команды.\n\t\treturn wrapExecutionError(cmd.Name(), err) // Возвращаем ошибку с именем команды.\n\t}\n\treturn nil // Откат успешен.\n}\n\nfunc (c LoggingCommand) Execute(ctx context.Context) error { // Execute логирует запуск команды.\n\tif c.Base == nil { // Проверяем наличие базовой команды.\n\t\treturn fmt.Errorf(\"missing base command\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif c.Logger != nil { // Если есть логгер, пишем событие.\n\t\tc.Logger.Log(\"execute:\" + c.Base.Name()) // Фиксируем запуск конкретной команды.\n\t}\n\terr := c.Base.Execute(ctx)                    // Выполняем базовую команду.\n\treturn wrapExecutionError(c.Base.Name(), err) // Возвращаем ошибку, если она произошла.\n}\n\nfunc (c LoggingCommand) Undo(ctx context.Context) error { // Undo логирует откат команды.\n\tif c.Base == nil { // Проверяем конфигурацию.\n\t\treturn fmt.Errorf(\"missing base command\") // Сообщаем об ошибке.\n\t}\n\tif c.Logger != nil { // Если есть логгер, фиксируем откат.\n\t\tc.Logger.Log(\"undo:\" + c.Base.Name()) // Записываем событие.\n\t}\n\terr := c.Base.Undo(ctx)                       // Вызываем Undo базовой команды.\n\treturn wrapExecutionError(c.Base.Name(), err) // Возвращаем результат с именем.\n}\n\nfunc (c LoggingCommand) Name() string { // Name проксирует имя базовой команды.\n\tif c.Base == nil { // Если базовой команды нет...\n\t\treturn \"\" // ...возвращаем пустую строку.\n\t}\n\treturn c.Base.Name() // В остальных случаях возвращаем имя Base.\n}\n\nfunc SerializeCommand(cmd Command) (CommandEnvelope, error) { // SerializeCommand переводит команду в конверт.\n\ttype jsonMarshaler interface { // Локальный интерфейс совместимых команд.\n\t\tMarshalJSON() ([]byte, error) // Требуем метод MarshalJSON.\n\t}\n\tmarshaler, ok := cmd.(jsonMarshaler) // Проверяем, реализует ли команда интерфейс.\n\tif !ok {                             // Если нет —\n\t\treturn CommandEnvelope{}, fmt.Errorf(\"command %s is not serializable\", cmd.Name()) // — возвращаем ошибку.\n\t}\n\tbody, err := marshaler.MarshalJSON() // Сериализуем команду в JSON.\n\tif err != nil {                      // При ошибке сериализации...\n\t\treturn CommandEnvelope{}, wrapExecutionError(cmd.Name(), err) // ...возвращаем обёрнутую ошибку.\n\t}\n\treturn CommandEnvelope{Name: cmd.Name(), Body: body}, nil // Возвращаем Envelope с именем и телом.\n}\n\nfunc DeserializeCommand(env CommandEnvelope, registry map[string]CommandFactory) (Command, error) { // DeserializeCommand создаёт команду из конверта.\n\tif registry == nil { // Проверяем наличие реестра фабрик.\n\t\treturn nil, fmt.Errorf(\"registry is nil\") // Сообщаем, что некуда смотреть.\n\t}\n\tfactory, ok := registry[env.Name] // Ищем фабрику по имени команды.\n\tif !ok {                          // Если фабрики нет —\n\t\treturn nil, fmt.Errorf(\"unknown command %s\", env.Name) // — возвращаем ошибку.\n\t}\n\tcmd, err := factory(env.Body) // Вызываем фабрику c JSON телом.\n\tif err != nil {               // Если фабрика вернула ошибку —\n\t\treturn nil, wrapExecutionError(env.Name, err) // — оборачиваем её именем команды.\n\t}\n\treturn cmd, nil // Возвращаем готовую команду.\n}\n\nfunc ProcessParallel(ctx context.Context, cmds []Command, workers int) error { // ProcessParallel запускает команды параллельно.\n\tif workers <= 0 { // Недопустимое число воркеров —\n\t\tworkers = 1 // — используем один воркер.\n\t}\n\tjobs := make(chan Command)         // Канал заданий для воркеров.\n\terrCh := make(chan error, workers) // Буферизированный канал ошибок.\n\tvar wg sync.WaitGroup              // Группа ожидания завершения воркеров.\n\n\tworker := func() { // Функция-воркер для выполнения команд.\n\t\tdefer wg.Done()         // По завершении уменьшаем счётчик WaitGroup.\n\t\tfor cmd := range jobs { // Читаем задания из канала.\n\t\t\tif cmd == nil { // Пропускаем nil команды.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err := cmd.Execute(ctx); err != nil { // Выполняем команду.\n\t\t\t\terrCh <- wrapExecutionError(cmd.Name(), err) // Отправляем ошибку в канал.\n\t\t\t\treturn                                       // Завершаем воркера.\n\t\t\t}\n\t\t}\n\t}\n\n\twg.Add(workers)                // Добавляем нужное количество воркеров в WaitGroup.\n\tfor i := 0; i < workers; i++ { // Запускаем воркеры.\n\t\tgo worker() // Каждый воркер работает в отдельной горутине.\n\t}\n\n\tgo func() { // Продюсерская горутина с заданиями.\n\t\tdefer close(jobs)          // Закрываем канал, когда закончатся команды.\n\t\tfor _, cmd := range cmds { // Итерируемся по списку команд.\n\t\t\tjobs <- cmd // Отправляем каждую команду в канал.\n\t\t}\n\t}()\n\n\tdone := make(chan struct{}) // Канал для завершения всех воркеров.\n\tgo func() {                 // Горутина, ожидающая WaitGroup.\n\t\twg.Wait()   // Ждём завершения всех воркеров.\n\t\tclose(done) // Сигнализируем о завершении.\n\t}()\n\n\tselect { // Ждём первое событие.\n\tcase err := <-errCh: // Если пришла ошибка от воркера —\n\t\tclose(errCh) // — закрываем канал ошибок.\n\t\treturn err   // — возвращаем ошибку.\n\tcase <-done: // Все воркеры завершились успешно.\n\t\treturn nil // Сообщаем об успехе.\n\tcase <-ctx.Done(): // Контекст отменён/истёк дедлайн.\n\t\treturn ctx.Err() // Возвращаем ошибку контекста.\n\t}\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype stubCommand struct {\n\tname string\n\texec func(context.Context) error\n\tundo func(context.Context) error\n}\n\nfunc (s *stubCommand) Execute(ctx context.Context) error {\n\tif s.exec != nil {\n\t\treturn s.exec(ctx)\n\t}\n\treturn nil\n}\n\nfunc (s *stubCommand) Undo(ctx context.Context) error {\n\tif s.undo != nil {\n\t\treturn s.undo(ctx)\n\t}\n\treturn nil\n}\n\nfunc (s *stubCommand) Name() string { return s.name }\n\ntype sliceLogger struct {\n\tmu      sync.Mutex\n\tentries []string\n}\n\nfunc (l *sliceLogger) Log(entry string) {\n\tl.mu.Lock()\n\tdefer l.mu.Unlock()\n\tl.entries = append(l.entries, entry)\n}\n\n// ---- CommandQueue ----\n\nfunc TestCommandQueueProcessExecutesInOrder(t *testing.T) {\n\tq := NewCommandQueue()\n\tvar executed []string\n\tq.Enqueue(&stubCommand{name: \"first\", exec: func(context.Context) error { executed = append(executed, \"first\"); return nil }})\n\tq.Enqueue(&stubCommand{name: \"second\", exec: func(context.Context) error { executed = append(executed, \"second\"); return nil }})\n\tif err := q.Process(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(executed) != 2 || executed[0] != \"first\" || executed[1] != \"second\" {\n\t\tt.Fatalf(\"commands executed in wrong order: %#v\", executed)\n\t}\n}\n\nfunc TestCommandQueueProcessStopsOnError(t *testing.T) {\n\tq := NewCommandQueue()\n\tq.Enqueue(&stubCommand{name: \"boom\", exec: func(context.Context) error { return errors.New(\"fail\") }})\n\tq.Enqueue(&stubCommand{name: \"second\", exec: func(context.Context) error { t.Fatalf(\"should not run\"); return nil }})\n\tif err := q.Process(context.Background()); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestCommandQueueUndoRevertsLast(t *testing.T) {\n\tq := NewCommandQueue()\n\tundone := false\n\tq.Enqueue(&stubCommand{name: \"ok\", exec: func(context.Context) error { return nil }, undo: func(context.Context) error { undone = true; return nil }})\n\tif err := q.Process(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif err := q.Undo(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected undo err: %v\", err)\n\t}\n\tif !undone {\n\t\tt.Fatalf(\"undo not called\")\n\t}\n}\n\n// ---- LoggingCommand ----\n\nfunc TestLoggingCommandLogsExecuteAndUndo(t *testing.T) {\n\tlogger := &sliceLogger{}\n\tcmd := LoggingCommand{\n\t\tBase:   &stubCommand{name: \"job\"},\n\t\tLogger: logger,\n\t}\n\t_ = cmd.Execute(context.Background())\n\t_ = cmd.Undo(context.Background())\n\tif len(logger.entries) != 2 || logger.entries[0] != \"execute:job\" || logger.entries[1] != \"undo:job\" {\n\t\tt.Fatalf(\"logger entries mismatch: %#v\", logger.entries)\n\t}\n}\n\nfunc TestLoggingCommandPropagatesErrors(t *testing.T) {\n\tlogger := &sliceLogger{}\n\twant := errors.New(\"fail\")\n\tcmd := LoggingCommand{\n\t\tBase:   &stubCommand{name: \"job\", exec: func(context.Context) error { return want }},\n\t\tLogger: logger,\n\t}\n\tif err := cmd.Execute(context.Background()); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestLoggingCommandReturnsBaseName(t *testing.T) {\n\tcmd := LoggingCommand{Base: &stubCommand{name: \"job\"}}\n\tif cmd.Name() != \"job\" {\n\t\tt.Fatalf(\"unexpected name: %s\", cmd.Name())\n\t}\n}\n\n// ---- Serialization ----\n\ntype serializableCommand struct {\n\tstubCommand\n\tpayload map[string]string\n}\n\nfunc (s *serializableCommand) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(s.payload)\n}\n\nfunc TestSerializeCommandProducesEnvelope(t *testing.T) {\n\tcmd := &serializableCommand{stubCommand: stubCommand{name: \"notify\"}, payload: map[string]string{\"key\": \"value\"}}\n\tenv, err := SerializeCommand(cmd)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif env.Name != \"notify\" || len(env.Body) == 0 {\n\t\tt.Fatalf(\"bad envelope: %#v\", env)\n\t}\n}\n\nfunc TestSerializeCommandErrorsWhenNotMarshaler(t *testing.T) {\n\t_, err := SerializeCommand(&stubCommand{name: \"plain\"})\n\tif err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestDeserializeCommandUsesRegistry(t *testing.T) {\n\tbody := json.RawMessage(`{\"key\":\"value\"}`)\n\tregistry := map[string]CommandFactory{\n\t\t\"notify\": func(b json.RawMessage) (Command, error) {\n\t\t\tif string(b) != string(body) {\n\t\t\t\tt.Fatalf(\"unexpected body: %s\", string(b))\n\t\t\t}\n\t\t\treturn &stubCommand{name: \"notify\"}, nil\n\t\t},\n\t}\n\tcmd, err := DeserializeCommand(CommandEnvelope{Name: \"notify\", Body: body}, registry)\n\tif err != nil || cmd == nil {\n\t\tt.Fatalf(\"unexpected result: cmd=%v err=%v\", cmd, err)\n\t}\n}\n\nfunc TestDeserializeCommandErrorsOnMissingFactory(t *testing.T) {\n\t_, err := DeserializeCommand(CommandEnvelope{Name: \"unknown\"}, nil)\n\tif err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\n// ---- ProcessParallel ----\n\nfunc TestProcessParallelRunsAll(t *testing.T) {\n\tvar mu sync.Mutex\n\tcount := 0\n\tcmds := []Command{\n\t\t&stubCommand{name: \"a\", exec: func(context.Context) error { mu.Lock(); count++; mu.Unlock(); return nil }},\n\t\t&stubCommand{name: \"b\", exec: func(context.Context) error { mu.Lock(); count++; mu.Unlock(); return nil }},\n\t\t&stubCommand{name: \"c\", exec: func(context.Context) error { mu.Lock(); count++; mu.Unlock(); return nil }},\n\t}\n\tif err := ProcessParallel(context.Background(), cmds, 2); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif count != len(cmds) {\n\t\tt.Fatalf(\"expected %d, got %d\", len(cmds), count)\n\t}\n}\n\nfunc TestProcessParallelPropagatesError(t *testing.T) {\n\tcmds := []Command{\n\t\t&stubCommand{name: \"a\"},\n\t\t&stubCommand{name: \"b\", exec: func(context.Context) error { return errors.New(\"fail\") }},\n\t\t&stubCommand{name: \"c\"},\n\t}\n\tif err := ProcessParallel(context.Background(), cmds, 3); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestProcessParallelDefaultWorkers(t *testing.T) {\n\tran := false\n\tcmds := []Command{&stubCommand{name: \"a\", exec: func(context.Context) error { ran = true; return nil }}}\n\tif err := ProcessParallel(context.Background(), cmds, 0); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif !ran {\n\t\tt.Fatalf(\"command not executed\")\n\t}\n}\n",
        "tags": [
          "go",
          "command",
          "patterns",
          "behavioral"
        ],
        "order": 3
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-interpreter",
    "tasks": [
      {
        "package": "interpreter",
        "slug": "go-interpreter-parsecomparison",
        "title": "ParseComparison",
        "description": "Task 1 (easy): ParseComparison\nРазберите простое выражение \"ключ=значение\" или \"ключ!=значение\" в Expression.\nПодсказка: поддержите переменные в виде {{name}} и сравнивайте значения из ctx.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of ParseComparison.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Expression описывает узел AST, который можно вычислить.\ntype Expression func(ctx map[string]string) (bool, error)\n\n// Ошибки интерпретатора.\nvar (\n\tErrEmptyComparison = errors.New(\"empty comparison\")\n\tErrUnknownOperator = errors.New(\"unknown operator\")\n\tErrEmptyExpression = errors.New(\"empty expression\")\n)\n\n// CachedInterpreter хранит кеш разобранных выражений.\ntype CachedInterpreter struct {\n\tmu     sync.RWMutex\n\tcache  map[string]Expression\n\tParser func(string) (Expression, error)\n}\n\n// Task 1 (easy): ParseComparison\n// Разберите простое выражение \"ключ=значение\" или \"ключ!=значение\" в Expression.\n// Подсказка: поддержите переменные в виде {{name}} и сравнивайте значения из ctx.\nfunc ParseComparison(input string) (Expression, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): ParseFilter\n// Разберите строку с логическими операциями AND/OR и скобками, построив Expression.\n// Подсказка: примените алгоритм сортировочной станции с приоритетом AND над OR.\nfunc ParseFilter(input string) (Expression, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CachedInterpreter.Interpret\n// Используйте кеш AST (cache) и Parser (если задан) для вычисления выражения.\n// Подсказка: храните разобранный Expression по исходной строке и переиспользуйте его.\nfunc (ci *CachedInterpreter) Interpret(ctx map[string]string, src string) (bool, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc ParseComparison(input string) (Expression, error) { // ParseComparison превращает текстовое сравнение в Expression.\n\ttrimmed := strings.TrimSpace(input) // Удаляем пробелы по краям для упрощения парсинга.\n\tif trimmed == \"\" {                  // Пустая строка невозможна.\n\t\treturn nil, ErrEmptyComparison // Сообщаем об ошибке формата.\n\t}\n\tvar op string                        // Храним найденный оператор.\n\tvar parts []string                   // Срез для левой и правой части.\n\tif strings.Contains(trimmed, \"!=\") { // Проверяем оператор \"не равно\".\n\t\top = \"!=\"                              // Фиксируем оператор.\n\t\tparts = strings.SplitN(trimmed, op, 2) // Делим выражение на две части.\n\t} else if strings.Contains(trimmed, \"=\") { // Проверяем оператор \"равно\".\n\t\top = \"=\"                               // Фиксируем оператор.\n\t\tparts = strings.SplitN(trimmed, op, 2) // Делим выражение на две части.\n\t} else { // Если оператор не найден — это ошибка.\n\t\treturn nil, ErrUnknownOperator // Возвращаем ошибку неизвестного оператора.\n\t}\n\tif len(parts) != 2 { // Должно быть ровно две части.\n\t\treturn nil, ErrEmptyComparison // Если нет — формат некорректен.\n\t}\n\tkey := strings.TrimSpace(parts[0])   // Выделяем имя ключа слева.\n\tvalue := strings.TrimSpace(parts[1]) // И ожидаемое значение справа.\n\tif key == \"\" || value == \"\" {        // Пустые части недопустимы.\n\t\treturn nil, ErrEmptyComparison // Сообщаем об ошибке.\n\t}\n\tnegate := op == \"!=\"                                                  // Флаг для инвертирования результата.\n\tvariable := \"\"                                                        // Имя переменной контекста (если используется).\n\tif strings.HasPrefix(value, \"{{\") && strings.HasSuffix(value, \"}}\") { // Проверяем ссылку на переменную.\n\t\tvariable = strings.TrimSpace(value[2 : len(value)-2]) // Достаём имя переменной без фигурных скобок.\n\t\tif variable == \"\" {                                   // Пустое имя переменной недопустимо.\n\t\t\treturn nil, ErrEmptyComparison // Возвращаем ошибку формата.\n\t\t}\n\t}\n\tliteral := value                                   // Сохраняем литеральное значение для прямого сравнения.\n\treturn func(ctx map[string]string) (bool, error) { // Возвращаем Expression как замыкание.\n\t\tif ctx == nil { // Nil-контекст трактуем как пустой.\n\t\t\tctx = map[string]string{} // Создаём пустую map, чтобы избежать паник.\n\t\t}\n\t\tleft := ctx[key]    // Получаем значение ключа из контекста.\n\t\tright := literal    // По умолчанию сравниваем с литералом.\n\t\tif variable != \"\" { // Если значение берётся из переменной...\n\t\t\tright = ctx[variable] // ...подставляем его из контекста.\n\t\t}\n\t\tresult := left == right // Сравниваем левое и правое значения.\n\t\tif negate {             // При операторе \"!=\" инвертируем результат.\n\t\t\tresult = !result // Инверсия булевого значения.\n\t\t}\n\t\treturn result, nil // Возвращаем итог без ошибки.\n\t}, nil\n}\n\nfunc ParseFilter(input string) (Expression, error) { // ParseFilter строит AST для выражения с AND/OR.\n\tif strings.TrimSpace(input) == \"\" { // Проверяем, что строка не пустая.\n\t\treturn nil, ErrEmptyExpression // Пустое выражение недопустимо.\n\t}\n\tnormalized := strings.NewReplacer(\"(\", \" ( \", \")\", \" ) \").Replace(input) // Добавляем пробелы вокруг скобок для токенизации.\n\ttokens := strings.Fields(normalized)                                     // Разбиваем строку на токены по пробелам.\n\tif len(tokens) == 0 {                                                    // После разбиения должен остаться хотя бы один токен.\n\t\treturn nil, ErrEmptyExpression // Иначе выражение некорректно.\n\t}\n\tprecedence := map[string]int{\"OR\": 1, \"AND\": 2} // Определяем приоритет операторов.\n\tvar exprStack []Expression                      // Стек частичных выражений.\n\tvar opStack []string                            // Стек операторов.\n\tapplyOperator := func() error {                 // Вспомогательная функция для применения оператора.\n\t\tif len(opStack) == 0 || len(exprStack) < 2 { // Нужны оператор и минимум два операнда.\n\t\t\treturn ErrEmptyExpression // Если их нет — выражение некорректно.\n\t\t}\n\t\top := opStack[len(opStack)-1]            // Достаём последний оператор.\n\t\topStack = opStack[:len(opStack)-1]       // Удаляем его из стека.\n\t\tright := exprStack[len(exprStack)-1]     // Берём правый операнд.\n\t\tleft := exprStack[len(exprStack)-2]      // Берём левый операнд.\n\t\texprStack = exprStack[:len(exprStack)-2] // Удаляем операнды из стека.\n\t\tvar combined Expression                  // Здесь будет замыкание для объединения.\n\t\tswitch op {                              // Ветвим по типу оператора.\n\t\tcase \"AND\": // Оператор логического И.\n\t\t\tcombined = func(ctx map[string]string) (bool, error) { // Создаём Expression, объединяющий левого и правого потомков.\n\t\t\t\tlb, err := left(ctx)   // Вычисляем левое выражение.\n\t\t\t\tif err != nil || !lb { // Ошибка или false позволяют коротко завершить.\n\t\t\t\t\treturn lb, err // Возвращаем сразу же.\n\t\t\t\t}\n\t\t\t\treturn right(ctx) // Вычисляем правое выражение.\n\t\t\t}\n\t\tcase \"OR\": // Оператор логического ИЛИ.\n\t\t\tcombined = func(ctx map[string]string) (bool, error) {\n\t\t\t\tlb, err := left(ctx) // Вычисляем левое выражение.\n\t\t\t\tif err != nil {      // Ошибка прокидывается наверх.\n\t\t\t\t\treturn false, err // Возвращаем ошибку без вычисления правого операнда.\n\t\t\t\t}\n\t\t\t\tif lb { // Если левый дал true — можно коротко вернуть true.\n\t\t\t\t\treturn true, nil // Успешный результат.\n\t\t\t\t}\n\t\t\t\treturn right(ctx) // Иначе вычисляем правый операнд.\n\t\t\t}\n\t\tdefault: // Неизвестный оператор не поддерживается.\n\t\t\treturn ErrUnknownOperator // Сообщаем, что оператор неизвестен.\n\t\t}\n\t\texprStack = append(exprStack, combined) // Кладём комбинированное выражение обратно на стек.\n\t\treturn nil                              // Возвращаем успех.\n\t}\n\tfor _, token := range tokens { // Итерируемся по токенам.\n\t\tupper := strings.ToUpper(token) // Для операторов используем верхний регистр.\n\t\tswitch upper {                  // Анализируем токен.\n\t\tcase \"AND\", \"OR\": // Обрабатываем логические операторы.\n\t\t\tfor len(opStack) > 0 && opStack[len(opStack)-1] != \"(\" && precedence[opStack[len(opStack)-1]] >= precedence[upper] { // Пока наверху более приоритетный оператор...\n\t\t\t\tif err := applyOperator(); err != nil { // ...применяем его.\n\t\t\t\t\treturn nil, err // В случае ошибки возвращаем её.\n\t\t\t\t}\n\t\t\t}\n\t\t\topStack = append(opStack, upper) // Кладём текущий оператор на стек.\n\t\tcase \"(\": // Открывающая скобка просто пушится в стек операторов.\n\t\t\topStack = append(opStack, upper) // Добавляем маркер скобки.\n\t\tcase \")\": // Закрывающая скобка инициирует свёртку.\n\t\t\tfor len(opStack) > 0 && opStack[len(opStack)-1] != \"(\" { // Пока не найдём открытую скобку...\n\t\t\t\tif err := applyOperator(); err != nil { // ...применяем операторы.\n\t\t\t\t\treturn nil, err // Ошибку прокидываем наверх.\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(opStack) == 0 { // Если скобка не найдена — выражение некорректно.\n\t\t\t\treturn nil, ErrEmptyExpression // Сообщаем об ошибке.\n\t\t\t}\n\t\t\topStack = opStack[:len(opStack)-1] // Удаляем открывающую скобку из стека.\n\t\tdefault: // Все остальные токены трактуем как сравнения.\n\t\t\texpr, err := ParseComparison(token) // Парсим сравнение в Expression.\n\t\t\tif err != nil {                     // Ошибки парсинга сравнения прокидываем наверх.\n\t\t\t\treturn nil, err // Возвращаем ошибку парсера сравнения.\n\t\t\t}\n\t\t\texprStack = append(exprStack, expr) // Пушим выражение в стек операндов.\n\t\t}\n\t}\n\tfor len(opStack) > 0 { // После обработки всех токенов сворачиваем оставшиеся операторы.\n\t\tif opStack[len(opStack)-1] == \"(\" { // Оставшаяся открытая скобка означает ошибку.\n\t\t\treturn nil, ErrEmptyExpression // Сообщаем о некорректных скобках.\n\t\t}\n\t\tif err := applyOperator(); err != nil { // Применяем оператор.\n\t\t\treturn nil, err // Ошибку возвращаем вызывающему коду.\n\t\t}\n\t}\n\tif len(exprStack) != 1 { // После свёртки должен остаться один элемент.\n\t\treturn nil, ErrEmptyExpression // Если нет — выражение некорректно.\n\t}\n\treturn exprStack[0], nil // Возвращаем итоговое Expression.\n}\n\nfunc (ci *CachedInterpreter) Interpret(ctx map[string]string, src string) (bool, error) { // Interpret использует кешированное AST для вычисления.\n\tif ci == nil { // Nil-получатель использовать нельзя.\n\t\treturn false, errors.New(\"interpreter is nil\") // Сообщаем о неправильно созданном интерпретаторе.\n\t}\n\ttrimmed := strings.TrimSpace(src) // Обрезаем пробелы в исходной строке.\n\tif trimmed == \"\" {                // Пустая строка недопустима.\n\t\treturn false, ErrEmptyExpression // Возвращаем соответствующую ошибку.\n\t}\n\tparser := ci.Parser // Используем пользовательский парсер, если задан.\n\tif parser == nil {  // Если парсер не задан — используем ParseFilter.\n\t\tparser = ParseFilter // Присваиваем стандартную функцию разбора.\n\t}\n\tci.mu.RLock()        // Берём read-lock для проверки кеша.\n\tif ci.cache == nil { // Если карта ещё не инициализирована...\n\t\tci.mu.RUnlock()      // ...отпускаем rlock...\n\t\tci.mu.Lock()         // ...берём write-lock для инициализации.\n\t\tif ci.cache == nil { // Повторно проверяем после захвата lock.\n\t\t\tci.cache = make(map[string]Expression) // Создаём map для хранения AST.\n\t\t}\n\t\tci.mu.Unlock() // Освобождаем write-lock.\n\t\tci.mu.RLock()  // Берём rlock снова для доступа к кешу.\n\t}\n\texpr, ok := ci.cache[trimmed] // Пытаемся найти выражение в кеше.\n\tci.mu.RUnlock()               // Освобождаем rlock.\n\tif !ok {                      // Если выражения нет в кеше — нужно распарсить.\n\t\tparsed, err := parser(trimmed) // Парсим строку в AST.\n\t\tif err != nil {                // Ошибку парсера сразу возвращаем.\n\t\t\treturn false, err // Прокидываем ошибку наверх.\n\t\t}\n\t\tci.mu.Lock()         // Захватываем write-lock для записи в кеш.\n\t\tif ci.cache == nil { // Проверяем, что карта всё ещё инициализирована.\n\t\t\tci.cache = make(map[string]Expression) // Инициализируем при необходимости (если была вычищена).\n\t\t}\n\t\tci.cache[trimmed] = parsed // Записываем новое AST в кеш.\n\t\tci.mu.Unlock()             // Освобождаем lock.\n\t\texpr = parsed              // Используем распарсенное выражение.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на пустой для безопасной работы замыканий.\n\t\tctx = map[string]string{} // Создаём пустую map.\n\t}\n\treturn expr(ctx) // Вычисляем итоговое выражение и возвращаем результат.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\n// ---- ParseComparison ----\n\nfunc TestParseComparisonLiteralEquals(t *testing.T) {\n\texpr, err := ParseComparison(\"status=green\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tok, err := expr(map[string]string{\"status\": \"green\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected comparison to be true\")\n\t}\n}\n\nfunc TestParseComparisonLiteralNotEquals(t *testing.T) {\n\texpr, err := ParseComparison(\"env!=prod\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tok, err := expr(map[string]string{\"env\": \"stage\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"!= expression should be true\")\n\t}\n}\n\nfunc TestParseComparisonVariableLookup(t *testing.T) {\n\texpr, err := ParseComparison(\"owner={{user}}\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"owner\": \"dev\", \"user\": \"dev\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected variable comparison to be true\")\n\t}\n}\n\nfunc TestParseComparisonRejectsEmpty(t *testing.T) {\n\tif _, err := ParseComparison(\"   \"); !errors.Is(err, ErrEmptyComparison) {\n\t\tt.Fatalf(\"expected ErrEmptyComparison, got %v\", err)\n\t}\n}\n\n// ---- ParseFilter ----\n\nfunc TestParseFilterAndPrecedence(t *testing.T) {\n\texpr, err := ParseFilter(\"role=admin AND team=core OR role=guest\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"role\": \"admin\", \"team\": \"sales\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"AND should bind tighter than OR\")\n\t}\n}\n\nfunc TestParseFilterParentheses(t *testing.T) {\n\texpr, err := ParseFilter(\"role=admin AND (team=core OR team=ops)\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"role\": \"admin\", \"team\": \"ops\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"parentheses should allow OR to match\")\n\t}\n}\n\nfunc TestParseFilterInvalidToken(t *testing.T) {\n\tif _, err := ParseFilter(\"role=admin XOR team=core\"); err == nil {\n\t\tt.Fatalf(\"expected error for unknown operator\")\n\t}\n}\n\n// ---- CachedInterpreter.Interpret ----\n\nfunc TestCachedInterpreterInterpretCachesAST(t *testing.T) {\n\tvar calls atomic.Int64\n\tci := &CachedInterpreter{\n\t\tParser: func(src string) (Expression, error) {\n\t\t\tcalls.Add(1)\n\t\t\treturn ParseComparison(src)\n\t\t},\n\t}\n\tctx := map[string]string{\"status\": \"ok\"}\n\tfor i := 0; i < 3; i++ {\n\t\tok, err := ci.Interpret(ctx, \"status=ok\")\n\t\tif err != nil || !ok {\n\t\t\tt.Fatalf(\"unexpected result: ok=%v err=%v\", ok, err)\n\t\t}\n\t}\n\tif calls.Load() != 1 {\n\t\tt.Fatalf(\"expression should be cached, calls=%d\", calls.Load())\n\t}\n}\n\nfunc TestCachedInterpreterInterpretUsesDefaultParser(t *testing.T) {\n\tci := &CachedInterpreter{}\n\tok, err := ci.Interpret(map[string]string{\"env\": \"prod\"}, \"env=prod\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected expression to be true\")\n\t}\n}\n\nfunc TestCachedInterpreterInterpretPropagatesParserError(t *testing.T) {\n\twant := errors.New(\"boom\")\n\tci := &CachedInterpreter{\n\t\tParser: func(string) (Expression, error) {\n\t\t\treturn nil, want\n\t\t},\n\t}\n\tif _, err := ci.Interpret(nil, \"status=ok\"); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestCachedInterpreterInterpretHandlesNilContext(t *testing.T) {\n\tci := &CachedInterpreter{}\n\tok, err := ci.Interpret(nil, \"status=ok\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"nil context should not satisfy comparison\")\n\t}\n}\n",
        "tags": [
          "go",
          "interpreter",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "interpreter",
        "slug": "go-interpreter-parsefilter",
        "title": "ParseFilter",
        "description": "Task 2 (easy+): ParseFilter\nРазберите строку с логическими операциями AND/OR и скобками, построив Expression.\nПодсказка: примените алгоритм сортировочной станции с приоритетом AND над OR.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of ParseFilter.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Expression описывает узел AST, который можно вычислить.\ntype Expression func(ctx map[string]string) (bool, error)\n\n// Ошибки интерпретатора.\nvar (\n\tErrEmptyComparison = errors.New(\"empty comparison\")\n\tErrUnknownOperator = errors.New(\"unknown operator\")\n\tErrEmptyExpression = errors.New(\"empty expression\")\n)\n\n// CachedInterpreter хранит кеш разобранных выражений.\ntype CachedInterpreter struct {\n\tmu     sync.RWMutex\n\tcache  map[string]Expression\n\tParser func(string) (Expression, error)\n}\n\n// Task 1 (easy): ParseComparison\n// Разберите простое выражение \"ключ=значение\" или \"ключ!=значение\" в Expression.\n// Подсказка: поддержите переменные в виде {{name}} и сравнивайте значения из ctx.\nfunc ParseComparison(input string) (Expression, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): ParseFilter\n// Разберите строку с логическими операциями AND/OR и скобками, построив Expression.\n// Подсказка: примените алгоритм сортировочной станции с приоритетом AND над OR.\nfunc ParseFilter(input string) (Expression, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CachedInterpreter.Interpret\n// Используйте кеш AST (cache) и Parser (если задан) для вычисления выражения.\n// Подсказка: храните разобранный Expression по исходной строке и переиспользуйте его.\nfunc (ci *CachedInterpreter) Interpret(ctx map[string]string, src string) (bool, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc ParseComparison(input string) (Expression, error) { // ParseComparison превращает текстовое сравнение в Expression.\n\ttrimmed := strings.TrimSpace(input) // Удаляем пробелы по краям для упрощения парсинга.\n\tif trimmed == \"\" {                  // Пустая строка невозможна.\n\t\treturn nil, ErrEmptyComparison // Сообщаем об ошибке формата.\n\t}\n\tvar op string                        // Храним найденный оператор.\n\tvar parts []string                   // Срез для левой и правой части.\n\tif strings.Contains(trimmed, \"!=\") { // Проверяем оператор \"не равно\".\n\t\top = \"!=\"                              // Фиксируем оператор.\n\t\tparts = strings.SplitN(trimmed, op, 2) // Делим выражение на две части.\n\t} else if strings.Contains(trimmed, \"=\") { // Проверяем оператор \"равно\".\n\t\top = \"=\"                               // Фиксируем оператор.\n\t\tparts = strings.SplitN(trimmed, op, 2) // Делим выражение на две части.\n\t} else { // Если оператор не найден — это ошибка.\n\t\treturn nil, ErrUnknownOperator // Возвращаем ошибку неизвестного оператора.\n\t}\n\tif len(parts) != 2 { // Должно быть ровно две части.\n\t\treturn nil, ErrEmptyComparison // Если нет — формат некорректен.\n\t}\n\tkey := strings.TrimSpace(parts[0])   // Выделяем имя ключа слева.\n\tvalue := strings.TrimSpace(parts[1]) // И ожидаемое значение справа.\n\tif key == \"\" || value == \"\" {        // Пустые части недопустимы.\n\t\treturn nil, ErrEmptyComparison // Сообщаем об ошибке.\n\t}\n\tnegate := op == \"!=\"                                                  // Флаг для инвертирования результата.\n\tvariable := \"\"                                                        // Имя переменной контекста (если используется).\n\tif strings.HasPrefix(value, \"{{\") && strings.HasSuffix(value, \"}}\") { // Проверяем ссылку на переменную.\n\t\tvariable = strings.TrimSpace(value[2 : len(value)-2]) // Достаём имя переменной без фигурных скобок.\n\t\tif variable == \"\" {                                   // Пустое имя переменной недопустимо.\n\t\t\treturn nil, ErrEmptyComparison // Возвращаем ошибку формата.\n\t\t}\n\t}\n\tliteral := value                                   // Сохраняем литеральное значение для прямого сравнения.\n\treturn func(ctx map[string]string) (bool, error) { // Возвращаем Expression как замыкание.\n\t\tif ctx == nil { // Nil-контекст трактуем как пустой.\n\t\t\tctx = map[string]string{} // Создаём пустую map, чтобы избежать паник.\n\t\t}\n\t\tleft := ctx[key]    // Получаем значение ключа из контекста.\n\t\tright := literal    // По умолчанию сравниваем с литералом.\n\t\tif variable != \"\" { // Если значение берётся из переменной...\n\t\t\tright = ctx[variable] // ...подставляем его из контекста.\n\t\t}\n\t\tresult := left == right // Сравниваем левое и правое значения.\n\t\tif negate {             // При операторе \"!=\" инвертируем результат.\n\t\t\tresult = !result // Инверсия булевого значения.\n\t\t}\n\t\treturn result, nil // Возвращаем итог без ошибки.\n\t}, nil\n}\n\nfunc ParseFilter(input string) (Expression, error) { // ParseFilter строит AST для выражения с AND/OR.\n\tif strings.TrimSpace(input) == \"\" { // Проверяем, что строка не пустая.\n\t\treturn nil, ErrEmptyExpression // Пустое выражение недопустимо.\n\t}\n\tnormalized := strings.NewReplacer(\"(\", \" ( \", \")\", \" ) \").Replace(input) // Добавляем пробелы вокруг скобок для токенизации.\n\ttokens := strings.Fields(normalized)                                     // Разбиваем строку на токены по пробелам.\n\tif len(tokens) == 0 {                                                    // После разбиения должен остаться хотя бы один токен.\n\t\treturn nil, ErrEmptyExpression // Иначе выражение некорректно.\n\t}\n\tprecedence := map[string]int{\"OR\": 1, \"AND\": 2} // Определяем приоритет операторов.\n\tvar exprStack []Expression                      // Стек частичных выражений.\n\tvar opStack []string                            // Стек операторов.\n\tapplyOperator := func() error {                 // Вспомогательная функция для применения оператора.\n\t\tif len(opStack) == 0 || len(exprStack) < 2 { // Нужны оператор и минимум два операнда.\n\t\t\treturn ErrEmptyExpression // Если их нет — выражение некорректно.\n\t\t}\n\t\top := opStack[len(opStack)-1]            // Достаём последний оператор.\n\t\topStack = opStack[:len(opStack)-1]       // Удаляем его из стека.\n\t\tright := exprStack[len(exprStack)-1]     // Берём правый операнд.\n\t\tleft := exprStack[len(exprStack)-2]      // Берём левый операнд.\n\t\texprStack = exprStack[:len(exprStack)-2] // Удаляем операнды из стека.\n\t\tvar combined Expression                  // Здесь будет замыкание для объединения.\n\t\tswitch op {                              // Ветвим по типу оператора.\n\t\tcase \"AND\": // Оператор логического И.\n\t\t\tcombined = func(ctx map[string]string) (bool, error) { // Создаём Expression, объединяющий левого и правого потомков.\n\t\t\t\tlb, err := left(ctx)   // Вычисляем левое выражение.\n\t\t\t\tif err != nil || !lb { // Ошибка или false позволяют коротко завершить.\n\t\t\t\t\treturn lb, err // Возвращаем сразу же.\n\t\t\t\t}\n\t\t\t\treturn right(ctx) // Вычисляем правое выражение.\n\t\t\t}\n\t\tcase \"OR\": // Оператор логического ИЛИ.\n\t\t\tcombined = func(ctx map[string]string) (bool, error) {\n\t\t\t\tlb, err := left(ctx) // Вычисляем левое выражение.\n\t\t\t\tif err != nil {      // Ошибка прокидывается наверх.\n\t\t\t\t\treturn false, err // Возвращаем ошибку без вычисления правого операнда.\n\t\t\t\t}\n\t\t\t\tif lb { // Если левый дал true — можно коротко вернуть true.\n\t\t\t\t\treturn true, nil // Успешный результат.\n\t\t\t\t}\n\t\t\t\treturn right(ctx) // Иначе вычисляем правый операнд.\n\t\t\t}\n\t\tdefault: // Неизвестный оператор не поддерживается.\n\t\t\treturn ErrUnknownOperator // Сообщаем, что оператор неизвестен.\n\t\t}\n\t\texprStack = append(exprStack, combined) // Кладём комбинированное выражение обратно на стек.\n\t\treturn nil                              // Возвращаем успех.\n\t}\n\tfor _, token := range tokens { // Итерируемся по токенам.\n\t\tupper := strings.ToUpper(token) // Для операторов используем верхний регистр.\n\t\tswitch upper {                  // Анализируем токен.\n\t\tcase \"AND\", \"OR\": // Обрабатываем логические операторы.\n\t\t\tfor len(opStack) > 0 && opStack[len(opStack)-1] != \"(\" && precedence[opStack[len(opStack)-1]] >= precedence[upper] { // Пока наверху более приоритетный оператор...\n\t\t\t\tif err := applyOperator(); err != nil { // ...применяем его.\n\t\t\t\t\treturn nil, err // В случае ошибки возвращаем её.\n\t\t\t\t}\n\t\t\t}\n\t\t\topStack = append(opStack, upper) // Кладём текущий оператор на стек.\n\t\tcase \"(\": // Открывающая скобка просто пушится в стек операторов.\n\t\t\topStack = append(opStack, upper) // Добавляем маркер скобки.\n\t\tcase \")\": // Закрывающая скобка инициирует свёртку.\n\t\t\tfor len(opStack) > 0 && opStack[len(opStack)-1] != \"(\" { // Пока не найдём открытую скобку...\n\t\t\t\tif err := applyOperator(); err != nil { // ...применяем операторы.\n\t\t\t\t\treturn nil, err // Ошибку прокидываем наверх.\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(opStack) == 0 { // Если скобка не найдена — выражение некорректно.\n\t\t\t\treturn nil, ErrEmptyExpression // Сообщаем об ошибке.\n\t\t\t}\n\t\t\topStack = opStack[:len(opStack)-1] // Удаляем открывающую скобку из стека.\n\t\tdefault: // Все остальные токены трактуем как сравнения.\n\t\t\texpr, err := ParseComparison(token) // Парсим сравнение в Expression.\n\t\t\tif err != nil {                     // Ошибки парсинга сравнения прокидываем наверх.\n\t\t\t\treturn nil, err // Возвращаем ошибку парсера сравнения.\n\t\t\t}\n\t\t\texprStack = append(exprStack, expr) // Пушим выражение в стек операндов.\n\t\t}\n\t}\n\tfor len(opStack) > 0 { // После обработки всех токенов сворачиваем оставшиеся операторы.\n\t\tif opStack[len(opStack)-1] == \"(\" { // Оставшаяся открытая скобка означает ошибку.\n\t\t\treturn nil, ErrEmptyExpression // Сообщаем о некорректных скобках.\n\t\t}\n\t\tif err := applyOperator(); err != nil { // Применяем оператор.\n\t\t\treturn nil, err // Ошибку возвращаем вызывающему коду.\n\t\t}\n\t}\n\tif len(exprStack) != 1 { // После свёртки должен остаться один элемент.\n\t\treturn nil, ErrEmptyExpression // Если нет — выражение некорректно.\n\t}\n\treturn exprStack[0], nil // Возвращаем итоговое Expression.\n}\n\nfunc (ci *CachedInterpreter) Interpret(ctx map[string]string, src string) (bool, error) { // Interpret использует кешированное AST для вычисления.\n\tif ci == nil { // Nil-получатель использовать нельзя.\n\t\treturn false, errors.New(\"interpreter is nil\") // Сообщаем о неправильно созданном интерпретаторе.\n\t}\n\ttrimmed := strings.TrimSpace(src) // Обрезаем пробелы в исходной строке.\n\tif trimmed == \"\" {                // Пустая строка недопустима.\n\t\treturn false, ErrEmptyExpression // Возвращаем соответствующую ошибку.\n\t}\n\tparser := ci.Parser // Используем пользовательский парсер, если задан.\n\tif parser == nil {  // Если парсер не задан — используем ParseFilter.\n\t\tparser = ParseFilter // Присваиваем стандартную функцию разбора.\n\t}\n\tci.mu.RLock()        // Берём read-lock для проверки кеша.\n\tif ci.cache == nil { // Если карта ещё не инициализирована...\n\t\tci.mu.RUnlock()      // ...отпускаем rlock...\n\t\tci.mu.Lock()         // ...берём write-lock для инициализации.\n\t\tif ci.cache == nil { // Повторно проверяем после захвата lock.\n\t\t\tci.cache = make(map[string]Expression) // Создаём map для хранения AST.\n\t\t}\n\t\tci.mu.Unlock() // Освобождаем write-lock.\n\t\tci.mu.RLock()  // Берём rlock снова для доступа к кешу.\n\t}\n\texpr, ok := ci.cache[trimmed] // Пытаемся найти выражение в кеше.\n\tci.mu.RUnlock()               // Освобождаем rlock.\n\tif !ok {                      // Если выражения нет в кеше — нужно распарсить.\n\t\tparsed, err := parser(trimmed) // Парсим строку в AST.\n\t\tif err != nil {                // Ошибку парсера сразу возвращаем.\n\t\t\treturn false, err // Прокидываем ошибку наверх.\n\t\t}\n\t\tci.mu.Lock()         // Захватываем write-lock для записи в кеш.\n\t\tif ci.cache == nil { // Проверяем, что карта всё ещё инициализирована.\n\t\t\tci.cache = make(map[string]Expression) // Инициализируем при необходимости (если была вычищена).\n\t\t}\n\t\tci.cache[trimmed] = parsed // Записываем новое AST в кеш.\n\t\tci.mu.Unlock()             // Освобождаем lock.\n\t\texpr = parsed              // Используем распарсенное выражение.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на пустой для безопасной работы замыканий.\n\t\tctx = map[string]string{} // Создаём пустую map.\n\t}\n\treturn expr(ctx) // Вычисляем итоговое выражение и возвращаем результат.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\n// ---- ParseComparison ----\n\nfunc TestParseComparisonLiteralEquals(t *testing.T) {\n\texpr, err := ParseComparison(\"status=green\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tok, err := expr(map[string]string{\"status\": \"green\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected comparison to be true\")\n\t}\n}\n\nfunc TestParseComparisonLiteralNotEquals(t *testing.T) {\n\texpr, err := ParseComparison(\"env!=prod\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tok, err := expr(map[string]string{\"env\": \"stage\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"!= expression should be true\")\n\t}\n}\n\nfunc TestParseComparisonVariableLookup(t *testing.T) {\n\texpr, err := ParseComparison(\"owner={{user}}\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"owner\": \"dev\", \"user\": \"dev\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected variable comparison to be true\")\n\t}\n}\n\nfunc TestParseComparisonRejectsEmpty(t *testing.T) {\n\tif _, err := ParseComparison(\"   \"); !errors.Is(err, ErrEmptyComparison) {\n\t\tt.Fatalf(\"expected ErrEmptyComparison, got %v\", err)\n\t}\n}\n\n// ---- ParseFilter ----\n\nfunc TestParseFilterAndPrecedence(t *testing.T) {\n\texpr, err := ParseFilter(\"role=admin AND team=core OR role=guest\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"role\": \"admin\", \"team\": \"sales\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"AND should bind tighter than OR\")\n\t}\n}\n\nfunc TestParseFilterParentheses(t *testing.T) {\n\texpr, err := ParseFilter(\"role=admin AND (team=core OR team=ops)\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"role\": \"admin\", \"team\": \"ops\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"parentheses should allow OR to match\")\n\t}\n}\n\nfunc TestParseFilterInvalidToken(t *testing.T) {\n\tif _, err := ParseFilter(\"role=admin XOR team=core\"); err == nil {\n\t\tt.Fatalf(\"expected error for unknown operator\")\n\t}\n}\n\n// ---- CachedInterpreter.Interpret ----\n\nfunc TestCachedInterpreterInterpretCachesAST(t *testing.T) {\n\tvar calls atomic.Int64\n\tci := &CachedInterpreter{\n\t\tParser: func(src string) (Expression, error) {\n\t\t\tcalls.Add(1)\n\t\t\treturn ParseComparison(src)\n\t\t},\n\t}\n\tctx := map[string]string{\"status\": \"ok\"}\n\tfor i := 0; i < 3; i++ {\n\t\tok, err := ci.Interpret(ctx, \"status=ok\")\n\t\tif err != nil || !ok {\n\t\t\tt.Fatalf(\"unexpected result: ok=%v err=%v\", ok, err)\n\t\t}\n\t}\n\tif calls.Load() != 1 {\n\t\tt.Fatalf(\"expression should be cached, calls=%d\", calls.Load())\n\t}\n}\n\nfunc TestCachedInterpreterInterpretUsesDefaultParser(t *testing.T) {\n\tci := &CachedInterpreter{}\n\tok, err := ci.Interpret(map[string]string{\"env\": \"prod\"}, \"env=prod\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected expression to be true\")\n\t}\n}\n\nfunc TestCachedInterpreterInterpretPropagatesParserError(t *testing.T) {\n\twant := errors.New(\"boom\")\n\tci := &CachedInterpreter{\n\t\tParser: func(string) (Expression, error) {\n\t\t\treturn nil, want\n\t\t},\n\t}\n\tif _, err := ci.Interpret(nil, \"status=ok\"); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestCachedInterpreterInterpretHandlesNilContext(t *testing.T) {\n\tci := &CachedInterpreter{}\n\tok, err := ci.Interpret(nil, \"status=ok\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"nil context should not satisfy comparison\")\n\t}\n}\n",
        "tags": [
          "go",
          "interpreter",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "interpreter",
        "slug": "go-interpreter-interpret",
        "title": "CachedInterpreter.Interpret",
        "description": "Task 3 (medium): CachedInterpreter.Interpret\nИспользуйте кеш AST (cache) и Parser (если задан) для вычисления выражения.\nПодсказка: храните разобранный Expression по исходной строке и переиспользуйте его.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of CachedInterpreter.Interpret.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Expression описывает узел AST, который можно вычислить.\ntype Expression func(ctx map[string]string) (bool, error)\n\n// Ошибки интерпретатора.\nvar (\n\tErrEmptyComparison = errors.New(\"empty comparison\")\n\tErrUnknownOperator = errors.New(\"unknown operator\")\n\tErrEmptyExpression = errors.New(\"empty expression\")\n)\n\n// CachedInterpreter хранит кеш разобранных выражений.\ntype CachedInterpreter struct {\n\tmu     sync.RWMutex\n\tcache  map[string]Expression\n\tParser func(string) (Expression, error)\n}\n\n// Task 1 (easy): ParseComparison\n// Разберите простое выражение \"ключ=значение\" или \"ключ!=значение\" в Expression.\n// Подсказка: поддержите переменные в виде {{name}} и сравнивайте значения из ctx.\nfunc ParseComparison(input string) (Expression, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): ParseFilter\n// Разберите строку с логическими операциями AND/OR и скобками, построив Expression.\n// Подсказка: примените алгоритм сортировочной станции с приоритетом AND над OR.\nfunc ParseFilter(input string) (Expression, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CachedInterpreter.Interpret\n// Используйте кеш AST (cache) и Parser (если задан) для вычисления выражения.\n// Подсказка: храните разобранный Expression по исходной строке и переиспользуйте его.\nfunc (ci *CachedInterpreter) Interpret(ctx map[string]string, src string) (bool, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc ParseComparison(input string) (Expression, error) { // ParseComparison превращает текстовое сравнение в Expression.\n\ttrimmed := strings.TrimSpace(input) // Удаляем пробелы по краям для упрощения парсинга.\n\tif trimmed == \"\" {                  // Пустая строка невозможна.\n\t\treturn nil, ErrEmptyComparison // Сообщаем об ошибке формата.\n\t}\n\tvar op string                        // Храним найденный оператор.\n\tvar parts []string                   // Срез для левой и правой части.\n\tif strings.Contains(trimmed, \"!=\") { // Проверяем оператор \"не равно\".\n\t\top = \"!=\"                              // Фиксируем оператор.\n\t\tparts = strings.SplitN(trimmed, op, 2) // Делим выражение на две части.\n\t} else if strings.Contains(trimmed, \"=\") { // Проверяем оператор \"равно\".\n\t\top = \"=\"                               // Фиксируем оператор.\n\t\tparts = strings.SplitN(trimmed, op, 2) // Делим выражение на две части.\n\t} else { // Если оператор не найден — это ошибка.\n\t\treturn nil, ErrUnknownOperator // Возвращаем ошибку неизвестного оператора.\n\t}\n\tif len(parts) != 2 { // Должно быть ровно две части.\n\t\treturn nil, ErrEmptyComparison // Если нет — формат некорректен.\n\t}\n\tkey := strings.TrimSpace(parts[0])   // Выделяем имя ключа слева.\n\tvalue := strings.TrimSpace(parts[1]) // И ожидаемое значение справа.\n\tif key == \"\" || value == \"\" {        // Пустые части недопустимы.\n\t\treturn nil, ErrEmptyComparison // Сообщаем об ошибке.\n\t}\n\tnegate := op == \"!=\"                                                  // Флаг для инвертирования результата.\n\tvariable := \"\"                                                        // Имя переменной контекста (если используется).\n\tif strings.HasPrefix(value, \"{{\") && strings.HasSuffix(value, \"}}\") { // Проверяем ссылку на переменную.\n\t\tvariable = strings.TrimSpace(value[2 : len(value)-2]) // Достаём имя переменной без фигурных скобок.\n\t\tif variable == \"\" {                                   // Пустое имя переменной недопустимо.\n\t\t\treturn nil, ErrEmptyComparison // Возвращаем ошибку формата.\n\t\t}\n\t}\n\tliteral := value                                   // Сохраняем литеральное значение для прямого сравнения.\n\treturn func(ctx map[string]string) (bool, error) { // Возвращаем Expression как замыкание.\n\t\tif ctx == nil { // Nil-контекст трактуем как пустой.\n\t\t\tctx = map[string]string{} // Создаём пустую map, чтобы избежать паник.\n\t\t}\n\t\tleft := ctx[key]    // Получаем значение ключа из контекста.\n\t\tright := literal    // По умолчанию сравниваем с литералом.\n\t\tif variable != \"\" { // Если значение берётся из переменной...\n\t\t\tright = ctx[variable] // ...подставляем его из контекста.\n\t\t}\n\t\tresult := left == right // Сравниваем левое и правое значения.\n\t\tif negate {             // При операторе \"!=\" инвертируем результат.\n\t\t\tresult = !result // Инверсия булевого значения.\n\t\t}\n\t\treturn result, nil // Возвращаем итог без ошибки.\n\t}, nil\n}\n\nfunc ParseFilter(input string) (Expression, error) { // ParseFilter строит AST для выражения с AND/OR.\n\tif strings.TrimSpace(input) == \"\" { // Проверяем, что строка не пустая.\n\t\treturn nil, ErrEmptyExpression // Пустое выражение недопустимо.\n\t}\n\tnormalized := strings.NewReplacer(\"(\", \" ( \", \")\", \" ) \").Replace(input) // Добавляем пробелы вокруг скобок для токенизации.\n\ttokens := strings.Fields(normalized)                                     // Разбиваем строку на токены по пробелам.\n\tif len(tokens) == 0 {                                                    // После разбиения должен остаться хотя бы один токен.\n\t\treturn nil, ErrEmptyExpression // Иначе выражение некорректно.\n\t}\n\tprecedence := map[string]int{\"OR\": 1, \"AND\": 2} // Определяем приоритет операторов.\n\tvar exprStack []Expression                      // Стек частичных выражений.\n\tvar opStack []string                            // Стек операторов.\n\tapplyOperator := func() error {                 // Вспомогательная функция для применения оператора.\n\t\tif len(opStack) == 0 || len(exprStack) < 2 { // Нужны оператор и минимум два операнда.\n\t\t\treturn ErrEmptyExpression // Если их нет — выражение некорректно.\n\t\t}\n\t\top := opStack[len(opStack)-1]            // Достаём последний оператор.\n\t\topStack = opStack[:len(opStack)-1]       // Удаляем его из стека.\n\t\tright := exprStack[len(exprStack)-1]     // Берём правый операнд.\n\t\tleft := exprStack[len(exprStack)-2]      // Берём левый операнд.\n\t\texprStack = exprStack[:len(exprStack)-2] // Удаляем операнды из стека.\n\t\tvar combined Expression                  // Здесь будет замыкание для объединения.\n\t\tswitch op {                              // Ветвим по типу оператора.\n\t\tcase \"AND\": // Оператор логического И.\n\t\t\tcombined = func(ctx map[string]string) (bool, error) { // Создаём Expression, объединяющий левого и правого потомков.\n\t\t\t\tlb, err := left(ctx)   // Вычисляем левое выражение.\n\t\t\t\tif err != nil || !lb { // Ошибка или false позволяют коротко завершить.\n\t\t\t\t\treturn lb, err // Возвращаем сразу же.\n\t\t\t\t}\n\t\t\t\treturn right(ctx) // Вычисляем правое выражение.\n\t\t\t}\n\t\tcase \"OR\": // Оператор логического ИЛИ.\n\t\t\tcombined = func(ctx map[string]string) (bool, error) {\n\t\t\t\tlb, err := left(ctx) // Вычисляем левое выражение.\n\t\t\t\tif err != nil {      // Ошибка прокидывается наверх.\n\t\t\t\t\treturn false, err // Возвращаем ошибку без вычисления правого операнда.\n\t\t\t\t}\n\t\t\t\tif lb { // Если левый дал true — можно коротко вернуть true.\n\t\t\t\t\treturn true, nil // Успешный результат.\n\t\t\t\t}\n\t\t\t\treturn right(ctx) // Иначе вычисляем правый операнд.\n\t\t\t}\n\t\tdefault: // Неизвестный оператор не поддерживается.\n\t\t\treturn ErrUnknownOperator // Сообщаем, что оператор неизвестен.\n\t\t}\n\t\texprStack = append(exprStack, combined) // Кладём комбинированное выражение обратно на стек.\n\t\treturn nil                              // Возвращаем успех.\n\t}\n\tfor _, token := range tokens { // Итерируемся по токенам.\n\t\tupper := strings.ToUpper(token) // Для операторов используем верхний регистр.\n\t\tswitch upper {                  // Анализируем токен.\n\t\tcase \"AND\", \"OR\": // Обрабатываем логические операторы.\n\t\t\tfor len(opStack) > 0 && opStack[len(opStack)-1] != \"(\" && precedence[opStack[len(opStack)-1]] >= precedence[upper] { // Пока наверху более приоритетный оператор...\n\t\t\t\tif err := applyOperator(); err != nil { // ...применяем его.\n\t\t\t\t\treturn nil, err // В случае ошибки возвращаем её.\n\t\t\t\t}\n\t\t\t}\n\t\t\topStack = append(opStack, upper) // Кладём текущий оператор на стек.\n\t\tcase \"(\": // Открывающая скобка просто пушится в стек операторов.\n\t\t\topStack = append(opStack, upper) // Добавляем маркер скобки.\n\t\tcase \")\": // Закрывающая скобка инициирует свёртку.\n\t\t\tfor len(opStack) > 0 && opStack[len(opStack)-1] != \"(\" { // Пока не найдём открытую скобку...\n\t\t\t\tif err := applyOperator(); err != nil { // ...применяем операторы.\n\t\t\t\t\treturn nil, err // Ошибку прокидываем наверх.\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(opStack) == 0 { // Если скобка не найдена — выражение некорректно.\n\t\t\t\treturn nil, ErrEmptyExpression // Сообщаем об ошибке.\n\t\t\t}\n\t\t\topStack = opStack[:len(opStack)-1] // Удаляем открывающую скобку из стека.\n\t\tdefault: // Все остальные токены трактуем как сравнения.\n\t\t\texpr, err := ParseComparison(token) // Парсим сравнение в Expression.\n\t\t\tif err != nil {                     // Ошибки парсинга сравнения прокидываем наверх.\n\t\t\t\treturn nil, err // Возвращаем ошибку парсера сравнения.\n\t\t\t}\n\t\t\texprStack = append(exprStack, expr) // Пушим выражение в стек операндов.\n\t\t}\n\t}\n\tfor len(opStack) > 0 { // После обработки всех токенов сворачиваем оставшиеся операторы.\n\t\tif opStack[len(opStack)-1] == \"(\" { // Оставшаяся открытая скобка означает ошибку.\n\t\t\treturn nil, ErrEmptyExpression // Сообщаем о некорректных скобках.\n\t\t}\n\t\tif err := applyOperator(); err != nil { // Применяем оператор.\n\t\t\treturn nil, err // Ошибку возвращаем вызывающему коду.\n\t\t}\n\t}\n\tif len(exprStack) != 1 { // После свёртки должен остаться один элемент.\n\t\treturn nil, ErrEmptyExpression // Если нет — выражение некорректно.\n\t}\n\treturn exprStack[0], nil // Возвращаем итоговое Expression.\n}\n\nfunc (ci *CachedInterpreter) Interpret(ctx map[string]string, src string) (bool, error) { // Interpret использует кешированное AST для вычисления.\n\tif ci == nil { // Nil-получатель использовать нельзя.\n\t\treturn false, errors.New(\"interpreter is nil\") // Сообщаем о неправильно созданном интерпретаторе.\n\t}\n\ttrimmed := strings.TrimSpace(src) // Обрезаем пробелы в исходной строке.\n\tif trimmed == \"\" {                // Пустая строка недопустима.\n\t\treturn false, ErrEmptyExpression // Возвращаем соответствующую ошибку.\n\t}\n\tparser := ci.Parser // Используем пользовательский парсер, если задан.\n\tif parser == nil {  // Если парсер не задан — используем ParseFilter.\n\t\tparser = ParseFilter // Присваиваем стандартную функцию разбора.\n\t}\n\tci.mu.RLock()        // Берём read-lock для проверки кеша.\n\tif ci.cache == nil { // Если карта ещё не инициализирована...\n\t\tci.mu.RUnlock()      // ...отпускаем rlock...\n\t\tci.mu.Lock()         // ...берём write-lock для инициализации.\n\t\tif ci.cache == nil { // Повторно проверяем после захвата lock.\n\t\t\tci.cache = make(map[string]Expression) // Создаём map для хранения AST.\n\t\t}\n\t\tci.mu.Unlock() // Освобождаем write-lock.\n\t\tci.mu.RLock()  // Берём rlock снова для доступа к кешу.\n\t}\n\texpr, ok := ci.cache[trimmed] // Пытаемся найти выражение в кеше.\n\tci.mu.RUnlock()               // Освобождаем rlock.\n\tif !ok {                      // Если выражения нет в кеше — нужно распарсить.\n\t\tparsed, err := parser(trimmed) // Парсим строку в AST.\n\t\tif err != nil {                // Ошибку парсера сразу возвращаем.\n\t\t\treturn false, err // Прокидываем ошибку наверх.\n\t\t}\n\t\tci.mu.Lock()         // Захватываем write-lock для записи в кеш.\n\t\tif ci.cache == nil { // Проверяем, что карта всё ещё инициализирована.\n\t\t\tci.cache = make(map[string]Expression) // Инициализируем при необходимости (если была вычищена).\n\t\t}\n\t\tci.cache[trimmed] = parsed // Записываем новое AST в кеш.\n\t\tci.mu.Unlock()             // Освобождаем lock.\n\t\texpr = parsed              // Используем распарсенное выражение.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на пустой для безопасной работы замыканий.\n\t\tctx = map[string]string{} // Создаём пустую map.\n\t}\n\treturn expr(ctx) // Вычисляем итоговое выражение и возвращаем результат.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"sync/atomic\"\n\t\"testing\"\n)\n\n// ---- ParseComparison ----\n\nfunc TestParseComparisonLiteralEquals(t *testing.T) {\n\texpr, err := ParseComparison(\"status=green\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tok, err := expr(map[string]string{\"status\": \"green\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected comparison to be true\")\n\t}\n}\n\nfunc TestParseComparisonLiteralNotEquals(t *testing.T) {\n\texpr, err := ParseComparison(\"env!=prod\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tok, err := expr(map[string]string{\"env\": \"stage\"})\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"!= expression should be true\")\n\t}\n}\n\nfunc TestParseComparisonVariableLookup(t *testing.T) {\n\texpr, err := ParseComparison(\"owner={{user}}\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"owner\": \"dev\", \"user\": \"dev\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected variable comparison to be true\")\n\t}\n}\n\nfunc TestParseComparisonRejectsEmpty(t *testing.T) {\n\tif _, err := ParseComparison(\"   \"); !errors.Is(err, ErrEmptyComparison) {\n\t\tt.Fatalf(\"expected ErrEmptyComparison, got %v\", err)\n\t}\n}\n\n// ---- ParseFilter ----\n\nfunc TestParseFilterAndPrecedence(t *testing.T) {\n\texpr, err := ParseFilter(\"role=admin AND team=core OR role=guest\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"role\": \"admin\", \"team\": \"sales\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"AND should bind tighter than OR\")\n\t}\n}\n\nfunc TestParseFilterParentheses(t *testing.T) {\n\texpr, err := ParseFilter(\"role=admin AND (team=core OR team=ops)\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tctx := map[string]string{\"role\": \"admin\", \"team\": \"ops\"}\n\tok, err := expr(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected eval err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"parentheses should allow OR to match\")\n\t}\n}\n\nfunc TestParseFilterInvalidToken(t *testing.T) {\n\tif _, err := ParseFilter(\"role=admin XOR team=core\"); err == nil {\n\t\tt.Fatalf(\"expected error for unknown operator\")\n\t}\n}\n\n// ---- CachedInterpreter.Interpret ----\n\nfunc TestCachedInterpreterInterpretCachesAST(t *testing.T) {\n\tvar calls atomic.Int64\n\tci := &CachedInterpreter{\n\t\tParser: func(src string) (Expression, error) {\n\t\t\tcalls.Add(1)\n\t\t\treturn ParseComparison(src)\n\t\t},\n\t}\n\tctx := map[string]string{\"status\": \"ok\"}\n\tfor i := 0; i < 3; i++ {\n\t\tok, err := ci.Interpret(ctx, \"status=ok\")\n\t\tif err != nil || !ok {\n\t\t\tt.Fatalf(\"unexpected result: ok=%v err=%v\", ok, err)\n\t\t}\n\t}\n\tif calls.Load() != 1 {\n\t\tt.Fatalf(\"expression should be cached, calls=%d\", calls.Load())\n\t}\n}\n\nfunc TestCachedInterpreterInterpretUsesDefaultParser(t *testing.T) {\n\tci := &CachedInterpreter{}\n\tok, err := ci.Interpret(map[string]string{\"env\": \"prod\"}, \"env=prod\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif !ok {\n\t\tt.Fatalf(\"expected expression to be true\")\n\t}\n}\n\nfunc TestCachedInterpreterInterpretPropagatesParserError(t *testing.T) {\n\twant := errors.New(\"boom\")\n\tci := &CachedInterpreter{\n\t\tParser: func(string) (Expression, error) {\n\t\t\treturn nil, want\n\t\t},\n\t}\n\tif _, err := ci.Interpret(nil, \"status=ok\"); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestCachedInterpreterInterpretHandlesNilContext(t *testing.T) {\n\tci := &CachedInterpreter{}\n\tok, err := ci.Interpret(nil, \"status=ok\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif ok {\n\t\tt.Fatalf(\"nil context should not satisfy comparison\")\n\t}\n}\n",
        "tags": [
          "go",
          "interpreter",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-iterator",
    "tasks": [
      {
        "package": "iterator",
        "slug": "go-iterator-newsliceiterator",
        "title": "NewSliceIterator",
        "description": "Task 1 (easy): NewSliceIterator\nВерните итератор по срезу строк, который возвращает элементы ровно один раз.\nПодсказка: замкните индекс и исходный slice внутри возвращаемой функции.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of NewSliceIterator.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\n// Iterator описывает функцию, возвращающую следующий элемент последовательности.\ntype Iterator func() (string, bool)\n\n// Task 1 (easy): NewSliceIterator\n// Верните итератор по срезу строк, который возвращает элементы ровно один раз.\n// Подсказка: замкните индекс и исходный slice внутри возвращаемой функции.\nfunc NewSliceIterator(items []string) Iterator {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): FilterIterator\n// Оберните итератор, пропуская только элементы, удовлетворяющие predicate.\n// Подсказка: вызывайте исходный итератор до тех пор, пока не найдёте подходящее значение.\nfunc FilterIterator(src Iterator, predicate func(string) bool) Iterator {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CollectIterator\n// Соберите все элементы итератора, передавая каждый найденный элемент в callback fn.\n// Подсказка: прекращайте обход, если callback возвращает false.\nfunc CollectIterator(it Iterator, fn func(item string) bool) []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc NewSliceIterator(items []string) Iterator { // NewSliceIterator создаёт итератор по срезу строк.\n\tidx := 0          // Текущая позиция в срезе удерживается внутри замыкания.\n\tif items == nil { // Nil-срез приводим к пустому для единообразия.\n\t\titems = []string{} // Пустой срез безопаснее для обращения по индексу.\n\t}\n\treturn func() (string, bool) { // Возвращаем функцию, реализующую интерфейс Iterator.\n\t\tif idx >= len(items) { // Если элементы закончились...\n\t\t\treturn \"\", false // ...сообщаем об окончании последовательности.\n\t\t}\n\t\tval := items[idx] // Берём текущий элемент.\n\t\tidx++             // Сдвигаем позицию вперёд для следующего вызова.\n\t\treturn val, true  // Возвращаем найденное значение и признак успеха.\n\t}\n}\n\nfunc FilterIterator(src Iterator, predicate func(string) bool) Iterator { // FilterIterator оборачивает итератор фильтрацией.\n\tif src == nil { // Nil-итератор означает пустую последовательность.\n\t\treturn func() (string, bool) { return \"\", false } // Возвращаем итератор, всегда завершающийся сразу.\n\t}\n\treturn func() (string, bool) { // Возвращаем новое замыкание.\n\t\tfor { // Цикл повторяется, пока не найдём подходящий элемент.\n\t\t\tval, ok := src() // Получаем следующий элемент из исходного итератора.\n\t\t\tif !ok {         // Если элементы закончились...\n\t\t\t\treturn \"\", false // ...сообщаем о завершении.\n\t\t\t}\n\t\t\tif predicate == nil || predicate(val) { // Проверяем условие фильтрации (или пропускаем при nil predicate).\n\t\t\t\treturn val, true // Возвращаем подходящий элемент.\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc CollectIterator(it Iterator, fn func(item string) bool) []string { // CollectIterator пробегается по итератору и собирает значения.\n\tif it == nil { // Nil-итератор ничего не даёт.\n\t\treturn nil // Возвращаем nil/пустой список.\n\t}\n\tvar out []string // Срез с накопленными значениями.\n\tif fn == nil {   // Nil-callback трактуем как функцию, всегда возвращающую true.\n\t\tfn = func(string) bool { return true } // Подменяем на дефолтную реализацию.\n\t}\n\tfor { // Последовательно читаем элементы итератора.\n\t\tval, ok := it() // Получаем следующий элемент.\n\t\tif !ok {        // Если элементы закончились...\n\t\t\tbreak // ...прерываем цикл.\n\t\t}\n\t\tout = append(out, val)      // Добавляем значение в результирующий срез.\n\t\tif cont := fn(val); !cont { // Вызываем callback и проверяем, хочет ли он продолжения.\n\t\t\tbreak // Прерываем обход по запросу callback'а.\n\t\t}\n\t}\n\treturn out // Возвращаем собранные значения.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- NewSliceIterator ----\n\nfunc TestNewSliceIteratorTraversesAllItems(t *testing.T) {\n\tit := NewSliceIterator([]string{\"a\", \"b\", \"c\"})\n\tvar got []string\n\tfor {\n\t\tval, ok := it()\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tgot = append(got, val)\n\t}\n\tif len(got) != 3 || got[0] != \"a\" || got[2] != \"c\" {\n\t\tt.Fatalf(\"unexpected iteration result: %#v\", got)\n\t}\n}\n\nfunc TestNewSliceIteratorEmptySlice(t *testing.T) {\n\tit := NewSliceIterator(nil)\n\tif _, ok := it(); ok {\n\t\tt.Fatalf(\"iterator should be empty\")\n\t}\n}\n\nfunc TestNewSliceIteratorIndependentStates(t *testing.T) {\n\titems := []string{\"x\", \"y\"}\n\tit1 := NewSliceIterator(items)\n\tit2 := NewSliceIterator(items)\n\t_, _ = it1()\n\tval, ok := it2()\n\tif !ok || val != \"x\" {\n\t\tt.Fatalf(\"iterators should not share state\")\n\t}\n}\n\n// ---- FilterIterator ----\n\nfunc TestFilterIteratorAppliesPredicate(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"dev\", \"ops\", \"qa\"})\n\tfiltered := FilterIterator(src, func(item string) bool { return item != \"ops\" })\n\tvals := CollectIterator(filtered, func(string) bool { return true })\n\tif len(vals) != 2 || vals[1] != \"qa\" {\n\t\tt.Fatalf(\"filter produced wrong slice: %#v\", vals)\n\t}\n}\n\nfunc TestFilterIteratorStopsWithSource(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"only\"})\n\tfiltered := FilterIterator(src, func(string) bool { return false })\n\tif _, ok := filtered(); ok {\n\t\tt.Fatalf(\"filtered iterator should be empty\")\n\t}\n}\n\nfunc TestFilterIteratorNilPredicateAllowsAll(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"a\", \"b\"})\n\tfiltered := FilterIterator(src, nil)\n\tvals := CollectIterator(filtered, func(string) bool { return true })\n\tif len(vals) != 2 {\n\t\tt.Fatalf(\"expected all items, got %#v\", vals)\n\t}\n}\n\n// ---- CollectIterator ----\n\nfunc TestCollectIteratorReturnsSlice(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"1\", \"2\"})\n\tgot := CollectIterator(src, func(string) bool { return true })\n\tif len(got) != 2 || got[0] != \"1\" {\n\t\tt.Fatalf(\"unexpected collect: %#v\", got)\n\t}\n}\n\nfunc TestCollectIteratorStopsWhenCallbackReturnsFalse(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"a\", \"b\", \"c\"})\n\tgot := CollectIterator(src, func(item string) bool {\n\t\treturn item != \"b\"\n\t})\n\tif len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"callback stop not respected: %#v\", got)\n\t}\n}\n\nfunc TestCollectIteratorHandlesNilIterator(t *testing.T) {\n\tgot := CollectIterator(nil, func(string) bool { return true })\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"nil iterator should yield empty slice\")\n\t}\n}\n",
        "tags": [
          "go",
          "iterator",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "iterator",
        "slug": "go-iterator-filteriterator",
        "title": "FilterIterator",
        "description": "Task 2 (easy+): FilterIterator\nОберните итератор, пропуская только элементы, удовлетворяющие predicate.\nПодсказка: вызывайте исходный итератор до тех пор, пока не найдёте подходящее значение.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of FilterIterator.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\n// Iterator описывает функцию, возвращающую следующий элемент последовательности.\ntype Iterator func() (string, bool)\n\n// Task 1 (easy): NewSliceIterator\n// Верните итератор по срезу строк, который возвращает элементы ровно один раз.\n// Подсказка: замкните индекс и исходный slice внутри возвращаемой функции.\nfunc NewSliceIterator(items []string) Iterator {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): FilterIterator\n// Оберните итератор, пропуская только элементы, удовлетворяющие predicate.\n// Подсказка: вызывайте исходный итератор до тех пор, пока не найдёте подходящее значение.\nfunc FilterIterator(src Iterator, predicate func(string) bool) Iterator {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CollectIterator\n// Соберите все элементы итератора, передавая каждый найденный элемент в callback fn.\n// Подсказка: прекращайте обход, если callback возвращает false.\nfunc CollectIterator(it Iterator, fn func(item string) bool) []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc NewSliceIterator(items []string) Iterator { // NewSliceIterator создаёт итератор по срезу строк.\n\tidx := 0          // Текущая позиция в срезе удерживается внутри замыкания.\n\tif items == nil { // Nil-срез приводим к пустому для единообразия.\n\t\titems = []string{} // Пустой срез безопаснее для обращения по индексу.\n\t}\n\treturn func() (string, bool) { // Возвращаем функцию, реализующую интерфейс Iterator.\n\t\tif idx >= len(items) { // Если элементы закончились...\n\t\t\treturn \"\", false // ...сообщаем об окончании последовательности.\n\t\t}\n\t\tval := items[idx] // Берём текущий элемент.\n\t\tidx++             // Сдвигаем позицию вперёд для следующего вызова.\n\t\treturn val, true  // Возвращаем найденное значение и признак успеха.\n\t}\n}\n\nfunc FilterIterator(src Iterator, predicate func(string) bool) Iterator { // FilterIterator оборачивает итератор фильтрацией.\n\tif src == nil { // Nil-итератор означает пустую последовательность.\n\t\treturn func() (string, bool) { return \"\", false } // Возвращаем итератор, всегда завершающийся сразу.\n\t}\n\treturn func() (string, bool) { // Возвращаем новое замыкание.\n\t\tfor { // Цикл повторяется, пока не найдём подходящий элемент.\n\t\t\tval, ok := src() // Получаем следующий элемент из исходного итератора.\n\t\t\tif !ok {         // Если элементы закончились...\n\t\t\t\treturn \"\", false // ...сообщаем о завершении.\n\t\t\t}\n\t\t\tif predicate == nil || predicate(val) { // Проверяем условие фильтрации (или пропускаем при nil predicate).\n\t\t\t\treturn val, true // Возвращаем подходящий элемент.\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc CollectIterator(it Iterator, fn func(item string) bool) []string { // CollectIterator пробегается по итератору и собирает значения.\n\tif it == nil { // Nil-итератор ничего не даёт.\n\t\treturn nil // Возвращаем nil/пустой список.\n\t}\n\tvar out []string // Срез с накопленными значениями.\n\tif fn == nil {   // Nil-callback трактуем как функцию, всегда возвращающую true.\n\t\tfn = func(string) bool { return true } // Подменяем на дефолтную реализацию.\n\t}\n\tfor { // Последовательно читаем элементы итератора.\n\t\tval, ok := it() // Получаем следующий элемент.\n\t\tif !ok {        // Если элементы закончились...\n\t\t\tbreak // ...прерываем цикл.\n\t\t}\n\t\tout = append(out, val)      // Добавляем значение в результирующий срез.\n\t\tif cont := fn(val); !cont { // Вызываем callback и проверяем, хочет ли он продолжения.\n\t\t\tbreak // Прерываем обход по запросу callback'а.\n\t\t}\n\t}\n\treturn out // Возвращаем собранные значения.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- NewSliceIterator ----\n\nfunc TestNewSliceIteratorTraversesAllItems(t *testing.T) {\n\tit := NewSliceIterator([]string{\"a\", \"b\", \"c\"})\n\tvar got []string\n\tfor {\n\t\tval, ok := it()\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tgot = append(got, val)\n\t}\n\tif len(got) != 3 || got[0] != \"a\" || got[2] != \"c\" {\n\t\tt.Fatalf(\"unexpected iteration result: %#v\", got)\n\t}\n}\n\nfunc TestNewSliceIteratorEmptySlice(t *testing.T) {\n\tit := NewSliceIterator(nil)\n\tif _, ok := it(); ok {\n\t\tt.Fatalf(\"iterator should be empty\")\n\t}\n}\n\nfunc TestNewSliceIteratorIndependentStates(t *testing.T) {\n\titems := []string{\"x\", \"y\"}\n\tit1 := NewSliceIterator(items)\n\tit2 := NewSliceIterator(items)\n\t_, _ = it1()\n\tval, ok := it2()\n\tif !ok || val != \"x\" {\n\t\tt.Fatalf(\"iterators should not share state\")\n\t}\n}\n\n// ---- FilterIterator ----\n\nfunc TestFilterIteratorAppliesPredicate(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"dev\", \"ops\", \"qa\"})\n\tfiltered := FilterIterator(src, func(item string) bool { return item != \"ops\" })\n\tvals := CollectIterator(filtered, func(string) bool { return true })\n\tif len(vals) != 2 || vals[1] != \"qa\" {\n\t\tt.Fatalf(\"filter produced wrong slice: %#v\", vals)\n\t}\n}\n\nfunc TestFilterIteratorStopsWithSource(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"only\"})\n\tfiltered := FilterIterator(src, func(string) bool { return false })\n\tif _, ok := filtered(); ok {\n\t\tt.Fatalf(\"filtered iterator should be empty\")\n\t}\n}\n\nfunc TestFilterIteratorNilPredicateAllowsAll(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"a\", \"b\"})\n\tfiltered := FilterIterator(src, nil)\n\tvals := CollectIterator(filtered, func(string) bool { return true })\n\tif len(vals) != 2 {\n\t\tt.Fatalf(\"expected all items, got %#v\", vals)\n\t}\n}\n\n// ---- CollectIterator ----\n\nfunc TestCollectIteratorReturnsSlice(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"1\", \"2\"})\n\tgot := CollectIterator(src, func(string) bool { return true })\n\tif len(got) != 2 || got[0] != \"1\" {\n\t\tt.Fatalf(\"unexpected collect: %#v\", got)\n\t}\n}\n\nfunc TestCollectIteratorStopsWhenCallbackReturnsFalse(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"a\", \"b\", \"c\"})\n\tgot := CollectIterator(src, func(item string) bool {\n\t\treturn item != \"b\"\n\t})\n\tif len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"callback stop not respected: %#v\", got)\n\t}\n}\n\nfunc TestCollectIteratorHandlesNilIterator(t *testing.T) {\n\tgot := CollectIterator(nil, func(string) bool { return true })\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"nil iterator should yield empty slice\")\n\t}\n}\n",
        "tags": [
          "go",
          "iterator",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "iterator",
        "slug": "go-iterator-collectiterator",
        "title": "CollectIterator",
        "description": "Task 3 (medium): CollectIterator\nСоберите все элементы итератора, передавая каждый найденный элемент в callback fn.\nПодсказка: прекращайте обход, если callback возвращает false.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of CollectIterator.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\n// Iterator описывает функцию, возвращающую следующий элемент последовательности.\ntype Iterator func() (string, bool)\n\n// Task 1 (easy): NewSliceIterator\n// Верните итератор по срезу строк, который возвращает элементы ровно один раз.\n// Подсказка: замкните индекс и исходный slice внутри возвращаемой функции.\nfunc NewSliceIterator(items []string) Iterator {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): FilterIterator\n// Оберните итератор, пропуская только элементы, удовлетворяющие predicate.\n// Подсказка: вызывайте исходный итератор до тех пор, пока не найдёте подходящее значение.\nfunc FilterIterator(src Iterator, predicate func(string) bool) Iterator {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): CollectIterator\n// Соберите все элементы итератора, передавая каждый найденный элемент в callback fn.\n// Подсказка: прекращайте обход, если callback возвращает false.\nfunc CollectIterator(it Iterator, fn func(item string) bool) []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc NewSliceIterator(items []string) Iterator { // NewSliceIterator создаёт итератор по срезу строк.\n\tidx := 0          // Текущая позиция в срезе удерживается внутри замыкания.\n\tif items == nil { // Nil-срез приводим к пустому для единообразия.\n\t\titems = []string{} // Пустой срез безопаснее для обращения по индексу.\n\t}\n\treturn func() (string, bool) { // Возвращаем функцию, реализующую интерфейс Iterator.\n\t\tif idx >= len(items) { // Если элементы закончились...\n\t\t\treturn \"\", false // ...сообщаем об окончании последовательности.\n\t\t}\n\t\tval := items[idx] // Берём текущий элемент.\n\t\tidx++             // Сдвигаем позицию вперёд для следующего вызова.\n\t\treturn val, true  // Возвращаем найденное значение и признак успеха.\n\t}\n}\n\nfunc FilterIterator(src Iterator, predicate func(string) bool) Iterator { // FilterIterator оборачивает итератор фильтрацией.\n\tif src == nil { // Nil-итератор означает пустую последовательность.\n\t\treturn func() (string, bool) { return \"\", false } // Возвращаем итератор, всегда завершающийся сразу.\n\t}\n\treturn func() (string, bool) { // Возвращаем новое замыкание.\n\t\tfor { // Цикл повторяется, пока не найдём подходящий элемент.\n\t\t\tval, ok := src() // Получаем следующий элемент из исходного итератора.\n\t\t\tif !ok {         // Если элементы закончились...\n\t\t\t\treturn \"\", false // ...сообщаем о завершении.\n\t\t\t}\n\t\t\tif predicate == nil || predicate(val) { // Проверяем условие фильтрации (или пропускаем при nil predicate).\n\t\t\t\treturn val, true // Возвращаем подходящий элемент.\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc CollectIterator(it Iterator, fn func(item string) bool) []string { // CollectIterator пробегается по итератору и собирает значения.\n\tif it == nil { // Nil-итератор ничего не даёт.\n\t\treturn nil // Возвращаем nil/пустой список.\n\t}\n\tvar out []string // Срез с накопленными значениями.\n\tif fn == nil {   // Nil-callback трактуем как функцию, всегда возвращающую true.\n\t\tfn = func(string) bool { return true } // Подменяем на дефолтную реализацию.\n\t}\n\tfor { // Последовательно читаем элементы итератора.\n\t\tval, ok := it() // Получаем следующий элемент.\n\t\tif !ok {        // Если элементы закончились...\n\t\t\tbreak // ...прерываем цикл.\n\t\t}\n\t\tout = append(out, val)      // Добавляем значение в результирующий срез.\n\t\tif cont := fn(val); !cont { // Вызываем callback и проверяем, хочет ли он продолжения.\n\t\t\tbreak // Прерываем обход по запросу callback'а.\n\t\t}\n\t}\n\treturn out // Возвращаем собранные значения.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- NewSliceIterator ----\n\nfunc TestNewSliceIteratorTraversesAllItems(t *testing.T) {\n\tit := NewSliceIterator([]string{\"a\", \"b\", \"c\"})\n\tvar got []string\n\tfor {\n\t\tval, ok := it()\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tgot = append(got, val)\n\t}\n\tif len(got) != 3 || got[0] != \"a\" || got[2] != \"c\" {\n\t\tt.Fatalf(\"unexpected iteration result: %#v\", got)\n\t}\n}\n\nfunc TestNewSliceIteratorEmptySlice(t *testing.T) {\n\tit := NewSliceIterator(nil)\n\tif _, ok := it(); ok {\n\t\tt.Fatalf(\"iterator should be empty\")\n\t}\n}\n\nfunc TestNewSliceIteratorIndependentStates(t *testing.T) {\n\titems := []string{\"x\", \"y\"}\n\tit1 := NewSliceIterator(items)\n\tit2 := NewSliceIterator(items)\n\t_, _ = it1()\n\tval, ok := it2()\n\tif !ok || val != \"x\" {\n\t\tt.Fatalf(\"iterators should not share state\")\n\t}\n}\n\n// ---- FilterIterator ----\n\nfunc TestFilterIteratorAppliesPredicate(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"dev\", \"ops\", \"qa\"})\n\tfiltered := FilterIterator(src, func(item string) bool { return item != \"ops\" })\n\tvals := CollectIterator(filtered, func(string) bool { return true })\n\tif len(vals) != 2 || vals[1] != \"qa\" {\n\t\tt.Fatalf(\"filter produced wrong slice: %#v\", vals)\n\t}\n}\n\nfunc TestFilterIteratorStopsWithSource(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"only\"})\n\tfiltered := FilterIterator(src, func(string) bool { return false })\n\tif _, ok := filtered(); ok {\n\t\tt.Fatalf(\"filtered iterator should be empty\")\n\t}\n}\n\nfunc TestFilterIteratorNilPredicateAllowsAll(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"a\", \"b\"})\n\tfiltered := FilterIterator(src, nil)\n\tvals := CollectIterator(filtered, func(string) bool { return true })\n\tif len(vals) != 2 {\n\t\tt.Fatalf(\"expected all items, got %#v\", vals)\n\t}\n}\n\n// ---- CollectIterator ----\n\nfunc TestCollectIteratorReturnsSlice(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"1\", \"2\"})\n\tgot := CollectIterator(src, func(string) bool { return true })\n\tif len(got) != 2 || got[0] != \"1\" {\n\t\tt.Fatalf(\"unexpected collect: %#v\", got)\n\t}\n}\n\nfunc TestCollectIteratorStopsWhenCallbackReturnsFalse(t *testing.T) {\n\tsrc := NewSliceIterator([]string{\"a\", \"b\", \"c\"})\n\tgot := CollectIterator(src, func(item string) bool {\n\t\treturn item != \"b\"\n\t})\n\tif len(got) != 2 || got[1] != \"b\" {\n\t\tt.Fatalf(\"callback stop not respected: %#v\", got)\n\t}\n}\n\nfunc TestCollectIteratorHandlesNilIterator(t *testing.T) {\n\tgot := CollectIterator(nil, func(string) bool { return true })\n\tif len(got) != 0 {\n\t\tt.Fatalf(\"nil iterator should yield empty slice\")\n\t}\n}\n",
        "tags": [
          "go",
          "iterator",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-mediator",
    "tasks": [
      {
        "package": "mediator",
        "slug": "go-mediator-register",
        "title": "Register",
        "description": "Task 1 (easy): Register\nЗарегистрируйте участника по имени и callback'у, запрещая дубликаты.\nПодсказка: лениво инициализируйте map и возвращайте ErrDuplicateParticipant при конфликте.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Register.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n)\n\n// Message описывает событие, которое рассылает медиатор.\ntype Message struct {\n\tFrom string\n\tTo   string\n\tBody string\n}\n\n// Ошибки медиатора.\nvar (\n\tErrDuplicateParticipant = errors.New(\"participant already exists\")\n\tErrUnknownParticipant   = errors.New(\"participant not found\")\n\tErrInvalidHandler       = errors.New(\"handler is nil\")\n)\n\n// ChatRoom реализует медиатор между участниками.\ntype ChatRoom struct {\n\tmu        sync.RWMutex\n\tlisteners map[string]func(Message)\n}\n\n// Task 1 (easy): Register\n// Зарегистрируйте участника по имени и callback'у, запрещая дубликаты.\n// Подсказка: лениво инициализируйте map и возвращайте ErrDuplicateParticipant при конфликте.\nfunc (c *ChatRoom) Register(name string, handler func(Message)) error {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Broadcast\n// Отправьте сообщение всем зарегистрированным участникам параллельно.\n// Подсказка: уважайте ctx.Done() и возвращайте ctx.Err() при отмене.\nfunc (c *ChatRoom) Broadcast(ctx context.Context, msg Message) error {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): SendDirect\n// Доставьте сообщение конкретному адресу, если он зарегистрирован.\n// Подсказка: возвращайте ErrUnknownParticipant для неизвестных имён, поддержите ctx.\nfunc (c *ChatRoom) SendDirect(ctx context.Context, to string, msg Message) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n)\n\nfunc (c *ChatRoom) Register(name string, handler func(Message)) error { // Register добавляет участника в медиатор.\n\tif c == nil { // Проверяем корректность получателя.\n\t\treturn errors.New(\"chat room is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif handler == nil { // Nil-handler не имеет смысла.\n\t\treturn ErrInvalidHandler // Возвращаем заранее объявленную ошибку.\n\t}\n\tc.mu.Lock()             // Захватываем mutex для работы с map.\n\tdefer c.mu.Unlock()     // Освобождаем его по завершении.\n\tif c.listeners == nil { // Лениво инициализируем map при первом вызове.\n\t\tc.listeners = make(map[string]func(Message)) // Создаём хранилище обработчиков.\n\t}\n\tif _, ok := c.listeners[name]; ok { // Проверяем наличие дубликата.\n\t\treturn ErrDuplicateParticipant // Сообщаем, что имя уже занято.\n\t}\n\tc.listeners[name] = handler // Сохраняем callback участника.\n\treturn nil                  // Успешная регистрация.\n}\n\nfunc (c *ChatRoom) Broadcast(ctx context.Context, msg Message) error { // Broadcast рассылает сообщение всем слушателям.\n\tif c == nil { // Nil-получатель использовать нельзя.\n\t\treturn errors.New(\"chat room is nil\") // Возвращаем ошибку конфигурации.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на Background.\n\t\tctx = context.Background() // Используем базовый контекст.\n\t}\n\tselect { // Проверяем отмену до начала отправки.\n\tcase <-ctx.Done(): // Контекст уже отменён.\n\t\treturn ctx.Err() // Возвращаем ошибку контекста.\n\tdefault:\n\t}\n\tc.mu.RLock()                                           // Берём read-lock для копирования handlers.\n\thandlers := make([]func(Message), 0, len(c.listeners)) // Подготавливаем временный срез обработчиков.\n\tfor _, h := range c.listeners {                        // Перебираем зарегистрированных участников.\n\t\tif h != nil { // Пропускаем nil-обработчики.\n\t\t\thandlers = append(handlers, h) // Копируем callback в срез.\n\t\t}\n\t}\n\tc.mu.RUnlock()                     // Освобождаем read-lock.\n\tvar wg sync.WaitGroup              // WaitGroup синхронизирует горутины.\n\terrCh := make(chan error, 1)       // Буферизированный канал для первой ошибки.\n\tfor _, handler := range handlers { // Запускаем обработку для каждого слушателя.\n\t\twg.Add(1)                  // Увеличиваем счётчик WaitGroup.\n\t\tgo func(h func(Message)) { // Стартуем горутину для конкретного слушателя.\n\t\t\tdefer wg.Done() // По завершении уменьшаем счётчик.\n\t\t\tselect {        // Проверяем отмену контекста перед отправкой.\n\t\t\tcase <-ctx.Done(): // Контекст отменён.\n\t\t\t\tselect { // Пытаемся сообщить об ошибке.\n\t\t\t\tcase errCh <- ctx.Err(): // Отправляем ошибку, если канал свободен.\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\treturn // Завершаем горутину досрочно.\n\t\t\tdefault:\n\t\t\t}\n\t\t\th(msg) // Вызываем callback с сообщением.\n\t\t}(handler)\n\t}\n\twg.Wait() // Ждём завершения всех горутин.\n\tselect {  // Проверяем, была ли отправлена ошибка отмены.\n\tcase err := <-errCh: // Если ошибка присутствует...\n\t\treturn err // ...возвращаем её вызывающему коду.\n\tdefault:\n\t\treturn nil // Иначе сообщаем об успешной рассылке.\n\t}\n}\n\nfunc (c *ChatRoom) SendDirect(ctx context.Context, to string, msg Message) error { // SendDirect отправляет сообщение конкретному участнику.\n\tif c == nil { // Nil-получатель невозможен.\n\t\treturn errors.New(\"chat room is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на Background.\n\t\tctx = context.Background() // Используем базовый контекст.\n\t}\n\tselect { // Проверяем отмену до поиска участника.\n\tcase <-ctx.Done(): // Контекст уже отменён.\n\t\treturn ctx.Err() // Возвращаем ошибку отмены.\n\tdefault:\n\t}\n\tc.mu.RLock()                   // Берём read-lock для доступа к map.\n\thandler, ok := c.listeners[to] // Ищем обработчик по имени.\n\tc.mu.RUnlock()                 // Освобождаем lock как можно раньше.\n\tif !ok || handler == nil {     // Если участника нет или у него нет handler'а...\n\t\treturn ErrUnknownParticipant // ...возвращаем соответствующую ошибку.\n\t}\n\tselect { // Повторно проверяем контекст перед вызовом callback.\n\tcase <-ctx.Done(): // Контекст отменён.\n\t\treturn ctx.Err() // Сообщаем об этом вызывающему коду.\n\tdefault:\n\t}\n\thandler(msg) // Доставляем сообщение напрямую слушателю.\n\treturn nil   // Возвращаем успешный результат.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- Register ----\n\nfunc TestChatRoomRegisterStoresHandler(t *testing.T) {\n\troom := &ChatRoom{}\n\thandlerCalled := false\n\tif err := room.Register(\"alice\", func(Message) { handlerCalled = true }); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\t_ = room.Broadcast(context.Background(), Message{From: \"system\", Body: \"hi\"})\n\tif !handlerCalled {\n\t\tt.Fatalf(\"registered handler not invoked\")\n\t}\n}\n\nfunc TestChatRoomRegisterRejectsDuplicates(t *testing.T) {\n\troom := &ChatRoom{}\n\t_ = room.Register(\"alice\", func(Message) {})\n\tif err := room.Register(\"alice\", func(Message) {}); !errors.Is(err, ErrDuplicateParticipant) {\n\t\tt.Fatalf(\"expected ErrDuplicateParticipant, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomRegisterValidatesHandler(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Register(\"alice\", nil); !errors.Is(err, ErrInvalidHandler) {\n\t\tt.Fatalf(\"expected ErrInvalidHandler, got %v\", err)\n\t}\n}\n\n// ---- Broadcast ----\n\nfunc TestChatRoomBroadcastDeliversToAll(t *testing.T) {\n\troom := &ChatRoom{}\n\tvar mu sync.Mutex\n\treceived := make(map[string]int)\n\tadd := func(name string) {\n\t\tt.Helper()\n\t\tif err := room.Register(name, func(Message) {\n\t\t\tmu.Lock()\n\t\t\treceived[name]++\n\t\t\tmu.Unlock()\n\t\t}); err != nil {\n\t\t\tt.Fatalf(\"register: %v\", err)\n\t\t}\n\t}\n\tadd(\"alice\")\n\tadd(\"bob\")\n\tif err := room.Broadcast(context.Background(), Message{Body: \"ping\"}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif received[\"alice\"] != 1 || received[\"bob\"] != 1 {\n\t\tt.Fatalf(\"not all participants received message: %#v\", received)\n\t}\n}\n\nfunc TestChatRoomBroadcastHonorsContext(t *testing.T) {\n\troom := &ChatRoom{}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := room.Broadcast(ctx, Message{}); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomBroadcastWithoutParticipants(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Broadcast(context.Background(), Message{}); err != nil {\n\t\tt.Fatalf(\"broadcast without participants should succeed: %v\", err)\n\t}\n}\n\n// ---- SendDirect ----\n\nfunc TestChatRoomSendDirectDeliversToRecipient(t *testing.T) {\n\troom := &ChatRoom{}\n\tdelivered := make(chan Message, 1)\n\tif err := room.Register(\"bob\", func(m Message) { delivered <- m }); err != nil {\n\t\tt.Fatalf(\"register: %v\", err)\n\t}\n\tif err := room.SendDirect(context.Background(), \"bob\", Message{Body: \"hi\"}); err != nil {\n\t\tt.Fatalf(\"send direct: %v\", err)\n\t}\n\tselect {\n\tcase msg := <-delivered:\n\t\tif msg.Body != \"hi\" {\n\t\t\tt.Fatalf(\"unexpected payload: %#v\", msg)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatalf(\"message not delivered\")\n\t}\n}\n\nfunc TestChatRoomSendDirectUnknownParticipant(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.SendDirect(context.Background(), \"missing\", Message{}); !errors.Is(err, ErrUnknownParticipant) {\n\t\tt.Fatalf(\"expected ErrUnknownParticipant, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomSendDirectHonorsContext(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Register(\"bob\", func(Message) {}); err != nil {\n\t\tt.Fatalf(\"register: %v\", err)\n\t}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := room.SendDirect(ctx, \"bob\", Message{}); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "mediator",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "mediator",
        "slug": "go-mediator-broadcast",
        "title": "Broadcast",
        "description": "Task 2 (easy+): Broadcast\nОтправьте сообщение всем зарегистрированным участникам параллельно.\nПодсказка: уважайте ctx.Done() и возвращайте ctx.Err() при отмене.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Broadcast.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n)\n\n// Message описывает событие, которое рассылает медиатор.\ntype Message struct {\n\tFrom string\n\tTo   string\n\tBody string\n}\n\n// Ошибки медиатора.\nvar (\n\tErrDuplicateParticipant = errors.New(\"participant already exists\")\n\tErrUnknownParticipant   = errors.New(\"participant not found\")\n\tErrInvalidHandler       = errors.New(\"handler is nil\")\n)\n\n// ChatRoom реализует медиатор между участниками.\ntype ChatRoom struct {\n\tmu        sync.RWMutex\n\tlisteners map[string]func(Message)\n}\n\n// Task 1 (easy): Register\n// Зарегистрируйте участника по имени и callback'у, запрещая дубликаты.\n// Подсказка: лениво инициализируйте map и возвращайте ErrDuplicateParticipant при конфликте.\nfunc (c *ChatRoom) Register(name string, handler func(Message)) error {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Broadcast\n// Отправьте сообщение всем зарегистрированным участникам параллельно.\n// Подсказка: уважайте ctx.Done() и возвращайте ctx.Err() при отмене.\nfunc (c *ChatRoom) Broadcast(ctx context.Context, msg Message) error {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): SendDirect\n// Доставьте сообщение конкретному адресу, если он зарегистрирован.\n// Подсказка: возвращайте ErrUnknownParticipant для неизвестных имён, поддержите ctx.\nfunc (c *ChatRoom) SendDirect(ctx context.Context, to string, msg Message) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n)\n\nfunc (c *ChatRoom) Register(name string, handler func(Message)) error { // Register добавляет участника в медиатор.\n\tif c == nil { // Проверяем корректность получателя.\n\t\treturn errors.New(\"chat room is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif handler == nil { // Nil-handler не имеет смысла.\n\t\treturn ErrInvalidHandler // Возвращаем заранее объявленную ошибку.\n\t}\n\tc.mu.Lock()             // Захватываем mutex для работы с map.\n\tdefer c.mu.Unlock()     // Освобождаем его по завершении.\n\tif c.listeners == nil { // Лениво инициализируем map при первом вызове.\n\t\tc.listeners = make(map[string]func(Message)) // Создаём хранилище обработчиков.\n\t}\n\tif _, ok := c.listeners[name]; ok { // Проверяем наличие дубликата.\n\t\treturn ErrDuplicateParticipant // Сообщаем, что имя уже занято.\n\t}\n\tc.listeners[name] = handler // Сохраняем callback участника.\n\treturn nil                  // Успешная регистрация.\n}\n\nfunc (c *ChatRoom) Broadcast(ctx context.Context, msg Message) error { // Broadcast рассылает сообщение всем слушателям.\n\tif c == nil { // Nil-получатель использовать нельзя.\n\t\treturn errors.New(\"chat room is nil\") // Возвращаем ошибку конфигурации.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на Background.\n\t\tctx = context.Background() // Используем базовый контекст.\n\t}\n\tselect { // Проверяем отмену до начала отправки.\n\tcase <-ctx.Done(): // Контекст уже отменён.\n\t\treturn ctx.Err() // Возвращаем ошибку контекста.\n\tdefault:\n\t}\n\tc.mu.RLock()                                           // Берём read-lock для копирования handlers.\n\thandlers := make([]func(Message), 0, len(c.listeners)) // Подготавливаем временный срез обработчиков.\n\tfor _, h := range c.listeners {                        // Перебираем зарегистрированных участников.\n\t\tif h != nil { // Пропускаем nil-обработчики.\n\t\t\thandlers = append(handlers, h) // Копируем callback в срез.\n\t\t}\n\t}\n\tc.mu.RUnlock()                     // Освобождаем read-lock.\n\tvar wg sync.WaitGroup              // WaitGroup синхронизирует горутины.\n\terrCh := make(chan error, 1)       // Буферизированный канал для первой ошибки.\n\tfor _, handler := range handlers { // Запускаем обработку для каждого слушателя.\n\t\twg.Add(1)                  // Увеличиваем счётчик WaitGroup.\n\t\tgo func(h func(Message)) { // Стартуем горутину для конкретного слушателя.\n\t\t\tdefer wg.Done() // По завершении уменьшаем счётчик.\n\t\t\tselect {        // Проверяем отмену контекста перед отправкой.\n\t\t\tcase <-ctx.Done(): // Контекст отменён.\n\t\t\t\tselect { // Пытаемся сообщить об ошибке.\n\t\t\t\tcase errCh <- ctx.Err(): // Отправляем ошибку, если канал свободен.\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\treturn // Завершаем горутину досрочно.\n\t\t\tdefault:\n\t\t\t}\n\t\t\th(msg) // Вызываем callback с сообщением.\n\t\t}(handler)\n\t}\n\twg.Wait() // Ждём завершения всех горутин.\n\tselect {  // Проверяем, была ли отправлена ошибка отмены.\n\tcase err := <-errCh: // Если ошибка присутствует...\n\t\treturn err // ...возвращаем её вызывающему коду.\n\tdefault:\n\t\treturn nil // Иначе сообщаем об успешной рассылке.\n\t}\n}\n\nfunc (c *ChatRoom) SendDirect(ctx context.Context, to string, msg Message) error { // SendDirect отправляет сообщение конкретному участнику.\n\tif c == nil { // Nil-получатель невозможен.\n\t\treturn errors.New(\"chat room is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на Background.\n\t\tctx = context.Background() // Используем базовый контекст.\n\t}\n\tselect { // Проверяем отмену до поиска участника.\n\tcase <-ctx.Done(): // Контекст уже отменён.\n\t\treturn ctx.Err() // Возвращаем ошибку отмены.\n\tdefault:\n\t}\n\tc.mu.RLock()                   // Берём read-lock для доступа к map.\n\thandler, ok := c.listeners[to] // Ищем обработчик по имени.\n\tc.mu.RUnlock()                 // Освобождаем lock как можно раньше.\n\tif !ok || handler == nil {     // Если участника нет или у него нет handler'а...\n\t\treturn ErrUnknownParticipant // ...возвращаем соответствующую ошибку.\n\t}\n\tselect { // Повторно проверяем контекст перед вызовом callback.\n\tcase <-ctx.Done(): // Контекст отменён.\n\t\treturn ctx.Err() // Сообщаем об этом вызывающему коду.\n\tdefault:\n\t}\n\thandler(msg) // Доставляем сообщение напрямую слушателю.\n\treturn nil   // Возвращаем успешный результат.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- Register ----\n\nfunc TestChatRoomRegisterStoresHandler(t *testing.T) {\n\troom := &ChatRoom{}\n\thandlerCalled := false\n\tif err := room.Register(\"alice\", func(Message) { handlerCalled = true }); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\t_ = room.Broadcast(context.Background(), Message{From: \"system\", Body: \"hi\"})\n\tif !handlerCalled {\n\t\tt.Fatalf(\"registered handler not invoked\")\n\t}\n}\n\nfunc TestChatRoomRegisterRejectsDuplicates(t *testing.T) {\n\troom := &ChatRoom{}\n\t_ = room.Register(\"alice\", func(Message) {})\n\tif err := room.Register(\"alice\", func(Message) {}); !errors.Is(err, ErrDuplicateParticipant) {\n\t\tt.Fatalf(\"expected ErrDuplicateParticipant, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomRegisterValidatesHandler(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Register(\"alice\", nil); !errors.Is(err, ErrInvalidHandler) {\n\t\tt.Fatalf(\"expected ErrInvalidHandler, got %v\", err)\n\t}\n}\n\n// ---- Broadcast ----\n\nfunc TestChatRoomBroadcastDeliversToAll(t *testing.T) {\n\troom := &ChatRoom{}\n\tvar mu sync.Mutex\n\treceived := make(map[string]int)\n\tadd := func(name string) {\n\t\tt.Helper()\n\t\tif err := room.Register(name, func(Message) {\n\t\t\tmu.Lock()\n\t\t\treceived[name]++\n\t\t\tmu.Unlock()\n\t\t}); err != nil {\n\t\t\tt.Fatalf(\"register: %v\", err)\n\t\t}\n\t}\n\tadd(\"alice\")\n\tadd(\"bob\")\n\tif err := room.Broadcast(context.Background(), Message{Body: \"ping\"}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif received[\"alice\"] != 1 || received[\"bob\"] != 1 {\n\t\tt.Fatalf(\"not all participants received message: %#v\", received)\n\t}\n}\n\nfunc TestChatRoomBroadcastHonorsContext(t *testing.T) {\n\troom := &ChatRoom{}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := room.Broadcast(ctx, Message{}); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomBroadcastWithoutParticipants(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Broadcast(context.Background(), Message{}); err != nil {\n\t\tt.Fatalf(\"broadcast without participants should succeed: %v\", err)\n\t}\n}\n\n// ---- SendDirect ----\n\nfunc TestChatRoomSendDirectDeliversToRecipient(t *testing.T) {\n\troom := &ChatRoom{}\n\tdelivered := make(chan Message, 1)\n\tif err := room.Register(\"bob\", func(m Message) { delivered <- m }); err != nil {\n\t\tt.Fatalf(\"register: %v\", err)\n\t}\n\tif err := room.SendDirect(context.Background(), \"bob\", Message{Body: \"hi\"}); err != nil {\n\t\tt.Fatalf(\"send direct: %v\", err)\n\t}\n\tselect {\n\tcase msg := <-delivered:\n\t\tif msg.Body != \"hi\" {\n\t\t\tt.Fatalf(\"unexpected payload: %#v\", msg)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatalf(\"message not delivered\")\n\t}\n}\n\nfunc TestChatRoomSendDirectUnknownParticipant(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.SendDirect(context.Background(), \"missing\", Message{}); !errors.Is(err, ErrUnknownParticipant) {\n\t\tt.Fatalf(\"expected ErrUnknownParticipant, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomSendDirectHonorsContext(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Register(\"bob\", func(Message) {}); err != nil {\n\t\tt.Fatalf(\"register: %v\", err)\n\t}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := room.SendDirect(ctx, \"bob\", Message{}); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "mediator",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "mediator",
        "slug": "go-mediator-senddirect",
        "title": "SendDirect",
        "description": "Task 3 (medium): SendDirect\nДоставьте сообщение конкретному адресу, если он зарегистрирован.\nПодсказка: возвращайте ErrUnknownParticipant для неизвестных имён, поддержите ctx.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of SendDirect.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n)\n\n// Message описывает событие, которое рассылает медиатор.\ntype Message struct {\n\tFrom string\n\tTo   string\n\tBody string\n}\n\n// Ошибки медиатора.\nvar (\n\tErrDuplicateParticipant = errors.New(\"participant already exists\")\n\tErrUnknownParticipant   = errors.New(\"participant not found\")\n\tErrInvalidHandler       = errors.New(\"handler is nil\")\n)\n\n// ChatRoom реализует медиатор между участниками.\ntype ChatRoom struct {\n\tmu        sync.RWMutex\n\tlisteners map[string]func(Message)\n}\n\n// Task 1 (easy): Register\n// Зарегистрируйте участника по имени и callback'у, запрещая дубликаты.\n// Подсказка: лениво инициализируйте map и возвращайте ErrDuplicateParticipant при конфликте.\nfunc (c *ChatRoom) Register(name string, handler func(Message)) error {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Broadcast\n// Отправьте сообщение всем зарегистрированным участникам параллельно.\n// Подсказка: уважайте ctx.Done() и возвращайте ctx.Err() при отмене.\nfunc (c *ChatRoom) Broadcast(ctx context.Context, msg Message) error {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): SendDirect\n// Доставьте сообщение конкретному адресу, если он зарегистрирован.\n// Подсказка: возвращайте ErrUnknownParticipant для неизвестных имён, поддержите ctx.\nfunc (c *ChatRoom) SendDirect(ctx context.Context, to string, msg Message) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n)\n\nfunc (c *ChatRoom) Register(name string, handler func(Message)) error { // Register добавляет участника в медиатор.\n\tif c == nil { // Проверяем корректность получателя.\n\t\treturn errors.New(\"chat room is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif handler == nil { // Nil-handler не имеет смысла.\n\t\treturn ErrInvalidHandler // Возвращаем заранее объявленную ошибку.\n\t}\n\tc.mu.Lock()             // Захватываем mutex для работы с map.\n\tdefer c.mu.Unlock()     // Освобождаем его по завершении.\n\tif c.listeners == nil { // Лениво инициализируем map при первом вызове.\n\t\tc.listeners = make(map[string]func(Message)) // Создаём хранилище обработчиков.\n\t}\n\tif _, ok := c.listeners[name]; ok { // Проверяем наличие дубликата.\n\t\treturn ErrDuplicateParticipant // Сообщаем, что имя уже занято.\n\t}\n\tc.listeners[name] = handler // Сохраняем callback участника.\n\treturn nil                  // Успешная регистрация.\n}\n\nfunc (c *ChatRoom) Broadcast(ctx context.Context, msg Message) error { // Broadcast рассылает сообщение всем слушателям.\n\tif c == nil { // Nil-получатель использовать нельзя.\n\t\treturn errors.New(\"chat room is nil\") // Возвращаем ошибку конфигурации.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на Background.\n\t\tctx = context.Background() // Используем базовый контекст.\n\t}\n\tselect { // Проверяем отмену до начала отправки.\n\tcase <-ctx.Done(): // Контекст уже отменён.\n\t\treturn ctx.Err() // Возвращаем ошибку контекста.\n\tdefault:\n\t}\n\tc.mu.RLock()                                           // Берём read-lock для копирования handlers.\n\thandlers := make([]func(Message), 0, len(c.listeners)) // Подготавливаем временный срез обработчиков.\n\tfor _, h := range c.listeners {                        // Перебираем зарегистрированных участников.\n\t\tif h != nil { // Пропускаем nil-обработчики.\n\t\t\thandlers = append(handlers, h) // Копируем callback в срез.\n\t\t}\n\t}\n\tc.mu.RUnlock()                     // Освобождаем read-lock.\n\tvar wg sync.WaitGroup              // WaitGroup синхронизирует горутины.\n\terrCh := make(chan error, 1)       // Буферизированный канал для первой ошибки.\n\tfor _, handler := range handlers { // Запускаем обработку для каждого слушателя.\n\t\twg.Add(1)                  // Увеличиваем счётчик WaitGroup.\n\t\tgo func(h func(Message)) { // Стартуем горутину для конкретного слушателя.\n\t\t\tdefer wg.Done() // По завершении уменьшаем счётчик.\n\t\t\tselect {        // Проверяем отмену контекста перед отправкой.\n\t\t\tcase <-ctx.Done(): // Контекст отменён.\n\t\t\t\tselect { // Пытаемся сообщить об ошибке.\n\t\t\t\tcase errCh <- ctx.Err(): // Отправляем ошибку, если канал свободен.\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\treturn // Завершаем горутину досрочно.\n\t\t\tdefault:\n\t\t\t}\n\t\t\th(msg) // Вызываем callback с сообщением.\n\t\t}(handler)\n\t}\n\twg.Wait() // Ждём завершения всех горутин.\n\tselect {  // Проверяем, была ли отправлена ошибка отмены.\n\tcase err := <-errCh: // Если ошибка присутствует...\n\t\treturn err // ...возвращаем её вызывающему коду.\n\tdefault:\n\t\treturn nil // Иначе сообщаем об успешной рассылке.\n\t}\n}\n\nfunc (c *ChatRoom) SendDirect(ctx context.Context, to string, msg Message) error { // SendDirect отправляет сообщение конкретному участнику.\n\tif c == nil { // Nil-получатель невозможен.\n\t\treturn errors.New(\"chat room is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на Background.\n\t\tctx = context.Background() // Используем базовый контекст.\n\t}\n\tselect { // Проверяем отмену до поиска участника.\n\tcase <-ctx.Done(): // Контекст уже отменён.\n\t\treturn ctx.Err() // Возвращаем ошибку отмены.\n\tdefault:\n\t}\n\tc.mu.RLock()                   // Берём read-lock для доступа к map.\n\thandler, ok := c.listeners[to] // Ищем обработчик по имени.\n\tc.mu.RUnlock()                 // Освобождаем lock как можно раньше.\n\tif !ok || handler == nil {     // Если участника нет или у него нет handler'а...\n\t\treturn ErrUnknownParticipant // ...возвращаем соответствующую ошибку.\n\t}\n\tselect { // Повторно проверяем контекст перед вызовом callback.\n\tcase <-ctx.Done(): // Контекст отменён.\n\t\treturn ctx.Err() // Сообщаем об этом вызывающему коду.\n\tdefault:\n\t}\n\thandler(msg) // Доставляем сообщение напрямую слушателю.\n\treturn nil   // Возвращаем успешный результат.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// ---- Register ----\n\nfunc TestChatRoomRegisterStoresHandler(t *testing.T) {\n\troom := &ChatRoom{}\n\thandlerCalled := false\n\tif err := room.Register(\"alice\", func(Message) { handlerCalled = true }); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\t_ = room.Broadcast(context.Background(), Message{From: \"system\", Body: \"hi\"})\n\tif !handlerCalled {\n\t\tt.Fatalf(\"registered handler not invoked\")\n\t}\n}\n\nfunc TestChatRoomRegisterRejectsDuplicates(t *testing.T) {\n\troom := &ChatRoom{}\n\t_ = room.Register(\"alice\", func(Message) {})\n\tif err := room.Register(\"alice\", func(Message) {}); !errors.Is(err, ErrDuplicateParticipant) {\n\t\tt.Fatalf(\"expected ErrDuplicateParticipant, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomRegisterValidatesHandler(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Register(\"alice\", nil); !errors.Is(err, ErrInvalidHandler) {\n\t\tt.Fatalf(\"expected ErrInvalidHandler, got %v\", err)\n\t}\n}\n\n// ---- Broadcast ----\n\nfunc TestChatRoomBroadcastDeliversToAll(t *testing.T) {\n\troom := &ChatRoom{}\n\tvar mu sync.Mutex\n\treceived := make(map[string]int)\n\tadd := func(name string) {\n\t\tt.Helper()\n\t\tif err := room.Register(name, func(Message) {\n\t\t\tmu.Lock()\n\t\t\treceived[name]++\n\t\t\tmu.Unlock()\n\t\t}); err != nil {\n\t\t\tt.Fatalf(\"register: %v\", err)\n\t\t}\n\t}\n\tadd(\"alice\")\n\tadd(\"bob\")\n\tif err := room.Broadcast(context.Background(), Message{Body: \"ping\"}); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif received[\"alice\"] != 1 || received[\"bob\"] != 1 {\n\t\tt.Fatalf(\"not all participants received message: %#v\", received)\n\t}\n}\n\nfunc TestChatRoomBroadcastHonorsContext(t *testing.T) {\n\troom := &ChatRoom{}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := room.Broadcast(ctx, Message{}); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomBroadcastWithoutParticipants(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Broadcast(context.Background(), Message{}); err != nil {\n\t\tt.Fatalf(\"broadcast without participants should succeed: %v\", err)\n\t}\n}\n\n// ---- SendDirect ----\n\nfunc TestChatRoomSendDirectDeliversToRecipient(t *testing.T) {\n\troom := &ChatRoom{}\n\tdelivered := make(chan Message, 1)\n\tif err := room.Register(\"bob\", func(m Message) { delivered <- m }); err != nil {\n\t\tt.Fatalf(\"register: %v\", err)\n\t}\n\tif err := room.SendDirect(context.Background(), \"bob\", Message{Body: \"hi\"}); err != nil {\n\t\tt.Fatalf(\"send direct: %v\", err)\n\t}\n\tselect {\n\tcase msg := <-delivered:\n\t\tif msg.Body != \"hi\" {\n\t\t\tt.Fatalf(\"unexpected payload: %#v\", msg)\n\t\t}\n\tcase <-time.After(time.Second):\n\t\tt.Fatalf(\"message not delivered\")\n\t}\n}\n\nfunc TestChatRoomSendDirectUnknownParticipant(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.SendDirect(context.Background(), \"missing\", Message{}); !errors.Is(err, ErrUnknownParticipant) {\n\t\tt.Fatalf(\"expected ErrUnknownParticipant, got %v\", err)\n\t}\n}\n\nfunc TestChatRoomSendDirectHonorsContext(t *testing.T) {\n\troom := &ChatRoom{}\n\tif err := room.Register(\"bob\", func(Message) {}); err != nil {\n\t\tt.Fatalf(\"register: %v\", err)\n\t}\n\tctx, cancel := context.WithCancel(context.Background())\n\tcancel()\n\tif err := room.SendDirect(ctx, \"bob\", Message{}); !errors.Is(err, context.Canceled) {\n\t\tt.Fatalf(\"expected context cancellation, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "mediator",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-memento",
    "tasks": [
      {
        "package": "memento",
        "slug": "go-memento-save",
        "title": "Save",
        "description": "Task 1 (easy): Save\nСоздайте снимок текущего состояния документа и добавьте его в историю.\nПодсказка: копируйте Body, чтобы изменения не влияли на снимок.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Save.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"errors\"\n\n// Document описывает текстовый документ, поддерживающий откат изменений.\ntype Document struct {\n\tTitle   string\n\tBody    []string\n\thistory []DocumentMemento\n}\n\n// DocumentMemento хранит снимок состояния документа.\ntype DocumentMemento struct {\n\ttitle string\n\tbody  []string\n}\n\n// ErrNoHistory сигнализирует, что история пуста.\nvar ErrNoHistory = errors.New(\"history is empty\")\n\n// Task 1 (easy): Save\n// Создайте снимок текущего состояния документа и добавьте его в историю.\n// Подсказка: копируйте Body, чтобы изменения не влияли на снимок.\nfunc (d *Document) Save() DocumentMemento {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Restore\n// Восстановите состояние документа из переданного снимка.\n// Подсказка: копируйте Body из memento и не забудьте сбросить пустые значения.\nfunc (d *Document) Restore(m DocumentMemento) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Rewind\n// Откатите состояние на указанное число шагов из истории и верните применённый снимок.\n// Подсказка: считайте шаги от последнего сохранения, при отсутствии снимков верните ErrNoHistory.\nfunc (d *Document) Rewind(steps int) (DocumentMemento, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (d *Document) Save() DocumentMemento { // Save создаёт снимок текущего состояния и кладёт его в историю.\n\tif d == nil { // Nil-документ не копируем, но возвращаем пустой снимок для предсказуемости.\n\t\treturn DocumentMemento{} // Возвращаем zero-value, чтобы вызов был безопасным.\n\t}\n\tsnapshot := DocumentMemento{ // Формируем новый снимок.\n\t\ttitle: d.Title,                          // Копируем заголовок.\n\t\tbody:  append([]string(nil), d.Body...), // Делаем копию среза Body, чтобы избежать aliasing.\n\t}\n\td.history = append(d.history, snapshot) // Сохраняем снимок в историю документа.\n\treturn snapshot                         // Возвращаем созданный снимок вызывающему коду.\n}\n\nfunc (d *Document) Restore(m DocumentMemento) { // Restore применяет переданный снимок к документу.\n\tif d == nil { // Nil-получатель игнорируем для безопасности.\n\t\treturn // Ничего не делаем.\n\t}\n\td.Title = m.title  // Восстанавливаем заголовок.\n\tif m.body == nil { // Если Body пустой — обнуляем срез.\n\t\td.Body = nil // Сбрасываем Body в nil.\n\t} else {\n\t\td.Body = append([]string(nil), m.body...) // Копируем содержимое Body из снимка.\n\t}\n}\n\nfunc (d *Document) Rewind(steps int) (DocumentMemento, error) { // Rewind откатывает документ к старому состоянию.\n\tif d == nil || len(d.history) == 0 { // Проверяем наличие истории и корректность получателя.\n\t\treturn DocumentMemento{}, ErrNoHistory // Без истории откат невозможен.\n\t}\n\tif steps <= 0 { // Нулевые и отрицательные шаги трактуем как один шаг.\n\t\tsteps = 1 // Приводим значение к минимуму.\n\t}\n\tif steps > len(d.history) { // Нельзя откатиться глубже доступных снимков.\n\t\treturn DocumentMemento{}, ErrNoHistory // Сообщаем об отсутствии достаточной истории.\n\t}\n\tidx := len(d.history) - steps // Индекс снимка, который нужно применить.\n\tsnapshot := d.history[idx]    // Забираем выбранный снимок.\n\td.history = d.history[:idx]   // Удаляем его и все более новые записи.\n\td.Restore(snapshot)           // Применяем снимок к документу.\n\treturn snapshot, nil          // Возвращаем использованный снимок и nil-ошибку.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- Save ----\n\nfunc TestDocumentSaveCopiesBody(t *testing.T) {\n\tdoc := &Document{Title: \"draft\", Body: []string{\"a\", \"b\"}}\n\tsnap := doc.Save()\n\tdoc.Body[0] = \"changed\"\n\tif snap.body[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot should keep original content\")\n\t}\n}\n\nfunc TestDocumentSaveAppendsHistory(t *testing.T) {\n\tdoc := &Document{}\n\t_ = doc.Save()\n\t_ = doc.Save()\n\tif len(doc.history) != 2 {\n\t\tt.Fatalf(\"history length mismatch: %d\", len(doc.history))\n\t}\n}\n\nfunc TestDocumentSaveNilReceiver(t *testing.T) {\n\tvar doc *Document\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"Save should be nil-safe, got panic %v\", err)\n\t\t}\n\t}()\n\tdoc.Save()\n}\n\n// ---- Restore ----\n\nfunc TestDocumentRestoreSetsFields(t *testing.T) {\n\tdoc := &Document{}\n\tdoc.Restore(DocumentMemento{title: \"final\", body: []string{\"ok\"}})\n\tif doc.Title != \"final\" || len(doc.Body) != 1 {\n\t\tt.Fatalf(\"restore failed: %#v\", doc)\n\t}\n}\n\nfunc TestDocumentRestoreCopiesBody(t *testing.T) {\n\tmemo := DocumentMemento{title: \"draft\", body: []string{\"x\"}}\n\tdoc := &Document{}\n\tdoc.Restore(memo)\n\tdoc.Body[0] = \"changed\"\n\tif memo.body[0] != \"x\" {\n\t\tt.Fatalf(\"restore should copy body\")\n\t}\n}\n\nfunc TestDocumentRestoreNilReceiver(t *testing.T) {\n\tvar doc *Document\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"Restore should be nil-safe: %v\", err)\n\t\t}\n\t}()\n\tdoc.Restore(DocumentMemento{})\n}\n\n// ---- Rewind ----\n\nfunc TestDocumentRewindRestoresLatestSnapshot(t *testing.T) {\n\tdoc := &Document{Title: \"v1\", Body: []string{\"a\"}}\n\tdoc.Save() // snapshot 1\n\tdoc.Title = \"v2\"\n\tdoc.Body = []string{\"b\"}\n\tdoc.Save() // snapshot 2\n\tdoc.Title = \"v3\"\n\tdoc.Body = []string{\"c\"}\n\tsnap, err := doc.Rewind(1)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif doc.Title != \"v2\" || doc.Body[0] != \"b\" {\n\t\tt.Fatalf(\"document should match latest snapshot: %#v\", doc)\n\t}\n\tif snap.title != \"v2\" {\n\t\tt.Fatalf(\"rewind should return applied snapshot\")\n\t}\n}\n\nfunc TestDocumentRewindSupportsSteps(t *testing.T) {\n\tdoc := &Document{Title: \"v1\", Body: []string{\"a\"}}\n\tdoc.Save()\n\tdoc.Title = \"v2\"\n\tdoc.Body = []string{\"b\"}\n\tdoc.Save()\n\tdoc.Title = \"v3\"\n\tdoc.Body = []string{\"c\"}\n\tsnap, err := doc.Rewind(2)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif doc.Title != \"v1\" || doc.Body[0] != \"a\" {\n\t\tt.Fatalf(\"document should rewind to first snapshot: %#v\", doc)\n\t}\n\tif snap.title != \"v1\" {\n\t\tt.Fatalf(\"expected first snapshot, got %#v\", snap)\n\t}\n}\n\nfunc TestDocumentRewindInsufficientHistory(t *testing.T) {\n\tdoc := &Document{}\n\tif _, err := doc.Rewind(1); err != ErrNoHistory {\n\t\tt.Fatalf(\"expected ErrNoHistory, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "memento",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "memento",
        "slug": "go-memento-restore",
        "title": "Restore",
        "description": "Task 2 (easy+): Restore\nВосстановите состояние документа из переданного снимка.\nПодсказка: копируйте Body из memento и не забудьте сбросить пустые значения.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Restore.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"errors\"\n\n// Document описывает текстовый документ, поддерживающий откат изменений.\ntype Document struct {\n\tTitle   string\n\tBody    []string\n\thistory []DocumentMemento\n}\n\n// DocumentMemento хранит снимок состояния документа.\ntype DocumentMemento struct {\n\ttitle string\n\tbody  []string\n}\n\n// ErrNoHistory сигнализирует, что история пуста.\nvar ErrNoHistory = errors.New(\"history is empty\")\n\n// Task 1 (easy): Save\n// Создайте снимок текущего состояния документа и добавьте его в историю.\n// Подсказка: копируйте Body, чтобы изменения не влияли на снимок.\nfunc (d *Document) Save() DocumentMemento {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Restore\n// Восстановите состояние документа из переданного снимка.\n// Подсказка: копируйте Body из memento и не забудьте сбросить пустые значения.\nfunc (d *Document) Restore(m DocumentMemento) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Rewind\n// Откатите состояние на указанное число шагов из истории и верните применённый снимок.\n// Подсказка: считайте шаги от последнего сохранения, при отсутствии снимков верните ErrNoHistory.\nfunc (d *Document) Rewind(steps int) (DocumentMemento, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (d *Document) Save() DocumentMemento { // Save создаёт снимок текущего состояния и кладёт его в историю.\n\tif d == nil { // Nil-документ не копируем, но возвращаем пустой снимок для предсказуемости.\n\t\treturn DocumentMemento{} // Возвращаем zero-value, чтобы вызов был безопасным.\n\t}\n\tsnapshot := DocumentMemento{ // Формируем новый снимок.\n\t\ttitle: d.Title,                          // Копируем заголовок.\n\t\tbody:  append([]string(nil), d.Body...), // Делаем копию среза Body, чтобы избежать aliasing.\n\t}\n\td.history = append(d.history, snapshot) // Сохраняем снимок в историю документа.\n\treturn snapshot                         // Возвращаем созданный снимок вызывающему коду.\n}\n\nfunc (d *Document) Restore(m DocumentMemento) { // Restore применяет переданный снимок к документу.\n\tif d == nil { // Nil-получатель игнорируем для безопасности.\n\t\treturn // Ничего не делаем.\n\t}\n\td.Title = m.title  // Восстанавливаем заголовок.\n\tif m.body == nil { // Если Body пустой — обнуляем срез.\n\t\td.Body = nil // Сбрасываем Body в nil.\n\t} else {\n\t\td.Body = append([]string(nil), m.body...) // Копируем содержимое Body из снимка.\n\t}\n}\n\nfunc (d *Document) Rewind(steps int) (DocumentMemento, error) { // Rewind откатывает документ к старому состоянию.\n\tif d == nil || len(d.history) == 0 { // Проверяем наличие истории и корректность получателя.\n\t\treturn DocumentMemento{}, ErrNoHistory // Без истории откат невозможен.\n\t}\n\tif steps <= 0 { // Нулевые и отрицательные шаги трактуем как один шаг.\n\t\tsteps = 1 // Приводим значение к минимуму.\n\t}\n\tif steps > len(d.history) { // Нельзя откатиться глубже доступных снимков.\n\t\treturn DocumentMemento{}, ErrNoHistory // Сообщаем об отсутствии достаточной истории.\n\t}\n\tidx := len(d.history) - steps // Индекс снимка, который нужно применить.\n\tsnapshot := d.history[idx]    // Забираем выбранный снимок.\n\td.history = d.history[:idx]   // Удаляем его и все более новые записи.\n\td.Restore(snapshot)           // Применяем снимок к документу.\n\treturn snapshot, nil          // Возвращаем использованный снимок и nil-ошибку.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- Save ----\n\nfunc TestDocumentSaveCopiesBody(t *testing.T) {\n\tdoc := &Document{Title: \"draft\", Body: []string{\"a\", \"b\"}}\n\tsnap := doc.Save()\n\tdoc.Body[0] = \"changed\"\n\tif snap.body[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot should keep original content\")\n\t}\n}\n\nfunc TestDocumentSaveAppendsHistory(t *testing.T) {\n\tdoc := &Document{}\n\t_ = doc.Save()\n\t_ = doc.Save()\n\tif len(doc.history) != 2 {\n\t\tt.Fatalf(\"history length mismatch: %d\", len(doc.history))\n\t}\n}\n\nfunc TestDocumentSaveNilReceiver(t *testing.T) {\n\tvar doc *Document\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"Save should be nil-safe, got panic %v\", err)\n\t\t}\n\t}()\n\tdoc.Save()\n}\n\n// ---- Restore ----\n\nfunc TestDocumentRestoreSetsFields(t *testing.T) {\n\tdoc := &Document{}\n\tdoc.Restore(DocumentMemento{title: \"final\", body: []string{\"ok\"}})\n\tif doc.Title != \"final\" || len(doc.Body) != 1 {\n\t\tt.Fatalf(\"restore failed: %#v\", doc)\n\t}\n}\n\nfunc TestDocumentRestoreCopiesBody(t *testing.T) {\n\tmemo := DocumentMemento{title: \"draft\", body: []string{\"x\"}}\n\tdoc := &Document{}\n\tdoc.Restore(memo)\n\tdoc.Body[0] = \"changed\"\n\tif memo.body[0] != \"x\" {\n\t\tt.Fatalf(\"restore should copy body\")\n\t}\n}\n\nfunc TestDocumentRestoreNilReceiver(t *testing.T) {\n\tvar doc *Document\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"Restore should be nil-safe: %v\", err)\n\t\t}\n\t}()\n\tdoc.Restore(DocumentMemento{})\n}\n\n// ---- Rewind ----\n\nfunc TestDocumentRewindRestoresLatestSnapshot(t *testing.T) {\n\tdoc := &Document{Title: \"v1\", Body: []string{\"a\"}}\n\tdoc.Save() // snapshot 1\n\tdoc.Title = \"v2\"\n\tdoc.Body = []string{\"b\"}\n\tdoc.Save() // snapshot 2\n\tdoc.Title = \"v3\"\n\tdoc.Body = []string{\"c\"}\n\tsnap, err := doc.Rewind(1)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif doc.Title != \"v2\" || doc.Body[0] != \"b\" {\n\t\tt.Fatalf(\"document should match latest snapshot: %#v\", doc)\n\t}\n\tif snap.title != \"v2\" {\n\t\tt.Fatalf(\"rewind should return applied snapshot\")\n\t}\n}\n\nfunc TestDocumentRewindSupportsSteps(t *testing.T) {\n\tdoc := &Document{Title: \"v1\", Body: []string{\"a\"}}\n\tdoc.Save()\n\tdoc.Title = \"v2\"\n\tdoc.Body = []string{\"b\"}\n\tdoc.Save()\n\tdoc.Title = \"v3\"\n\tdoc.Body = []string{\"c\"}\n\tsnap, err := doc.Rewind(2)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif doc.Title != \"v1\" || doc.Body[0] != \"a\" {\n\t\tt.Fatalf(\"document should rewind to first snapshot: %#v\", doc)\n\t}\n\tif snap.title != \"v1\" {\n\t\tt.Fatalf(\"expected first snapshot, got %#v\", snap)\n\t}\n}\n\nfunc TestDocumentRewindInsufficientHistory(t *testing.T) {\n\tdoc := &Document{}\n\tif _, err := doc.Rewind(1); err != ErrNoHistory {\n\t\tt.Fatalf(\"expected ErrNoHistory, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "memento",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "memento",
        "slug": "go-memento-rewind",
        "title": "Rewind",
        "description": "Task 3 (medium): Rewind\nОткатите состояние на указанное число шагов из истории и верните применённый снимок.\nПодсказка: считайте шаги от последнего сохранения, при отсутствии снимков верните ErrNoHistory.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Rewind.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"errors\"\n\n// Document описывает текстовый документ, поддерживающий откат изменений.\ntype Document struct {\n\tTitle   string\n\tBody    []string\n\thistory []DocumentMemento\n}\n\n// DocumentMemento хранит снимок состояния документа.\ntype DocumentMemento struct {\n\ttitle string\n\tbody  []string\n}\n\n// ErrNoHistory сигнализирует, что история пуста.\nvar ErrNoHistory = errors.New(\"history is empty\")\n\n// Task 1 (easy): Save\n// Создайте снимок текущего состояния документа и добавьте его в историю.\n// Подсказка: копируйте Body, чтобы изменения не влияли на снимок.\nfunc (d *Document) Save() DocumentMemento {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Restore\n// Восстановите состояние документа из переданного снимка.\n// Подсказка: копируйте Body из memento и не забудьте сбросить пустые значения.\nfunc (d *Document) Restore(m DocumentMemento) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Rewind\n// Откатите состояние на указанное число шагов из истории и верните применённый снимок.\n// Подсказка: считайте шаги от последнего сохранения, при отсутствии снимков верните ErrNoHistory.\nfunc (d *Document) Rewind(steps int) (DocumentMemento, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (d *Document) Save() DocumentMemento { // Save создаёт снимок текущего состояния и кладёт его в историю.\n\tif d == nil { // Nil-документ не копируем, но возвращаем пустой снимок для предсказуемости.\n\t\treturn DocumentMemento{} // Возвращаем zero-value, чтобы вызов был безопасным.\n\t}\n\tsnapshot := DocumentMemento{ // Формируем новый снимок.\n\t\ttitle: d.Title,                          // Копируем заголовок.\n\t\tbody:  append([]string(nil), d.Body...), // Делаем копию среза Body, чтобы избежать aliasing.\n\t}\n\td.history = append(d.history, snapshot) // Сохраняем снимок в историю документа.\n\treturn snapshot                         // Возвращаем созданный снимок вызывающему коду.\n}\n\nfunc (d *Document) Restore(m DocumentMemento) { // Restore применяет переданный снимок к документу.\n\tif d == nil { // Nil-получатель игнорируем для безопасности.\n\t\treturn // Ничего не делаем.\n\t}\n\td.Title = m.title  // Восстанавливаем заголовок.\n\tif m.body == nil { // Если Body пустой — обнуляем срез.\n\t\td.Body = nil // Сбрасываем Body в nil.\n\t} else {\n\t\td.Body = append([]string(nil), m.body...) // Копируем содержимое Body из снимка.\n\t}\n}\n\nfunc (d *Document) Rewind(steps int) (DocumentMemento, error) { // Rewind откатывает документ к старому состоянию.\n\tif d == nil || len(d.history) == 0 { // Проверяем наличие истории и корректность получателя.\n\t\treturn DocumentMemento{}, ErrNoHistory // Без истории откат невозможен.\n\t}\n\tif steps <= 0 { // Нулевые и отрицательные шаги трактуем как один шаг.\n\t\tsteps = 1 // Приводим значение к минимуму.\n\t}\n\tif steps > len(d.history) { // Нельзя откатиться глубже доступных снимков.\n\t\treturn DocumentMemento{}, ErrNoHistory // Сообщаем об отсутствии достаточной истории.\n\t}\n\tidx := len(d.history) - steps // Индекс снимка, который нужно применить.\n\tsnapshot := d.history[idx]    // Забираем выбранный снимок.\n\td.history = d.history[:idx]   // Удаляем его и все более новые записи.\n\td.Restore(snapshot)           // Применяем снимок к документу.\n\treturn snapshot, nil          // Возвращаем использованный снимок и nil-ошибку.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- Save ----\n\nfunc TestDocumentSaveCopiesBody(t *testing.T) {\n\tdoc := &Document{Title: \"draft\", Body: []string{\"a\", \"b\"}}\n\tsnap := doc.Save()\n\tdoc.Body[0] = \"changed\"\n\tif snap.body[0] != \"a\" {\n\t\tt.Fatalf(\"snapshot should keep original content\")\n\t}\n}\n\nfunc TestDocumentSaveAppendsHistory(t *testing.T) {\n\tdoc := &Document{}\n\t_ = doc.Save()\n\t_ = doc.Save()\n\tif len(doc.history) != 2 {\n\t\tt.Fatalf(\"history length mismatch: %d\", len(doc.history))\n\t}\n}\n\nfunc TestDocumentSaveNilReceiver(t *testing.T) {\n\tvar doc *Document\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"Save should be nil-safe, got panic %v\", err)\n\t\t}\n\t}()\n\tdoc.Save()\n}\n\n// ---- Restore ----\n\nfunc TestDocumentRestoreSetsFields(t *testing.T) {\n\tdoc := &Document{}\n\tdoc.Restore(DocumentMemento{title: \"final\", body: []string{\"ok\"}})\n\tif doc.Title != \"final\" || len(doc.Body) != 1 {\n\t\tt.Fatalf(\"restore failed: %#v\", doc)\n\t}\n}\n\nfunc TestDocumentRestoreCopiesBody(t *testing.T) {\n\tmemo := DocumentMemento{title: \"draft\", body: []string{\"x\"}}\n\tdoc := &Document{}\n\tdoc.Restore(memo)\n\tdoc.Body[0] = \"changed\"\n\tif memo.body[0] != \"x\" {\n\t\tt.Fatalf(\"restore should copy body\")\n\t}\n}\n\nfunc TestDocumentRestoreNilReceiver(t *testing.T) {\n\tvar doc *Document\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"Restore should be nil-safe: %v\", err)\n\t\t}\n\t}()\n\tdoc.Restore(DocumentMemento{})\n}\n\n// ---- Rewind ----\n\nfunc TestDocumentRewindRestoresLatestSnapshot(t *testing.T) {\n\tdoc := &Document{Title: \"v1\", Body: []string{\"a\"}}\n\tdoc.Save() // snapshot 1\n\tdoc.Title = \"v2\"\n\tdoc.Body = []string{\"b\"}\n\tdoc.Save() // snapshot 2\n\tdoc.Title = \"v3\"\n\tdoc.Body = []string{\"c\"}\n\tsnap, err := doc.Rewind(1)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif doc.Title != \"v2\" || doc.Body[0] != \"b\" {\n\t\tt.Fatalf(\"document should match latest snapshot: %#v\", doc)\n\t}\n\tif snap.title != \"v2\" {\n\t\tt.Fatalf(\"rewind should return applied snapshot\")\n\t}\n}\n\nfunc TestDocumentRewindSupportsSteps(t *testing.T) {\n\tdoc := &Document{Title: \"v1\", Body: []string{\"a\"}}\n\tdoc.Save()\n\tdoc.Title = \"v2\"\n\tdoc.Body = []string{\"b\"}\n\tdoc.Save()\n\tdoc.Title = \"v3\"\n\tdoc.Body = []string{\"c\"}\n\tsnap, err := doc.Rewind(2)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif doc.Title != \"v1\" || doc.Body[0] != \"a\" {\n\t\tt.Fatalf(\"document should rewind to first snapshot: %#v\", doc)\n\t}\n\tif snap.title != \"v1\" {\n\t\tt.Fatalf(\"expected first snapshot, got %#v\", snap)\n\t}\n}\n\nfunc TestDocumentRewindInsufficientHistory(t *testing.T) {\n\tdoc := &Document{}\n\tif _, err := doc.Rewind(1); err != ErrNoHistory {\n\t\tt.Fatalf(\"expected ErrNoHistory, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "memento",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-observer",
    "tasks": [
      {
        "package": "observer",
        "slug": "go-observer-subscribe",
        "title": "Subscribe",
        "description": "Task 1 (easy): Subscribe\nЗарегистрируйте нового подписчика и верните функцию отписки.\nПодсказка: используйте счётчик nextID для уникальных ключей и удаляйте listener при отписке.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Subscribe.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"sync\"\n\n// Event описывает уведомление, рассылемое наблюдателям.\ntype Event struct {\n\tTopic string\n\tData  any\n}\n\n// Listener — функция, получающая события определённой темы.\ntype Listener func(Event)\n\n// EventBus управляет подписчиками и рассылкой событий.\ntype EventBus struct {\n\tmu     sync.RWMutex\n\tsubs   map[string]map[int]Listener\n\tnextID int\n}\n\n// Task 1 (easy): Subscribe\n// Зарегистрируйте нового подписчика и верните функцию отписки.\n// Подсказка: используйте счётчик nextID для уникальных ключей и удаляйте listener при отписке.\nfunc (b *EventBus) Subscribe(topic string, listener Listener) func() {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Publish\n// Рассылайте события всем подписчикам темы, игнорируя паники внутри listener.\n// Подсказка: копируйте listeners под read-lock и вызывайте их вне критической секции.\nfunc (b *EventBus) Publish(evt Event) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Topics\n// Верните отсортированный список тем, на которые есть подписчики.\n// Подсказка: пропускайте пустые списки и используйте sort.Strings.\nfunc (b *EventBus) Topics() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport \"sort\"\n\nfunc (b *EventBus) Subscribe(topic string, listener Listener) func() { // Subscribe регистрирует listener на указанную тему.\n\tif b == nil || listener == nil || topic == \"\" { // Проверяем корректность входных данных.\n\t\treturn nil // Без валидного bus/listener вернуть нечего.\n\t}\n\tb.mu.Lock()         // Захватываем mutex для модификации хранилища подписок.\n\tdefer b.mu.Unlock() // Гарантируем освобождение mutex.\n\tif b.subs == nil {  // Лениво инициализируем карту тем.\n\t\tb.subs = make(map[string]map[int]Listener) // Создаём map topic -> listeners.\n\t}\n\tbucket, ok := b.subs[topic] // Ищем существующий набор подписчиков.\n\tif !ok {                    // Если тема новая...\n\t\tbucket = make(map[int]Listener) // ...создаём контейнер для listener'ов.\n\t\tb.subs[topic] = bucket          // Сохраняем его в основном хранилище.\n\t}\n\tb.nextID++            // Генерируем уникальный идентификатор подписки.\n\tid := b.nextID        // Сохраняем его в локальную переменную.\n\tbucket[id] = listener // Регистрируем listener под сгенерированным ключом.\n\treturn func() {       // Возвращаем функцию отписки.\n\t\tb.mu.Lock()                               // Для удаления снова захватываем mutex.\n\t\tdefer b.mu.Unlock()                       // Освобождаем его по завершении.\n\t\tif topicBucket, ok := b.subs[topic]; ok { // Проверяем, что тема всё ещё существует.\n\t\t\tdelete(topicBucket, id)    // Удаляем listener по идентификатору.\n\t\t\tif len(topicBucket) == 0 { // Если подписчиков не осталось...\n\t\t\t\tdelete(b.subs, topic) // ...удаляем и саму тему.\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (b *EventBus) Publish(evt Event) { // Publish рассылает событие всем подписчикам темы.\n\tif b == nil { // Nil-bus игнорируем для безопасности.\n\t\treturn // Ничего не делаем.\n\t}\n\tb.mu.RLock()                                  // Берём read-lock, чтобы скопировать listener'ов.\n\tbucket := b.subs[evt.Topic]                   // Получаем map подписчиков по теме.\n\tlisteners := make([]Listener, 0, len(bucket)) // Подготавливаем срез для копии.\n\tfor _, l := range bucket {                    // Копируем всех слушателей.\n\t\tlisteners = append(listeners, l) // Добавляем listener в срез.\n\t}\n\tb.mu.RUnlock()                       // Освобождаем read-lock до вызова коллбеков.\n\tfor _, listener := range listeners { // Итерируемся по скопированным listener'ам.\n\t\tif listener == nil { // Пропускаем nil-значения для безопасности.\n\t\t\tcontinue // Переходим к следующему listener'у.\n\t\t}\n\t\tfunc() { // Оборачиваем вызов в анонимную функцию для recover.\n\t\t\tdefer func() { // Устанавливаем recover на случай паники listener'а.\n\t\t\t\t_ = recover() // Игнорируем панику, чтобы не останавливать остальных.\n\t\t\t}()\n\t\t\tlistener(evt) // Вызываем listener с событием.\n\t\t}()\n\t}\n}\n\nfunc (b *EventBus) Topics() []string { // Topics возвращает отсортированный список активных тем.\n\tif b == nil { // Nil-bus не содержит тем.\n\t\treturn nil // Возвращаем nil/пустой срез.\n\t}\n\tb.mu.RLock()                             // Берём read-lock для чтения карты подписок.\n\ttopics := make([]string, 0, len(b.subs)) // Подготавливаем результирующий срез.\n\tfor topic, bucket := range b.subs {      // Перебираем все темы.\n\t\tif len(bucket) == 0 { // Пропускаем темы без подписчиков.\n\t\t\tcontinue // Ничего не добавляем.\n\t\t}\n\t\ttopics = append(topics, topic) // Добавляем тему в список.\n\t}\n\tb.mu.RUnlock()       // Освобождаем lock.\n\tsort.Strings(topics) // Сортируем темы по алфавиту для детерминированности.\n\treturn topics        // Возвращаем готовый список тем.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"testing\"\n)\n\n// ---- Subscribe ----\n\nfunc TestEventBusSubscribeRegistersListener(t *testing.T) {\n\tbus := &EventBus{}\n\treceived := make(chan Event, 1)\n\tunsub := bus.Subscribe(\"deploy\", func(evt Event) { received <- evt })\n\tif unsub == nil {\n\t\tt.Fatalf(\"subscribe should return unsubscribe func\")\n\t}\n\tbus.Publish(Event{Topic: \"deploy\", Data: \"v1\"})\n\tselect {\n\tcase evt := <-received:\n\t\tif evt.Data != \"v1\" {\n\t\t\tt.Fatalf(\"unexpected payload: %#v\", evt)\n\t\t}\n\tdefault:\n\t\tt.Fatalf(\"listener not invoked\")\n\t}\n}\n\nfunc TestEventBusSubscribeUnsubscribeStopsEvents(t *testing.T) {\n\tbus := &EventBus{}\n\tcount := 0\n\tunsub := bus.Subscribe(\"deploy\", func(Event) { count++ })\n\tunsub()\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif count != 0 {\n\t\tt.Fatalf(\"unsubscribed listener should not fire\")\n\t}\n}\n\nfunc TestEventBusSubscribeNilListener(t *testing.T) {\n\tbus := &EventBus{}\n\tunsub := bus.Subscribe(\"deploy\", nil)\n\tif unsub != nil {\n\t\tt.Fatalf(\"nil listener should return nil unsubscribe\")\n\t}\n}\n\n// ---- Publish ----\n\nfunc TestEventBusPublishDeliversAll(t *testing.T) {\n\tbus := &EventBus{}\n\ttotal := 0\n\tbus.Subscribe(\"deploy\", func(Event) { total++ })\n\tbus.Subscribe(\"deploy\", func(Event) { total++ })\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif total != 2 {\n\t\tt.Fatalf(\"publish should notify all listeners, got %d\", total)\n\t}\n}\n\nfunc TestEventBusPublishIgnoresPanics(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"deploy\", func(Event) { panic(\"boom\") })\n\tcalled := false\n\tbus.Subscribe(\"deploy\", func(Event) { called = true })\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif !called {\n\t\tt.Fatalf(\"panic in one listener should not stop others\")\n\t}\n}\n\nfunc TestEventBusPublishDifferentTopic(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"deploy\", func(Event) { t.Fatalf(\"should not be called\") })\n\tbus.Publish(Event{Topic: \"metrics\"})\n}\n\n// ---- Topics ----\n\nfunc TestEventBusTopicsSorted(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"b\", func(Event) {})\n\tbus.Subscribe(\"a\", func(Event) {})\n\twant := []string{\"a\", \"b\"}\n\tgot := bus.Topics()\n\tif len(got) != len(want) || got[0] != \"a\" || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected topics: %#v\", got)\n\t}\n}\n\nfunc TestEventBusTopicsSkipsEmpty(t *testing.T) {\n\tbus := &EventBus{}\n\tunsub := bus.Subscribe(\"temp\", func(Event) {})\n\tunsub()\n\tif topics := bus.Topics(); len(topics) != 0 {\n\t\tt.Fatalf(\"expected empty topics, got %#v\", topics)\n\t}\n}\n\nfunc TestEventBusTopicsNilBus(t *testing.T) {\n\tvar bus *EventBus\n\tif topics := bus.Topics(); len(topics) != 0 {\n\t\tt.Fatalf(\"nil bus should return empty slice\")\n\t}\n}\n",
        "tags": [
          "go",
          "observer",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "observer",
        "slug": "go-observer-publish",
        "title": "Publish",
        "description": "Task 2 (easy+): Publish\nРассылайте события всем подписчикам темы, игнорируя паники внутри listener.\nПодсказка: копируйте listeners под read-lock и вызывайте их вне критической секции.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Publish.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"sync\"\n\n// Event описывает уведомление, рассылемое наблюдателям.\ntype Event struct {\n\tTopic string\n\tData  any\n}\n\n// Listener — функция, получающая события определённой темы.\ntype Listener func(Event)\n\n// EventBus управляет подписчиками и рассылкой событий.\ntype EventBus struct {\n\tmu     sync.RWMutex\n\tsubs   map[string]map[int]Listener\n\tnextID int\n}\n\n// Task 1 (easy): Subscribe\n// Зарегистрируйте нового подписчика и верните функцию отписки.\n// Подсказка: используйте счётчик nextID для уникальных ключей и удаляйте listener при отписке.\nfunc (b *EventBus) Subscribe(topic string, listener Listener) func() {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Publish\n// Рассылайте события всем подписчикам темы, игнорируя паники внутри listener.\n// Подсказка: копируйте listeners под read-lock и вызывайте их вне критической секции.\nfunc (b *EventBus) Publish(evt Event) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Topics\n// Верните отсортированный список тем, на которые есть подписчики.\n// Подсказка: пропускайте пустые списки и используйте sort.Strings.\nfunc (b *EventBus) Topics() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport \"sort\"\n\nfunc (b *EventBus) Subscribe(topic string, listener Listener) func() { // Subscribe регистрирует listener на указанную тему.\n\tif b == nil || listener == nil || topic == \"\" { // Проверяем корректность входных данных.\n\t\treturn nil // Без валидного bus/listener вернуть нечего.\n\t}\n\tb.mu.Lock()         // Захватываем mutex для модификации хранилища подписок.\n\tdefer b.mu.Unlock() // Гарантируем освобождение mutex.\n\tif b.subs == nil {  // Лениво инициализируем карту тем.\n\t\tb.subs = make(map[string]map[int]Listener) // Создаём map topic -> listeners.\n\t}\n\tbucket, ok := b.subs[topic] // Ищем существующий набор подписчиков.\n\tif !ok {                    // Если тема новая...\n\t\tbucket = make(map[int]Listener) // ...создаём контейнер для listener'ов.\n\t\tb.subs[topic] = bucket          // Сохраняем его в основном хранилище.\n\t}\n\tb.nextID++            // Генерируем уникальный идентификатор подписки.\n\tid := b.nextID        // Сохраняем его в локальную переменную.\n\tbucket[id] = listener // Регистрируем listener под сгенерированным ключом.\n\treturn func() {       // Возвращаем функцию отписки.\n\t\tb.mu.Lock()                               // Для удаления снова захватываем mutex.\n\t\tdefer b.mu.Unlock()                       // Освобождаем его по завершении.\n\t\tif topicBucket, ok := b.subs[topic]; ok { // Проверяем, что тема всё ещё существует.\n\t\t\tdelete(topicBucket, id)    // Удаляем listener по идентификатору.\n\t\t\tif len(topicBucket) == 0 { // Если подписчиков не осталось...\n\t\t\t\tdelete(b.subs, topic) // ...удаляем и саму тему.\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (b *EventBus) Publish(evt Event) { // Publish рассылает событие всем подписчикам темы.\n\tif b == nil { // Nil-bus игнорируем для безопасности.\n\t\treturn // Ничего не делаем.\n\t}\n\tb.mu.RLock()                                  // Берём read-lock, чтобы скопировать listener'ов.\n\tbucket := b.subs[evt.Topic]                   // Получаем map подписчиков по теме.\n\tlisteners := make([]Listener, 0, len(bucket)) // Подготавливаем срез для копии.\n\tfor _, l := range bucket {                    // Копируем всех слушателей.\n\t\tlisteners = append(listeners, l) // Добавляем listener в срез.\n\t}\n\tb.mu.RUnlock()                       // Освобождаем read-lock до вызова коллбеков.\n\tfor _, listener := range listeners { // Итерируемся по скопированным listener'ам.\n\t\tif listener == nil { // Пропускаем nil-значения для безопасности.\n\t\t\tcontinue // Переходим к следующему listener'у.\n\t\t}\n\t\tfunc() { // Оборачиваем вызов в анонимную функцию для recover.\n\t\t\tdefer func() { // Устанавливаем recover на случай паники listener'а.\n\t\t\t\t_ = recover() // Игнорируем панику, чтобы не останавливать остальных.\n\t\t\t}()\n\t\t\tlistener(evt) // Вызываем listener с событием.\n\t\t}()\n\t}\n}\n\nfunc (b *EventBus) Topics() []string { // Topics возвращает отсортированный список активных тем.\n\tif b == nil { // Nil-bus не содержит тем.\n\t\treturn nil // Возвращаем nil/пустой срез.\n\t}\n\tb.mu.RLock()                             // Берём read-lock для чтения карты подписок.\n\ttopics := make([]string, 0, len(b.subs)) // Подготавливаем результирующий срез.\n\tfor topic, bucket := range b.subs {      // Перебираем все темы.\n\t\tif len(bucket) == 0 { // Пропускаем темы без подписчиков.\n\t\t\tcontinue // Ничего не добавляем.\n\t\t}\n\t\ttopics = append(topics, topic) // Добавляем тему в список.\n\t}\n\tb.mu.RUnlock()       // Освобождаем lock.\n\tsort.Strings(topics) // Сортируем темы по алфавиту для детерминированности.\n\treturn topics        // Возвращаем готовый список тем.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"testing\"\n)\n\n// ---- Subscribe ----\n\nfunc TestEventBusSubscribeRegistersListener(t *testing.T) {\n\tbus := &EventBus{}\n\treceived := make(chan Event, 1)\n\tunsub := bus.Subscribe(\"deploy\", func(evt Event) { received <- evt })\n\tif unsub == nil {\n\t\tt.Fatalf(\"subscribe should return unsubscribe func\")\n\t}\n\tbus.Publish(Event{Topic: \"deploy\", Data: \"v1\"})\n\tselect {\n\tcase evt := <-received:\n\t\tif evt.Data != \"v1\" {\n\t\t\tt.Fatalf(\"unexpected payload: %#v\", evt)\n\t\t}\n\tdefault:\n\t\tt.Fatalf(\"listener not invoked\")\n\t}\n}\n\nfunc TestEventBusSubscribeUnsubscribeStopsEvents(t *testing.T) {\n\tbus := &EventBus{}\n\tcount := 0\n\tunsub := bus.Subscribe(\"deploy\", func(Event) { count++ })\n\tunsub()\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif count != 0 {\n\t\tt.Fatalf(\"unsubscribed listener should not fire\")\n\t}\n}\n\nfunc TestEventBusSubscribeNilListener(t *testing.T) {\n\tbus := &EventBus{}\n\tunsub := bus.Subscribe(\"deploy\", nil)\n\tif unsub != nil {\n\t\tt.Fatalf(\"nil listener should return nil unsubscribe\")\n\t}\n}\n\n// ---- Publish ----\n\nfunc TestEventBusPublishDeliversAll(t *testing.T) {\n\tbus := &EventBus{}\n\ttotal := 0\n\tbus.Subscribe(\"deploy\", func(Event) { total++ })\n\tbus.Subscribe(\"deploy\", func(Event) { total++ })\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif total != 2 {\n\t\tt.Fatalf(\"publish should notify all listeners, got %d\", total)\n\t}\n}\n\nfunc TestEventBusPublishIgnoresPanics(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"deploy\", func(Event) { panic(\"boom\") })\n\tcalled := false\n\tbus.Subscribe(\"deploy\", func(Event) { called = true })\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif !called {\n\t\tt.Fatalf(\"panic in one listener should not stop others\")\n\t}\n}\n\nfunc TestEventBusPublishDifferentTopic(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"deploy\", func(Event) { t.Fatalf(\"should not be called\") })\n\tbus.Publish(Event{Topic: \"metrics\"})\n}\n\n// ---- Topics ----\n\nfunc TestEventBusTopicsSorted(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"b\", func(Event) {})\n\tbus.Subscribe(\"a\", func(Event) {})\n\twant := []string{\"a\", \"b\"}\n\tgot := bus.Topics()\n\tif len(got) != len(want) || got[0] != \"a\" || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected topics: %#v\", got)\n\t}\n}\n\nfunc TestEventBusTopicsSkipsEmpty(t *testing.T) {\n\tbus := &EventBus{}\n\tunsub := bus.Subscribe(\"temp\", func(Event) {})\n\tunsub()\n\tif topics := bus.Topics(); len(topics) != 0 {\n\t\tt.Fatalf(\"expected empty topics, got %#v\", topics)\n\t}\n}\n\nfunc TestEventBusTopicsNilBus(t *testing.T) {\n\tvar bus *EventBus\n\tif topics := bus.Topics(); len(topics) != 0 {\n\t\tt.Fatalf(\"nil bus should return empty slice\")\n\t}\n}\n",
        "tags": [
          "go",
          "observer",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "observer",
        "slug": "go-observer-topics",
        "title": "Topics",
        "description": "Task 3 (medium): Topics\nВерните отсортированный список тем, на которые есть подписчики.\nПодсказка: пропускайте пустые списки и используйте sort.Strings.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Topics.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"sync\"\n\n// Event описывает уведомление, рассылемое наблюдателям.\ntype Event struct {\n\tTopic string\n\tData  any\n}\n\n// Listener — функция, получающая события определённой темы.\ntype Listener func(Event)\n\n// EventBus управляет подписчиками и рассылкой событий.\ntype EventBus struct {\n\tmu     sync.RWMutex\n\tsubs   map[string]map[int]Listener\n\tnextID int\n}\n\n// Task 1 (easy): Subscribe\n// Зарегистрируйте нового подписчика и верните функцию отписки.\n// Подсказка: используйте счётчик nextID для уникальных ключей и удаляйте listener при отписке.\nfunc (b *EventBus) Subscribe(topic string, listener Listener) func() {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Publish\n// Рассылайте события всем подписчикам темы, игнорируя паники внутри listener.\n// Подсказка: копируйте listeners под read-lock и вызывайте их вне критической секции.\nfunc (b *EventBus) Publish(evt Event) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Topics\n// Верните отсортированный список тем, на которые есть подписчики.\n// Подсказка: пропускайте пустые списки и используйте sort.Strings.\nfunc (b *EventBus) Topics() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport \"sort\"\n\nfunc (b *EventBus) Subscribe(topic string, listener Listener) func() { // Subscribe регистрирует listener на указанную тему.\n\tif b == nil || listener == nil || topic == \"\" { // Проверяем корректность входных данных.\n\t\treturn nil // Без валидного bus/listener вернуть нечего.\n\t}\n\tb.mu.Lock()         // Захватываем mutex для модификации хранилища подписок.\n\tdefer b.mu.Unlock() // Гарантируем освобождение mutex.\n\tif b.subs == nil {  // Лениво инициализируем карту тем.\n\t\tb.subs = make(map[string]map[int]Listener) // Создаём map topic -> listeners.\n\t}\n\tbucket, ok := b.subs[topic] // Ищем существующий набор подписчиков.\n\tif !ok {                    // Если тема новая...\n\t\tbucket = make(map[int]Listener) // ...создаём контейнер для listener'ов.\n\t\tb.subs[topic] = bucket          // Сохраняем его в основном хранилище.\n\t}\n\tb.nextID++            // Генерируем уникальный идентификатор подписки.\n\tid := b.nextID        // Сохраняем его в локальную переменную.\n\tbucket[id] = listener // Регистрируем listener под сгенерированным ключом.\n\treturn func() {       // Возвращаем функцию отписки.\n\t\tb.mu.Lock()                               // Для удаления снова захватываем mutex.\n\t\tdefer b.mu.Unlock()                       // Освобождаем его по завершении.\n\t\tif topicBucket, ok := b.subs[topic]; ok { // Проверяем, что тема всё ещё существует.\n\t\t\tdelete(topicBucket, id)    // Удаляем listener по идентификатору.\n\t\t\tif len(topicBucket) == 0 { // Если подписчиков не осталось...\n\t\t\t\tdelete(b.subs, topic) // ...удаляем и саму тему.\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (b *EventBus) Publish(evt Event) { // Publish рассылает событие всем подписчикам темы.\n\tif b == nil { // Nil-bus игнорируем для безопасности.\n\t\treturn // Ничего не делаем.\n\t}\n\tb.mu.RLock()                                  // Берём read-lock, чтобы скопировать listener'ов.\n\tbucket := b.subs[evt.Topic]                   // Получаем map подписчиков по теме.\n\tlisteners := make([]Listener, 0, len(bucket)) // Подготавливаем срез для копии.\n\tfor _, l := range bucket {                    // Копируем всех слушателей.\n\t\tlisteners = append(listeners, l) // Добавляем listener в срез.\n\t}\n\tb.mu.RUnlock()                       // Освобождаем read-lock до вызова коллбеков.\n\tfor _, listener := range listeners { // Итерируемся по скопированным listener'ам.\n\t\tif listener == nil { // Пропускаем nil-значения для безопасности.\n\t\t\tcontinue // Переходим к следующему listener'у.\n\t\t}\n\t\tfunc() { // Оборачиваем вызов в анонимную функцию для recover.\n\t\t\tdefer func() { // Устанавливаем recover на случай паники listener'а.\n\t\t\t\t_ = recover() // Игнорируем панику, чтобы не останавливать остальных.\n\t\t\t}()\n\t\t\tlistener(evt) // Вызываем listener с событием.\n\t\t}()\n\t}\n}\n\nfunc (b *EventBus) Topics() []string { // Topics возвращает отсортированный список активных тем.\n\tif b == nil { // Nil-bus не содержит тем.\n\t\treturn nil // Возвращаем nil/пустой срез.\n\t}\n\tb.mu.RLock()                             // Берём read-lock для чтения карты подписок.\n\ttopics := make([]string, 0, len(b.subs)) // Подготавливаем результирующий срез.\n\tfor topic, bucket := range b.subs {      // Перебираем все темы.\n\t\tif len(bucket) == 0 { // Пропускаем темы без подписчиков.\n\t\t\tcontinue // Ничего не добавляем.\n\t\t}\n\t\ttopics = append(topics, topic) // Добавляем тему в список.\n\t}\n\tb.mu.RUnlock()       // Освобождаем lock.\n\tsort.Strings(topics) // Сортируем темы по алфавиту для детерминированности.\n\treturn topics        // Возвращаем готовый список тем.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"testing\"\n)\n\n// ---- Subscribe ----\n\nfunc TestEventBusSubscribeRegistersListener(t *testing.T) {\n\tbus := &EventBus{}\n\treceived := make(chan Event, 1)\n\tunsub := bus.Subscribe(\"deploy\", func(evt Event) { received <- evt })\n\tif unsub == nil {\n\t\tt.Fatalf(\"subscribe should return unsubscribe func\")\n\t}\n\tbus.Publish(Event{Topic: \"deploy\", Data: \"v1\"})\n\tselect {\n\tcase evt := <-received:\n\t\tif evt.Data != \"v1\" {\n\t\t\tt.Fatalf(\"unexpected payload: %#v\", evt)\n\t\t}\n\tdefault:\n\t\tt.Fatalf(\"listener not invoked\")\n\t}\n}\n\nfunc TestEventBusSubscribeUnsubscribeStopsEvents(t *testing.T) {\n\tbus := &EventBus{}\n\tcount := 0\n\tunsub := bus.Subscribe(\"deploy\", func(Event) { count++ })\n\tunsub()\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif count != 0 {\n\t\tt.Fatalf(\"unsubscribed listener should not fire\")\n\t}\n}\n\nfunc TestEventBusSubscribeNilListener(t *testing.T) {\n\tbus := &EventBus{}\n\tunsub := bus.Subscribe(\"deploy\", nil)\n\tif unsub != nil {\n\t\tt.Fatalf(\"nil listener should return nil unsubscribe\")\n\t}\n}\n\n// ---- Publish ----\n\nfunc TestEventBusPublishDeliversAll(t *testing.T) {\n\tbus := &EventBus{}\n\ttotal := 0\n\tbus.Subscribe(\"deploy\", func(Event) { total++ })\n\tbus.Subscribe(\"deploy\", func(Event) { total++ })\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif total != 2 {\n\t\tt.Fatalf(\"publish should notify all listeners, got %d\", total)\n\t}\n}\n\nfunc TestEventBusPublishIgnoresPanics(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"deploy\", func(Event) { panic(\"boom\") })\n\tcalled := false\n\tbus.Subscribe(\"deploy\", func(Event) { called = true })\n\tbus.Publish(Event{Topic: \"deploy\"})\n\tif !called {\n\t\tt.Fatalf(\"panic in one listener should not stop others\")\n\t}\n}\n\nfunc TestEventBusPublishDifferentTopic(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"deploy\", func(Event) { t.Fatalf(\"should not be called\") })\n\tbus.Publish(Event{Topic: \"metrics\"})\n}\n\n// ---- Topics ----\n\nfunc TestEventBusTopicsSorted(t *testing.T) {\n\tbus := &EventBus{}\n\tbus.Subscribe(\"b\", func(Event) {})\n\tbus.Subscribe(\"a\", func(Event) {})\n\twant := []string{\"a\", \"b\"}\n\tgot := bus.Topics()\n\tif len(got) != len(want) || got[0] != \"a\" || got[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected topics: %#v\", got)\n\t}\n}\n\nfunc TestEventBusTopicsSkipsEmpty(t *testing.T) {\n\tbus := &EventBus{}\n\tunsub := bus.Subscribe(\"temp\", func(Event) {})\n\tunsub()\n\tif topics := bus.Topics(); len(topics) != 0 {\n\t\tt.Fatalf(\"expected empty topics, got %#v\", topics)\n\t}\n}\n\nfunc TestEventBusTopicsNilBus(t *testing.T) {\n\tvar bus *EventBus\n\tif topics := bus.Topics(); len(topics) != 0 {\n\t\tt.Fatalf(\"nil bus should return empty slice\")\n\t}\n}\n",
        "tags": [
          "go",
          "observer",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-state",
    "tasks": [
      {
        "package": "state",
        "slug": "go-state-setinitial",
        "title": "SetInitial",
        "description": "Task 1 (easy): SetInitial\nУстановите начальное состояние машины и сбросьте историю переходов.\nПодсказка: защищайте запись mutex'ом и допускайте повторную инициализацию.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of SetInitial.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// StateFunc описывает обработчик события, возвращающий новое состояние и метку перехода.\ntype StateFunc func(event string) (StateFunc, string, error)\n\n// ErrNoState сигнализирует, что текущее состояние не установлено.\nvar ErrNoState = errors.New(\"state machine is not initialized\")\n\n// StateMachine реализует переключение состояний с историей переходов.\ntype StateMachine struct {\n\tmu      sync.Mutex\n\tcurrent StateFunc\n\thistory []string\n}\n\n// Task 1 (easy): SetInitial\n// Установите начальное состояние машины и сбросьте историю переходов.\n// Подсказка: защищайте запись mutex'ом и допускайте повторную инициализацию.\nfunc (sm *StateMachine) SetInitial(state StateFunc) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Handle\n// Обработайте событие с помощью текущего состояния и сохраните метку перехода в history.\n// Подсказка: возвращайте ErrNoState, если состояние не задано.\nfunc (sm *StateMachine) Handle(event string) (string, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): History\n// Верните копию истории переходов для чтения извне.\n// Подсказка: скопируйте slice под mutex'ом, чтобы избежать data race.\nfunc (sm *StateMachine) History() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (sm *StateMachine) SetInitial(state StateFunc) { // SetInitial устанавливает начальное состояние и очищает историю.\n\tif sm == nil { // Nil-получатель игнорируем, чтобы вызов был безопасным.\n\t\treturn // Ничего не делаем.\n\t}\n\tsm.mu.Lock()         // Захватываем mutex для изменения полей.\n\tdefer sm.mu.Unlock() // Освобождаем mutex по завершении.\n\tsm.current = state   // Обновляем текущий обработчик событий.\n\tsm.history = nil     // Сбрасываем историю переходов.\n}\n\nfunc (sm *StateMachine) Handle(event string) (string, error) { // Handle делегирует обработку текущему состоянию.\n\tif sm == nil { // Nil-машина не может обрабатывать события.\n\t\treturn \"\", ErrNoState // Сообщаем, что машина не инициализирована.\n\t}\n\tsm.mu.Lock()        // Берём mutex, чтобы прочитать ссылку на текущее состояние.\n\tstate := sm.current // Копируем указатель на текущий обработчик.\n\tsm.mu.Unlock()      // Освобождаем mutex до выполнения пользовательского кода.\n\tif state == nil {   // Если состояние не установлено...\n\t\treturn \"\", ErrNoState // ...возвращаем ошибку ErrNoState.\n\t}\n\tnext, label, err := state(event) // Вызываем состояние, получая новое состояние и метку перехода.\n\tif err != nil {                  // При ошибке из состояния...\n\t\treturn label, err // ...возвращаем её вызывающему коду.\n\t}\n\tsm.mu.Lock()                           // Берём mutex, чтобы обновить историю и текущее состояние.\n\tsm.history = append(sm.history, label) // Запоминаем метку перехода.\n\tsm.current = next                      // Обновляем состояние на возвращённое из обработчика (может быть nil).\n\tsm.mu.Unlock()                         // Освобождаем mutex.\n\treturn label, nil                      // Возвращаем метку и успешный результат.\n}\n\nfunc (sm *StateMachine) History() []string { // History возвращает копию истории переходов.\n\tif sm == nil { // Nil-получатель не содержит истории.\n\t\treturn nil // Возвращаем nil/пустой срез.\n\t}\n\tsm.mu.Lock()                             // Захватываем mutex для безопасного чтения.\n\tdefer sm.mu.Unlock()                     // Освобождаем mutex по завершении.\n\tclone := make([]string, len(sm.history)) // Создаём срез нужной длины.\n\tcopy(clone, sm.history)                  // Копируем элементы истории в новый срез.\n\treturn clone                             // Возвращаем копию вызвавшему коду.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"testing\"\n)\n\n// ---- SetInitial ----\n\nfunc TestStateMachineSetInitialSetsState(t *testing.T) {\n\tsm := &StateMachine{}\n\tcalled := false\n\tsm.SetInitial(func(event string) (StateFunc, string, error) {\n\t\tcalled = true\n\t\treturn nil, event, nil\n\t})\n\t_, err := sm.Handle(\"start\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif !called {\n\t\tt.Fatalf(\"state function not invoked\")\n\t}\n}\n\nfunc TestStateMachineSetInitialResetsHistory(t *testing.T) {\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"one\", nil })\n\t_, _ = sm.Handle(\"event\")\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"two\", nil })\n\tif got := sm.History(); len(got) != 0 {\n\t\tt.Fatalf(\"history should reset, got %v\", got)\n\t}\n}\n\nfunc TestStateMachineSetInitialNilReceiver(t *testing.T) {\n\tvar sm *StateMachine\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"SetInitial should be nil-safe: %v\", err)\n\t\t}\n\t}()\n\tsm.SetInitial(nil)\n}\n\n// ---- Handle ----\n\nfunc TestStateMachineHandleTransitions(t *testing.T) {\n\tnext := func(event string) (StateFunc, string, error) {\n\t\treturn nil, \"handled:\" + event, nil\n\t}\n\tsm := &StateMachine{}\n\tsm.SetInitial(next)\n\tlabel, err := sm.Handle(\"deploy\")\n\tif err != nil || label != \"handled:deploy\" {\n\t\tt.Fatalf(\"unexpected result label=%s err=%v\", label, err)\n\t}\n}\n\nfunc TestStateMachineHandleStoresHistory(t *testing.T) {\n\tseq := []string{\"first\", \"second\"}\n\tidx := 0\n\tvar state StateFunc\n\tstate = func(event string) (StateFunc, string, error) {\n\t\tlabel := seq[idx]\n\t\tidx = (idx + 1) % len(seq)\n\t\treturn state, label, nil\n\t}\n\tsm := &StateMachine{}\n\tsm.SetInitial(state)\n\t_, _ = sm.Handle(\"evt1\")\n\t_, _ = sm.Handle(\"evt2\")\n\thistory := sm.History()\n\tif len(history) != 2 || history[0] != \"first\" || history[1] != \"second\" {\n\t\tt.Fatalf(\"unexpected history: %#v\", history)\n\t}\n}\n\nfunc TestStateMachineHandlePropagatesErrors(t *testing.T) {\n\twant := errors.New(\"boom\")\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"\", want })\n\tif _, err := sm.Handle(\"evt\"); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestStateMachineHandleWithoutState(t *testing.T) {\n\tsm := &StateMachine{}\n\tif _, err := sm.Handle(\"event\"); !errors.Is(err, ErrNoState) {\n\t\tt.Fatalf(\"expected ErrNoState, got %v\", err)\n\t}\n}\n\n// ---- History ----\n\nfunc TestStateMachineHistoryReturnsCopy(t *testing.T) {\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"x\", nil })\n\t_, _ = sm.Handle(\"evt\")\n\thist := sm.History()\n\thist[0] = \"mutated\"\n\tif sm.history[0] == \"mutated\" {\n\t\tt.Fatalf(\"history slice should be copied\")\n\t}\n}\n\nfunc TestStateMachineHistoryNilReceiver(t *testing.T) {\n\tvar sm *StateMachine\n\tif hist := sm.History(); len(hist) != 0 {\n\t\tt.Fatalf(\"nil machine should return empty slice\")\n\t}\n}\n\nfunc TestStateMachineHistoryEmpty(t *testing.T) {\n\tsm := &StateMachine{}\n\tif hist := sm.History(); len(hist) != 0 {\n\t\tt.Fatalf(\"empty history expected\")\n\t}\n}\n",
        "tags": [
          "go",
          "state",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "state",
        "slug": "go-state-handle",
        "title": "Handle",
        "description": "Task 2 (easy+): Handle\nОбработайте событие с помощью текущего состояния и сохраните метку перехода в history.\nПодсказка: возвращайте ErrNoState, если состояние не задано.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Handle.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// StateFunc описывает обработчик события, возвращающий новое состояние и метку перехода.\ntype StateFunc func(event string) (StateFunc, string, error)\n\n// ErrNoState сигнализирует, что текущее состояние не установлено.\nvar ErrNoState = errors.New(\"state machine is not initialized\")\n\n// StateMachine реализует переключение состояний с историей переходов.\ntype StateMachine struct {\n\tmu      sync.Mutex\n\tcurrent StateFunc\n\thistory []string\n}\n\n// Task 1 (easy): SetInitial\n// Установите начальное состояние машины и сбросьте историю переходов.\n// Подсказка: защищайте запись mutex'ом и допускайте повторную инициализацию.\nfunc (sm *StateMachine) SetInitial(state StateFunc) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Handle\n// Обработайте событие с помощью текущего состояния и сохраните метку перехода в history.\n// Подсказка: возвращайте ErrNoState, если состояние не задано.\nfunc (sm *StateMachine) Handle(event string) (string, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): History\n// Верните копию истории переходов для чтения извне.\n// Подсказка: скопируйте slice под mutex'ом, чтобы избежать data race.\nfunc (sm *StateMachine) History() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (sm *StateMachine) SetInitial(state StateFunc) { // SetInitial устанавливает начальное состояние и очищает историю.\n\tif sm == nil { // Nil-получатель игнорируем, чтобы вызов был безопасным.\n\t\treturn // Ничего не делаем.\n\t}\n\tsm.mu.Lock()         // Захватываем mutex для изменения полей.\n\tdefer sm.mu.Unlock() // Освобождаем mutex по завершении.\n\tsm.current = state   // Обновляем текущий обработчик событий.\n\tsm.history = nil     // Сбрасываем историю переходов.\n}\n\nfunc (sm *StateMachine) Handle(event string) (string, error) { // Handle делегирует обработку текущему состоянию.\n\tif sm == nil { // Nil-машина не может обрабатывать события.\n\t\treturn \"\", ErrNoState // Сообщаем, что машина не инициализирована.\n\t}\n\tsm.mu.Lock()        // Берём mutex, чтобы прочитать ссылку на текущее состояние.\n\tstate := sm.current // Копируем указатель на текущий обработчик.\n\tsm.mu.Unlock()      // Освобождаем mutex до выполнения пользовательского кода.\n\tif state == nil {   // Если состояние не установлено...\n\t\treturn \"\", ErrNoState // ...возвращаем ошибку ErrNoState.\n\t}\n\tnext, label, err := state(event) // Вызываем состояние, получая новое состояние и метку перехода.\n\tif err != nil {                  // При ошибке из состояния...\n\t\treturn label, err // ...возвращаем её вызывающему коду.\n\t}\n\tsm.mu.Lock()                           // Берём mutex, чтобы обновить историю и текущее состояние.\n\tsm.history = append(sm.history, label) // Запоминаем метку перехода.\n\tsm.current = next                      // Обновляем состояние на возвращённое из обработчика (может быть nil).\n\tsm.mu.Unlock()                         // Освобождаем mutex.\n\treturn label, nil                      // Возвращаем метку и успешный результат.\n}\n\nfunc (sm *StateMachine) History() []string { // History возвращает копию истории переходов.\n\tif sm == nil { // Nil-получатель не содержит истории.\n\t\treturn nil // Возвращаем nil/пустой срез.\n\t}\n\tsm.mu.Lock()                             // Захватываем mutex для безопасного чтения.\n\tdefer sm.mu.Unlock()                     // Освобождаем mutex по завершении.\n\tclone := make([]string, len(sm.history)) // Создаём срез нужной длины.\n\tcopy(clone, sm.history)                  // Копируем элементы истории в новый срез.\n\treturn clone                             // Возвращаем копию вызвавшему коду.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"testing\"\n)\n\n// ---- SetInitial ----\n\nfunc TestStateMachineSetInitialSetsState(t *testing.T) {\n\tsm := &StateMachine{}\n\tcalled := false\n\tsm.SetInitial(func(event string) (StateFunc, string, error) {\n\t\tcalled = true\n\t\treturn nil, event, nil\n\t})\n\t_, err := sm.Handle(\"start\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif !called {\n\t\tt.Fatalf(\"state function not invoked\")\n\t}\n}\n\nfunc TestStateMachineSetInitialResetsHistory(t *testing.T) {\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"one\", nil })\n\t_, _ = sm.Handle(\"event\")\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"two\", nil })\n\tif got := sm.History(); len(got) != 0 {\n\t\tt.Fatalf(\"history should reset, got %v\", got)\n\t}\n}\n\nfunc TestStateMachineSetInitialNilReceiver(t *testing.T) {\n\tvar sm *StateMachine\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"SetInitial should be nil-safe: %v\", err)\n\t\t}\n\t}()\n\tsm.SetInitial(nil)\n}\n\n// ---- Handle ----\n\nfunc TestStateMachineHandleTransitions(t *testing.T) {\n\tnext := func(event string) (StateFunc, string, error) {\n\t\treturn nil, \"handled:\" + event, nil\n\t}\n\tsm := &StateMachine{}\n\tsm.SetInitial(next)\n\tlabel, err := sm.Handle(\"deploy\")\n\tif err != nil || label != \"handled:deploy\" {\n\t\tt.Fatalf(\"unexpected result label=%s err=%v\", label, err)\n\t}\n}\n\nfunc TestStateMachineHandleStoresHistory(t *testing.T) {\n\tseq := []string{\"first\", \"second\"}\n\tidx := 0\n\tvar state StateFunc\n\tstate = func(event string) (StateFunc, string, error) {\n\t\tlabel := seq[idx]\n\t\tidx = (idx + 1) % len(seq)\n\t\treturn state, label, nil\n\t}\n\tsm := &StateMachine{}\n\tsm.SetInitial(state)\n\t_, _ = sm.Handle(\"evt1\")\n\t_, _ = sm.Handle(\"evt2\")\n\thistory := sm.History()\n\tif len(history) != 2 || history[0] != \"first\" || history[1] != \"second\" {\n\t\tt.Fatalf(\"unexpected history: %#v\", history)\n\t}\n}\n\nfunc TestStateMachineHandlePropagatesErrors(t *testing.T) {\n\twant := errors.New(\"boom\")\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"\", want })\n\tif _, err := sm.Handle(\"evt\"); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestStateMachineHandleWithoutState(t *testing.T) {\n\tsm := &StateMachine{}\n\tif _, err := sm.Handle(\"event\"); !errors.Is(err, ErrNoState) {\n\t\tt.Fatalf(\"expected ErrNoState, got %v\", err)\n\t}\n}\n\n// ---- History ----\n\nfunc TestStateMachineHistoryReturnsCopy(t *testing.T) {\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"x\", nil })\n\t_, _ = sm.Handle(\"evt\")\n\thist := sm.History()\n\thist[0] = \"mutated\"\n\tif sm.history[0] == \"mutated\" {\n\t\tt.Fatalf(\"history slice should be copied\")\n\t}\n}\n\nfunc TestStateMachineHistoryNilReceiver(t *testing.T) {\n\tvar sm *StateMachine\n\tif hist := sm.History(); len(hist) != 0 {\n\t\tt.Fatalf(\"nil machine should return empty slice\")\n\t}\n}\n\nfunc TestStateMachineHistoryEmpty(t *testing.T) {\n\tsm := &StateMachine{}\n\tif hist := sm.History(); len(hist) != 0 {\n\t\tt.Fatalf(\"empty history expected\")\n\t}\n}\n",
        "tags": [
          "go",
          "state",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "state",
        "slug": "go-state-history",
        "title": "History",
        "description": "Task 3 (medium): History\nВерните копию истории переходов для чтения извне.\nПодсказка: скопируйте slice под mutex'ом, чтобы избежать data race.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of History.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// StateFunc описывает обработчик события, возвращающий новое состояние и метку перехода.\ntype StateFunc func(event string) (StateFunc, string, error)\n\n// ErrNoState сигнализирует, что текущее состояние не установлено.\nvar ErrNoState = errors.New(\"state machine is not initialized\")\n\n// StateMachine реализует переключение состояний с историей переходов.\ntype StateMachine struct {\n\tmu      sync.Mutex\n\tcurrent StateFunc\n\thistory []string\n}\n\n// Task 1 (easy): SetInitial\n// Установите начальное состояние машины и сбросьте историю переходов.\n// Подсказка: защищайте запись mutex'ом и допускайте повторную инициализацию.\nfunc (sm *StateMachine) SetInitial(state StateFunc) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Handle\n// Обработайте событие с помощью текущего состояния и сохраните метку перехода в history.\n// Подсказка: возвращайте ErrNoState, если состояние не задано.\nfunc (sm *StateMachine) Handle(event string) (string, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): History\n// Верните копию истории переходов для чтения извне.\n// Подсказка: скопируйте slice под mutex'ом, чтобы избежать data race.\nfunc (sm *StateMachine) History() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (sm *StateMachine) SetInitial(state StateFunc) { // SetInitial устанавливает начальное состояние и очищает историю.\n\tif sm == nil { // Nil-получатель игнорируем, чтобы вызов был безопасным.\n\t\treturn // Ничего не делаем.\n\t}\n\tsm.mu.Lock()         // Захватываем mutex для изменения полей.\n\tdefer sm.mu.Unlock() // Освобождаем mutex по завершении.\n\tsm.current = state   // Обновляем текущий обработчик событий.\n\tsm.history = nil     // Сбрасываем историю переходов.\n}\n\nfunc (sm *StateMachine) Handle(event string) (string, error) { // Handle делегирует обработку текущему состоянию.\n\tif sm == nil { // Nil-машина не может обрабатывать события.\n\t\treturn \"\", ErrNoState // Сообщаем, что машина не инициализирована.\n\t}\n\tsm.mu.Lock()        // Берём mutex, чтобы прочитать ссылку на текущее состояние.\n\tstate := sm.current // Копируем указатель на текущий обработчик.\n\tsm.mu.Unlock()      // Освобождаем mutex до выполнения пользовательского кода.\n\tif state == nil {   // Если состояние не установлено...\n\t\treturn \"\", ErrNoState // ...возвращаем ошибку ErrNoState.\n\t}\n\tnext, label, err := state(event) // Вызываем состояние, получая новое состояние и метку перехода.\n\tif err != nil {                  // При ошибке из состояния...\n\t\treturn label, err // ...возвращаем её вызывающему коду.\n\t}\n\tsm.mu.Lock()                           // Берём mutex, чтобы обновить историю и текущее состояние.\n\tsm.history = append(sm.history, label) // Запоминаем метку перехода.\n\tsm.current = next                      // Обновляем состояние на возвращённое из обработчика (может быть nil).\n\tsm.mu.Unlock()                         // Освобождаем mutex.\n\treturn label, nil                      // Возвращаем метку и успешный результат.\n}\n\nfunc (sm *StateMachine) History() []string { // History возвращает копию истории переходов.\n\tif sm == nil { // Nil-получатель не содержит истории.\n\t\treturn nil // Возвращаем nil/пустой срез.\n\t}\n\tsm.mu.Lock()                             // Захватываем mutex для безопасного чтения.\n\tdefer sm.mu.Unlock()                     // Освобождаем mutex по завершении.\n\tclone := make([]string, len(sm.history)) // Создаём срез нужной длины.\n\tcopy(clone, sm.history)                  // Копируем элементы истории в новый срез.\n\treturn clone                             // Возвращаем копию вызвавшему коду.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"testing\"\n)\n\n// ---- SetInitial ----\n\nfunc TestStateMachineSetInitialSetsState(t *testing.T) {\n\tsm := &StateMachine{}\n\tcalled := false\n\tsm.SetInitial(func(event string) (StateFunc, string, error) {\n\t\tcalled = true\n\t\treturn nil, event, nil\n\t})\n\t_, err := sm.Handle(\"start\")\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif !called {\n\t\tt.Fatalf(\"state function not invoked\")\n\t}\n}\n\nfunc TestStateMachineSetInitialResetsHistory(t *testing.T) {\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"one\", nil })\n\t_, _ = sm.Handle(\"event\")\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"two\", nil })\n\tif got := sm.History(); len(got) != 0 {\n\t\tt.Fatalf(\"history should reset, got %v\", got)\n\t}\n}\n\nfunc TestStateMachineSetInitialNilReceiver(t *testing.T) {\n\tvar sm *StateMachine\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tt.Fatalf(\"SetInitial should be nil-safe: %v\", err)\n\t\t}\n\t}()\n\tsm.SetInitial(nil)\n}\n\n// ---- Handle ----\n\nfunc TestStateMachineHandleTransitions(t *testing.T) {\n\tnext := func(event string) (StateFunc, string, error) {\n\t\treturn nil, \"handled:\" + event, nil\n\t}\n\tsm := &StateMachine{}\n\tsm.SetInitial(next)\n\tlabel, err := sm.Handle(\"deploy\")\n\tif err != nil || label != \"handled:deploy\" {\n\t\tt.Fatalf(\"unexpected result label=%s err=%v\", label, err)\n\t}\n}\n\nfunc TestStateMachineHandleStoresHistory(t *testing.T) {\n\tseq := []string{\"first\", \"second\"}\n\tidx := 0\n\tvar state StateFunc\n\tstate = func(event string) (StateFunc, string, error) {\n\t\tlabel := seq[idx]\n\t\tidx = (idx + 1) % len(seq)\n\t\treturn state, label, nil\n\t}\n\tsm := &StateMachine{}\n\tsm.SetInitial(state)\n\t_, _ = sm.Handle(\"evt1\")\n\t_, _ = sm.Handle(\"evt2\")\n\thistory := sm.History()\n\tif len(history) != 2 || history[0] != \"first\" || history[1] != \"second\" {\n\t\tt.Fatalf(\"unexpected history: %#v\", history)\n\t}\n}\n\nfunc TestStateMachineHandlePropagatesErrors(t *testing.T) {\n\twant := errors.New(\"boom\")\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"\", want })\n\tif _, err := sm.Handle(\"evt\"); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestStateMachineHandleWithoutState(t *testing.T) {\n\tsm := &StateMachine{}\n\tif _, err := sm.Handle(\"event\"); !errors.Is(err, ErrNoState) {\n\t\tt.Fatalf(\"expected ErrNoState, got %v\", err)\n\t}\n}\n\n// ---- History ----\n\nfunc TestStateMachineHistoryReturnsCopy(t *testing.T) {\n\tsm := &StateMachine{}\n\tsm.SetInitial(func(string) (StateFunc, string, error) { return nil, \"x\", nil })\n\t_, _ = sm.Handle(\"evt\")\n\thist := sm.History()\n\thist[0] = \"mutated\"\n\tif sm.history[0] == \"mutated\" {\n\t\tt.Fatalf(\"history slice should be copied\")\n\t}\n}\n\nfunc TestStateMachineHistoryNilReceiver(t *testing.T) {\n\tvar sm *StateMachine\n\tif hist := sm.History(); len(hist) != 0 {\n\t\tt.Fatalf(\"nil machine should return empty slice\")\n\t}\n}\n\nfunc TestStateMachineHistoryEmpty(t *testing.T) {\n\tsm := &StateMachine{}\n\tif hist := sm.History(); len(hist) != 0 {\n\t\tt.Fatalf(\"empty history expected\")\n\t}\n}\n",
        "tags": [
          "go",
          "state",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-strategy",
    "tasks": [
      {
        "package": "strategy",
        "slug": "go-strategy-register",
        "title": "Register",
        "description": "Task 1 (easy): Register\nЗарегистрируйте стратегию по имени, позволяя перезапись существующей.\nПодсказка: лениво инициализируйте map и игнорируйте nil-стратегии.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Register.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// DiscountStrategy вычисляет скидку для заказа.\ntype DiscountStrategy func(total float64) float64\n\n// ErrUnknownStrategy сигнализирует об отсутствии стратегии.\nvar ErrUnknownStrategy = errors.New(\"strategy not found\")\n\n// StrategyRegistry хранит зарегистрированные стратегии скидок.\ntype StrategyRegistry struct {\n\tmu         sync.RWMutex\n\tstrategies map[string]DiscountStrategy\n}\n\n// Task 1 (easy): Register\n// Зарегистрируйте стратегию по имени, позволяя перезапись существующей.\n// Подсказка: лениво инициализируйте map и игнорируйте nil-стратегии.\nfunc (r *StrategyRegistry) Register(name string, strategy DiscountStrategy) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Calculate\n// Примените стратегию к сумме заказа, вернув ErrUnknownStrategy при отсутствии стратегии.\n// Подсказка: защищайте чтение map mutex'ом и не допускайте отрицательных итогов.\nfunc (r *StrategyRegistry) Calculate(name string, total float64) (float64, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Available\n// Верните отсортированный список имён стратегий.\n// Подсказка: делайте копию ключей под read-lock и сортируйте slice.\nfunc (r *StrategyRegistry) Available() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport \"sort\"\n\nfunc (r *StrategyRegistry) Register(name string, strategy DiscountStrategy) { // Register добавляет стратегию в реестр.\n\tif r == nil || strategy == nil || name == \"\" { // Проверяем входные данные.\n\t\treturn // Ничего не делаем для некорректных аргументов.\n\t}\n\tr.mu.Lock()              // Захватываем mutex для изменения map.\n\tdefer r.mu.Unlock()      // Освобождаем mutex по завершении.\n\tif r.strategies == nil { // Лениво инициализируем карту стратегий.\n\t\tr.strategies = make(map[string]DiscountStrategy) // Создаём map name->strategy.\n\t}\n\tr.strategies[name] = strategy // Сохраняем (либо перезаписываем) стратегию по имени.\n}\n\nfunc (r *StrategyRegistry) Calculate(name string, total float64) (float64, error) { // Calculate применяет стратегию скидки.\n\tif r == nil { // Nil-реестр не содержит стратегий.\n\t\treturn 0, ErrUnknownStrategy // Сообщаем об отсутствии стратегии.\n\t}\n\tr.mu.RLock()                   // Берём read-lock для доступа к map.\n\tstrategy := r.strategies[name] // Ищем стратегию по имени.\n\tr.mu.RUnlock()                 // Освобождаем lock.\n\tif strategy == nil {           // Если стратегия не найдена...\n\t\treturn 0, ErrUnknownStrategy // ...возвращаем ошибку ErrUnknownStrategy.\n\t}\n\tresult := strategy(total) // Вычисляем скидку/итог с помощью стратегии.\n\tif result < 0 {           // Итог не должен быть отрицательным.\n\t\tresult = 0 // Ограничиваем минимальным значением 0.\n\t}\n\treturn result, nil // Возвращаем вычисленный итог и nil-ошибку.\n}\n\nfunc (r *StrategyRegistry) Available() []string { // Available возвращает отсортированный список имён стратегий.\n\tif r == nil { // Nil-реестр не содержит стратегий.\n\t\treturn nil // Возвращаем nil/пустой список.\n\t}\n\tr.mu.RLock()                                  // Берём read-lock для копирования ключей.\n\tnames := make([]string, 0, len(r.strategies)) // Предвыделяем срез под имена.\n\tfor name, strategy := range r.strategies {    // Перебираем элементы map.\n\t\tif strategy == nil { // Пропускаем имена без валидной реализации.\n\t\t\tcontinue // Не добавляем их в список.\n\t\t}\n\t\tnames = append(names, name) // Добавляем имя стратегии.\n\t}\n\tr.mu.RUnlock()      // Освобождаем lock.\n\tsort.Strings(names) // Сортируем список для детерминированного вывода.\n\treturn names        // Возвращаем готовый список имён.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- Register ----\n\nfunc TestStrategyRegistryRegisterStoresStrategy(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"flat\", func(total float64) float64 { return total * 0.9 })\n\tval, err := r.Calculate(\"flat\", 100)\n\tif err != nil || val != 90 {\n\t\tt.Fatalf(\"unexpected result: %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryRegisterIgnoresNil(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"nil\", nil)\n\tif _, err := r.Calculate(\"nil\", 10); err != ErrUnknownStrategy {\n\t\tt.Fatalf(\"nil strategy should not be stored\")\n\t}\n}\n\nfunc TestStrategyRegistryRegisterOverrides(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"flat\", func(float64) float64 { return 50 })\n\tr.Register(\"flat\", func(float64) float64 { return 25 })\n\tval, _ := r.Calculate(\"flat\", 100)\n\tif val != 25 {\n\t\tt.Fatalf(\"expected overridden value, got %v\", val)\n\t}\n}\n\n// ---- Calculate ----\n\nfunc TestStrategyRegistryCalculateAppliesStrategy(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"percent\", func(total float64) float64 { return total * 0.5 })\n\tval, err := r.Calculate(\"percent\", 200)\n\tif err != nil || val != 100 {\n\t\tt.Fatalf(\"unexpected result: %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryCalculateClampsNegative(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"bad\", func(total float64) float64 { return -10 })\n\tval, err := r.Calculate(\"bad\", 50)\n\tif err != nil || val != 0 {\n\t\tt.Fatalf(\"expected clamp to zero, got %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryCalculateUnknown(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tif _, err := r.Calculate(\"missing\", 10); err != ErrUnknownStrategy {\n\t\tt.Fatalf(\"expected ErrUnknownStrategy, got %v\", err)\n\t}\n}\n\n// ---- Available ----\n\nfunc TestStrategyRegistryAvailableSorted(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"b\", func(float64) float64 { return 0 })\n\tr.Register(\"a\", func(float64) float64 { return 0 })\n\ttopics := r.Available()\n\tif len(topics) != 2 || topics[0] != \"a\" || topics[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected list: %#v\", topics)\n\t}\n}\n\nfunc TestStrategyRegistryAvailableNilRegistry(t *testing.T) {\n\tvar r *StrategyRegistry\n\tif list := r.Available(); len(list) != 0 {\n\t\tt.Fatalf(\"nil registry should return empty slice\")\n\t}\n}\n\nfunc TestStrategyRegistryAvailableSkipsNilStrategies(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"x\", nil)\n\tif len(r.Available()) != 0 {\n\t\tt.Fatalf(\"nil strategy should not appear in list\")\n\t}\n}\n",
        "tags": [
          "go",
          "strategy",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "strategy",
        "slug": "go-strategy-calculate",
        "title": "Calculate",
        "description": "Task 2 (easy+): Calculate\nПримените стратегию к сумме заказа, вернув ErrUnknownStrategy при отсутствии стратегии.\nПодсказка: защищайте чтение map mutex'ом и не допускайте отрицательных итогов.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of Calculate.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// DiscountStrategy вычисляет скидку для заказа.\ntype DiscountStrategy func(total float64) float64\n\n// ErrUnknownStrategy сигнализирует об отсутствии стратегии.\nvar ErrUnknownStrategy = errors.New(\"strategy not found\")\n\n// StrategyRegistry хранит зарегистрированные стратегии скидок.\ntype StrategyRegistry struct {\n\tmu         sync.RWMutex\n\tstrategies map[string]DiscountStrategy\n}\n\n// Task 1 (easy): Register\n// Зарегистрируйте стратегию по имени, позволяя перезапись существующей.\n// Подсказка: лениво инициализируйте map и игнорируйте nil-стратегии.\nfunc (r *StrategyRegistry) Register(name string, strategy DiscountStrategy) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Calculate\n// Примените стратегию к сумме заказа, вернув ErrUnknownStrategy при отсутствии стратегии.\n// Подсказка: защищайте чтение map mutex'ом и не допускайте отрицательных итогов.\nfunc (r *StrategyRegistry) Calculate(name string, total float64) (float64, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Available\n// Верните отсортированный список имён стратегий.\n// Подсказка: делайте копию ключей под read-lock и сортируйте slice.\nfunc (r *StrategyRegistry) Available() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport \"sort\"\n\nfunc (r *StrategyRegistry) Register(name string, strategy DiscountStrategy) { // Register добавляет стратегию в реестр.\n\tif r == nil || strategy == nil || name == \"\" { // Проверяем входные данные.\n\t\treturn // Ничего не делаем для некорректных аргументов.\n\t}\n\tr.mu.Lock()              // Захватываем mutex для изменения map.\n\tdefer r.mu.Unlock()      // Освобождаем mutex по завершении.\n\tif r.strategies == nil { // Лениво инициализируем карту стратегий.\n\t\tr.strategies = make(map[string]DiscountStrategy) // Создаём map name->strategy.\n\t}\n\tr.strategies[name] = strategy // Сохраняем (либо перезаписываем) стратегию по имени.\n}\n\nfunc (r *StrategyRegistry) Calculate(name string, total float64) (float64, error) { // Calculate применяет стратегию скидки.\n\tif r == nil { // Nil-реестр не содержит стратегий.\n\t\treturn 0, ErrUnknownStrategy // Сообщаем об отсутствии стратегии.\n\t}\n\tr.mu.RLock()                   // Берём read-lock для доступа к map.\n\tstrategy := r.strategies[name] // Ищем стратегию по имени.\n\tr.mu.RUnlock()                 // Освобождаем lock.\n\tif strategy == nil {           // Если стратегия не найдена...\n\t\treturn 0, ErrUnknownStrategy // ...возвращаем ошибку ErrUnknownStrategy.\n\t}\n\tresult := strategy(total) // Вычисляем скидку/итог с помощью стратегии.\n\tif result < 0 {           // Итог не должен быть отрицательным.\n\t\tresult = 0 // Ограничиваем минимальным значением 0.\n\t}\n\treturn result, nil // Возвращаем вычисленный итог и nil-ошибку.\n}\n\nfunc (r *StrategyRegistry) Available() []string { // Available возвращает отсортированный список имён стратегий.\n\tif r == nil { // Nil-реестр не содержит стратегий.\n\t\treturn nil // Возвращаем nil/пустой список.\n\t}\n\tr.mu.RLock()                                  // Берём read-lock для копирования ключей.\n\tnames := make([]string, 0, len(r.strategies)) // Предвыделяем срез под имена.\n\tfor name, strategy := range r.strategies {    // Перебираем элементы map.\n\t\tif strategy == nil { // Пропускаем имена без валидной реализации.\n\t\t\tcontinue // Не добавляем их в список.\n\t\t}\n\t\tnames = append(names, name) // Добавляем имя стратегии.\n\t}\n\tr.mu.RUnlock()      // Освобождаем lock.\n\tsort.Strings(names) // Сортируем список для детерминированного вывода.\n\treturn names        // Возвращаем готовый список имён.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- Register ----\n\nfunc TestStrategyRegistryRegisterStoresStrategy(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"flat\", func(total float64) float64 { return total * 0.9 })\n\tval, err := r.Calculate(\"flat\", 100)\n\tif err != nil || val != 90 {\n\t\tt.Fatalf(\"unexpected result: %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryRegisterIgnoresNil(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"nil\", nil)\n\tif _, err := r.Calculate(\"nil\", 10); err != ErrUnknownStrategy {\n\t\tt.Fatalf(\"nil strategy should not be stored\")\n\t}\n}\n\nfunc TestStrategyRegistryRegisterOverrides(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"flat\", func(float64) float64 { return 50 })\n\tr.Register(\"flat\", func(float64) float64 { return 25 })\n\tval, _ := r.Calculate(\"flat\", 100)\n\tif val != 25 {\n\t\tt.Fatalf(\"expected overridden value, got %v\", val)\n\t}\n}\n\n// ---- Calculate ----\n\nfunc TestStrategyRegistryCalculateAppliesStrategy(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"percent\", func(total float64) float64 { return total * 0.5 })\n\tval, err := r.Calculate(\"percent\", 200)\n\tif err != nil || val != 100 {\n\t\tt.Fatalf(\"unexpected result: %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryCalculateClampsNegative(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"bad\", func(total float64) float64 { return -10 })\n\tval, err := r.Calculate(\"bad\", 50)\n\tif err != nil || val != 0 {\n\t\tt.Fatalf(\"expected clamp to zero, got %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryCalculateUnknown(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tif _, err := r.Calculate(\"missing\", 10); err != ErrUnknownStrategy {\n\t\tt.Fatalf(\"expected ErrUnknownStrategy, got %v\", err)\n\t}\n}\n\n// ---- Available ----\n\nfunc TestStrategyRegistryAvailableSorted(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"b\", func(float64) float64 { return 0 })\n\tr.Register(\"a\", func(float64) float64 { return 0 })\n\ttopics := r.Available()\n\tif len(topics) != 2 || topics[0] != \"a\" || topics[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected list: %#v\", topics)\n\t}\n}\n\nfunc TestStrategyRegistryAvailableNilRegistry(t *testing.T) {\n\tvar r *StrategyRegistry\n\tif list := r.Available(); len(list) != 0 {\n\t\tt.Fatalf(\"nil registry should return empty slice\")\n\t}\n}\n\nfunc TestStrategyRegistryAvailableSkipsNilStrategies(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"x\", nil)\n\tif len(r.Available()) != 0 {\n\t\tt.Fatalf(\"nil strategy should not appear in list\")\n\t}\n}\n",
        "tags": [
          "go",
          "strategy",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "strategy",
        "slug": "go-strategy-available",
        "title": "Available",
        "description": "Task 3 (medium): Available\nВерните отсортированный список имён стратегий.\nПодсказка: делайте копию ключей под read-lock и сортируйте slice.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Available.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport (\n\t\"errors\"\n\t\"sync\"\n)\n\n// DiscountStrategy вычисляет скидку для заказа.\ntype DiscountStrategy func(total float64) float64\n\n// ErrUnknownStrategy сигнализирует об отсутствии стратегии.\nvar ErrUnknownStrategy = errors.New(\"strategy not found\")\n\n// StrategyRegistry хранит зарегистрированные стратегии скидок.\ntype StrategyRegistry struct {\n\tmu         sync.RWMutex\n\tstrategies map[string]DiscountStrategy\n}\n\n// Task 1 (easy): Register\n// Зарегистрируйте стратегию по имени, позволяя перезапись существующей.\n// Подсказка: лениво инициализируйте map и игнорируйте nil-стратегии.\nfunc (r *StrategyRegistry) Register(name string, strategy DiscountStrategy) {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): Calculate\n// Примените стратегию к сумме заказа, вернув ErrUnknownStrategy при отсутствии стратегии.\n// Подсказка: защищайте чтение map mutex'ом и не допускайте отрицательных итогов.\nfunc (r *StrategyRegistry) Calculate(name string, total float64) (float64, error) {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): Available\n// Верните отсортированный список имён стратегий.\n// Подсказка: делайте копию ключей под read-lock и сортируйте slice.\nfunc (r *StrategyRegistry) Available() []string {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport \"sort\"\n\nfunc (r *StrategyRegistry) Register(name string, strategy DiscountStrategy) { // Register добавляет стратегию в реестр.\n\tif r == nil || strategy == nil || name == \"\" { // Проверяем входные данные.\n\t\treturn // Ничего не делаем для некорректных аргументов.\n\t}\n\tr.mu.Lock()              // Захватываем mutex для изменения map.\n\tdefer r.mu.Unlock()      // Освобождаем mutex по завершении.\n\tif r.strategies == nil { // Лениво инициализируем карту стратегий.\n\t\tr.strategies = make(map[string]DiscountStrategy) // Создаём map name->strategy.\n\t}\n\tr.strategies[name] = strategy // Сохраняем (либо перезаписываем) стратегию по имени.\n}\n\nfunc (r *StrategyRegistry) Calculate(name string, total float64) (float64, error) { // Calculate применяет стратегию скидки.\n\tif r == nil { // Nil-реестр не содержит стратегий.\n\t\treturn 0, ErrUnknownStrategy // Сообщаем об отсутствии стратегии.\n\t}\n\tr.mu.RLock()                   // Берём read-lock для доступа к map.\n\tstrategy := r.strategies[name] // Ищем стратегию по имени.\n\tr.mu.RUnlock()                 // Освобождаем lock.\n\tif strategy == nil {           // Если стратегия не найдена...\n\t\treturn 0, ErrUnknownStrategy // ...возвращаем ошибку ErrUnknownStrategy.\n\t}\n\tresult := strategy(total) // Вычисляем скидку/итог с помощью стратегии.\n\tif result < 0 {           // Итог не должен быть отрицательным.\n\t\tresult = 0 // Ограничиваем минимальным значением 0.\n\t}\n\treturn result, nil // Возвращаем вычисленный итог и nil-ошибку.\n}\n\nfunc (r *StrategyRegistry) Available() []string { // Available возвращает отсортированный список имён стратегий.\n\tif r == nil { // Nil-реестр не содержит стратегий.\n\t\treturn nil // Возвращаем nil/пустой список.\n\t}\n\tr.mu.RLock()                                  // Берём read-lock для копирования ключей.\n\tnames := make([]string, 0, len(r.strategies)) // Предвыделяем срез под имена.\n\tfor name, strategy := range r.strategies {    // Перебираем элементы map.\n\t\tif strategy == nil { // Пропускаем имена без валидной реализации.\n\t\t\tcontinue // Не добавляем их в список.\n\t\t}\n\t\tnames = append(names, name) // Добавляем имя стратегии.\n\t}\n\tr.mu.RUnlock()      // Освобождаем lock.\n\tsort.Strings(names) // Сортируем список для детерминированного вывода.\n\treturn names        // Возвращаем готовый список имён.\n}\n",
        "testCode": "package behavioral\n\nimport \"testing\"\n\n// ---- Register ----\n\nfunc TestStrategyRegistryRegisterStoresStrategy(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"flat\", func(total float64) float64 { return total * 0.9 })\n\tval, err := r.Calculate(\"flat\", 100)\n\tif err != nil || val != 90 {\n\t\tt.Fatalf(\"unexpected result: %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryRegisterIgnoresNil(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"nil\", nil)\n\tif _, err := r.Calculate(\"nil\", 10); err != ErrUnknownStrategy {\n\t\tt.Fatalf(\"nil strategy should not be stored\")\n\t}\n}\n\nfunc TestStrategyRegistryRegisterOverrides(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"flat\", func(float64) float64 { return 50 })\n\tr.Register(\"flat\", func(float64) float64 { return 25 })\n\tval, _ := r.Calculate(\"flat\", 100)\n\tif val != 25 {\n\t\tt.Fatalf(\"expected overridden value, got %v\", val)\n\t}\n}\n\n// ---- Calculate ----\n\nfunc TestStrategyRegistryCalculateAppliesStrategy(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"percent\", func(total float64) float64 { return total * 0.5 })\n\tval, err := r.Calculate(\"percent\", 200)\n\tif err != nil || val != 100 {\n\t\tt.Fatalf(\"unexpected result: %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryCalculateClampsNegative(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"bad\", func(total float64) float64 { return -10 })\n\tval, err := r.Calculate(\"bad\", 50)\n\tif err != nil || val != 0 {\n\t\tt.Fatalf(\"expected clamp to zero, got %v err=%v\", val, err)\n\t}\n}\n\nfunc TestStrategyRegistryCalculateUnknown(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tif _, err := r.Calculate(\"missing\", 10); err != ErrUnknownStrategy {\n\t\tt.Fatalf(\"expected ErrUnknownStrategy, got %v\", err)\n\t}\n}\n\n// ---- Available ----\n\nfunc TestStrategyRegistryAvailableSorted(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"b\", func(float64) float64 { return 0 })\n\tr.Register(\"a\", func(float64) float64 { return 0 })\n\ttopics := r.Available()\n\tif len(topics) != 2 || topics[0] != \"a\" || topics[1] != \"b\" {\n\t\tt.Fatalf(\"unexpected list: %#v\", topics)\n\t}\n}\n\nfunc TestStrategyRegistryAvailableNilRegistry(t *testing.T) {\n\tvar r *StrategyRegistry\n\tif list := r.Available(); len(list) != 0 {\n\t\tt.Fatalf(\"nil registry should return empty slice\")\n\t}\n}\n\nfunc TestStrategyRegistryAvailableSkipsNilStrategies(t *testing.T) {\n\tr := &StrategyRegistry{}\n\tr.Register(\"x\", nil)\n\tif len(r.Available()) != 0 {\n\t\tt.Fatalf(\"nil strategy should not appear in list\")\n\t}\n}\n",
        "tags": [
          "go",
          "strategy",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-template_method",
    "tasks": [
      {
        "package": "template_method",
        "slug": "go-template_method-run",
        "title": "Run",
        "description": "Task 1 (medium): Run\nРеализуйте шаблонный метод, который выполняет Prepare -> Render -> Deliver с вызовом hook'ов перед каждым шагом.\nПодсказка: останавливайтесь на первой ошибке и возвращайте промежуточное значение отчёта.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of Run.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"context\"\n\n// ReportTemplate задаёт шаблон генерации отчёта.\ntype ReportTemplate struct {\n\tPrepare func(ctx context.Context) (string, error)\n\tRender  func(ctx context.Context, data string) (string, error)\n\tDeliver func(ctx context.Context, report string) error\n\tHooks   []func(ctx context.Context, stage string) error\n}\n\n// Task 1 (medium): Run\n// Реализуйте шаблонный метод, который выполняет Prepare -> Render -> Deliver с вызовом hook'ов перед каждым шагом.\n// Подсказка: останавливайтесь на первой ошибке и возвращайте промежуточное значение отчёта.\nfunc (t *ReportTemplate) Run(ctx context.Context) (string, error) {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n)\n\nfunc (t *ReportTemplate) Run(ctx context.Context) (string, error) { // Run реализует шаблонный метод Prepare -> Render -> Deliver.\n\tif t == nil { // Nil-шаблон не способен выполнять шаги.\n\t\treturn \"\", errors.New(\"template is nil\") // Сообщаем об ошибке конфигурации.\n\t}\n\tif ctx == nil { // Nil-контекст заменяем на Background.\n\t\tctx = context.Background() // Это позволяет шагам не проверять ctx на nil.\n\t}\n\tif t.Prepare == nil || t.Render == nil || t.Deliver == nil { // Все шаги обязательны.\n\t\treturn \"\", errors.New(\"template steps are not defined\") // Сообщаем об отсутствии реализаций.\n\t}\n\trunHooks := func(stage string) error { // Вспомогательная функция для запуска hook'ов.\n\t\tfor _, hook := range t.Hooks { // Перебираем зарегистрированные hook'и.\n\t\t\tif hook == nil { // Пропускаем пустые функции.\n\t\t\t\tcontinue // Переходим к следующему hook'у.\n\t\t\t}\n\t\t\tif err := hook(ctx, stage); err != nil { // Вызываем hook и проверяем ошибку.\n\t\t\t\treturn err // При ошибке прекращаем выполнение и возвращаем её.\n\t\t\t}\n\t\t}\n\t\treturn nil // Все hook'и завершились успешно.\n\t}\n\tif err := runHooks(\"prepare\"); err != nil { // Запускаем hook'и перед Prepare.\n\t\treturn \"\", err // Ошибка hook'а завершает метод сразу.\n\t}\n\tdata, err := t.Prepare(ctx) // Выполняем шаг Prepare.\n\tif err != nil {             // Ошибка Prepare останавливает процесс.\n\t\treturn \"\", err // Возвращаем ошибку без отчёта.\n\t}\n\tif err := runHooks(\"render\"); err != nil { // Hook'и перед Render.\n\t\treturn data, err // Возвращаем промежуточные данные и ошибку hook'а.\n\t}\n\treport, err := t.Render(ctx, data) // Выполняем шаг Render, получая отчёт.\n\tif err != nil {                    // Ошибка на стадии рендеринга.\n\t\treturn data, err // Возвращаем исходные данные и ошибку.\n\t}\n\tif err := runHooks(\"deliver\"); err != nil { // Hook'и перед Deliver.\n\t\treturn report, err // Возвращаем уже сгенерированный отчёт и ошибку hook'а.\n\t}\n\tif err := t.Deliver(ctx, report); err != nil { // Выполняем доставку отчёта.\n\t\treturn report, err // Возвращаем отчёт и ошибку доставки.\n\t}\n\treturn report, nil // Успешное выполнение возвращает готовый отчёт.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"testing\"\n)\n\n// ---- Run ----\n\nfunc TestReportTemplateRunExecutesAllSteps(t *testing.T) {\n\ttpl := &ReportTemplate{\n\t\tPrepare: func(context.Context) (string, error) { return \"data\", nil },\n\t\tRender:  func(_ context.Context, data string) (string, error) { return data + \"-render\", nil },\n\t\tDeliver: func(_ context.Context, report string) error {\n\t\t\tif report != \"data-render\" {\n\t\t\t\tt.Fatalf(\"unexpected report: %s\", report)\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\tout, err := tpl.Run(context.Background())\n\tif err != nil || out != \"data-render\" {\n\t\tt.Fatalf(\"unexpected result: %s err=%v\", out, err)\n\t}\n}\n\nfunc TestReportTemplateRunHooksBeforeSteps(t *testing.T) {\n\torder := []string{}\n\thook := func(_ context.Context, stage string) error {\n\t\torder = append(order, \"hook:\"+stage)\n\t\treturn nil\n\t}\n\ttpl := &ReportTemplate{\n\t\tPrepare: func(context.Context) (string, error) { order = append(order, \"prepare\"); return \"d\", nil },\n\t\tRender:  func(context.Context, string) (string, error) { order = append(order, \"render\"); return \"r\", nil },\n\t\tDeliver: func(context.Context, string) error { order = append(order, \"deliver\"); return nil },\n\t\tHooks:   []func(context.Context, string) error{hook},\n\t}\n\tif _, err := tpl.Run(context.Background()); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\twant := []string{\"hook:prepare\", \"prepare\", \"hook:render\", \"render\", \"hook:deliver\", \"deliver\"}\n\tif len(order) != len(want) {\n\t\tt.Fatalf(\"unexpected order: %#v\", order)\n\t}\n\tfor i := range want {\n\t\tif order[i] != want[i] {\n\t\t\tt.Fatalf(\"order[%d]=%s want %s\", i, order[i], want[i])\n\t\t}\n\t}\n}\n\nfunc TestReportTemplateRunStopsOnError(t *testing.T) {\n\twant := errors.New(\"boom\")\n\ttpl := &ReportTemplate{\n\t\tPrepare: func(context.Context) (string, error) { return \"\", want },\n\t\tRender:  func(context.Context, string) (string, error) { t.Fatalf(\"should not run render\"); return \"\", nil },\n\t\tDeliver: func(context.Context, string) error { t.Fatalf(\"should not run deliver\"); return nil },\n\t}\n\tif _, err := tpl.Run(context.Background()); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\nfunc TestReportTemplateRunNilTemplate(t *testing.T) {\n\tvar tpl *ReportTemplate\n\tif _, err := tpl.Run(context.Background()); err == nil {\n\t\tt.Fatalf(\"nil template should return error\")\n\t}\n}\n",
        "tags": [
          "go",
          "template_method",
          "patterns",
          "behavioral"
        ],
        "order": 0
      }
    ],
    "category": "patterns"
  },
  {
    "name": "pattern-visitor",
    "tasks": [
      {
        "package": "visitor",
        "slug": "go-visitor-accept",
        "title": "TextNode.Accept",
        "description": "Task 1 (easy): TextNode.Accept\nРеализуйте метод Accept, который вызывает VisitText посетителя.\nПодсказка: проверяйте v на nil и прокидывайте ошибку посетителя.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of TextNode.Accept.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"errors\"\n\n// Visitor определяет операции для разных типов узлов.\ntype Visitor interface {\n\tVisitText(node *TextNode) error\n\tVisitImage(node *ImageNode) error\n}\n\n// Node описывает элемент документа, поддерживающий посетителя.\ntype Node interface {\n\tAccept(v Visitor) error\n}\n\n// TextNode представляет текстовый блок.\ntype TextNode struct {\n\tContent string\n}\n\n// ImageNode представляет изображение.\ntype ImageNode struct {\n\tURL string\n\tAlt string\n}\n\n// ErrNilVisitor возвращается, если Accept вызван с nil-посетителем.\nvar ErrNilVisitor = errors.New(\"visitor is nil\")\n\n// Task 1 (easy): TextNode.Accept\n// Реализуйте метод Accept, который вызывает VisitText посетителя.\n// Подсказка: проверяйте v на nil и прокидывайте ошибку посетителя.\nfunc (n *TextNode) Accept(v Visitor) error {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): ImageNode.Accept\n// Реализуйте Accept для изображений, вызывая VisitImage.\n// Подсказка: возвращайте ErrNilVisitor при отсутствии посетителя.\nfunc (n *ImageNode) Accept(v Visitor) error {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): WalkDocument\n// Обойдите набор узлов и вызовите Accept для каждого, останавливаясь на первой ошибке.\n// Подсказка: пропускайте nil-узлы и возвращайте ErrNilVisitor, если visitor nil.\nfunc WalkDocument(nodes []Node, visitor Visitor) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (n *TextNode) Accept(v Visitor) error { // Accept у TextNode передаёт узел посетителю.\n\tif v == nil { // Посетитель обязателен для обработки узла.\n\t\treturn ErrNilVisitor // Сообщаем о некорректном вызове.\n\t}\n\tif n == nil { // Nil-узел не требует обработки.\n\t\treturn nil // Возвращаем успешный результат.\n\t}\n\treturn v.VisitText(n) // Делегируем работу посетителю.\n}\n\nfunc (n *ImageNode) Accept(v Visitor) error { // Accept у ImageNode передаёт узел посетителю.\n\tif v == nil { // Проверяем, что посетитель существует.\n\t\treturn ErrNilVisitor // Сообщаем об ошибке конфигурации.\n\t}\n\tif n == nil { // Nil-узел игнорируем.\n\t\treturn nil // Ничего не делаем.\n\t}\n\treturn v.VisitImage(n) // Передаём управление посетителю.\n}\n\nfunc WalkDocument(nodes []Node, visitor Visitor) error { // WalkDocument обходит узлы документа.\n\tif visitor == nil { // Без посетителя обход не имеет смысла.\n\t\treturn ErrNilVisitor // Сообщаем об ошибке.\n\t}\n\tfor _, node := range nodes { // Перебираем все узлы документа.\n\t\tif node == nil { // Пропускаем отсутствующие узлы.\n\t\t\tcontinue // Переходим к следующему.\n\t\t}\n\t\tif err := node.Accept(visitor); err != nil { // Вызываем Accept и проверяем ошибку.\n\t\t\treturn err // Останавливаем обход на первой ошибке.\n\t\t}\n\t}\n\treturn nil // Все узлы успешно обработаны.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"testing\"\n)\n\ntype recordingVisitor struct {\n\ttexts  []string\n\timages []string\n\terr    error\n}\n\nfunc (v *recordingVisitor) VisitText(node *TextNode) error {\n\tif v.err != nil {\n\t\treturn v.err\n\t}\n\tv.texts = append(v.texts, node.Content)\n\treturn nil\n}\n\nfunc (v *recordingVisitor) VisitImage(node *ImageNode) error {\n\tif v.err != nil {\n\t\treturn v.err\n\t}\n\tv.images = append(v.images, node.URL)\n\treturn nil\n}\n\n// ---- TextNode.Accept ----\n\nfunc TestTextNodeAcceptCallsVisitor(t *testing.T) {\n\tnode := &TextNode{Content: \"hello\"}\n\tvis := &recordingVisitor{}\n\tif err := node.Accept(vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.texts) != 1 || vis.texts[0] != \"hello\" {\n\t\tt.Fatalf(\"visitor not invoked: %#v\", vis.texts)\n\t}\n}\n\nfunc TestTextNodeAcceptNilVisitor(t *testing.T) {\n\tnode := &TextNode{}\n\tif err := node.Accept(nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n\nfunc TestTextNodeAcceptPropagatesError(t *testing.T) {\n\tnode := &TextNode{}\n\twant := errors.New(\"boom\")\n\tvis := &recordingVisitor{err: want}\n\tif err := node.Accept(vis); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\n// ---- ImageNode.Accept ----\n\nfunc TestImageNodeAcceptCallsVisitor(t *testing.T) {\n\tnode := &ImageNode{URL: \"logo.png\"}\n\tvis := &recordingVisitor{}\n\tif err := node.Accept(vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.images) != 1 || vis.images[0] != \"logo.png\" {\n\t\tt.Fatalf(\"visitor not invoked: %#v\", vis.images)\n\t}\n}\n\nfunc TestImageNodeAcceptNilVisitor(t *testing.T) {\n\tnode := &ImageNode{}\n\tif err := node.Accept(nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n\nfunc TestImageNodeAcceptPropagatesError(t *testing.T) {\n\tnode := &ImageNode{}\n\twant := errors.New(\"oops\")\n\tvis := &recordingVisitor{err: want}\n\tif err := node.Accept(vis); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\n// ---- WalkDocument ----\n\nfunc TestWalkDocumentVisitsAllNodes(t *testing.T) {\n\tnodes := []Node{&TextNode{Content: \"a\"}, &ImageNode{URL: \"img\"}}\n\tvis := &recordingVisitor{}\n\tif err := WalkDocument(nodes, vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.texts) != 1 || len(vis.images) != 1 {\n\t\tt.Fatalf(\"visitor not applied to all nodes\")\n\t}\n}\n\nfunc TestWalkDocumentStopsOnError(t *testing.T) {\n\tnodes := []Node{&TextNode{Content: \"a\"}, &TextNode{Content: \"b\"}}\n\tvis := &recordingVisitor{err: errors.New(\"boom\")}\n\tif err := WalkDocument(nodes, vis); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestWalkDocumentNilNodesAndVisitor(t *testing.T) {\n\tif err := WalkDocument([]Node{nil}, nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "visitor",
          "patterns",
          "behavioral"
        ],
        "order": 0
      },
      {
        "package": "visitor",
        "slug": "go-visitor-accept",
        "title": "ImageNode.Accept",
        "description": "Task 2 (easy+): ImageNode.Accept\nРеализуйте Accept для изображений, вызывая VisitImage.\nПодсказка: возвращайте ErrNilVisitor при отсутствии посетителя.",
        "difficulty": "easy",
        "hint1": "Think about the core concept of ImageNode.Accept.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"errors\"\n\n// Visitor определяет операции для разных типов узлов.\ntype Visitor interface {\n\tVisitText(node *TextNode) error\n\tVisitImage(node *ImageNode) error\n}\n\n// Node описывает элемент документа, поддерживающий посетителя.\ntype Node interface {\n\tAccept(v Visitor) error\n}\n\n// TextNode представляет текстовый блок.\ntype TextNode struct {\n\tContent string\n}\n\n// ImageNode представляет изображение.\ntype ImageNode struct {\n\tURL string\n\tAlt string\n}\n\n// ErrNilVisitor возвращается, если Accept вызван с nil-посетителем.\nvar ErrNilVisitor = errors.New(\"visitor is nil\")\n\n// Task 1 (easy): TextNode.Accept\n// Реализуйте метод Accept, который вызывает VisitText посетителя.\n// Подсказка: проверяйте v на nil и прокидывайте ошибку посетителя.\nfunc (n *TextNode) Accept(v Visitor) error {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): ImageNode.Accept\n// Реализуйте Accept для изображений, вызывая VisitImage.\n// Подсказка: возвращайте ErrNilVisitor при отсутствии посетителя.\nfunc (n *ImageNode) Accept(v Visitor) error {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): WalkDocument\n// Обойдите набор узлов и вызовите Accept для каждого, останавливаясь на первой ошибке.\n// Подсказка: пропускайте nil-узлы и возвращайте ErrNilVisitor, если visitor nil.\nfunc WalkDocument(nodes []Node, visitor Visitor) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (n *TextNode) Accept(v Visitor) error { // Accept у TextNode передаёт узел посетителю.\n\tif v == nil { // Посетитель обязателен для обработки узла.\n\t\treturn ErrNilVisitor // Сообщаем о некорректном вызове.\n\t}\n\tif n == nil { // Nil-узел не требует обработки.\n\t\treturn nil // Возвращаем успешный результат.\n\t}\n\treturn v.VisitText(n) // Делегируем работу посетителю.\n}\n\nfunc (n *ImageNode) Accept(v Visitor) error { // Accept у ImageNode передаёт узел посетителю.\n\tif v == nil { // Проверяем, что посетитель существует.\n\t\treturn ErrNilVisitor // Сообщаем об ошибке конфигурации.\n\t}\n\tif n == nil { // Nil-узел игнорируем.\n\t\treturn nil // Ничего не делаем.\n\t}\n\treturn v.VisitImage(n) // Передаём управление посетителю.\n}\n\nfunc WalkDocument(nodes []Node, visitor Visitor) error { // WalkDocument обходит узлы документа.\n\tif visitor == nil { // Без посетителя обход не имеет смысла.\n\t\treturn ErrNilVisitor // Сообщаем об ошибке.\n\t}\n\tfor _, node := range nodes { // Перебираем все узлы документа.\n\t\tif node == nil { // Пропускаем отсутствующие узлы.\n\t\t\tcontinue // Переходим к следующему.\n\t\t}\n\t\tif err := node.Accept(visitor); err != nil { // Вызываем Accept и проверяем ошибку.\n\t\t\treturn err // Останавливаем обход на первой ошибке.\n\t\t}\n\t}\n\treturn nil // Все узлы успешно обработаны.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"testing\"\n)\n\ntype recordingVisitor struct {\n\ttexts  []string\n\timages []string\n\terr    error\n}\n\nfunc (v *recordingVisitor) VisitText(node *TextNode) error {\n\tif v.err != nil {\n\t\treturn v.err\n\t}\n\tv.texts = append(v.texts, node.Content)\n\treturn nil\n}\n\nfunc (v *recordingVisitor) VisitImage(node *ImageNode) error {\n\tif v.err != nil {\n\t\treturn v.err\n\t}\n\tv.images = append(v.images, node.URL)\n\treturn nil\n}\n\n// ---- TextNode.Accept ----\n\nfunc TestTextNodeAcceptCallsVisitor(t *testing.T) {\n\tnode := &TextNode{Content: \"hello\"}\n\tvis := &recordingVisitor{}\n\tif err := node.Accept(vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.texts) != 1 || vis.texts[0] != \"hello\" {\n\t\tt.Fatalf(\"visitor not invoked: %#v\", vis.texts)\n\t}\n}\n\nfunc TestTextNodeAcceptNilVisitor(t *testing.T) {\n\tnode := &TextNode{}\n\tif err := node.Accept(nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n\nfunc TestTextNodeAcceptPropagatesError(t *testing.T) {\n\tnode := &TextNode{}\n\twant := errors.New(\"boom\")\n\tvis := &recordingVisitor{err: want}\n\tif err := node.Accept(vis); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\n// ---- ImageNode.Accept ----\n\nfunc TestImageNodeAcceptCallsVisitor(t *testing.T) {\n\tnode := &ImageNode{URL: \"logo.png\"}\n\tvis := &recordingVisitor{}\n\tif err := node.Accept(vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.images) != 1 || vis.images[0] != \"logo.png\" {\n\t\tt.Fatalf(\"visitor not invoked: %#v\", vis.images)\n\t}\n}\n\nfunc TestImageNodeAcceptNilVisitor(t *testing.T) {\n\tnode := &ImageNode{}\n\tif err := node.Accept(nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n\nfunc TestImageNodeAcceptPropagatesError(t *testing.T) {\n\tnode := &ImageNode{}\n\twant := errors.New(\"oops\")\n\tvis := &recordingVisitor{err: want}\n\tif err := node.Accept(vis); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\n// ---- WalkDocument ----\n\nfunc TestWalkDocumentVisitsAllNodes(t *testing.T) {\n\tnodes := []Node{&TextNode{Content: \"a\"}, &ImageNode{URL: \"img\"}}\n\tvis := &recordingVisitor{}\n\tif err := WalkDocument(nodes, vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.texts) != 1 || len(vis.images) != 1 {\n\t\tt.Fatalf(\"visitor not applied to all nodes\")\n\t}\n}\n\nfunc TestWalkDocumentStopsOnError(t *testing.T) {\n\tnodes := []Node{&TextNode{Content: \"a\"}, &TextNode{Content: \"b\"}}\n\tvis := &recordingVisitor{err: errors.New(\"boom\")}\n\tif err := WalkDocument(nodes, vis); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestWalkDocumentNilNodesAndVisitor(t *testing.T) {\n\tif err := WalkDocument([]Node{nil}, nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "visitor",
          "patterns",
          "behavioral"
        ],
        "order": 1
      },
      {
        "package": "visitor",
        "slug": "go-visitor-walkdocument",
        "title": "WalkDocument",
        "description": "Task 3 (medium): WalkDocument\nОбойдите набор узлов и вызовите Accept для каждого, останавливаясь на первой ошибке.\nПодсказка: пропускайте nil-узлы и возвращайте ErrNilVisitor, если visitor nil.",
        "difficulty": "medium",
        "hint1": "Think about the core concept of WalkDocument.",
        "hint2": "Check the function signature for expected behavior.",
        "initialCode": "//go:build !solution\n\npackage behavioral\n\nimport \"errors\"\n\n// Visitor определяет операции для разных типов узлов.\ntype Visitor interface {\n\tVisitText(node *TextNode) error\n\tVisitImage(node *ImageNode) error\n}\n\n// Node описывает элемент документа, поддерживающий посетителя.\ntype Node interface {\n\tAccept(v Visitor) error\n}\n\n// TextNode представляет текстовый блок.\ntype TextNode struct {\n\tContent string\n}\n\n// ImageNode представляет изображение.\ntype ImageNode struct {\n\tURL string\n\tAlt string\n}\n\n// ErrNilVisitor возвращается, если Accept вызван с nil-посетителем.\nvar ErrNilVisitor = errors.New(\"visitor is nil\")\n\n// Task 1 (easy): TextNode.Accept\n// Реализуйте метод Accept, который вызывает VisitText посетителя.\n// Подсказка: проверяйте v на nil и прокидывайте ошибку посетителя.\nfunc (n *TextNode) Accept(v Visitor) error {\n\tpanic(\"TODO\")\n}\n\n// Task 2 (easy+): ImageNode.Accept\n// Реализуйте Accept для изображений, вызывая VisitImage.\n// Подсказка: возвращайте ErrNilVisitor при отсутствии посетителя.\nfunc (n *ImageNode) Accept(v Visitor) error {\n\tpanic(\"TODO\")\n}\n\n// Task 3 (medium): WalkDocument\n// Обойдите набор узлов и вызовите Accept для каждого, останавливаясь на первой ошибке.\n// Подсказка: пропускайте nil-узлы и возвращайте ErrNilVisitor, если visitor nil.\nfunc WalkDocument(nodes []Node, visitor Visitor) error {\n\tpanic(\"TODO\")\n}\n",
        "solutionCode": "//go:build solution\n\npackage behavioral\n\nfunc (n *TextNode) Accept(v Visitor) error { // Accept у TextNode передаёт узел посетителю.\n\tif v == nil { // Посетитель обязателен для обработки узла.\n\t\treturn ErrNilVisitor // Сообщаем о некорректном вызове.\n\t}\n\tif n == nil { // Nil-узел не требует обработки.\n\t\treturn nil // Возвращаем успешный результат.\n\t}\n\treturn v.VisitText(n) // Делегируем работу посетителю.\n}\n\nfunc (n *ImageNode) Accept(v Visitor) error { // Accept у ImageNode передаёт узел посетителю.\n\tif v == nil { // Проверяем, что посетитель существует.\n\t\treturn ErrNilVisitor // Сообщаем об ошибке конфигурации.\n\t}\n\tif n == nil { // Nil-узел игнорируем.\n\t\treturn nil // Ничего не делаем.\n\t}\n\treturn v.VisitImage(n) // Передаём управление посетителю.\n}\n\nfunc WalkDocument(nodes []Node, visitor Visitor) error { // WalkDocument обходит узлы документа.\n\tif visitor == nil { // Без посетителя обход не имеет смысла.\n\t\treturn ErrNilVisitor // Сообщаем об ошибке.\n\t}\n\tfor _, node := range nodes { // Перебираем все узлы документа.\n\t\tif node == nil { // Пропускаем отсутствующие узлы.\n\t\t\tcontinue // Переходим к следующему.\n\t\t}\n\t\tif err := node.Accept(visitor); err != nil { // Вызываем Accept и проверяем ошибку.\n\t\t\treturn err // Останавливаем обход на первой ошибке.\n\t\t}\n\t}\n\treturn nil // Все узлы успешно обработаны.\n}\n",
        "testCode": "package behavioral\n\nimport (\n\t\"errors\"\n\t\"testing\"\n)\n\ntype recordingVisitor struct {\n\ttexts  []string\n\timages []string\n\terr    error\n}\n\nfunc (v *recordingVisitor) VisitText(node *TextNode) error {\n\tif v.err != nil {\n\t\treturn v.err\n\t}\n\tv.texts = append(v.texts, node.Content)\n\treturn nil\n}\n\nfunc (v *recordingVisitor) VisitImage(node *ImageNode) error {\n\tif v.err != nil {\n\t\treturn v.err\n\t}\n\tv.images = append(v.images, node.URL)\n\treturn nil\n}\n\n// ---- TextNode.Accept ----\n\nfunc TestTextNodeAcceptCallsVisitor(t *testing.T) {\n\tnode := &TextNode{Content: \"hello\"}\n\tvis := &recordingVisitor{}\n\tif err := node.Accept(vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.texts) != 1 || vis.texts[0] != \"hello\" {\n\t\tt.Fatalf(\"visitor not invoked: %#v\", vis.texts)\n\t}\n}\n\nfunc TestTextNodeAcceptNilVisitor(t *testing.T) {\n\tnode := &TextNode{}\n\tif err := node.Accept(nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n\nfunc TestTextNodeAcceptPropagatesError(t *testing.T) {\n\tnode := &TextNode{}\n\twant := errors.New(\"boom\")\n\tvis := &recordingVisitor{err: want}\n\tif err := node.Accept(vis); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\n// ---- ImageNode.Accept ----\n\nfunc TestImageNodeAcceptCallsVisitor(t *testing.T) {\n\tnode := &ImageNode{URL: \"logo.png\"}\n\tvis := &recordingVisitor{}\n\tif err := node.Accept(vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.images) != 1 || vis.images[0] != \"logo.png\" {\n\t\tt.Fatalf(\"visitor not invoked: %#v\", vis.images)\n\t}\n}\n\nfunc TestImageNodeAcceptNilVisitor(t *testing.T) {\n\tnode := &ImageNode{}\n\tif err := node.Accept(nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n\nfunc TestImageNodeAcceptPropagatesError(t *testing.T) {\n\tnode := &ImageNode{}\n\twant := errors.New(\"oops\")\n\tvis := &recordingVisitor{err: want}\n\tif err := node.Accept(vis); !errors.Is(err, want) {\n\t\tt.Fatalf(\"expected %v got %v\", want, err)\n\t}\n}\n\n// ---- WalkDocument ----\n\nfunc TestWalkDocumentVisitsAllNodes(t *testing.T) {\n\tnodes := []Node{&TextNode{Content: \"a\"}, &ImageNode{URL: \"img\"}}\n\tvis := &recordingVisitor{}\n\tif err := WalkDocument(nodes, vis); err != nil {\n\t\tt.Fatalf(\"unexpected err: %v\", err)\n\t}\n\tif len(vis.texts) != 1 || len(vis.images) != 1 {\n\t\tt.Fatalf(\"visitor not applied to all nodes\")\n\t}\n}\n\nfunc TestWalkDocumentStopsOnError(t *testing.T) {\n\tnodes := []Node{&TextNode{Content: \"a\"}, &TextNode{Content: \"b\"}}\n\tvis := &recordingVisitor{err: errors.New(\"boom\")}\n\tif err := WalkDocument(nodes, vis); err == nil {\n\t\tt.Fatalf(\"expected error\")\n\t}\n}\n\nfunc TestWalkDocumentNilNodesAndVisitor(t *testing.T) {\n\tif err := WalkDocument([]Node{nil}, nil); !errors.Is(err, ErrNilVisitor) {\n\t\tt.Fatalf(\"expected ErrNilVisitor, got %v\", err)\n\t}\n}\n",
        "tags": [
          "go",
          "visitor",
          "patterns",
          "behavioral"
        ],
        "order": 2
      }
    ],
    "category": "patterns"
  }
]